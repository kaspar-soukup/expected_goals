{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba190db",
   "metadata": {
    "id": "4ba190db"
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133e8d59",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1764598320594,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "133e8d59"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import ast\n",
    "import math\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import sklearn.isotonic as sk_i\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea16aa4",
   "metadata": {
    "id": "2ea16aa4"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6SMrbzowm2VT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31226,
     "status": "ok",
     "timestamp": 1764598351832,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "6SMrbzowm2VT",
    "outputId": "e9044ba9-076a-40d7-b567-d1f2514dc59f"
   },
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "RAW_DIR = DATA_DIR / \"raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df62e30",
   "metadata": {
    "executionInfo": {
     "elapsed": 8693,
     "status": "ok",
     "timestamp": 1764598360528,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "4df62e30"
   },
   "outputs": [],
   "source": [
    "football_df = pd.read_pickle(PROCESSED_DIR / \"football_processed.pickle\")\n",
    "football_model_df = pd.read_pickle(PROCESSED_DIR / \"football_model_processed.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985d459",
   "metadata": {
    "id": "0985d459"
   },
   "source": [
    "# Looking at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a635472",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1764598360544,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "8a635472",
    "outputId": "411cfd5f-d9e1-41ee-f4e8-c0420e758dc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['under_pressure', 'shot_open_goal', 'shot_first_time',\n",
       "       'shot_one_on_one', 'shot_outcome_encoded', 'player_x', 'player_y',\n",
       "       'distance_from_goal_center', 'distance_from_goal_left_post',\n",
       "       'distance_from_goal_right_post', 'body_part_head', 'body_part_other',\n",
       "       'body_part_foot', 'shot_technique_backheel',\n",
       "       'shot_technique_diving_header', 'shot_technique_half_volley',\n",
       "       'shot_technique_lob', 'shot_technique_normal',\n",
       "       'shot_technique_overhead_kick', 'shot_technique_volley',\n",
       "       'play_pattern_from_corner', 'play_pattern_from_counter',\n",
       "       'play_pattern_from_free_kick', 'play_pattern_from_goal_kick',\n",
       "       'play_pattern_from_keeper', 'play_pattern_from_kick_off',\n",
       "       'play_pattern_from_throw_in', 'play_pattern_other',\n",
       "       'play_pattern_regular_play', 'shot_type_free_kick',\n",
       "       'shot_type_open_play', 'goalkeeper_x', 'goalkeeper_y',\n",
       "       'gk_distance_from_goal_center', 'gk_distance_from_goal_left_post',\n",
       "       'gk_distance_from_goal_right_post', 'shot_angle', 'distance_player_gk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "football_model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8178d6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2769,
     "status": "ok",
     "timestamp": 1764598363314,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "c8178d6f",
    "outputId": "e51b6636-08dc-43cd-fafa-5c0f85b02580"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 12))  # increase figure size\n",
    "sns.heatmap(football_model_df.corr(), annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d05b33",
   "metadata": {
    "id": "82d05b33"
   },
   "source": [
    "# Preparing Data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125e8733",
   "metadata": {
    "id": "125e8733"
   },
   "source": [
    "Splitting train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df5f83e",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1764598363330,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "9df5f83e"
   },
   "outputs": [],
   "source": [
    "X = football_model_df.drop(\"shot_outcome_encoded\", axis = 1)\n",
    "y = football_model_df[\"shot_outcome_encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1751dd9",
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1764598384210,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "b1751dd9"
   },
   "outputs": [],
   "source": [
    "# setting a seed\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# splitting the data\n",
    "train_x, test_x , train_y, test_y = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.25,\n",
    "    random_state= 123,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Mtm5jifSmwde",
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1764598388320,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "Mtm5jifSmwde"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = tf.convert_to_tensor(train_x, dtype=tf.float32), tf.convert_to_tensor(train_y, dtype=tf.float32)\n",
    "test_x, test_y = tf.convert_to_tensor(test_x, dtype=tf.float32), tf.convert_to_tensor(test_y, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aa2fa6",
   "metadata": {
    "id": "91aa2fa6"
   },
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-87hAuFrDlr8",
   "metadata": {
    "id": "-87hAuFrDlr8"
   },
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d253ea",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1764598388322,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "56d253ea"
   },
   "outputs": [],
   "source": [
    "def build_model(hl: int = 1, nodes: int = 32, activation: str = 'relu', epochs: int = 5, batches: int = 100):\n",
    "\n",
    "    # initiating model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # adding input layer\n",
    "    model.add(Input(shape=(37,), name = \"Input_Layer\")) # 37 input columns\n",
    "\n",
    "    # adding hidden layers\n",
    "    for i in range(hl):\n",
    "        model.add(Dense(units = nodes, activation = activation, name = f\"HL_{i+1}\"))\n",
    "\n",
    "    # add output layer\n",
    "    model.add(Dense(units = 1, activation = \"sigmoid\", name = \"Output_Layer\"))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"binary_accuracy\", tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "189d9dad",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1764598390008,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "189d9dad"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(hl: int = 1,\n",
    "                             nodes: int = 32,\n",
    "                             activation: str = 'relu',\n",
    "                             epochs: int = 5,\n",
    "                             batches: int = 100,\n",
    "                             train_x = train_x,\n",
    "                             train_y = train_y,\n",
    "                             test_x = test_x,\n",
    "                             test_y = test_y\n",
    "                             ):\n",
    "\n",
    "    model = build_model(hl, nodes, activation, epochs, batches)\n",
    "\n",
    "    # training the model\n",
    "    history = model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        epochs = epochs,\n",
    "        batch_size = batches,\n",
    "        validation_data = (test_x, test_y),\n",
    "        verbose = 1\n",
    "    )\n",
    "\n",
    "    # getting accuracies\n",
    "    eval_accuracies = model.evaluate(test_x, test_y)\n",
    "\n",
    "    return model, history, eval_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "XvGeXqOLDr-k",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1764598391336,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "XvGeXqOLDr-k"
   },
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(hl: int = 1,\n",
    "                            nodes: int = 32,\n",
    "                            activation: str = 'relu',\n",
    "                            epochs: int = 5,\n",
    "                            batches: int = 100,\n",
    "                            k: int = 5,\n",
    "                            train_x = train_x,\n",
    "                            train_y = train_y\n",
    "                            ):\n",
    "\n",
    "    # set seed\n",
    "    seed = 123\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # Initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Create empty lists to store metrics from each fold\n",
    "    fold_losses = []\n",
    "    fold_accuracies = []\n",
    "    fold_aucs = []\n",
    "\n",
    "    # Convert train_x and train_y to numpy for StratifiedKFold\n",
    "    train_x_np = train_x.numpy()\n",
    "    train_y_np = train_y.numpy()\n",
    "\n",
    "    # Loop through the splits\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(train_x_np, train_y_np)):\n",
    "        print(f\"\\n--- Starting Fold {fold+1}/{k} ---\")\n",
    "\n",
    "        # Create training and validation datasets for the current fold\n",
    "        fold_train_x = train_x_np[train_index]\n",
    "        fold_train_y = train_y_np[train_index]\n",
    "        fold_val_x = train_x_np[val_index]\n",
    "        fold_val_y = train_y_np[val_index]\n",
    "\n",
    "        # Convert to TensorFlow tensors\n",
    "        fold_train_x = tf.convert_to_tensor(fold_train_x, dtype=tf.float32)\n",
    "        fold_train_y = tf.convert_to_tensor(fold_train_y, dtype=tf.float32)\n",
    "        fold_val_x = tf.convert_to_tensor(fold_val_x, dtype=tf.float32)\n",
    "        fold_val_y = tf.convert_to_tensor(fold_val_y, dtype=tf.float32)\n",
    "\n",
    "        # Train and evaluate the model for the current fold\n",
    "        model, history, eval_accuracies = train_and_evaluate_model(\n",
    "            hl=hl,\n",
    "            nodes=nodes,\n",
    "            activation=activation,\n",
    "            epochs=epochs,\n",
    "            batches=batches,\n",
    "            train_x=fold_train_x,\n",
    "            train_y=fold_train_y,\n",
    "            test_x=fold_val_x,\n",
    "            test_y=fold_val_y\n",
    "        )\n",
    "\n",
    "        # eval_accuracies contains [loss, binary_accuracy, auc]\n",
    "        fold_losses.append(eval_accuracies[0])\n",
    "        fold_accuracies.append(eval_accuracies[1])\n",
    "        fold_aucs.append(eval_accuracies[2])\n",
    "\n",
    "        print(f\"Fold {fold+1} Metrics: Loss = {eval_accuracies[0]:.4f}, Accuracy = {eval_accuracies[1]:.4f}, AUC = {eval_accuracies[2]:.4f}\")\n",
    "\n",
    "    print(\"\\n--- K-Fold Cross-Validation Complete ---\")\n",
    "    print(f\"Average Loss: {np.mean(fold_losses):.4f}\")\n",
    "    print(f\"Average Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
    "    print(f\"Average AUC: {np.mean(fold_aucs):.4f}\")\n",
    "\n",
    "    return fold_losses, fold_accuracies, fold_aucs, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4BBxgx0XgUrf",
   "metadata": {
    "id": "4BBxgx0XgUrf"
   },
   "source": [
    "# Looking at Training results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XIXijxpkDoEN",
   "metadata": {
    "id": "XIXijxpkDoEN"
   },
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "FD-pBaOOGhGY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1785957,
     "status": "ok",
     "timestamp": 1764608414036,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "FD-pBaOOGhGY",
    "outputId": "263c70df-0c15-4a58-f2f4-190631a56439"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Performing training for: ('relu', 1, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6250 - binary_accuracy: 0.7419 - loss: 2.9174 - val_auc: 0.7233 - val_binary_accuracy: 0.9023 - val_loss: 0.2893\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7684 - binary_accuracy: 0.8985 - loss: 0.2768 - val_auc: 0.7710 - val_binary_accuracy: 0.9034 - val_loss: 0.2737\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7898 - binary_accuracy: 0.9029 - loss: 0.2642 - val_auc: 0.7802 - val_binary_accuracy: 0.9062 - val_loss: 0.2763\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7945 - binary_accuracy: 0.9060 - loss: 0.2605 - val_auc: 0.7825 - val_binary_accuracy: 0.9068 - val_loss: 0.2724\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7973 - binary_accuracy: 0.9079 - loss: 0.2581 - val_auc: 0.7835 - val_binary_accuracy: 0.9072 - val_loss: 0.2663\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7994 - binary_accuracy: 0.9098 - loss: 0.2565 - val_auc: 0.7842 - val_binary_accuracy: 0.9066 - val_loss: 0.2645\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9096 - loss: 0.2557 - val_auc: 0.7851 - val_binary_accuracy: 0.9069 - val_loss: 0.2665\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9101 - loss: 0.2554 - val_auc: 0.7856 - val_binary_accuracy: 0.9054 - val_loss: 0.2695\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9103 - loss: 0.2554 - val_auc: 0.7869 - val_binary_accuracy: 0.9056 - val_loss: 0.2700\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7983 - binary_accuracy: 0.9108 - loss: 0.2551 - val_auc: 0.7872 - val_binary_accuracy: 0.9059 - val_loss: 0.2692\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7845 - binary_accuracy: 0.9087 - loss: 0.2646\n",
      "Fold 1 Metrics: Loss = 0.2692, Accuracy = 0.9059, AUC = 0.7872\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6458 - binary_accuracy: 0.7401 - loss: 1.6699 - val_auc: 0.7206 - val_binary_accuracy: 0.9065 - val_loss: 0.2979\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7412 - binary_accuracy: 0.9039 - loss: 0.2875 - val_auc: 0.7840 - val_binary_accuracy: 0.9081 - val_loss: 0.2675\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7819 - binary_accuracy: 0.9047 - loss: 0.2712 - val_auc: 0.7983 - val_binary_accuracy: 0.9096 - val_loss: 0.2613\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9052 - loss: 0.2674 - val_auc: 0.8031 - val_binary_accuracy: 0.9100 - val_loss: 0.2587\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7932 - binary_accuracy: 0.9062 - loss: 0.2653 - val_auc: 0.8059 - val_binary_accuracy: 0.9102 - val_loss: 0.2570\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7953 - binary_accuracy: 0.9070 - loss: 0.2639 - val_auc: 0.8074 - val_binary_accuracy: 0.9099 - val_loss: 0.2561\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7970 - binary_accuracy: 0.9073 - loss: 0.2630 - val_auc: 0.8096 - val_binary_accuracy: 0.9099 - val_loss: 0.2554\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9079 - loss: 0.2624 - val_auc: 0.8112 - val_binary_accuracy: 0.9099 - val_loss: 0.2546\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9081 - loss: 0.2619 - val_auc: 0.8117 - val_binary_accuracy: 0.9104 - val_loss: 0.2538\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8123 - val_binary_accuracy: 0.9104 - val_loss: 0.2533\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8149 - binary_accuracy: 0.9138 - loss: 0.2448\n",
      "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9104, AUC = 0.8123\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6087 - binary_accuracy: 0.8443 - loss: 0.4981 - val_auc: 0.7668 - val_binary_accuracy: 0.9063 - val_loss: 0.2722\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7682 - binary_accuracy: 0.9075 - loss: 0.2699 - val_auc: 0.7957 - val_binary_accuracy: 0.9071 - val_loss: 0.2641\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9079 - loss: 0.2636 - val_auc: 0.7999 - val_binary_accuracy: 0.9081 - val_loss: 0.2622\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9076 - loss: 0.2630 - val_auc: 0.8021 - val_binary_accuracy: 0.9093 - val_loss: 0.2608\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9084 - loss: 0.2627 - val_auc: 0.8034 - val_binary_accuracy: 0.9103 - val_loss: 0.2592\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7858 - binary_accuracy: 0.9091 - loss: 0.2625 - val_auc: 0.8041 - val_binary_accuracy: 0.9109 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9094 - loss: 0.2622 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2577\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9096 - loss: 0.2619 - val_auc: 0.8062 - val_binary_accuracy: 0.9110 - val_loss: 0.2572\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8057 - val_binary_accuracy: 0.9110 - val_loss: 0.2570\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9097 - loss: 0.2615 - val_auc: 0.8063 - val_binary_accuracy: 0.9110 - val_loss: 0.2568\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7996 - binary_accuracy: 0.9131 - loss: 0.2566\n",
      "Fold 3 Metrics: Loss = 0.2568, Accuracy = 0.9110, AUC = 0.8063\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6235 - binary_accuracy: 0.8994 - loss: 0.3500 - val_auc: 0.7747 - val_binary_accuracy: 0.9039 - val_loss: 0.2720\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7676 - binary_accuracy: 0.9040 - loss: 0.2741 - val_auc: 0.7865 - val_binary_accuracy: 0.9050 - val_loss: 0.2661\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7771 - binary_accuracy: 0.9056 - loss: 0.2696 - val_auc: 0.7906 - val_binary_accuracy: 0.9060 - val_loss: 0.2636\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7811 - binary_accuracy: 0.9065 - loss: 0.2672 - val_auc: 0.7939 - val_binary_accuracy: 0.9084 - val_loss: 0.2617\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7829 - binary_accuracy: 0.9073 - loss: 0.2656 - val_auc: 0.7964 - val_binary_accuracy: 0.9097 - val_loss: 0.2603\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7848 - binary_accuracy: 0.9078 - loss: 0.2644 - val_auc: 0.7986 - val_binary_accuracy: 0.9097 - val_loss: 0.2593\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2636 - val_auc: 0.8002 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7873 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8024 - val_binary_accuracy: 0.9100 - val_loss: 0.2572\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9090 - loss: 0.2625 - val_auc: 0.8033 - val_binary_accuracy: 0.9101 - val_loss: 0.2567\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9092 - loss: 0.2620 - val_auc: 0.8044 - val_binary_accuracy: 0.9103 - val_loss: 0.2563\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7873 - binary_accuracy: 0.9101 - loss: 0.2631\n",
      "Fold 4 Metrics: Loss = 0.2563, Accuracy = 0.9103, AUC = 0.8044\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6808 - binary_accuracy: 0.9036 - loss: 0.3078 - val_auc: 0.7917 - val_binary_accuracy: 0.8995 - val_loss: 0.2775\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7666 - binary_accuracy: 0.9011 - loss: 0.2789 - val_auc: 0.8004 - val_binary_accuracy: 0.8998 - val_loss: 0.2746\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7763 - binary_accuracy: 0.9021 - loss: 0.2731 - val_auc: 0.8049 - val_binary_accuracy: 0.9028 - val_loss: 0.2718\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7813 - binary_accuracy: 0.9043 - loss: 0.2693 - val_auc: 0.8059 - val_binary_accuracy: 0.9026 - val_loss: 0.2720\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9044 - loss: 0.2677 - val_auc: 0.8072 - val_binary_accuracy: 0.9032 - val_loss: 0.2711\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9052 - loss: 0.2666 - val_auc: 0.8078 - val_binary_accuracy: 0.9041 - val_loss: 0.2714\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9064 - loss: 0.2657 - val_auc: 0.8079 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9066 - loss: 0.2651 - val_auc: 0.8082 - val_binary_accuracy: 0.9054 - val_loss: 0.2698\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9070 - loss: 0.2646 - val_auc: 0.8076 - val_binary_accuracy: 0.9032 - val_loss: 0.2711\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9072 - loss: 0.2644 - val_auc: 0.8082 - val_binary_accuracy: 0.9036 - val_loss: 0.2706\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8170 - binary_accuracy: 0.9056 - loss: 0.2685\n",
      "Fold 5 Metrics: Loss = 0.2706, Accuracy = 0.9036, AUC = 0.8082\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2612\n",
      "Average Accuracy: 0.9083\n",
      "Average AUC: 0.8037\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 1, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6862 - binary_accuracy: 0.8592 - loss: 0.5908 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2762\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9071 - loss: 0.2693 - val_auc: 0.7723 - val_binary_accuracy: 0.9017 - val_loss: 0.2800\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.7786 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9106 - loss: 0.2594 - val_auc: 0.7839 - val_binary_accuracy: 0.9076 - val_loss: 0.2692\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7911 - binary_accuracy: 0.9115 - loss: 0.2565 - val_auc: 0.7872 - val_binary_accuracy: 0.9084 - val_loss: 0.2660\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9117 - loss: 0.2548 - val_auc: 0.7893 - val_binary_accuracy: 0.9085 - val_loss: 0.2638\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7968 - binary_accuracy: 0.9120 - loss: 0.2536 - val_auc: 0.7911 - val_binary_accuracy: 0.9090 - val_loss: 0.2623\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7984 - binary_accuracy: 0.9120 - loss: 0.2528 - val_auc: 0.7923 - val_binary_accuracy: 0.9090 - val_loss: 0.2615\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7932 - val_binary_accuracy: 0.9088 - val_loss: 0.2610\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9126 - loss: 0.2519 - val_auc: 0.7936 - val_binary_accuracy: 0.9088 - val_loss: 0.2605\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7857 - binary_accuracy: 0.9111 - loss: 0.2563\n",
      "Fold 1 Metrics: Loss = 0.2605, Accuracy = 0.9088, AUC = 0.7936\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6825 - binary_accuracy: 0.8857 - loss: 0.3480 - val_auc: 0.7850 - val_binary_accuracy: 0.9081 - val_loss: 0.2691\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7647 - binary_accuracy: 0.9056 - loss: 0.2777 - val_auc: 0.8016 - val_binary_accuracy: 0.9096 - val_loss: 0.2620\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7806 - binary_accuracy: 0.9065 - loss: 0.2707 - val_auc: 0.8064 - val_binary_accuracy: 0.9100 - val_loss: 0.2589\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7863 - binary_accuracy: 0.9068 - loss: 0.2678 - val_auc: 0.8093 - val_binary_accuracy: 0.9091 - val_loss: 0.2574\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9071 - loss: 0.2658 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2560\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7921 - binary_accuracy: 0.9075 - loss: 0.2644 - val_auc: 0.8114 - val_binary_accuracy: 0.9099 - val_loss: 0.2562\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7935 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8138 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9083 - loss: 0.2625 - val_auc: 0.8145 - val_binary_accuracy: 0.9099 - val_loss: 0.2559\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7972 - binary_accuracy: 0.9083 - loss: 0.2618 - val_auc: 0.8161 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9082 - loss: 0.2612 - val_auc: 0.8158 - val_binary_accuracy: 0.9090 - val_loss: 0.2553\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8227 - binary_accuracy: 0.9125 - loss: 0.2459\n",
      "Fold 2 Metrics: Loss = 0.2553, Accuracy = 0.9090, AUC = 0.8158\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7163 - binary_accuracy: 0.8859 - loss: 0.3651 - val_auc: 0.7699 - val_binary_accuracy: 0.8982 - val_loss: 0.2847\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7610 - binary_accuracy: 0.9030 - loss: 0.2754 - val_auc: 0.7911 - val_binary_accuracy: 0.9032 - val_loss: 0.2727\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7758 - binary_accuracy: 0.9063 - loss: 0.2673 - val_auc: 0.7974 - val_binary_accuracy: 0.9048 - val_loss: 0.2686\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7810 - binary_accuracy: 0.9072 - loss: 0.2647 - val_auc: 0.8013 - val_binary_accuracy: 0.9054 - val_loss: 0.2672\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7837 - binary_accuracy: 0.9080 - loss: 0.2631 - val_auc: 0.8034 - val_binary_accuracy: 0.9059 - val_loss: 0.2669\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2622 - val_auc: 0.8041 - val_binary_accuracy: 0.9057 - val_loss: 0.2666\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7869 - binary_accuracy: 0.9083 - loss: 0.2617 - val_auc: 0.8053 - val_binary_accuracy: 0.9056 - val_loss: 0.2675\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7876 - binary_accuracy: 0.9083 - loss: 0.2613 - val_auc: 0.8061 - val_binary_accuracy: 0.9057 - val_loss: 0.2676\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7886 - binary_accuracy: 0.9085 - loss: 0.2610 - val_auc: 0.8064 - val_binary_accuracy: 0.9056 - val_loss: 0.2677\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7890 - binary_accuracy: 0.9088 - loss: 0.2608 - val_auc: 0.8070 - val_binary_accuracy: 0.9056 - val_loss: 0.2678\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8043 - binary_accuracy: 0.9058 - loss: 0.2677\n",
      "Fold 3 Metrics: Loss = 0.2678, Accuracy = 0.9056, AUC = 0.8070\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6602 - binary_accuracy: 0.8776 - loss: 0.3897 - val_auc: 0.7762 - val_binary_accuracy: 0.9062 - val_loss: 0.2726\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7629 - binary_accuracy: 0.9050 - loss: 0.2777 - val_auc: 0.7908 - val_binary_accuracy: 0.9060 - val_loss: 0.2644\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7732 - binary_accuracy: 0.9068 - loss: 0.2709 - val_auc: 0.7972 - val_binary_accuracy: 0.9076 - val_loss: 0.2611\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7797 - binary_accuracy: 0.9078 - loss: 0.2675 - val_auc: 0.8001 - val_binary_accuracy: 0.9081 - val_loss: 0.2601\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7836 - binary_accuracy: 0.9080 - loss: 0.2655 - val_auc: 0.8028 - val_binary_accuracy: 0.9081 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7862 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8046 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7881 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2583\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7889 - binary_accuracy: 0.9082 - loss: 0.2621 - val_auc: 0.8077 - val_binary_accuracy: 0.9091 - val_loss: 0.2578\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7897 - binary_accuracy: 0.9083 - loss: 0.2617 - val_auc: 0.8084 - val_binary_accuracy: 0.9091 - val_loss: 0.2574\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7907 - binary_accuracy: 0.9090 - loss: 0.2613 - val_auc: 0.8090 - val_binary_accuracy: 0.9087 - val_loss: 0.2571\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9066 - loss: 0.2637\n",
      "Fold 4 Metrics: Loss = 0.2571, Accuracy = 0.9087, AUC = 0.8090\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6565 - binary_accuracy: 0.8934 - loss: 0.3689 - val_auc: 0.7838 - val_binary_accuracy: 0.9048 - val_loss: 0.2664\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7613 - binary_accuracy: 0.9052 - loss: 0.2762 - val_auc: 0.7952 - val_binary_accuracy: 0.9078 - val_loss: 0.2599\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7696 - binary_accuracy: 0.9075 - loss: 0.2717 - val_auc: 0.7998 - val_binary_accuracy: 0.9091 - val_loss: 0.2568\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9078 - loss: 0.2691 - val_auc: 0.8030 - val_binary_accuracy: 0.9106 - val_loss: 0.2558\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7778 - binary_accuracy: 0.9085 - loss: 0.2677 - val_auc: 0.8046 - val_binary_accuracy: 0.9104 - val_loss: 0.2548\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9087 - loss: 0.2668 - val_auc: 0.8068 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7806 - binary_accuracy: 0.9088 - loss: 0.2663 - val_auc: 0.8078 - val_binary_accuracy: 0.9101 - val_loss: 0.2534\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9077 - loss: 0.2656 - val_auc: 0.8072 - val_binary_accuracy: 0.9087 - val_loss: 0.2536\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7821 - binary_accuracy: 0.9082 - loss: 0.2655 - val_auc: 0.8076 - val_binary_accuracy: 0.9079 - val_loss: 0.2537\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7832 - binary_accuracy: 0.9089 - loss: 0.2651 - val_auc: 0.8080 - val_binary_accuracy: 0.9082 - val_loss: 0.2537\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9069 - loss: 0.2532\n",
      "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9082, AUC = 0.8080\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2589\n",
      "Average Accuracy: 0.9081\n",
      "Average AUC: 0.8067\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 1, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7034 - binary_accuracy: 0.8996 - loss: 0.3101 - val_auc: 0.7697 - val_binary_accuracy: 0.9081 - val_loss: 0.2725\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9089 - loss: 0.2643 - val_auc: 0.7847 - val_binary_accuracy: 0.9103 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9109 - loss: 0.2571 - val_auc: 0.7876 - val_binary_accuracy: 0.9099 - val_loss: 0.2676\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7957 - binary_accuracy: 0.9117 - loss: 0.2555 - val_auc: 0.7925 - val_binary_accuracy: 0.9097 - val_loss: 0.2603\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9120 - loss: 0.2532 - val_auc: 0.7931 - val_binary_accuracy: 0.9097 - val_loss: 0.2600\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9119 - loss: 0.2528 - val_auc: 0.7942 - val_binary_accuracy: 0.9097 - val_loss: 0.2597\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9122 - loss: 0.2521 - val_auc: 0.7947 - val_binary_accuracy: 0.9096 - val_loss: 0.2594\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9125 - loss: 0.2515 - val_auc: 0.7953 - val_binary_accuracy: 0.9099 - val_loss: 0.2593\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8048 - binary_accuracy: 0.9125 - loss: 0.2513 - val_auc: 0.7956 - val_binary_accuracy: 0.9093 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9127 - loss: 0.2508 - val_auc: 0.7962 - val_binary_accuracy: 0.9093 - val_loss: 0.2593\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7917 - binary_accuracy: 0.9135 - loss: 0.2520\n",
      "Fold 1 Metrics: Loss = 0.2593, Accuracy = 0.9093, AUC = 0.7962\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5927 - binary_accuracy: 0.8873 - loss: 0.7866 - val_auc: 0.7893 - val_binary_accuracy: 0.9068 - val_loss: 0.2654\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9050 - loss: 0.2744 - val_auc: 0.8040 - val_binary_accuracy: 0.9079 - val_loss: 0.2582\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7799 - binary_accuracy: 0.9065 - loss: 0.2693 - val_auc: 0.8073 - val_binary_accuracy: 0.9088 - val_loss: 0.2563\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7863 - binary_accuracy: 0.9064 - loss: 0.2670 - val_auc: 0.8056 - val_binary_accuracy: 0.9104 - val_loss: 0.2571\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9065 - loss: 0.2658 - val_auc: 0.8097 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7927 - binary_accuracy: 0.9067 - loss: 0.2643 - val_auc: 0.8107 - val_binary_accuracy: 0.9082 - val_loss: 0.2552\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7934 - binary_accuracy: 0.9068 - loss: 0.2639 - val_auc: 0.8125 - val_binary_accuracy: 0.9090 - val_loss: 0.2537\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7962 - binary_accuracy: 0.9070 - loss: 0.2629 - val_auc: 0.8124 - val_binary_accuracy: 0.9088 - val_loss: 0.2539\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9070 - loss: 0.2630 - val_auc: 0.8131 - val_binary_accuracy: 0.9085 - val_loss: 0.2533\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9075 - loss: 0.2623 - val_auc: 0.8130 - val_binary_accuracy: 0.9087 - val_loss: 0.2533\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8199 - binary_accuracy: 0.9122 - loss: 0.2438\n",
      "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9087, AUC = 0.8130\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6633 - binary_accuracy: 0.8966 - loss: 0.4320 - val_auc: 0.7971 - val_binary_accuracy: 0.9096 - val_loss: 0.2604\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7724 - binary_accuracy: 0.9059 - loss: 0.2692 - val_auc: 0.8024 - val_binary_accuracy: 0.9106 - val_loss: 0.2572\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7767 - binary_accuracy: 0.9061 - loss: 0.2674 - val_auc: 0.8041 - val_binary_accuracy: 0.9107 - val_loss: 0.2562\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7777 - binary_accuracy: 0.9063 - loss: 0.2667 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7786 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.8062 - val_binary_accuracy: 0.9107 - val_loss: 0.2557\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7803 - binary_accuracy: 0.9066 - loss: 0.2658 - val_auc: 0.8074 - val_binary_accuracy: 0.9116 - val_loss: 0.2554\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7817 - binary_accuracy: 0.9069 - loss: 0.2652 - val_auc: 0.8072 - val_binary_accuracy: 0.9112 - val_loss: 0.2555\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7825 - binary_accuracy: 0.9072 - loss: 0.2648 - val_auc: 0.8082 - val_binary_accuracy: 0.9122 - val_loss: 0.2550\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7831 - binary_accuracy: 0.9076 - loss: 0.2643 - val_auc: 0.8072 - val_binary_accuracy: 0.9121 - val_loss: 0.2556\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9075 - loss: 0.2640 - val_auc: 0.8074 - val_binary_accuracy: 0.9124 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8025 - binary_accuracy: 0.9128 - loss: 0.2555\n",
      "Fold 3 Metrics: Loss = 0.2552, Accuracy = 0.9124, AUC = 0.8074\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5709 - binary_accuracy: 0.7201 - loss: 4.4762 - val_auc: 0.7878 - val_binary_accuracy: 0.9041 - val_loss: 0.2668\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7690 - binary_accuracy: 0.9050 - loss: 0.2725 - val_auc: 0.8000 - val_binary_accuracy: 0.9081 - val_loss: 0.2606\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7791 - binary_accuracy: 0.9080 - loss: 0.2666 - val_auc: 0.8041 - val_binary_accuracy: 0.9078 - val_loss: 0.2594\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7819 - binary_accuracy: 0.9085 - loss: 0.2651 - val_auc: 0.8063 - val_binary_accuracy: 0.9064 - val_loss: 0.2598\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7838 - binary_accuracy: 0.9089 - loss: 0.2641 - val_auc: 0.8078 - val_binary_accuracy: 0.9072 - val_loss: 0.2585\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7865 - binary_accuracy: 0.9090 - loss: 0.2629 - val_auc: 0.8090 - val_binary_accuracy: 0.9088 - val_loss: 0.2567\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7886 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8087 - val_binary_accuracy: 0.9104 - val_loss: 0.2558\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9094 - loss: 0.2620 - val_auc: 0.8094 - val_binary_accuracy: 0.9104 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7879 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8103 - val_binary_accuracy: 0.9104 - val_loss: 0.2550\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7879 - binary_accuracy: 0.9089 - loss: 0.2620 - val_auc: 0.8102 - val_binary_accuracy: 0.9103 - val_loss: 0.2550\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7952 - binary_accuracy: 0.9090 - loss: 0.2614\n",
      "Fold 4 Metrics: Loss = 0.2550, Accuracy = 0.9103, AUC = 0.8102\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6283 - binary_accuracy: 0.8896 - loss: 0.8065 - val_auc: 0.7923 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9053 - loss: 0.2773 - val_auc: 0.7995 - val_binary_accuracy: 0.9097 - val_loss: 0.2592\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7657 - binary_accuracy: 0.9060 - loss: 0.2736 - val_auc: 0.8023 - val_binary_accuracy: 0.9073 - val_loss: 0.2591\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7692 - binary_accuracy: 0.9066 - loss: 0.2720 - val_auc: 0.8053 - val_binary_accuracy: 0.9073 - val_loss: 0.2592\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7710 - binary_accuracy: 0.9063 - loss: 0.2711 - val_auc: 0.8066 - val_binary_accuracy: 0.9067 - val_loss: 0.2597\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7718 - binary_accuracy: 0.9065 - loss: 0.2709 - val_auc: 0.8074 - val_binary_accuracy: 0.9066 - val_loss: 0.2588\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7732 - binary_accuracy: 0.9073 - loss: 0.2704 - val_auc: 0.8080 - val_binary_accuracy: 0.9064 - val_loss: 0.2585\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9070 - loss: 0.2697 - val_auc: 0.8082 - val_binary_accuracy: 0.9062 - val_loss: 0.2578\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7762 - binary_accuracy: 0.9072 - loss: 0.2693 - val_auc: 0.8085 - val_binary_accuracy: 0.9067 - val_loss: 0.2573\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7768 - binary_accuracy: 0.9072 - loss: 0.2691 - val_auc: 0.8083 - val_binary_accuracy: 0.9059 - val_loss: 0.2567\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8140 - binary_accuracy: 0.9062 - loss: 0.2557\n",
      "Fold 5 Metrics: Loss = 0.2567, Accuracy = 0.9059, AUC = 0.8083\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2559\n",
      "Average Accuracy: 0.9093\n",
      "Average AUC: 0.8070\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 1, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6756 - binary_accuracy: 0.8977 - loss: 0.4019 - val_auc: 0.7866 - val_binary_accuracy: 0.9085 - val_loss: 0.2622\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7899 - binary_accuracy: 0.9116 - loss: 0.2575 - val_auc: 0.7926 - val_binary_accuracy: 0.9100 - val_loss: 0.2600\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7940 - binary_accuracy: 0.9120 - loss: 0.2555 - val_auc: 0.7960 - val_binary_accuracy: 0.9104 - val_loss: 0.2591\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7984 - binary_accuracy: 0.9123 - loss: 0.2535 - val_auc: 0.7967 - val_binary_accuracy: 0.9100 - val_loss: 0.2590\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7998 - binary_accuracy: 0.9126 - loss: 0.2527 - val_auc: 0.7972 - val_binary_accuracy: 0.9096 - val_loss: 0.2587\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8011 - binary_accuracy: 0.9127 - loss: 0.2522 - val_auc: 0.7987 - val_binary_accuracy: 0.9094 - val_loss: 0.2582\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8031 - binary_accuracy: 0.9129 - loss: 0.2515 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8033 - binary_accuracy: 0.9130 - loss: 0.2514 - val_auc: 0.7990 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9132 - loss: 0.2509 - val_auc: 0.7989 - val_binary_accuracy: 0.9097 - val_loss: 0.2574\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8052 - binary_accuracy: 0.9132 - loss: 0.2507 - val_auc: 0.7983 - val_binary_accuracy: 0.9099 - val_loss: 0.2576\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7944 - binary_accuracy: 0.9140 - loss: 0.2500\n",
      "Fold 1 Metrics: Loss = 0.2576, Accuracy = 0.9099, AUC = 0.7983\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5951 - binary_accuracy: 0.8489 - loss: 0.9462 - val_auc: 0.8019 - val_binary_accuracy: 0.9059 - val_loss: 0.2635\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9057 - loss: 0.2711 - val_auc: 0.8111 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9069 - loss: 0.2685 - val_auc: 0.8111 - val_binary_accuracy: 0.9099 - val_loss: 0.2563\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7852 - binary_accuracy: 0.9067 - loss: 0.2683 - val_auc: 0.8115 - val_binary_accuracy: 0.9099 - val_loss: 0.2557\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9063 - loss: 0.2683 - val_auc: 0.8118 - val_binary_accuracy: 0.9104 - val_loss: 0.2554\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7856 - binary_accuracy: 0.9066 - loss: 0.2683 - val_auc: 0.8115 - val_binary_accuracy: 0.9104 - val_loss: 0.2557\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7856 - binary_accuracy: 0.9063 - loss: 0.2681 - val_auc: 0.8113 - val_binary_accuracy: 0.9100 - val_loss: 0.2559\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9065 - loss: 0.2679 - val_auc: 0.8113 - val_binary_accuracy: 0.9100 - val_loss: 0.2558\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7875 - binary_accuracy: 0.9067 - loss: 0.2673 - val_auc: 0.8120 - val_binary_accuracy: 0.9097 - val_loss: 0.2559\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9069 - loss: 0.2665 - val_auc: 0.8124 - val_binary_accuracy: 0.9099 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8201 - binary_accuracy: 0.9141 - loss: 0.2456\n",
      "Fold 2 Metrics: Loss = 0.2552, Accuracy = 0.9099, AUC = 0.8124\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6426 - binary_accuracy: 0.8351 - loss: 1.1844 - val_auc: 0.7773 - val_binary_accuracy: 0.9087 - val_loss: 0.2691\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7591 - binary_accuracy: 0.9047 - loss: 0.2747 - val_auc: 0.7910 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7657 - binary_accuracy: 0.9053 - loss: 0.2727 - val_auc: 0.7981 - val_binary_accuracy: 0.9038 - val_loss: 0.2686\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7738 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.8018 - val_binary_accuracy: 0.9004 - val_loss: 0.2724\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7756 - binary_accuracy: 0.9069 - loss: 0.2682 - val_auc: 0.8036 - val_binary_accuracy: 0.8972 - val_loss: 0.2742\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7772 - binary_accuracy: 0.9066 - loss: 0.2682 - val_auc: 0.8053 - val_binary_accuracy: 0.8969 - val_loss: 0.2742\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7776 - binary_accuracy: 0.9060 - loss: 0.2677 - val_auc: 0.8064 - val_binary_accuracy: 0.8969 - val_loss: 0.2747\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9065 - loss: 0.2677 - val_auc: 0.8074 - val_binary_accuracy: 0.8948 - val_loss: 0.2769\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7789 - binary_accuracy: 0.9064 - loss: 0.2673 - val_auc: 0.8078 - val_binary_accuracy: 0.8942 - val_loss: 0.2772\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7800 - binary_accuracy: 0.9066 - loss: 0.2670 - val_auc: 0.8081 - val_binary_accuracy: 0.8952 - val_loss: 0.2765\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8043 - binary_accuracy: 0.8954 - loss: 0.2766\n",
      "Fold 3 Metrics: Loss = 0.2765, Accuracy = 0.8952, AUC = 0.8081\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6570 - binary_accuracy: 0.8842 - loss: 0.5254 - val_auc: 0.7953 - val_binary_accuracy: 0.9085 - val_loss: 0.2630\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9084 - loss: 0.2721 - val_auc: 0.8073 - val_binary_accuracy: 0.9091 - val_loss: 0.2611\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9088 - loss: 0.2692 - val_auc: 0.8104 - val_binary_accuracy: 0.9090 - val_loss: 0.2599\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7772 - binary_accuracy: 0.9090 - loss: 0.2674 - val_auc: 0.8116 - val_binary_accuracy: 0.9090 - val_loss: 0.2589\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7794 - binary_accuracy: 0.9094 - loss: 0.2663 - val_auc: 0.8130 - val_binary_accuracy: 0.9097 - val_loss: 0.2582\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7804 - binary_accuracy: 0.9089 - loss: 0.2658 - val_auc: 0.8144 - val_binary_accuracy: 0.9097 - val_loss: 0.2564\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7822 - binary_accuracy: 0.9093 - loss: 0.2649 - val_auc: 0.8145 - val_binary_accuracy: 0.9097 - val_loss: 0.2562\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7826 - binary_accuracy: 0.9095 - loss: 0.2649 - val_auc: 0.8143 - val_binary_accuracy: 0.9095 - val_loss: 0.2561\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2644 - val_auc: 0.8142 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7843 - binary_accuracy: 0.9096 - loss: 0.2643 - val_auc: 0.8145 - val_binary_accuracy: 0.9098 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7978 - binary_accuracy: 0.9082 - loss: 0.2625\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9098, AUC = 0.8145\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5360 - binary_accuracy: 0.8048 - loss: 1.9087 - val_auc: 0.7869 - val_binary_accuracy: 0.9063 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7625 - binary_accuracy: 0.9056 - loss: 0.2748 - val_auc: 0.8003 - val_binary_accuracy: 0.9090 - val_loss: 0.2569\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9065 - loss: 0.2711 - val_auc: 0.8047 - val_binary_accuracy: 0.9051 - val_loss: 0.2613\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7709 - binary_accuracy: 0.9061 - loss: 0.2709 - val_auc: 0.8069 - val_binary_accuracy: 0.9019 - val_loss: 0.2670\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9063 - loss: 0.2703 - val_auc: 0.8073 - val_binary_accuracy: 0.9014 - val_loss: 0.2696\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7751 - binary_accuracy: 0.9061 - loss: 0.2699 - val_auc: 0.8077 - val_binary_accuracy: 0.9005 - val_loss: 0.2702\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7751 - binary_accuracy: 0.9064 - loss: 0.2701 - val_auc: 0.8078 - val_binary_accuracy: 0.8997 - val_loss: 0.2712\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7752 - binary_accuracy: 0.9063 - loss: 0.2702 - val_auc: 0.8079 - val_binary_accuracy: 0.8988 - val_loss: 0.2723\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7752 - binary_accuracy: 0.9065 - loss: 0.2706 - val_auc: 0.8079 - val_binary_accuracy: 0.8991 - val_loss: 0.2726\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7747 - binary_accuracy: 0.9063 - loss: 0.2707 - val_auc: 0.8083 - val_binary_accuracy: 0.8995 - val_loss: 0.2723\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9035 - loss: 0.2698\n",
      "Fold 5 Metrics: Loss = 0.2723, Accuracy = 0.8995, AUC = 0.8083\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2633\n",
      "Average Accuracy: 0.9049\n",
      "Average AUC: 0.8083\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 1, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7102 - binary_accuracy: 0.9002 - loss: 0.3113 - val_auc: 0.7878 - val_binary_accuracy: 0.9062 - val_loss: 0.2950\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9093 - loss: 0.2649 - val_auc: 0.7940 - val_binary_accuracy: 0.9072 - val_loss: 0.3029\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9096 - loss: 0.2626 - val_auc: 0.7944 - val_binary_accuracy: 0.9079 - val_loss: 0.3055\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9106 - loss: 0.2611 - val_auc: 0.7986 - val_binary_accuracy: 0.9078 - val_loss: 0.3028\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7866 - binary_accuracy: 0.9106 - loss: 0.2602 - val_auc: 0.7988 - val_binary_accuracy: 0.9081 - val_loss: 0.3022\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7889 - binary_accuracy: 0.9111 - loss: 0.2591 - val_auc: 0.8007 - val_binary_accuracy: 0.9081 - val_loss: 0.3000\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7902 - binary_accuracy: 0.9110 - loss: 0.2587 - val_auc: 0.7994 - val_binary_accuracy: 0.9081 - val_loss: 0.2919\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7928 - binary_accuracy: 0.9108 - loss: 0.2572 - val_auc: 0.7990 - val_binary_accuracy: 0.9081 - val_loss: 0.2882\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9112 - loss: 0.2564 - val_auc: 0.7994 - val_binary_accuracy: 0.9088 - val_loss: 0.2844\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7958 - binary_accuracy: 0.9111 - loss: 0.2556 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2794\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7957 - binary_accuracy: 0.9128 - loss: 0.2695\n",
      "Fold 1 Metrics: Loss = 0.2794, Accuracy = 0.9088, AUC = 0.7997\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6661 - binary_accuracy: 0.8791 - loss: 0.4294 - val_auc: 0.8100 - val_binary_accuracy: 0.8960 - val_loss: 0.2967\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7596 - binary_accuracy: 0.9035 - loss: 0.2802 - val_auc: 0.8109 - val_binary_accuracy: 0.8964 - val_loss: 0.2970\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9048 - loss: 0.2791 - val_auc: 0.8142 - val_binary_accuracy: 0.8979 - val_loss: 0.2922\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9052 - loss: 0.2777 - val_auc: 0.8110 - val_binary_accuracy: 0.8991 - val_loss: 0.2890\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7701 - binary_accuracy: 0.9056 - loss: 0.2762 - val_auc: 0.8113 - val_binary_accuracy: 0.8991 - val_loss: 0.2898\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7716 - binary_accuracy: 0.9055 - loss: 0.2758 - val_auc: 0.8125 - val_binary_accuracy: 0.8986 - val_loss: 0.2876\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9055 - loss: 0.2743 - val_auc: 0.8114 - val_binary_accuracy: 0.8986 - val_loss: 0.2883\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7757 - binary_accuracy: 0.9058 - loss: 0.2740 - val_auc: 0.8065 - val_binary_accuracy: 0.9007 - val_loss: 0.2841\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7784 - binary_accuracy: 0.9059 - loss: 0.2727 - val_auc: 0.8114 - val_binary_accuracy: 0.9023 - val_loss: 0.2745\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7812 - binary_accuracy: 0.9059 - loss: 0.2707 - val_auc: 0.8090 - val_binary_accuracy: 0.9054 - val_loss: 0.2709\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9082 - loss: 0.2627\n",
      "Fold 2 Metrics: Loss = 0.2709, Accuracy = 0.9054, AUC = 0.8090\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6325 - binary_accuracy: 0.8668 - loss: 0.6690 - val_auc: 0.7893 - val_binary_accuracy: 0.9063 - val_loss: 0.2674\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7722 - binary_accuracy: 0.9058 - loss: 0.2699 - val_auc: 0.7994 - val_binary_accuracy: 0.9017 - val_loss: 0.2711\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7725 - binary_accuracy: 0.9071 - loss: 0.2699 - val_auc: 0.8024 - val_binary_accuracy: 0.9023 - val_loss: 0.2673\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9061 - loss: 0.2710 - val_auc: 0.8041 - val_binary_accuracy: 0.9038 - val_loss: 0.2652\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9066 - loss: 0.2706 - val_auc: 0.8042 - val_binary_accuracy: 0.9026 - val_loss: 0.2683\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7737 - binary_accuracy: 0.9067 - loss: 0.2698 - val_auc: 0.8055 - val_binary_accuracy: 0.9013 - val_loss: 0.2680\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9070 - loss: 0.2690 - val_auc: 0.8053 - val_binary_accuracy: 0.9006 - val_loss: 0.2705\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7766 - binary_accuracy: 0.9071 - loss: 0.2684 - val_auc: 0.8061 - val_binary_accuracy: 0.9003 - val_loss: 0.2717\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.8058 - val_binary_accuracy: 0.9014 - val_loss: 0.2721\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7788 - binary_accuracy: 0.9072 - loss: 0.2672 - val_auc: 0.8059 - val_binary_accuracy: 0.8988 - val_loss: 0.2736\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8025 - binary_accuracy: 0.9010 - loss: 0.2736\n",
      "Fold 3 Metrics: Loss = 0.2736, Accuracy = 0.8988, AUC = 0.8059\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7025 - binary_accuracy: 0.8919 - loss: 0.3483 - val_auc: 0.8065 - val_binary_accuracy: 0.9081 - val_loss: 0.2577\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7717 - binary_accuracy: 0.9084 - loss: 0.2697 - val_auc: 0.8101 - val_binary_accuracy: 0.9026 - val_loss: 0.2593\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9081 - loss: 0.2691 - val_auc: 0.8120 - val_binary_accuracy: 0.9033 - val_loss: 0.2579\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9078 - loss: 0.2686 - val_auc: 0.8125 - val_binary_accuracy: 0.9069 - val_loss: 0.2551\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9088 - loss: 0.2676 - val_auc: 0.8118 - val_binary_accuracy: 0.9097 - val_loss: 0.2648\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9096 - loss: 0.2665 - val_auc: 0.8111 - val_binary_accuracy: 0.9100 - val_loss: 0.2961\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7777 - binary_accuracy: 0.9089 - loss: 0.2671 - val_auc: 0.8101 - val_binary_accuracy: 0.9090 - val_loss: 0.3140\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7748 - binary_accuracy: 0.9085 - loss: 0.2688 - val_auc: 0.8092 - val_binary_accuracy: 0.9091 - val_loss: 0.3189\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7715 - binary_accuracy: 0.9086 - loss: 0.2717 - val_auc: 0.8132 - val_binary_accuracy: 0.9095 - val_loss: 0.2976\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7718 - binary_accuracy: 0.9075 - loss: 0.2720 - val_auc: 0.8129 - val_binary_accuracy: 0.9098 - val_loss: 0.2836\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7967 - binary_accuracy: 0.9093 - loss: 0.2904\n",
      "Fold 4 Metrics: Loss = 0.2836, Accuracy = 0.9098, AUC = 0.8129\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6815 - binary_accuracy: 0.8778 - loss: 0.4993 - val_auc: 0.7960 - val_binary_accuracy: 0.8927 - val_loss: 0.2965\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7478 - binary_accuracy: 0.9037 - loss: 0.2840 - val_auc: 0.8031 - val_binary_accuracy: 0.8918 - val_loss: 0.2983\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7524 - binary_accuracy: 0.9039 - loss: 0.2828 - val_auc: 0.8050 - val_binary_accuracy: 0.8895 - val_loss: 0.2979\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7557 - binary_accuracy: 0.9038 - loss: 0.2810 - val_auc: 0.8066 - val_binary_accuracy: 0.8889 - val_loss: 0.2970\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7587 - binary_accuracy: 0.9036 - loss: 0.2797 - val_auc: 0.8074 - val_binary_accuracy: 0.8920 - val_loss: 0.2937\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7622 - binary_accuracy: 0.9041 - loss: 0.2781 - val_auc: 0.8080 - val_binary_accuracy: 0.8935 - val_loss: 0.2897\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7637 - binary_accuracy: 0.9046 - loss: 0.2772 - val_auc: 0.8079 - val_binary_accuracy: 0.8942 - val_loss: 0.2887\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9048 - loss: 0.2763 - val_auc: 0.8083 - val_binary_accuracy: 0.8941 - val_loss: 0.2876\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7663 - binary_accuracy: 0.9052 - loss: 0.2756 - val_auc: 0.8083 - val_binary_accuracy: 0.8939 - val_loss: 0.2867\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7681 - binary_accuracy: 0.9054 - loss: 0.2749 - val_auc: 0.8082 - val_binary_accuracy: 0.8954 - val_loss: 0.2848\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.8988 - loss: 0.2816\n",
      "Fold 5 Metrics: Loss = 0.2848, Accuracy = 0.8954, AUC = 0.8082\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2785\n",
      "Average Accuracy: 0.9037\n",
      "Average AUC: 0.8072\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 2, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6672 - binary_accuracy: 0.8183 - loss: 0.9800 - val_auc: 0.7084 - val_binary_accuracy: 0.9062 - val_loss: 0.2851\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7467 - binary_accuracy: 0.9104 - loss: 0.2730 - val_auc: 0.7630 - val_binary_accuracy: 0.9085 - val_loss: 0.2725\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9115 - loss: 0.2640 - val_auc: 0.7712 - val_binary_accuracy: 0.9078 - val_loss: 0.2701\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9116 - loss: 0.2609 - val_auc: 0.7749 - val_binary_accuracy: 0.9081 - val_loss: 0.2696\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9110 - loss: 0.2592 - val_auc: 0.7790 - val_binary_accuracy: 0.9088 - val_loss: 0.2691\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9110 - loss: 0.2577 - val_auc: 0.7828 - val_binary_accuracy: 0.9082 - val_loss: 0.2687\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9112 - loss: 0.2566 - val_auc: 0.7846 - val_binary_accuracy: 0.9088 - val_loss: 0.2677\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9117 - loss: 0.2557 - val_auc: 0.7861 - val_binary_accuracy: 0.9091 - val_loss: 0.2670\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9118 - loss: 0.2546 - val_auc: 0.7875 - val_binary_accuracy: 0.9091 - val_loss: 0.2667\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9122 - loss: 0.2539 - val_auc: 0.7892 - val_binary_accuracy: 0.9093 - val_loss: 0.2660\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7822 - binary_accuracy: 0.9124 - loss: 0.2588\n",
      "Fold 1 Metrics: Loss = 0.2660, Accuracy = 0.9093, AUC = 0.7892\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6465 - binary_accuracy: 0.8995 - loss: 0.4357 - val_auc: 0.7847 - val_binary_accuracy: 0.9057 - val_loss: 0.2662\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9039 - loss: 0.2732 - val_auc: 0.7982 - val_binary_accuracy: 0.9069 - val_loss: 0.2611\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9050 - loss: 0.2692 - val_auc: 0.8029 - val_binary_accuracy: 0.9078 - val_loss: 0.2584\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9053 - loss: 0.2669 - val_auc: 0.8064 - val_binary_accuracy: 0.9091 - val_loss: 0.2565\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9062 - loss: 0.2651 - val_auc: 0.8092 - val_binary_accuracy: 0.9097 - val_loss: 0.2555\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9067 - loss: 0.2640 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2546\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9072 - loss: 0.2629 - val_auc: 0.8124 - val_binary_accuracy: 0.9097 - val_loss: 0.2535\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9074 - loss: 0.2617 - val_auc: 0.8130 - val_binary_accuracy: 0.9099 - val_loss: 0.2538\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9083 - loss: 0.2610 - val_auc: 0.8145 - val_binary_accuracy: 0.9102 - val_loss: 0.2532\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9082 - loss: 0.2601 - val_auc: 0.8131 - val_binary_accuracy: 0.9100 - val_loss: 0.2538\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9138 - loss: 0.2447\n",
      "Fold 2 Metrics: Loss = 0.2538, Accuracy = 0.9100, AUC = 0.8131\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - auc: 0.6251 - binary_accuracy: 0.6070 - loss: 7.7190 - val_auc: 0.7514 - val_binary_accuracy: 0.8979 - val_loss: 0.3540\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7481 - binary_accuracy: 0.9018 - loss: 0.3162 - val_auc: 0.7567 - val_binary_accuracy: 0.9062 - val_loss: 0.2830\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7510 - binary_accuracy: 0.9061 - loss: 0.2809 - val_auc: 0.7641 - val_binary_accuracy: 0.9073 - val_loss: 0.2780\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7572 - binary_accuracy: 0.9071 - loss: 0.2766 - val_auc: 0.7705 - val_binary_accuracy: 0.9084 - val_loss: 0.2747\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7611 - binary_accuracy: 0.9078 - loss: 0.2740 - val_auc: 0.7745 - val_binary_accuracy: 0.9088 - val_loss: 0.2721\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9084 - loss: 0.2722 - val_auc: 0.7785 - val_binary_accuracy: 0.9099 - val_loss: 0.2698\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9087 - loss: 0.2710 - val_auc: 0.7810 - val_binary_accuracy: 0.9099 - val_loss: 0.2681\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9083 - loss: 0.2700 - val_auc: 0.7833 - val_binary_accuracy: 0.9102 - val_loss: 0.2663\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9085 - loss: 0.2693 - val_auc: 0.7858 - val_binary_accuracy: 0.9107 - val_loss: 0.2647\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9084 - loss: 0.2688 - val_auc: 0.7874 - val_binary_accuracy: 0.9106 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7845 - binary_accuracy: 0.9120 - loss: 0.2628\n",
      "Fold 3 Metrics: Loss = 0.2635, Accuracy = 0.9106, AUC = 0.7874\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6090 - binary_accuracy: 0.7314 - loss: 1.4009 - val_auc: 0.7550 - val_binary_accuracy: 0.9044 - val_loss: 0.2814\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7491 - binary_accuracy: 0.9039 - loss: 0.2804 - val_auc: 0.7699 - val_binary_accuracy: 0.9044 - val_loss: 0.2756\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9047 - loss: 0.2751 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9051 - loss: 0.2718 - val_auc: 0.7811 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9062 - loss: 0.2696 - val_auc: 0.7847 - val_binary_accuracy: 0.9048 - val_loss: 0.2687\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9075 - loss: 0.2675 - val_auc: 0.7883 - val_binary_accuracy: 0.9051 - val_loss: 0.2663\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9082 - loss: 0.2657 - val_auc: 0.7931 - val_binary_accuracy: 0.9067 - val_loss: 0.2641\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9091 - loss: 0.2642 - val_auc: 0.7973 - val_binary_accuracy: 0.9075 - val_loss: 0.2617\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9091 - loss: 0.2629 - val_auc: 0.8005 - val_binary_accuracy: 0.9075 - val_loss: 0.2599\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9097 - loss: 0.2620 - val_auc: 0.8028 - val_binary_accuracy: 0.9064 - val_loss: 0.2588\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7843 - binary_accuracy: 0.9057 - loss: 0.2647\n",
      "Fold 4 Metrics: Loss = 0.2588, Accuracy = 0.9064, AUC = 0.8028\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.3823 - binary_accuracy: 0.6444 - loss: 2.6988 - val_auc: 0.7613 - val_binary_accuracy: 0.9044 - val_loss: 0.2801\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7563 - binary_accuracy: 0.9041 - loss: 0.2800 - val_auc: 0.7886 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9042 - loss: 0.2727 - val_auc: 0.7919 - val_binary_accuracy: 0.9057 - val_loss: 0.2651\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9053 - loss: 0.2699 - val_auc: 0.7942 - val_binary_accuracy: 0.9066 - val_loss: 0.2634\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9067 - loss: 0.2681 - val_auc: 0.7959 - val_binary_accuracy: 0.9079 - val_loss: 0.2619\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.7979 - val_binary_accuracy: 0.9088 - val_loss: 0.2607\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9086 - loss: 0.2658 - val_auc: 0.7985 - val_binary_accuracy: 0.9088 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9088 - loss: 0.2649 - val_auc: 0.7996 - val_binary_accuracy: 0.9098 - val_loss: 0.2583\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9089 - loss: 0.2642 - val_auc: 0.8003 - val_binary_accuracy: 0.9106 - val_loss: 0.2573\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9089 - loss: 0.2636 - val_auc: 0.8013 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8121 - binary_accuracy: 0.9093 - loss: 0.2559\n",
      "Fold 5 Metrics: Loss = 0.2564, Accuracy = 0.9107, AUC = 0.8013\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2597\n",
      "Average Accuracy: 0.9094\n",
      "Average AUC: 0.7988\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 2, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5850 - binary_accuracy: 0.7056 - loss: 3.5820 - val_auc: 0.7506 - val_binary_accuracy: 0.9032 - val_loss: 0.2870\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9062 - loss: 0.2728 - val_auc: 0.7654 - val_binary_accuracy: 0.9012 - val_loss: 0.2774\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9059 - loss: 0.2640 - val_auc: 0.7735 - val_binary_accuracy: 0.9051 - val_loss: 0.2695\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9073 - loss: 0.2599 - val_auc: 0.7791 - val_binary_accuracy: 0.9065 - val_loss: 0.2673\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9091 - loss: 0.2576 - val_auc: 0.7819 - val_binary_accuracy: 0.9076 - val_loss: 0.2669\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9104 - loss: 0.2560 - val_auc: 0.7850 - val_binary_accuracy: 0.9082 - val_loss: 0.2670\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9110 - loss: 0.2544 - val_auc: 0.7886 - val_binary_accuracy: 0.9081 - val_loss: 0.2660\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9113 - loss: 0.2538 - val_auc: 0.7912 - val_binary_accuracy: 0.9081 - val_loss: 0.2651\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8023 - binary_accuracy: 0.9117 - loss: 0.2529 - val_auc: 0.7917 - val_binary_accuracy: 0.9094 - val_loss: 0.2645\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8033 - binary_accuracy: 0.9117 - loss: 0.2523 - val_auc: 0.7925 - val_binary_accuracy: 0.9097 - val_loss: 0.2641\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7866 - binary_accuracy: 0.9138 - loss: 0.2563\n",
      "Fold 1 Metrics: Loss = 0.2641, Accuracy = 0.9097, AUC = 0.7925\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6988 - binary_accuracy: 0.8928 - loss: 0.3315 - val_auc: 0.8039 - val_binary_accuracy: 0.9093 - val_loss: 0.2594\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9051 - loss: 0.2747 - val_auc: 0.8084 - val_binary_accuracy: 0.9090 - val_loss: 0.2561\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9049 - loss: 0.2702 - val_auc: 0.8109 - val_binary_accuracy: 0.9088 - val_loss: 0.2545\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9062 - loss: 0.2671 - val_auc: 0.8095 - val_binary_accuracy: 0.9097 - val_loss: 0.2549\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9058 - loss: 0.2657 - val_auc: 0.8088 - val_binary_accuracy: 0.9102 - val_loss: 0.2549\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9070 - loss: 0.2641 - val_auc: 0.8103 - val_binary_accuracy: 0.9106 - val_loss: 0.2543\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9065 - loss: 0.2636 - val_auc: 0.8100 - val_binary_accuracy: 0.9096 - val_loss: 0.2549\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9065 - loss: 0.2628 - val_auc: 0.8152 - val_binary_accuracy: 0.9096 - val_loss: 0.2527\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9064 - loss: 0.2621 - val_auc: 0.8099 - val_binary_accuracy: 0.9088 - val_loss: 0.2554\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9065 - loss: 0.2616 - val_auc: 0.8157 - val_binary_accuracy: 0.9097 - val_loss: 0.2523\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8194 - binary_accuracy: 0.9133 - loss: 0.2432\n",
      "Fold 2 Metrics: Loss = 0.2523, Accuracy = 0.9097, AUC = 0.8157\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5993 - binary_accuracy: 0.6960 - loss: 4.3704 - val_auc: 0.7570 - val_binary_accuracy: 0.9032 - val_loss: 0.2827\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7523 - binary_accuracy: 0.9015 - loss: 0.2811 - val_auc: 0.7754 - val_binary_accuracy: 0.9037 - val_loss: 0.2753\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7638 - binary_accuracy: 0.9037 - loss: 0.2751 - val_auc: 0.7816 - val_binary_accuracy: 0.9062 - val_loss: 0.2684\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9043 - loss: 0.2722 - val_auc: 0.7873 - val_binary_accuracy: 0.9073 - val_loss: 0.2650\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9061 - loss: 0.2696 - val_auc: 0.7918 - val_binary_accuracy: 0.9081 - val_loss: 0.2634\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9074 - loss: 0.2678 - val_auc: 0.7946 - val_binary_accuracy: 0.9072 - val_loss: 0.2637\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9081 - loss: 0.2660 - val_auc: 0.7969 - val_binary_accuracy: 0.9079 - val_loss: 0.2639\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9087 - loss: 0.2645 - val_auc: 0.7983 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9084 - loss: 0.2638 - val_auc: 0.8001 - val_binary_accuracy: 0.9065 - val_loss: 0.2652\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8013 - val_binary_accuracy: 0.9071 - val_loss: 0.2658\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7952 - binary_accuracy: 0.9058 - loss: 0.2666\n",
      "Fold 3 Metrics: Loss = 0.2658, Accuracy = 0.9071, AUC = 0.8013\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6354 - binary_accuracy: 0.8301 - loss: 0.6190 - val_auc: 0.7861 - val_binary_accuracy: 0.9060 - val_loss: 0.2670\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9055 - loss: 0.2697 - val_auc: 0.7922 - val_binary_accuracy: 0.9066 - val_loss: 0.2635\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9058 - loss: 0.2663 - val_auc: 0.7966 - val_binary_accuracy: 0.9072 - val_loss: 0.2611\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9073 - loss: 0.2643 - val_auc: 0.8001 - val_binary_accuracy: 0.9072 - val_loss: 0.2598\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9078 - loss: 0.2634 - val_auc: 0.8021 - val_binary_accuracy: 0.9085 - val_loss: 0.2589\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9080 - loss: 0.2620 - val_auc: 0.8040 - val_binary_accuracy: 0.9064 - val_loss: 0.2586\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9085 - loss: 0.2612 - val_auc: 0.8061 - val_binary_accuracy: 0.9085 - val_loss: 0.2573\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9087 - loss: 0.2607 - val_auc: 0.8071 - val_binary_accuracy: 0.9081 - val_loss: 0.2568\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9095 - loss: 0.2599 - val_auc: 0.8083 - val_binary_accuracy: 0.9079 - val_loss: 0.2561\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9095 - loss: 0.2597 - val_auc: 0.8095 - val_binary_accuracy: 0.9084 - val_loss: 0.2556\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9072 - loss: 0.2619\n",
      "Fold 4 Metrics: Loss = 0.2556, Accuracy = 0.9084, AUC = 0.8095\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5681 - binary_accuracy: 0.8017 - loss: 1.5777 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7602 - binary_accuracy: 0.9040 - loss: 0.2780 - val_auc: 0.7966 - val_binary_accuracy: 0.9060 - val_loss: 0.2675\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9051 - loss: 0.2728 - val_auc: 0.8024 - val_binary_accuracy: 0.9063 - val_loss: 0.2599\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9068 - loss: 0.2695 - val_auc: 0.8041 - val_binary_accuracy: 0.9062 - val_loss: 0.2572\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.8061 - val_binary_accuracy: 0.9060 - val_loss: 0.2557\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9073 - loss: 0.2677 - val_auc: 0.8068 - val_binary_accuracy: 0.9057 - val_loss: 0.2553\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9074 - loss: 0.2674 - val_auc: 0.8077 - val_binary_accuracy: 0.9050 - val_loss: 0.2549\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9074 - loss: 0.2671 - val_auc: 0.8084 - val_binary_accuracy: 0.9076 - val_loss: 0.2534\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9075 - loss: 0.2661 - val_auc: 0.8089 - val_binary_accuracy: 0.9085 - val_loss: 0.2527\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7823 - binary_accuracy: 0.9077 - loss: 0.2656 - val_auc: 0.8085 - val_binary_accuracy: 0.9062 - val_loss: 0.2537\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8185 - binary_accuracy: 0.9057 - loss: 0.2510\n",
      "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9062, AUC = 0.8085\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2583\n",
      "Average Accuracy: 0.9082\n",
      "Average AUC: 0.8055\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 2, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7206 - binary_accuracy: 0.9015 - loss: 0.2951 - val_auc: 0.7831 - val_binary_accuracy: 0.9057 - val_loss: 0.2774\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9075 - loss: 0.2660 - val_auc: 0.7913 - val_binary_accuracy: 0.9082 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9103 - loss: 0.2602 - val_auc: 0.7923 - val_binary_accuracy: 0.9100 - val_loss: 0.2604\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9117 - loss: 0.2571 - val_auc: 0.7938 - val_binary_accuracy: 0.9093 - val_loss: 0.2603\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9121 - loss: 0.2553 - val_auc: 0.7942 - val_binary_accuracy: 0.9097 - val_loss: 0.2599\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9120 - loss: 0.2541 - val_auc: 0.7920 - val_binary_accuracy: 0.9090 - val_loss: 0.2725\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9104 - loss: 0.2563 - val_auc: 0.7953 - val_binary_accuracy: 0.9113 - val_loss: 0.2587\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9130 - loss: 0.2515 - val_auc: 0.7960 - val_binary_accuracy: 0.9113 - val_loss: 0.2612\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9125 - loss: 0.2512 - val_auc: 0.7964 - val_binary_accuracy: 0.9093 - val_loss: 0.2646\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9130 - loss: 0.2505 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2682\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9115 - loss: 0.2636\n",
      "Fold 1 Metrics: Loss = 0.2682, Accuracy = 0.9084, AUC = 0.7962\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6507 - binary_accuracy: 0.8843 - loss: 0.4740 - val_auc: 0.7976 - val_binary_accuracy: 0.8947 - val_loss: 0.3016\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7485 - binary_accuracy: 0.9023 - loss: 0.2852 - val_auc: 0.8083 - val_binary_accuracy: 0.9025 - val_loss: 0.2893\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9043 - loss: 0.2794 - val_auc: 0.8127 - val_binary_accuracy: 0.8916 - val_loss: 0.2959\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9051 - loss: 0.2766 - val_auc: 0.8112 - val_binary_accuracy: 0.8998 - val_loss: 0.2769\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9057 - loss: 0.2730 - val_auc: 0.8106 - val_binary_accuracy: 0.9073 - val_loss: 0.2647\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9065 - loss: 0.2696 - val_auc: 0.8122 - val_binary_accuracy: 0.9090 - val_loss: 0.2586\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9060 - loss: 0.2673 - val_auc: 0.8116 - val_binary_accuracy: 0.9078 - val_loss: 0.2565\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9058 - loss: 0.2656 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9065 - loss: 0.2643 - val_auc: 0.8129 - val_binary_accuracy: 0.9087 - val_loss: 0.2559\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9058 - loss: 0.2639 - val_auc: 0.8117 - val_binary_accuracy: 0.9084 - val_loss: 0.2563\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9129 - loss: 0.2466\n",
      "Fold 2 Metrics: Loss = 0.2563, Accuracy = 0.9084, AUC = 0.8117\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6639 - binary_accuracy: 0.8643 - loss: 0.6035 - val_auc: 0.7813 - val_binary_accuracy: 0.9066 - val_loss: 0.2673\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9042 - loss: 0.2733 - val_auc: 0.7930 - val_binary_accuracy: 0.9078 - val_loss: 0.2642\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9054 - loss: 0.2707 - val_auc: 0.7990 - val_binary_accuracy: 0.9073 - val_loss: 0.2617\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7723 - binary_accuracy: 0.9055 - loss: 0.2689 - val_auc: 0.8002 - val_binary_accuracy: 0.9088 - val_loss: 0.2587\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9066 - loss: 0.2686 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2568\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2682 - val_auc: 0.8021 - val_binary_accuracy: 0.9103 - val_loss: 0.2572\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9059 - loss: 0.2670 - val_auc: 0.8038 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9064 - loss: 0.2652 - val_auc: 0.8028 - val_binary_accuracy: 0.9102 - val_loss: 0.2566\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9071 - loss: 0.2647 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2565\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9075 - loss: 0.2614 - val_auc: 0.8046 - val_binary_accuracy: 0.9091 - val_loss: 0.2583\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7994 - binary_accuracy: 0.9108 - loss: 0.2583\n",
      "Fold 3 Metrics: Loss = 0.2583, Accuracy = 0.9091, AUC = 0.8046\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5694 - binary_accuracy: 0.8304 - loss: 1.5457 - val_auc: 0.7800 - val_binary_accuracy: 0.9056 - val_loss: 0.2700\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7628 - binary_accuracy: 0.9050 - loss: 0.2748 - val_auc: 0.7886 - val_binary_accuracy: 0.9076 - val_loss: 0.2643\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9077 - loss: 0.2698 - val_auc: 0.7945 - val_binary_accuracy: 0.9100 - val_loss: 0.2620\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9082 - loss: 0.2678 - val_auc: 0.7987 - val_binary_accuracy: 0.9101 - val_loss: 0.2602\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9079 - loss: 0.2668 - val_auc: 0.8028 - val_binary_accuracy: 0.9095 - val_loss: 0.2585\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9085 - loss: 0.2658 - val_auc: 0.8057 - val_binary_accuracy: 0.9093 - val_loss: 0.2578\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9085 - loss: 0.2653 - val_auc: 0.8074 - val_binary_accuracy: 0.9095 - val_loss: 0.2566\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.8083 - val_binary_accuracy: 0.9097 - val_loss: 0.2561\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9086 - loss: 0.2635 - val_auc: 0.8092 - val_binary_accuracy: 0.9098 - val_loss: 0.2557\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9086 - loss: 0.2629 - val_auc: 0.8098 - val_binary_accuracy: 0.9093 - val_loss: 0.2554\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7923 - binary_accuracy: 0.9090 - loss: 0.2623\n",
      "Fold 4 Metrics: Loss = 0.2554, Accuracy = 0.9093, AUC = 0.8098\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6531 - binary_accuracy: 0.8927 - loss: 0.4317 - val_auc: 0.7936 - val_binary_accuracy: 0.8969 - val_loss: 0.2813\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7395 - binary_accuracy: 0.9018 - loss: 0.2877 - val_auc: 0.8023 - val_binary_accuracy: 0.8939 - val_loss: 0.2877\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7499 - binary_accuracy: 0.9029 - loss: 0.2835 - val_auc: 0.8056 - val_binary_accuracy: 0.8904 - val_loss: 0.2915\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7577 - binary_accuracy: 0.9043 - loss: 0.2793 - val_auc: 0.8084 - val_binary_accuracy: 0.8942 - val_loss: 0.2893\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9052 - loss: 0.2770 - val_auc: 0.8088 - val_binary_accuracy: 0.8972 - val_loss: 0.2828\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9055 - loss: 0.2751 - val_auc: 0.8097 - val_binary_accuracy: 0.8977 - val_loss: 0.2783\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9063 - loss: 0.2732 - val_auc: 0.8101 - val_binary_accuracy: 0.8997 - val_loss: 0.2738\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9056 - loss: 0.2718 - val_auc: 0.8100 - val_binary_accuracy: 0.9005 - val_loss: 0.2708\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9055 - loss: 0.2708 - val_auc: 0.8100 - val_binary_accuracy: 0.9016 - val_loss: 0.2697\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.8098 - val_binary_accuracy: 0.9017 - val_loss: 0.2687\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8171 - binary_accuracy: 0.9044 - loss: 0.2660\n",
      "Fold 5 Metrics: Loss = 0.2687, Accuracy = 0.9017, AUC = 0.8098\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2614\n",
      "Average Accuracy: 0.9074\n",
      "Average AUC: 0.8064\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 2, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6751 - binary_accuracy: 0.8891 - loss: 0.4576 - val_auc: 0.7801 - val_binary_accuracy: 0.9048 - val_loss: 0.2903\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9071 - loss: 0.2705 - val_auc: 0.7893 - val_binary_accuracy: 0.9072 - val_loss: 0.2758\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9083 - loss: 0.2653 - val_auc: 0.7927 - val_binary_accuracy: 0.9068 - val_loss: 0.2953\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7971 - val_binary_accuracy: 0.9072 - val_loss: 0.2744\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9099 - loss: 0.2589 - val_auc: 0.7995 - val_binary_accuracy: 0.9100 - val_loss: 0.2568\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9128 - loss: 0.2536 - val_auc: 0.7993 - val_binary_accuracy: 0.9085 - val_loss: 0.2695\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9110 - loss: 0.2546 - val_auc: 0.7992 - val_binary_accuracy: 0.9104 - val_loss: 0.2565\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9133 - loss: 0.2506 - val_auc: 0.7986 - val_binary_accuracy: 0.9100 - val_loss: 0.2572\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9129 - loss: 0.2498 - val_auc: 0.7979 - val_binary_accuracy: 0.9109 - val_loss: 0.2608\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9135 - loss: 0.2497 - val_auc: 0.7989 - val_binary_accuracy: 0.9110 - val_loss: 0.2685\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7940 - binary_accuracy: 0.9147 - loss: 0.2639\n",
      "Fold 1 Metrics: Loss = 0.2685, Accuracy = 0.9110, AUC = 0.7989\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6523 - binary_accuracy: 0.8804 - loss: 0.4424 - val_auc: 0.8101 - val_binary_accuracy: 0.9072 - val_loss: 0.2617\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9016 - loss: 0.2777 - val_auc: 0.8124 - val_binary_accuracy: 0.9082 - val_loss: 0.2594\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7771 - binary_accuracy: 0.9039 - loss: 0.2722 - val_auc: 0.8119 - val_binary_accuracy: 0.9069 - val_loss: 0.2695\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7794 - binary_accuracy: 0.9050 - loss: 0.2712 - val_auc: 0.8135 - val_binary_accuracy: 0.9075 - val_loss: 0.2694\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9047 - loss: 0.2728 - val_auc: 0.8077 - val_binary_accuracy: 0.9032 - val_loss: 0.2869\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7746 - binary_accuracy: 0.9046 - loss: 0.2735 - val_auc: 0.8085 - val_binary_accuracy: 0.9062 - val_loss: 0.2697\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7793 - binary_accuracy: 0.9053 - loss: 0.2711 - val_auc: 0.8074 - val_binary_accuracy: 0.9085 - val_loss: 0.2583\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9061 - loss: 0.2668 - val_auc: 0.8010 - val_binary_accuracy: 0.9081 - val_loss: 0.2615\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9065 - loss: 0.2658 - val_auc: 0.8077 - val_binary_accuracy: 0.9097 - val_loss: 0.2575\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7954 - binary_accuracy: 0.9076 - loss: 0.2630 - val_auc: 0.8098 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8171 - binary_accuracy: 0.9121 - loss: 0.2472\n",
      "Fold 2 Metrics: Loss = 0.2560, Accuracy = 0.9090, AUC = 0.8098\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6354 - binary_accuracy: 0.8592 - loss: 1.1882 - val_auc: 0.7836 - val_binary_accuracy: 0.9063 - val_loss: 0.2833\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7343 - binary_accuracy: 0.9017 - loss: 0.2911 - val_auc: 0.7957 - val_binary_accuracy: 0.9054 - val_loss: 0.3158\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7497 - binary_accuracy: 0.9062 - loss: 0.2802 - val_auc: 0.7990 - val_binary_accuracy: 0.9063 - val_loss: 0.3010\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7469 - binary_accuracy: 0.9048 - loss: 0.2840 - val_auc: 0.8028 - val_binary_accuracy: 0.9103 - val_loss: 0.2643\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7557 - binary_accuracy: 0.9056 - loss: 0.2795 - val_auc: 0.8042 - val_binary_accuracy: 0.9079 - val_loss: 0.2603\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9059 - loss: 0.2735 - val_auc: 0.8053 - val_binary_accuracy: 0.9019 - val_loss: 0.2697\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9073 - loss: 0.2696 - val_auc: 0.8050 - val_binary_accuracy: 0.8979 - val_loss: 0.2764\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9063 - loss: 0.2675 - val_auc: 0.8050 - val_binary_accuracy: 0.9032 - val_loss: 0.2713\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9069 - loss: 0.2662 - val_auc: 0.8055 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9075 - loss: 0.2672 - val_auc: 0.8045 - val_binary_accuracy: 0.9106 - val_loss: 0.2564\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9113 - loss: 0.2574\n",
      "Fold 3 Metrics: Loss = 0.2564, Accuracy = 0.9106, AUC = 0.8045\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6163 - binary_accuracy: 0.8575 - loss: 1.0092 - val_auc: 0.7969 - val_binary_accuracy: 0.9069 - val_loss: 0.2687\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9063 - loss: 0.2717 - val_auc: 0.7996 - val_binary_accuracy: 0.9072 - val_loss: 0.2764\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9062 - loss: 0.2717 - val_auc: 0.8056 - val_binary_accuracy: 0.9084 - val_loss: 0.2722\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9072 - loss: 0.2693 - val_auc: 0.8056 - val_binary_accuracy: 0.9093 - val_loss: 0.2649\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9081 - loss: 0.2673 - val_auc: 0.8103 - val_binary_accuracy: 0.9088 - val_loss: 0.2744\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9080 - loss: 0.2664 - val_auc: 0.8102 - val_binary_accuracy: 0.9095 - val_loss: 0.2560\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9096 - loss: 0.2632 - val_auc: 0.8079 - val_binary_accuracy: 0.9090 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9099 - loss: 0.2632 - val_auc: 0.8097 - val_binary_accuracy: 0.9098 - val_loss: 0.2559\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2621 - val_auc: 0.8114 - val_binary_accuracy: 0.9091 - val_loss: 0.2548\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8106 - val_binary_accuracy: 0.9091 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9082 - loss: 0.2627\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9091, AUC = 0.8106\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6018 - binary_accuracy: 0.8659 - loss: 0.8248 - val_auc: 0.7914 - val_binary_accuracy: 0.8991 - val_loss: 0.2734\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7383 - binary_accuracy: 0.9010 - loss: 0.2886 - val_auc: 0.8022 - val_binary_accuracy: 0.8964 - val_loss: 0.2739\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7462 - binary_accuracy: 0.9019 - loss: 0.2855 - val_auc: 0.8053 - val_binary_accuracy: 0.8974 - val_loss: 0.2661\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7504 - binary_accuracy: 0.9025 - loss: 0.2836 - val_auc: 0.8068 - val_binary_accuracy: 0.8948 - val_loss: 0.2792\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7560 - binary_accuracy: 0.9043 - loss: 0.2796 - val_auc: 0.8080 - val_binary_accuracy: 0.8963 - val_loss: 0.2804\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9047 - loss: 0.2770 - val_auc: 0.8085 - val_binary_accuracy: 0.8954 - val_loss: 0.2792\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9050 - loss: 0.2745 - val_auc: 0.8091 - val_binary_accuracy: 0.8986 - val_loss: 0.2732\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9049 - loss: 0.2723 - val_auc: 0.8096 - val_binary_accuracy: 0.9004 - val_loss: 0.2684\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9050 - loss: 0.2709 - val_auc: 0.8097 - val_binary_accuracy: 0.9047 - val_loss: 0.2630\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9055 - loss: 0.2689 - val_auc: 0.8094 - val_binary_accuracy: 0.9036 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9055 - loss: 0.2615\n",
      "Fold 5 Metrics: Loss = 0.2635, Accuracy = 0.9036, AUC = 0.8094\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2599\n",
      "Average Accuracy: 0.9087\n",
      "Average AUC: 0.8066\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 2, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6504 - binary_accuracy: 0.8786 - loss: 0.5864 - val_auc: 0.7817 - val_binary_accuracy: 0.9090 - val_loss: 0.2642\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7497 - binary_accuracy: 0.9061 - loss: 0.2797 - val_auc: 0.7915 - val_binary_accuracy: 0.9097 - val_loss: 0.2596\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9094 - loss: 0.2658 - val_auc: 0.7916 - val_binary_accuracy: 0.9096 - val_loss: 0.2672\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9096 - loss: 0.2645 - val_auc: 0.7939 - val_binary_accuracy: 0.9072 - val_loss: 0.2882\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9106 - loss: 0.2604 - val_auc: 0.7954 - val_binary_accuracy: 0.9075 - val_loss: 0.2800\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9101 - loss: 0.2594 - val_auc: 0.7972 - val_binary_accuracy: 0.9106 - val_loss: 0.2575\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9119 - loss: 0.2534 - val_auc: 0.7982 - val_binary_accuracy: 0.9110 - val_loss: 0.2569\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9129 - loss: 0.2515 - val_auc: 0.7977 - val_binary_accuracy: 0.9118 - val_loss: 0.2590\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9126 - loss: 0.2512 - val_auc: 0.7983 - val_binary_accuracy: 0.9115 - val_loss: 0.2604\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9129 - loss: 0.2498 - val_auc: 0.7975 - val_binary_accuracy: 0.9100 - val_loss: 0.2641\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7943 - binary_accuracy: 0.9126 - loss: 0.2593\n",
      "Fold 1 Metrics: Loss = 0.2641, Accuracy = 0.9100, AUC = 0.7975\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6451 - binary_accuracy: 0.8699 - loss: 0.7414 - val_auc: 0.8049 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9026 - loss: 0.2829 - val_auc: 0.8066 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9054 - loss: 0.2741 - val_auc: 0.8084 - val_binary_accuracy: 0.9090 - val_loss: 0.2603\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9047 - loss: 0.2715 - val_auc: 0.8099 - val_binary_accuracy: 0.9093 - val_loss: 0.2710\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9046 - loss: 0.2708 - val_auc: 0.8078 - val_binary_accuracy: 0.9068 - val_loss: 0.2784\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.8036 - val_binary_accuracy: 0.9097 - val_loss: 0.2598\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9065 - loss: 0.2692 - val_auc: 0.8046 - val_binary_accuracy: 0.9094 - val_loss: 0.2610\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9070 - loss: 0.2643 - val_auc: 0.8036 - val_binary_accuracy: 0.9099 - val_loss: 0.2586\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9073 - loss: 0.2626 - val_auc: 0.8043 - val_binary_accuracy: 0.9099 - val_loss: 0.2599\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9074 - loss: 0.2612 - val_auc: 0.7874 - val_binary_accuracy: 0.9091 - val_loss: 0.2646\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7999 - binary_accuracy: 0.9126 - loss: 0.2546\n",
      "Fold 2 Metrics: Loss = 0.2646, Accuracy = 0.9091, AUC = 0.7874\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6312 - binary_accuracy: 0.8660 - loss: 1.1762 - val_auc: 0.7974 - val_binary_accuracy: 0.9044 - val_loss: 0.2904\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7125 - binary_accuracy: 0.8964 - loss: 0.3124 - val_auc: 0.8023 - val_binary_accuracy: 0.9088 - val_loss: 0.2753\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7300 - binary_accuracy: 0.9011 - loss: 0.2977 - val_auc: 0.8039 - val_binary_accuracy: 0.9102 - val_loss: 0.2717\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7544 - binary_accuracy: 0.9030 - loss: 0.2803 - val_auc: 0.8034 - val_binary_accuracy: 0.9109 - val_loss: 0.2582\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7682 - binary_accuracy: 0.9053 - loss: 0.2721 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2785\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9056 - loss: 0.2778 - val_auc: 0.8070 - val_binary_accuracy: 0.9029 - val_loss: 0.2728\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9071 - loss: 0.2688 - val_auc: 0.8083 - val_binary_accuracy: 0.9048 - val_loss: 0.2672\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9059 - loss: 0.2665 - val_auc: 0.8085 - val_binary_accuracy: 0.9102 - val_loss: 0.2558\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9066 - loss: 0.2673 - val_auc: 0.8046 - val_binary_accuracy: 0.9115 - val_loss: 0.2581\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9060 - loss: 0.2694 - val_auc: 0.8055 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7987 - binary_accuracy: 0.9127 - loss: 0.2570\n",
      "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9109, AUC = 0.8055\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6304 - binary_accuracy: 0.8679 - loss: 0.8913 - val_auc: 0.7991 - val_binary_accuracy: 0.9059 - val_loss: 0.2620\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7455 - binary_accuracy: 0.9030 - loss: 0.2861 - val_auc: 0.8030 - val_binary_accuracy: 0.8994 - val_loss: 0.2697\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7504 - binary_accuracy: 0.9039 - loss: 0.2830 - val_auc: 0.8068 - val_binary_accuracy: 0.9036 - val_loss: 0.2613\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7532 - binary_accuracy: 0.9046 - loss: 0.2829 - val_auc: 0.8096 - val_binary_accuracy: 0.9062 - val_loss: 0.2562\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9077 - loss: 0.2700 - val_auc: 0.8097 - val_binary_accuracy: 0.9097 - val_loss: 0.2577\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9083 - loss: 0.2682 - val_auc: 0.8111 - val_binary_accuracy: 0.9087 - val_loss: 0.2879\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9082 - loss: 0.2706 - val_auc: 0.8127 - val_binary_accuracy: 0.9098 - val_loss: 0.2601\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9086 - loss: 0.2642 - val_auc: 0.8118 - val_binary_accuracy: 0.9097 - val_loss: 0.2550\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9096 - loss: 0.2642 - val_auc: 0.8109 - val_binary_accuracy: 0.9079 - val_loss: 0.2547\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9090 - loss: 0.2631 - val_auc: 0.8117 - val_binary_accuracy: 0.9097 - val_loss: 0.2546\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7939 - binary_accuracy: 0.9087 - loss: 0.2618\n",
      "Fold 4 Metrics: Loss = 0.2546, Accuracy = 0.9097, AUC = 0.8117\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6253 - binary_accuracy: 0.8703 - loss: 0.8894 - val_auc: 0.7991 - val_binary_accuracy: 0.9020 - val_loss: 0.2607\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7261 - binary_accuracy: 0.8994 - loss: 0.2994 - val_auc: 0.8043 - val_binary_accuracy: 0.8976 - val_loss: 0.2687\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7441 - binary_accuracy: 0.9007 - loss: 0.2874 - val_auc: 0.8064 - val_binary_accuracy: 0.8941 - val_loss: 0.2824\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7505 - binary_accuracy: 0.9025 - loss: 0.2835 - val_auc: 0.8074 - val_binary_accuracy: 0.8932 - val_loss: 0.2816\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9044 - loss: 0.2779 - val_auc: 0.8087 - val_binary_accuracy: 0.8955 - val_loss: 0.2819\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7670 - binary_accuracy: 0.9047 - loss: 0.2749 - val_auc: 0.8082 - val_binary_accuracy: 0.8997 - val_loss: 0.2742\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9046 - loss: 0.2726 - val_auc: 0.8087 - val_binary_accuracy: 0.8982 - val_loss: 0.2733\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9045 - loss: 0.2717 - val_auc: 0.8086 - val_binary_accuracy: 0.9028 - val_loss: 0.2651\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9049 - loss: 0.2713 - val_auc: 0.8088 - val_binary_accuracy: 0.9091 - val_loss: 0.2544\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9082 - loss: 0.2678 - val_auc: 0.8098 - val_binary_accuracy: 0.9103 - val_loss: 0.2518\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9092 - loss: 0.2512\n",
      "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9103, AUC = 0.8098\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2584\n",
      "Average Accuracy: 0.9100\n",
      "Average AUC: 0.8024\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 3, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6665 - binary_accuracy: 0.8809 - loss: 0.3548 - val_auc: 0.7707 - val_binary_accuracy: 0.9053 - val_loss: 0.2720\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9099 - loss: 0.2599 - val_auc: 0.7797 - val_binary_accuracy: 0.9054 - val_loss: 0.2697\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9112 - loss: 0.2573 - val_auc: 0.7813 - val_binary_accuracy: 0.9088 - val_loss: 0.2655\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9124 - loss: 0.2552 - val_auc: 0.7835 - val_binary_accuracy: 0.9094 - val_loss: 0.2650\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9120 - loss: 0.2541 - val_auc: 0.7842 - val_binary_accuracy: 0.9097 - val_loss: 0.2642\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9124 - loss: 0.2531 - val_auc: 0.7844 - val_binary_accuracy: 0.9082 - val_loss: 0.2656\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9124 - loss: 0.2528 - val_auc: 0.7838 - val_binary_accuracy: 0.9084 - val_loss: 0.2655\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9131 - loss: 0.2516 - val_auc: 0.7850 - val_binary_accuracy: 0.9087 - val_loss: 0.2645\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9131 - loss: 0.2506 - val_auc: 0.7873 - val_binary_accuracy: 0.9084 - val_loss: 0.2631\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9137 - loss: 0.2498 - val_auc: 0.7884 - val_binary_accuracy: 0.9090 - val_loss: 0.2616\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7839 - binary_accuracy: 0.9112 - loss: 0.2553\n",
      "Fold 1 Metrics: Loss = 0.2616, Accuracy = 0.9090, AUC = 0.7884\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6155 - binary_accuracy: 0.6510 - loss: 4.1405 - val_auc: 0.7794 - val_binary_accuracy: 0.9062 - val_loss: 0.2693\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9053 - loss: 0.2719 - val_auc: 0.7858 - val_binary_accuracy: 0.9066 - val_loss: 0.2671\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9056 - loss: 0.2693 - val_auc: 0.7872 - val_binary_accuracy: 0.9069 - val_loss: 0.2670\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9059 - loss: 0.2673 - val_auc: 0.7906 - val_binary_accuracy: 0.9073 - val_loss: 0.2652\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9057 - loss: 0.2665 - val_auc: 0.7928 - val_binary_accuracy: 0.9071 - val_loss: 0.2647\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9060 - loss: 0.2655 - val_auc: 0.7938 - val_binary_accuracy: 0.9075 - val_loss: 0.2648\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9067 - loss: 0.2648 - val_auc: 0.7987 - val_binary_accuracy: 0.9082 - val_loss: 0.2628\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9065 - loss: 0.2640 - val_auc: 0.7981 - val_binary_accuracy: 0.9081 - val_loss: 0.2629\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9069 - loss: 0.2633 - val_auc: 0.7996 - val_binary_accuracy: 0.9082 - val_loss: 0.2611\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9071 - loss: 0.2624 - val_auc: 0.8021 - val_binary_accuracy: 0.9084 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8058 - binary_accuracy: 0.9120 - loss: 0.2503\n",
      "Fold 2 Metrics: Loss = 0.2599, Accuracy = 0.9084, AUC = 0.8021\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5921 - binary_accuracy: 0.8004 - loss: 0.7227 - val_auc: 0.7783 - val_binary_accuracy: 0.9045 - val_loss: 0.2729\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9058 - loss: 0.2708 - val_auc: 0.7856 - val_binary_accuracy: 0.9045 - val_loss: 0.2701\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.7903 - val_binary_accuracy: 0.9056 - val_loss: 0.2687\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9070 - loss: 0.2667 - val_auc: 0.7940 - val_binary_accuracy: 0.9059 - val_loss: 0.2657\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9072 - loss: 0.2661 - val_auc: 0.7964 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9076 - loss: 0.2651 - val_auc: 0.7981 - val_binary_accuracy: 0.9097 - val_loss: 0.2615\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9085 - loss: 0.2648 - val_auc: 0.7985 - val_binary_accuracy: 0.9104 - val_loss: 0.2605\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9091 - loss: 0.2640 - val_auc: 0.7985 - val_binary_accuracy: 0.9107 - val_loss: 0.2604\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.7994 - val_binary_accuracy: 0.9112 - val_loss: 0.2601\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9092 - loss: 0.2630 - val_auc: 0.7999 - val_binary_accuracy: 0.9118 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9134 - loss: 0.2596\n",
      "Fold 3 Metrics: Loss = 0.2599, Accuracy = 0.9118, AUC = 0.7999\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5840 - binary_accuracy: 0.9036 - loss: 0.6592 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2716\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9041 - loss: 0.2733 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9053 - loss: 0.2686 - val_auc: 0.7917 - val_binary_accuracy: 0.9047 - val_loss: 0.2635\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9066 - loss: 0.2660 - val_auc: 0.7953 - val_binary_accuracy: 0.9069 - val_loss: 0.2616\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.7974 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9084 - loss: 0.2631 - val_auc: 0.7989 - val_binary_accuracy: 0.9087 - val_loss: 0.2593\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9092 - loss: 0.2622 - val_auc: 0.8015 - val_binary_accuracy: 0.9098 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9099 - loss: 0.2614 - val_auc: 0.8030 - val_binary_accuracy: 0.9100 - val_loss: 0.2574\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.8052 - val_binary_accuracy: 0.9106 - val_loss: 0.2567\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9099 - loss: 0.2600 - val_auc: 0.8075 - val_binary_accuracy: 0.9101 - val_loss: 0.2560\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7887 - binary_accuracy: 0.9099 - loss: 0.2617\n",
      "Fold 4 Metrics: Loss = 0.2560, Accuracy = 0.9101, AUC = 0.8075\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6327 - binary_accuracy: 0.9013 - loss: 0.3295 - val_auc: 0.7975 - val_binary_accuracy: 0.9050 - val_loss: 0.2635\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9047 - loss: 0.2742 - val_auc: 0.8009 - val_binary_accuracy: 0.9054 - val_loss: 0.2606\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9044 - loss: 0.2713 - val_auc: 0.8029 - val_binary_accuracy: 0.9048 - val_loss: 0.2600\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9054 - loss: 0.2696 - val_auc: 0.8037 - val_binary_accuracy: 0.9060 - val_loss: 0.2603\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9063 - loss: 0.2679 - val_auc: 0.8051 - val_binary_accuracy: 0.9064 - val_loss: 0.2612\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9065 - loss: 0.2664 - val_auc: 0.8060 - val_binary_accuracy: 0.9070 - val_loss: 0.2612\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9067 - loss: 0.2652 - val_auc: 0.8068 - val_binary_accuracy: 0.9073 - val_loss: 0.2614\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9071 - loss: 0.2646 - val_auc: 0.8073 - val_binary_accuracy: 0.9060 - val_loss: 0.2625\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9074 - loss: 0.2641 - val_auc: 0.8077 - val_binary_accuracy: 0.9062 - val_loss: 0.2635\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8081 - val_binary_accuracy: 0.9056 - val_loss: 0.2646\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8173 - binary_accuracy: 0.9061 - loss: 0.2620\n",
      "Fold 5 Metrics: Loss = 0.2646, Accuracy = 0.9056, AUC = 0.8081\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2604\n",
      "Average Accuracy: 0.9090\n",
      "Average AUC: 0.8012\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 3, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - auc: 0.5937 - binary_accuracy: 0.8173 - loss: 0.9928 - val_auc: 0.7537 - val_binary_accuracy: 0.9044 - val_loss: 0.2783\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9072 - loss: 0.2688 - val_auc: 0.7666 - val_binary_accuracy: 0.9051 - val_loss: 0.2734\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9082 - loss: 0.2637 - val_auc: 0.7752 - val_binary_accuracy: 0.9060 - val_loss: 0.2701\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9094 - loss: 0.2592 - val_auc: 0.7817 - val_binary_accuracy: 0.9075 - val_loss: 0.2679\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9099 - loss: 0.2582 - val_auc: 0.7860 - val_binary_accuracy: 0.9063 - val_loss: 0.2665\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9105 - loss: 0.2556 - val_auc: 0.7906 - val_binary_accuracy: 0.9078 - val_loss: 0.2641\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9114 - loss: 0.2535 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2627\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9114 - loss: 0.2525 - val_auc: 0.7919 - val_binary_accuracy: 0.9099 - val_loss: 0.2621\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8050 - binary_accuracy: 0.9117 - loss: 0.2514 - val_auc: 0.7944 - val_binary_accuracy: 0.9096 - val_loss: 0.2622\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8067 - binary_accuracy: 0.9119 - loss: 0.2506 - val_auc: 0.7947 - val_binary_accuracy: 0.9096 - val_loss: 0.2614\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9130 - loss: 0.2529\n",
      "Fold 1 Metrics: Loss = 0.2614, Accuracy = 0.9096, AUC = 0.7947\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6341 - binary_accuracy: 0.8556 - loss: 0.5990 - val_auc: 0.7921 - val_binary_accuracy: 0.9081 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9058 - loss: 0.2726 - val_auc: 0.8011 - val_binary_accuracy: 0.9071 - val_loss: 0.2636\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9061 - loss: 0.2684 - val_auc: 0.8076 - val_binary_accuracy: 0.9081 - val_loss: 0.2601\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9073 - loss: 0.2658 - val_auc: 0.8074 - val_binary_accuracy: 0.9088 - val_loss: 0.2601\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9070 - loss: 0.2646 - val_auc: 0.7926 - val_binary_accuracy: 0.9088 - val_loss: 0.2640\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9066 - loss: 0.2638 - val_auc: 0.8001 - val_binary_accuracy: 0.9097 - val_loss: 0.2617\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7975 - binary_accuracy: 0.9074 - loss: 0.2621 - val_auc: 0.8042 - val_binary_accuracy: 0.9097 - val_loss: 0.2602\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9077 - loss: 0.2613 - val_auc: 0.7962 - val_binary_accuracy: 0.9100 - val_loss: 0.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9077 - loss: 0.2617 - val_auc: 0.7965 - val_binary_accuracy: 0.9096 - val_loss: 0.2630\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9080 - loss: 0.2611 - val_auc: 0.8082 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8139 - binary_accuracy: 0.9123 - loss: 0.2519\n",
      "Fold 2 Metrics: Loss = 0.2608, Accuracy = 0.9078, AUC = 0.8082\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7358 - binary_accuracy: 0.9028 - loss: 0.2868 - val_auc: 0.7793 - val_binary_accuracy: 0.9050 - val_loss: 0.2715\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7651 - binary_accuracy: 0.9059 - loss: 0.2716 - val_auc: 0.7876 - val_binary_accuracy: 0.9065 - val_loss: 0.2706\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9080 - loss: 0.2672 - val_auc: 0.7938 - val_binary_accuracy: 0.9034 - val_loss: 0.2710\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9079 - loss: 0.2655 - val_auc: 0.7952 - val_binary_accuracy: 0.9066 - val_loss: 0.2670\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9085 - loss: 0.2657 - val_auc: 0.7968 - val_binary_accuracy: 0.9038 - val_loss: 0.2660\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9086 - loss: 0.2650 - val_auc: 0.7997 - val_binary_accuracy: 0.9056 - val_loss: 0.2631\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9088 - loss: 0.2656 - val_auc: 0.8009 - val_binary_accuracy: 0.9087 - val_loss: 0.2597\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9090 - loss: 0.2644 - val_auc: 0.8020 - val_binary_accuracy: 0.9047 - val_loss: 0.2618\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9090 - loss: 0.2648 - val_auc: 0.8026 - val_binary_accuracy: 0.9063 - val_loss: 0.2604\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9094 - loss: 0.2647 - val_auc: 0.8032 - val_binary_accuracy: 0.9094 - val_loss: 0.2573\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7966 - binary_accuracy: 0.9113 - loss: 0.2573\n",
      "Fold 3 Metrics: Loss = 0.2573, Accuracy = 0.9094, AUC = 0.8032\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6065 - binary_accuracy: 0.8294 - loss: 0.9768 - val_auc: 0.7830 - val_binary_accuracy: 0.9060 - val_loss: 0.2673\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9069 - loss: 0.2726 - val_auc: 0.7948 - val_binary_accuracy: 0.9094 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9085 - loss: 0.2673 - val_auc: 0.7999 - val_binary_accuracy: 0.9093 - val_loss: 0.2596\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9090 - loss: 0.2647 - val_auc: 0.8028 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9095 - loss: 0.2630 - val_auc: 0.8046 - val_binary_accuracy: 0.9091 - val_loss: 0.2571\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8064 - val_binary_accuracy: 0.9088 - val_loss: 0.2565\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9100 - loss: 0.2608 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2561\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9101 - loss: 0.2604 - val_auc: 0.8080 - val_binary_accuracy: 0.9078 - val_loss: 0.2560\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9098 - loss: 0.2601 - val_auc: 0.8078 - val_binary_accuracy: 0.9073 - val_loss: 0.2560\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9105 - loss: 0.2591 - val_auc: 0.8093 - val_binary_accuracy: 0.9067 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7920 - binary_accuracy: 0.9055 - loss: 0.2624\n",
      "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9067, AUC = 0.8093\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6545 - binary_accuracy: 0.8859 - loss: 0.3953 - val_auc: 0.7898 - val_binary_accuracy: 0.9073 - val_loss: 0.2651\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7587 - binary_accuracy: 0.9047 - loss: 0.2773 - val_auc: 0.7965 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7628 - binary_accuracy: 0.9048 - loss: 0.2751 - val_auc: 0.8017 - val_binary_accuracy: 0.9093 - val_loss: 0.2603\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7659 - binary_accuracy: 0.9043 - loss: 0.2730 - val_auc: 0.8038 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9056 - loss: 0.2703 - val_auc: 0.8052 - val_binary_accuracy: 0.9097 - val_loss: 0.2551\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9068 - loss: 0.2681 - val_auc: 0.8063 - val_binary_accuracy: 0.9094 - val_loss: 0.2535\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9077 - loss: 0.2662 - val_auc: 0.8072 - val_binary_accuracy: 0.9101 - val_loss: 0.2548\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9082 - loss: 0.2650 - val_auc: 0.8072 - val_binary_accuracy: 0.9066 - val_loss: 0.2581\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8079 - val_binary_accuracy: 0.9076 - val_loss: 0.2598\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.8072 - val_binary_accuracy: 0.9007 - val_loss: 0.2656\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8175 - binary_accuracy: 0.9040 - loss: 0.2620\n",
      "Fold 5 Metrics: Loss = 0.2656, Accuracy = 0.9007, AUC = 0.8072\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2602\n",
      "Average Accuracy: 0.9068\n",
      "Average AUC: 0.8045\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 3, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6956 - binary_accuracy: 0.8981 - loss: 0.3256 - val_auc: 0.7753 - val_binary_accuracy: 0.9066 - val_loss: 0.2714\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9109 - loss: 0.2643 - val_auc: 0.7793 - val_binary_accuracy: 0.9051 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9109 - loss: 0.2587 - val_auc: 0.7843 - val_binary_accuracy: 0.9053 - val_loss: 0.2744\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9102 - loss: 0.2562 - val_auc: 0.7861 - val_binary_accuracy: 0.9076 - val_loss: 0.2693\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9111 - loss: 0.2540 - val_auc: 0.7888 - val_binary_accuracy: 0.9091 - val_loss: 0.2610\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9134 - loss: 0.2522 - val_auc: 0.7873 - val_binary_accuracy: 0.9088 - val_loss: 0.2628\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9128 - loss: 0.2523 - val_auc: 0.7875 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9132 - loss: 0.2509 - val_auc: 0.7874 - val_binary_accuracy: 0.9081 - val_loss: 0.2658\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9125 - loss: 0.2510 - val_auc: 0.7905 - val_binary_accuracy: 0.9078 - val_loss: 0.2643\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9126 - loss: 0.2500 - val_auc: 0.7934 - val_binary_accuracy: 0.9087 - val_loss: 0.2630\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7922 - binary_accuracy: 0.9116 - loss: 0.2540\n",
      "Fold 1 Metrics: Loss = 0.2630, Accuracy = 0.9087, AUC = 0.7934\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6361 - binary_accuracy: 0.8670 - loss: 0.5392 - val_auc: 0.7902 - val_binary_accuracy: 0.9072 - val_loss: 0.2664\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9043 - loss: 0.2703 - val_auc: 0.7981 - val_binary_accuracy: 0.9079 - val_loss: 0.2626\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9057 - loss: 0.2677 - val_auc: 0.8008 - val_binary_accuracy: 0.9084 - val_loss: 0.2616\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9062 - loss: 0.2668 - val_auc: 0.7989 - val_binary_accuracy: 0.9099 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9065 - loss: 0.2667 - val_auc: 0.8062 - val_binary_accuracy: 0.9097 - val_loss: 0.2585\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9079 - loss: 0.2630 - val_auc: 0.8099 - val_binary_accuracy: 0.9097 - val_loss: 0.2600\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9078 - loss: 0.2615 - val_auc: 0.8086 - val_binary_accuracy: 0.9085 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9077 - loss: 0.2622 - val_auc: 0.8068 - val_binary_accuracy: 0.9099 - val_loss: 0.2579\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9086 - loss: 0.2605 - val_auc: 0.7886 - val_binary_accuracy: 0.9085 - val_loss: 0.2636\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9079 - loss: 0.2608 - val_auc: 0.8095 - val_binary_accuracy: 0.9084 - val_loss: 0.2578\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9133 - loss: 0.2487\n",
      "Fold 2 Metrics: Loss = 0.2578, Accuracy = 0.9084, AUC = 0.8095\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5923 - binary_accuracy: 0.8422 - loss: 1.5019 - val_auc: 0.7845 - val_binary_accuracy: 0.9094 - val_loss: 0.2713\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9060 - loss: 0.2708 - val_auc: 0.7917 - val_binary_accuracy: 0.9102 - val_loss: 0.2628\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9057 - loss: 0.2703 - val_auc: 0.7971 - val_binary_accuracy: 0.9103 - val_loss: 0.2601\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9060 - loss: 0.2695 - val_auc: 0.7996 - val_binary_accuracy: 0.9106 - val_loss: 0.2588\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9062 - loss: 0.2684 - val_auc: 0.8010 - val_binary_accuracy: 0.9107 - val_loss: 0.2581\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9062 - loss: 0.2660 - val_auc: 0.8041 - val_binary_accuracy: 0.9104 - val_loss: 0.2568\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9076 - loss: 0.2639 - val_auc: 0.8044 - val_binary_accuracy: 0.9107 - val_loss: 0.2583\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9084 - loss: 0.2621 - val_auc: 0.8048 - val_binary_accuracy: 0.9100 - val_loss: 0.2609\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.8040 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9087 - loss: 0.2611 - val_auc: 0.8040 - val_binary_accuracy: 0.9071 - val_loss: 0.2631\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7953 - binary_accuracy: 0.9070 - loss: 0.2647\n",
      "Fold 3 Metrics: Loss = 0.2631, Accuracy = 0.9071, AUC = 0.8040\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6367 - binary_accuracy: 0.8423 - loss: 0.8825 - val_auc: 0.7859 - val_binary_accuracy: 0.9056 - val_loss: 0.2670\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9066 - loss: 0.2724 - val_auc: 0.7916 - val_binary_accuracy: 0.9063 - val_loss: 0.2652\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9070 - loss: 0.2686 - val_auc: 0.7988 - val_binary_accuracy: 0.9063 - val_loss: 0.2617\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9069 - loss: 0.2664 - val_auc: 0.8009 - val_binary_accuracy: 0.9079 - val_loss: 0.2597\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9078 - loss: 0.2651 - val_auc: 0.8030 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9088 - loss: 0.2630 - val_auc: 0.8057 - val_binary_accuracy: 0.9067 - val_loss: 0.2583\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9096 - loss: 0.2612 - val_auc: 0.8065 - val_binary_accuracy: 0.9060 - val_loss: 0.2581\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9094 - loss: 0.2607 - val_auc: 0.8071 - val_binary_accuracy: 0.9054 - val_loss: 0.2576\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9095 - loss: 0.2596 - val_auc: 0.8063 - val_binary_accuracy: 0.9029 - val_loss: 0.2584\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9096 - loss: 0.2590 - val_auc: 0.8078 - val_binary_accuracy: 0.9045 - val_loss: 0.2571\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7888 - binary_accuracy: 0.9034 - loss: 0.2643\n",
      "Fold 4 Metrics: Loss = 0.2571, Accuracy = 0.9045, AUC = 0.8078\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6077 - binary_accuracy: 0.8418 - loss: 1.1925 - val_auc: 0.7915 - val_binary_accuracy: 0.9060 - val_loss: 0.2669\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9026 - loss: 0.2794 - val_auc: 0.7980 - val_binary_accuracy: 0.9013 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7592 - binary_accuracy: 0.9033 - loss: 0.2775 - val_auc: 0.8011 - val_binary_accuracy: 0.9022 - val_loss: 0.2667\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9039 - loss: 0.2756 - val_auc: 0.8030 - val_binary_accuracy: 0.9059 - val_loss: 0.2590\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9045 - loss: 0.2732 - val_auc: 0.8042 - val_binary_accuracy: 0.9073 - val_loss: 0.2569\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9055 - loss: 0.2711 - val_auc: 0.8046 - val_binary_accuracy: 0.9095 - val_loss: 0.2549\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9066 - loss: 0.2716 - val_auc: 0.8053 - val_binary_accuracy: 0.9082 - val_loss: 0.2546\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9071 - loss: 0.2672 - val_auc: 0.8060 - val_binary_accuracy: 0.9079 - val_loss: 0.2548\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9076 - loss: 0.2658 - val_auc: 0.8058 - val_binary_accuracy: 0.9101 - val_loss: 0.2537\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9083 - loss: 0.2641 - val_auc: 0.8068 - val_binary_accuracy: 0.9091 - val_loss: 0.2604\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9103 - loss: 0.2588\n",
      "Fold 5 Metrics: Loss = 0.2604, Accuracy = 0.9091, AUC = 0.8068\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2603\n",
      "Average Accuracy: 0.9075\n",
      "Average AUC: 0.8043\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 3, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6620 - binary_accuracy: 0.8833 - loss: 0.4496 - val_auc: 0.7799 - val_binary_accuracy: 0.9063 - val_loss: 0.2659\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9081 - loss: 0.2658 - val_auc: 0.7848 - val_binary_accuracy: 0.9094 - val_loss: 0.2648\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9113 - loss: 0.2585 - val_auc: 0.7904 - val_binary_accuracy: 0.9099 - val_loss: 0.2627\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9116 - loss: 0.2551 - val_auc: 0.7899 - val_binary_accuracy: 0.9099 - val_loss: 0.2674\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9122 - loss: 0.2547 - val_auc: 0.7905 - val_binary_accuracy: 0.9116 - val_loss: 0.2607\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9130 - loss: 0.2520 - val_auc: 0.7956 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9134 - loss: 0.2508 - val_auc: 0.7931 - val_binary_accuracy: 0.9091 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9132 - loss: 0.2502 - val_auc: 0.7965 - val_binary_accuracy: 0.9094 - val_loss: 0.2582\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9127 - loss: 0.2493 - val_auc: 0.7941 - val_binary_accuracy: 0.9084 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9126 - loss: 0.2507 - val_auc: 0.7925 - val_binary_accuracy: 0.9078 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2541\n",
      "Fold 1 Metrics: Loss = 0.2635, Accuracy = 0.9078, AUC = 0.7925\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6600 - binary_accuracy: 0.8773 - loss: 0.4980 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7620 - binary_accuracy: 0.9007 - loss: 0.2799 - val_auc: 0.8084 - val_binary_accuracy: 0.9075 - val_loss: 0.2741\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9035 - loss: 0.2776 - val_auc: 0.8099 - val_binary_accuracy: 0.9087 - val_loss: 0.2728\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9048 - loss: 0.2731 - val_auc: 0.8094 - val_binary_accuracy: 0.9090 - val_loss: 0.2603\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9072 - loss: 0.2662 - val_auc: 0.8081 - val_binary_accuracy: 0.9085 - val_loss: 0.2601\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9079 - loss: 0.2648 - val_auc: 0.8067 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9073 - loss: 0.2640 - val_auc: 0.8100 - val_binary_accuracy: 0.9093 - val_loss: 0.2604\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9082 - loss: 0.2621 - val_auc: 0.8084 - val_binary_accuracy: 0.9088 - val_loss: 0.2623\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9086 - loss: 0.2616 - val_auc: 0.8096 - val_binary_accuracy: 0.9091 - val_loss: 0.2619\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9087 - loss: 0.2606 - val_auc: 0.8117 - val_binary_accuracy: 0.9094 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9136 - loss: 0.2495\n",
      "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9094, AUC = 0.8117\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6791 - binary_accuracy: 0.8861 - loss: 0.3834 - val_auc: 0.7818 - val_binary_accuracy: 0.9048 - val_loss: 0.2699\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7358 - binary_accuracy: 0.9021 - loss: 0.2882 - val_auc: 0.7873 - val_binary_accuracy: 0.9094 - val_loss: 0.2638\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9046 - loss: 0.2724 - val_auc: 0.7951 - val_binary_accuracy: 0.9096 - val_loss: 0.2608\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9066 - loss: 0.2682 - val_auc: 0.7976 - val_binary_accuracy: 0.9082 - val_loss: 0.2660\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9086 - loss: 0.2634 - val_auc: 0.7979 - val_binary_accuracy: 0.9106 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9092 - loss: 0.2634 - val_auc: 0.7986 - val_binary_accuracy: 0.9090 - val_loss: 0.2644\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9092 - loss: 0.2627 - val_auc: 0.8002 - val_binary_accuracy: 0.9096 - val_loss: 0.2616\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8004 - val_binary_accuracy: 0.9109 - val_loss: 0.2614\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9106 - loss: 0.2622 - val_auc: 0.8011 - val_binary_accuracy: 0.9112 - val_loss: 0.2604\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9095 - loss: 0.2622 - val_auc: 0.8030 - val_binary_accuracy: 0.9112 - val_loss: 0.2607\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7959 - binary_accuracy: 0.9136 - loss: 0.2612\n",
      "Fold 3 Metrics: Loss = 0.2607, Accuracy = 0.9112, AUC = 0.8030\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6388 - binary_accuracy: 0.8631 - loss: 0.8942 - val_auc: 0.7867 - val_binary_accuracy: 0.9048 - val_loss: 0.2682\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9056 - loss: 0.2752 - val_auc: 0.7949 - val_binary_accuracy: 0.9082 - val_loss: 0.2619\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9076 - loss: 0.2698 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2594\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9079 - loss: 0.2675 - val_auc: 0.8062 - val_binary_accuracy: 0.9093 - val_loss: 0.2566\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9082 - loss: 0.2656 - val_auc: 0.8061 - val_binary_accuracy: 0.9094 - val_loss: 0.2567\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9089 - loss: 0.2627 - val_auc: 0.8084 - val_binary_accuracy: 0.9094 - val_loss: 0.2554\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9092 - loss: 0.2613 - val_auc: 0.8066 - val_binary_accuracy: 0.9081 - val_loss: 0.2564\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9097 - loss: 0.2597 - val_auc: 0.8074 - val_binary_accuracy: 0.9087 - val_loss: 0.2563\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9098 - loss: 0.2596 - val_auc: 0.8103 - val_binary_accuracy: 0.9082 - val_loss: 0.2549\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9098 - loss: 0.2587 - val_auc: 0.8091 - val_binary_accuracy: 0.9084 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7912 - binary_accuracy: 0.9070 - loss: 0.2622\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9084, AUC = 0.8091\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6449 - binary_accuracy: 0.8789 - loss: 0.6324 - val_auc: 0.7935 - val_binary_accuracy: 0.8997 - val_loss: 0.2774\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7408 - binary_accuracy: 0.9024 - loss: 0.2866 - val_auc: 0.7989 - val_binary_accuracy: 0.8995 - val_loss: 0.2754\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9037 - loss: 0.2780 - val_auc: 0.8015 - val_binary_accuracy: 0.8991 - val_loss: 0.2727\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9040 - loss: 0.2746 - val_auc: 0.8044 - val_binary_accuracy: 0.9035 - val_loss: 0.2653\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9039 - loss: 0.2743 - val_auc: 0.8053 - val_binary_accuracy: 0.9091 - val_loss: 0.2541\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9058 - loss: 0.2716 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2536\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9079 - loss: 0.2663 - val_auc: 0.8048 - val_binary_accuracy: 0.9078 - val_loss: 0.2582\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9072 - loss: 0.2669 - val_auc: 0.8068 - val_binary_accuracy: 0.9066 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9074 - loss: 0.2647 - val_auc: 0.8064 - val_binary_accuracy: 0.9059 - val_loss: 0.2610\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9076 - loss: 0.2646 - val_auc: 0.8082 - val_binary_accuracy: 0.9073 - val_loss: 0.2601\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8170 - binary_accuracy: 0.9088 - loss: 0.2586\n",
      "Fold 5 Metrics: Loss = 0.2601, Accuracy = 0.9073, AUC = 0.8082\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2596\n",
      "Average Accuracy: 0.9088\n",
      "Average AUC: 0.8049\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 3, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6388 - binary_accuracy: 0.8800 - loss: 0.6860 - val_auc: 0.7757 - val_binary_accuracy: 0.9048 - val_loss: 0.2865\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9083 - loss: 0.2669 - val_auc: 0.7827 - val_binary_accuracy: 0.9106 - val_loss: 0.2686\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9112 - loss: 0.2575 - val_auc: 0.7874 - val_binary_accuracy: 0.9103 - val_loss: 0.2672\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9115 - loss: 0.2548 - val_auc: 0.7905 - val_binary_accuracy: 0.9100 - val_loss: 0.2609\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9129 - loss: 0.2533 - val_auc: 0.7899 - val_binary_accuracy: 0.9112 - val_loss: 0.2639\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9118 - loss: 0.2521 - val_auc: 0.7929 - val_binary_accuracy: 0.9100 - val_loss: 0.2595\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9128 - loss: 0.2509 - val_auc: 0.7960 - val_binary_accuracy: 0.9084 - val_loss: 0.2597\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9123 - loss: 0.2501 - val_auc: 0.7964 - val_binary_accuracy: 0.9071 - val_loss: 0.2621\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9127 - loss: 0.2490 - val_auc: 0.7963 - val_binary_accuracy: 0.9072 - val_loss: 0.2632\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8086 - binary_accuracy: 0.9128 - loss: 0.2486 - val_auc: 0.7955 - val_binary_accuracy: 0.9076 - val_loss: 0.2637\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7939 - binary_accuracy: 0.9108 - loss: 0.2548\n",
      "Fold 1 Metrics: Loss = 0.2637, Accuracy = 0.9076, AUC = 0.7955\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6477 - binary_accuracy: 0.8743 - loss: 0.6347 - val_auc: 0.8025 - val_binary_accuracy: 0.9075 - val_loss: 0.2917\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9032 - loss: 0.2789 - val_auc: 0.8055 - val_binary_accuracy: 0.9063 - val_loss: 0.2628\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9052 - loss: 0.2677 - val_auc: 0.8072 - val_binary_accuracy: 0.9084 - val_loss: 0.2620\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9069 - loss: 0.2647 - val_auc: 0.7967 - val_binary_accuracy: 0.9073 - val_loss: 0.2640\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9070 - loss: 0.2656 - val_auc: 0.8046 - val_binary_accuracy: 0.9084 - val_loss: 0.2632\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.8033 - val_binary_accuracy: 0.9096 - val_loss: 0.2651\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8108 - val_binary_accuracy: 0.9093 - val_loss: 0.2593\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9081 - loss: 0.2610 - val_auc: 0.8091 - val_binary_accuracy: 0.9082 - val_loss: 0.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9084 - loss: 0.2606 - val_auc: 0.8068 - val_binary_accuracy: 0.9100 - val_loss: 0.2622\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9091 - loss: 0.2605 - val_auc: 0.8080 - val_binary_accuracy: 0.9094 - val_loss: 0.2625\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9132 - loss: 0.2537\n",
      "Fold 2 Metrics: Loss = 0.2625, Accuracy = 0.9094, AUC = 0.8080\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6304 - binary_accuracy: 0.8858 - loss: 0.5479 - val_auc: 0.7825 - val_binary_accuracy: 0.9045 - val_loss: 0.2745\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9056 - loss: 0.2742 - val_auc: 0.7914 - val_binary_accuracy: 0.9096 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9059 - loss: 0.2710 - val_auc: 0.7938 - val_binary_accuracy: 0.9094 - val_loss: 0.2681\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9089 - loss: 0.2652 - val_auc: 0.7984 - val_binary_accuracy: 0.9099 - val_loss: 0.2606\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9084 - loss: 0.2637 - val_auc: 0.8018 - val_binary_accuracy: 0.9106 - val_loss: 0.2602\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9081 - loss: 0.2631 - val_auc: 0.8028 - val_binary_accuracy: 0.9104 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9091 - loss: 0.2626 - val_auc: 0.8040 - val_binary_accuracy: 0.9115 - val_loss: 0.2586\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8036 - val_binary_accuracy: 0.9113 - val_loss: 0.2588\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9094 - loss: 0.2616 - val_auc: 0.8056 - val_binary_accuracy: 0.9112 - val_loss: 0.2570\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9092 - loss: 0.2620 - val_auc: 0.8072 - val_binary_accuracy: 0.9113 - val_loss: 0.2564\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7995 - binary_accuracy: 0.9131 - loss: 0.2569\n",
      "Fold 3 Metrics: Loss = 0.2564, Accuracy = 0.9113, AUC = 0.8072\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6582 - binary_accuracy: 0.8837 - loss: 0.4978 - val_auc: 0.7885 - val_binary_accuracy: 0.9063 - val_loss: 0.2651\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7616 - binary_accuracy: 0.9074 - loss: 0.2732 - val_auc: 0.7977 - val_binary_accuracy: 0.9084 - val_loss: 0.2606\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9080 - loss: 0.2676 - val_auc: 0.7999 - val_binary_accuracy: 0.9063 - val_loss: 0.2605\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.8037 - val_binary_accuracy: 0.9073 - val_loss: 0.2583\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9086 - loss: 0.2626 - val_auc: 0.8056 - val_binary_accuracy: 0.9053 - val_loss: 0.2606\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8077 - val_binary_accuracy: 0.9073 - val_loss: 0.2570\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9099 - loss: 0.2607 - val_auc: 0.8077 - val_binary_accuracy: 0.9072 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9097 - loss: 0.2600 - val_auc: 0.8090 - val_binary_accuracy: 0.9095 - val_loss: 0.2550\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9100 - loss: 0.2594 - val_auc: 0.8111 - val_binary_accuracy: 0.9066 - val_loss: 0.2576\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9105 - loss: 0.2590 - val_auc: 0.8121 - val_binary_accuracy: 0.9094 - val_loss: 0.2541\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9083 - loss: 0.2626\n",
      "Fold 4 Metrics: Loss = 0.2541, Accuracy = 0.9094, AUC = 0.8121\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6539 - binary_accuracy: 0.8786 - loss: 0.5847 - val_auc: 0.7943 - val_binary_accuracy: 0.8989 - val_loss: 0.2791\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7515 - binary_accuracy: 0.9014 - loss: 0.2809 - val_auc: 0.7996 - val_binary_accuracy: 0.9003 - val_loss: 0.2678\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7562 - binary_accuracy: 0.9038 - loss: 0.2776 - val_auc: 0.8028 - val_binary_accuracy: 0.9098 - val_loss: 0.2559\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9069 - loss: 0.2694 - val_auc: 0.8029 - val_binary_accuracy: 0.9072 - val_loss: 0.2561\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9055 - loss: 0.2693 - val_auc: 0.8059 - val_binary_accuracy: 0.9064 - val_loss: 0.2601\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.8060 - val_binary_accuracy: 0.9064 - val_loss: 0.2627\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9074 - loss: 0.2652 - val_auc: 0.8074 - val_binary_accuracy: 0.9098 - val_loss: 0.2635\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9087 - loss: 0.2641 - val_auc: 0.8080 - val_binary_accuracy: 0.9107 - val_loss: 0.2613\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9091 - loss: 0.2633 - val_auc: 0.8089 - val_binary_accuracy: 0.9107 - val_loss: 0.2611\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8096 - val_binary_accuracy: 0.9119 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8174 - binary_accuracy: 0.9104 - loss: 0.2589\n",
      "Fold 5 Metrics: Loss = 0.2599, Accuracy = 0.9119, AUC = 0.8096\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2593\n",
      "Average Accuracy: 0.9099\n",
      "Average AUC: 0.8065\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 4, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6384 - binary_accuracy: 0.7253 - loss: 0.6739 - val_auc: 0.7654 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9078 - loss: 0.2624 - val_auc: 0.7704 - val_binary_accuracy: 0.9071 - val_loss: 0.2705\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9102 - loss: 0.2583 - val_auc: 0.7766 - val_binary_accuracy: 0.9076 - val_loss: 0.2668\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9113 - loss: 0.2560 - val_auc: 0.7785 - val_binary_accuracy: 0.9082 - val_loss: 0.2660\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9109 - loss: 0.2554 - val_auc: 0.7813 - val_binary_accuracy: 0.9088 - val_loss: 0.2646\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9116 - loss: 0.2536 - val_auc: 0.7830 - val_binary_accuracy: 0.9084 - val_loss: 0.2646\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9120 - loss: 0.2528 - val_auc: 0.7833 - val_binary_accuracy: 0.9084 - val_loss: 0.2649\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9120 - loss: 0.2531 - val_auc: 0.7844 - val_binary_accuracy: 0.9088 - val_loss: 0.2636\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9117 - loss: 0.2523 - val_auc: 0.7862 - val_binary_accuracy: 0.9088 - val_loss: 0.2633\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8023 - binary_accuracy: 0.9122 - loss: 0.2519 - val_auc: 0.7858 - val_binary_accuracy: 0.9084 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7829 - binary_accuracy: 0.9113 - loss: 0.2570\n",
      "Fold 1 Metrics: Loss = 0.2635, Accuracy = 0.9084, AUC = 0.7858\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7086 - binary_accuracy: 0.9021 - loss: 0.2949 - val_auc: 0.7871 - val_binary_accuracy: 0.9037 - val_loss: 0.2693\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9035 - loss: 0.2758 - val_auc: 0.7947 - val_binary_accuracy: 0.9045 - val_loss: 0.2644\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9039 - loss: 0.2725 - val_auc: 0.7982 - val_binary_accuracy: 0.9071 - val_loss: 0.2615\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9041 - loss: 0.2703 - val_auc: 0.7994 - val_binary_accuracy: 0.9069 - val_loss: 0.2612\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9053 - loss: 0.2685 - val_auc: 0.8018 - val_binary_accuracy: 0.9068 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9066 - loss: 0.2672 - val_auc: 0.8031 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9077 - loss: 0.2657 - val_auc: 0.8058 - val_binary_accuracy: 0.9081 - val_loss: 0.2574\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9080 - loss: 0.2645 - val_auc: 0.8058 - val_binary_accuracy: 0.9072 - val_loss: 0.2594\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9084 - loss: 0.2639 - val_auc: 0.8076 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9077 - loss: 0.2627 - val_auc: 0.8092 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8094 - binary_accuracy: 0.9120 - loss: 0.2474\n",
      "Fold 2 Metrics: Loss = 0.2549, Accuracy = 0.9091, AUC = 0.8092\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5823 - binary_accuracy: 0.8480 - loss: 0.3761 - val_auc: 0.7783 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7558 - binary_accuracy: 0.9051 - loss: 0.2762 - val_auc: 0.7873 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9054 - loss: 0.2711 - val_auc: 0.7906 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9059 - loss: 0.2684 - val_auc: 0.7936 - val_binary_accuracy: 0.9048 - val_loss: 0.2640\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9069 - loss: 0.2670 - val_auc: 0.7955 - val_binary_accuracy: 0.9071 - val_loss: 0.2631\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9076 - loss: 0.2658 - val_auc: 0.7965 - val_binary_accuracy: 0.9090 - val_loss: 0.2616\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9077 - loss: 0.2651 - val_auc: 0.7986 - val_binary_accuracy: 0.9090 - val_loss: 0.2609\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.8005 - val_binary_accuracy: 0.9096 - val_loss: 0.2598\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9089 - loss: 0.2628 - val_auc: 0.8015 - val_binary_accuracy: 0.9093 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9090 - loss: 0.2623 - val_auc: 0.8019 - val_binary_accuracy: 0.9100 - val_loss: 0.2583\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7959 - binary_accuracy: 0.9112 - loss: 0.2586\n",
      "Fold 3 Metrics: Loss = 0.2583, Accuracy = 0.9100, AUC = 0.8019\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5424 - binary_accuracy: 0.7829 - loss: 2.5380 - val_auc: 0.7417 - val_binary_accuracy: 0.9042 - val_loss: 0.2835\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7403 - binary_accuracy: 0.9047 - loss: 0.2825 - val_auc: 0.7766 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7654 - binary_accuracy: 0.9051 - loss: 0.2741 - val_auc: 0.7845 - val_binary_accuracy: 0.9060 - val_loss: 0.2684\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9057 - loss: 0.2713 - val_auc: 0.7886 - val_binary_accuracy: 0.9057 - val_loss: 0.2669\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9066 - loss: 0.2691 - val_auc: 0.7914 - val_binary_accuracy: 0.9067 - val_loss: 0.2646\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9073 - loss: 0.2670 - val_auc: 0.7940 - val_binary_accuracy: 0.9072 - val_loss: 0.2627\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9083 - loss: 0.2652 - val_auc: 0.7963 - val_binary_accuracy: 0.9078 - val_loss: 0.2610\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9085 - loss: 0.2642 - val_auc: 0.7988 - val_binary_accuracy: 0.9079 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.7999 - val_binary_accuracy: 0.9078 - val_loss: 0.2587\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.8012 - val_binary_accuracy: 0.9084 - val_loss: 0.2582\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7816 - binary_accuracy: 0.9074 - loss: 0.2649\n",
      "Fold 4 Metrics: Loss = 0.2582, Accuracy = 0.9084, AUC = 0.8012\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6275 - binary_accuracy: 0.7391 - loss: 0.8155 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9040 - loss: 0.2751 - val_auc: 0.7884 - val_binary_accuracy: 0.9047 - val_loss: 0.2655\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9050 - loss: 0.2705 - val_auc: 0.7919 - val_binary_accuracy: 0.9054 - val_loss: 0.2642\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9060 - loss: 0.2683 - val_auc: 0.7948 - val_binary_accuracy: 0.9064 - val_loss: 0.2613\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9070 - loss: 0.2670 - val_auc: 0.7955 - val_binary_accuracy: 0.9059 - val_loss: 0.2607\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9073 - loss: 0.2658 - val_auc: 0.7986 - val_binary_accuracy: 0.9062 - val_loss: 0.2584\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9080 - loss: 0.2647 - val_auc: 0.8002 - val_binary_accuracy: 0.9082 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9081 - loss: 0.2642 - val_auc: 0.8006 - val_binary_accuracy: 0.9098 - val_loss: 0.2568\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9085 - loss: 0.2635 - val_auc: 0.8030 - val_binary_accuracy: 0.9095 - val_loss: 0.2563\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9092 - loss: 0.2628 - val_auc: 0.8030 - val_binary_accuracy: 0.9101 - val_loss: 0.2553\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9084 - loss: 0.2544\n",
      "Fold 5 Metrics: Loss = 0.2553, Accuracy = 0.9101, AUC = 0.8030\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2580\n",
      "Average Accuracy: 0.9092\n",
      "Average AUC: 0.8002\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 4, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6757 - binary_accuracy: 0.8468 - loss: 0.5495 - val_auc: 0.7643 - val_binary_accuracy: 0.9044 - val_loss: 0.2779\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9066 - loss: 0.2666 - val_auc: 0.7750 - val_binary_accuracy: 0.9047 - val_loss: 0.2712\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9079 - loss: 0.2623 - val_auc: 0.7807 - val_binary_accuracy: 0.9056 - val_loss: 0.2686\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9093 - loss: 0.2587 - val_auc: 0.7848 - val_binary_accuracy: 0.9059 - val_loss: 0.2674\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9096 - loss: 0.2566 - val_auc: 0.7860 - val_binary_accuracy: 0.9066 - val_loss: 0.2668\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9096 - loss: 0.2544 - val_auc: 0.7871 - val_binary_accuracy: 0.9069 - val_loss: 0.2668\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8017 - binary_accuracy: 0.9107 - loss: 0.2529 - val_auc: 0.7890 - val_binary_accuracy: 0.9068 - val_loss: 0.2661\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9107 - loss: 0.2526 - val_auc: 0.7918 - val_binary_accuracy: 0.9075 - val_loss: 0.2652\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9111 - loss: 0.2512 - val_auc: 0.7935 - val_binary_accuracy: 0.9079 - val_loss: 0.2638\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8081 - binary_accuracy: 0.9116 - loss: 0.2500 - val_auc: 0.7935 - val_binary_accuracy: 0.9085 - val_loss: 0.2631\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9120 - loss: 0.2536\n",
      "Fold 1 Metrics: Loss = 0.2631, Accuracy = 0.9085, AUC = 0.7935\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6902 - binary_accuracy: 0.8972 - loss: 0.3136 - val_auc: 0.7918 - val_binary_accuracy: 0.9079 - val_loss: 0.2654\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9049 - loss: 0.2730 - val_auc: 0.7993 - val_binary_accuracy: 0.9096 - val_loss: 0.2639\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9067 - loss: 0.2697 - val_auc: 0.8037 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9065 - loss: 0.2693 - val_auc: 0.8056 - val_binary_accuracy: 0.9106 - val_loss: 0.2598\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9073 - loss: 0.2667 - val_auc: 0.8046 - val_binary_accuracy: 0.9072 - val_loss: 0.2676\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9075 - loss: 0.2645 - val_auc: 0.8046 - val_binary_accuracy: 0.9073 - val_loss: 0.2627\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9075 - loss: 0.2636 - val_auc: 0.8023 - val_binary_accuracy: 0.9090 - val_loss: 0.2621\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9084 - loss: 0.2623 - val_auc: 0.8102 - val_binary_accuracy: 0.9102 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8023 - val_binary_accuracy: 0.9090 - val_loss: 0.2625\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9083 - loss: 0.2611 - val_auc: 0.8094 - val_binary_accuracy: 0.9087 - val_loss: 0.2577\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.9118 - loss: 0.2485\n",
      "Fold 2 Metrics: Loss = 0.2577, Accuracy = 0.9087, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6536 - binary_accuracy: 0.8522 - loss: 0.7490 - val_auc: 0.7771 - val_binary_accuracy: 0.9056 - val_loss: 0.2699\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7580 - binary_accuracy: 0.9071 - loss: 0.2740 - val_auc: 0.7829 - val_binary_accuracy: 0.9075 - val_loss: 0.2692\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7664 - binary_accuracy: 0.9071 - loss: 0.2707 - val_auc: 0.7879 - val_binary_accuracy: 0.9084 - val_loss: 0.2675\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9067 - loss: 0.2691 - val_auc: 0.7899 - val_binary_accuracy: 0.9087 - val_loss: 0.2670\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.7923 - val_binary_accuracy: 0.9059 - val_loss: 0.2672\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9075 - loss: 0.2664 - val_auc: 0.7951 - val_binary_accuracy: 0.9097 - val_loss: 0.2641\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9078 - loss: 0.2666 - val_auc: 0.7944 - val_binary_accuracy: 0.9103 - val_loss: 0.2628\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9081 - loss: 0.2658 - val_auc: 0.7962 - val_binary_accuracy: 0.9079 - val_loss: 0.2634\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9081 - loss: 0.2657 - val_auc: 0.7973 - val_binary_accuracy: 0.9099 - val_loss: 0.2622\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9082 - loss: 0.2648 - val_auc: 0.7984 - val_binary_accuracy: 0.9102 - val_loss: 0.2601\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7943 - binary_accuracy: 0.9107 - loss: 0.2599\n",
      "Fold 3 Metrics: Loss = 0.2601, Accuracy = 0.9102, AUC = 0.7984\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - auc: 0.6610 - binary_accuracy: 0.9044 - loss: 0.3356 - val_auc: 0.7807 - val_binary_accuracy: 0.9048 - val_loss: 0.2690\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9063 - loss: 0.2737 - val_auc: 0.7888 - val_binary_accuracy: 0.9070 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9070 - loss: 0.2696 - val_auc: 0.7962 - val_binary_accuracy: 0.9053 - val_loss: 0.2630\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9063 - loss: 0.2666 - val_auc: 0.7984 - val_binary_accuracy: 0.9023 - val_loss: 0.2622\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2643 - val_auc: 0.8011 - val_binary_accuracy: 0.9062 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9076 - loss: 0.2632 - val_auc: 0.8021 - val_binary_accuracy: 0.9035 - val_loss: 0.2602\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9086 - loss: 0.2624 - val_auc: 0.8032 - val_binary_accuracy: 0.9032 - val_loss: 0.2599\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.8072 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9094 - loss: 0.2603 - val_auc: 0.8086 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8094 - val_binary_accuracy: 0.9090 - val_loss: 0.2546\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7896 - binary_accuracy: 0.9082 - loss: 0.2620\n",
      "Fold 4 Metrics: Loss = 0.2546, Accuracy = 0.9090, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5903 - binary_accuracy: 0.8426 - loss: 0.8164 - val_auc: 0.7801 - val_binary_accuracy: 0.9066 - val_loss: 0.2782\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7524 - binary_accuracy: 0.9046 - loss: 0.2796 - val_auc: 0.7909 - val_binary_accuracy: 0.9069 - val_loss: 0.2708\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9046 - loss: 0.2746 - val_auc: 0.7965 - val_binary_accuracy: 0.9073 - val_loss: 0.2656\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9044 - loss: 0.2720 - val_auc: 0.8004 - val_binary_accuracy: 0.9069 - val_loss: 0.2650\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9039 - loss: 0.2702 - val_auc: 0.8023 - val_binary_accuracy: 0.9059 - val_loss: 0.2651\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9054 - loss: 0.2685 - val_auc: 0.8046 - val_binary_accuracy: 0.9066 - val_loss: 0.2666\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9065 - loss: 0.2671 - val_auc: 0.8059 - val_binary_accuracy: 0.9075 - val_loss: 0.2641\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9071 - loss: 0.2656 - val_auc: 0.8055 - val_binary_accuracy: 0.9053 - val_loss: 0.2659\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.8081 - val_binary_accuracy: 0.9063 - val_loss: 0.2657\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8076 - val_binary_accuracy: 0.9066 - val_loss: 0.2638\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9092 - loss: 0.2615\n",
      "Fold 5 Metrics: Loss = 0.2638, Accuracy = 0.9066, AUC = 0.8076\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2599\n",
      "Average Accuracy: 0.9086\n",
      "Average AUC: 0.8037\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 4, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6601 - binary_accuracy: 0.8901 - loss: 0.3777 - val_auc: 0.7766 - val_binary_accuracy: 0.9072 - val_loss: 0.2873\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9085 - loss: 0.2657 - val_auc: 0.7797 - val_binary_accuracy: 0.9054 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9094 - loss: 0.2584 - val_auc: 0.7858 - val_binary_accuracy: 0.9071 - val_loss: 0.2628\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9100 - loss: 0.2566 - val_auc: 0.7885 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9112 - loss: 0.2537 - val_auc: 0.7880 - val_binary_accuracy: 0.9073 - val_loss: 0.2634\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9117 - loss: 0.2526 - val_auc: 0.7910 - val_binary_accuracy: 0.9082 - val_loss: 0.2622\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9122 - loss: 0.2506 - val_auc: 0.7872 - val_binary_accuracy: 0.9066 - val_loss: 0.2642\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9123 - loss: 0.2502 - val_auc: 0.7878 - val_binary_accuracy: 0.9082 - val_loss: 0.2619\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9120 - loss: 0.2493 - val_auc: 0.7917 - val_binary_accuracy: 0.9076 - val_loss: 0.2609\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9129 - loss: 0.2482 - val_auc: 0.7920 - val_binary_accuracy: 0.9079 - val_loss: 0.2604\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7921 - binary_accuracy: 0.9108 - loss: 0.2517\n",
      "Fold 1 Metrics: Loss = 0.2604, Accuracy = 0.9079, AUC = 0.7920\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6860 - binary_accuracy: 0.8952 - loss: 0.3456 - val_auc: 0.7974 - val_binary_accuracy: 0.9045 - val_loss: 0.2650\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9038 - loss: 0.2723 - val_auc: 0.7958 - val_binary_accuracy: 0.9047 - val_loss: 0.2685\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9048 - loss: 0.2687 - val_auc: 0.8071 - val_binary_accuracy: 0.9065 - val_loss: 0.2631\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9066 - loss: 0.2662 - val_auc: 0.8038 - val_binary_accuracy: 0.9069 - val_loss: 0.2612\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9052 - loss: 0.2657 - val_auc: 0.8051 - val_binary_accuracy: 0.9087 - val_loss: 0.2634\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9080 - loss: 0.2622 - val_auc: 0.8095 - val_binary_accuracy: 0.9091 - val_loss: 0.2595\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9083 - loss: 0.2616 - val_auc: 0.8078 - val_binary_accuracy: 0.9085 - val_loss: 0.2598\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9082 - loss: 0.2610 - val_auc: 0.8081 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9082 - loss: 0.2608 - val_auc: 0.8132 - val_binary_accuracy: 0.9088 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9089 - loss: 0.2603 - val_auc: 0.8115 - val_binary_accuracy: 0.9093 - val_loss: 0.2583\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9126 - loss: 0.2503\n",
      "Fold 2 Metrics: Loss = 0.2583, Accuracy = 0.9093, AUC = 0.8115\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6137 - binary_accuracy: 0.8627 - loss: 0.8741 - val_auc: 0.7711 - val_binary_accuracy: 0.9042 - val_loss: 0.2741\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7423 - binary_accuracy: 0.9036 - loss: 0.2834 - val_auc: 0.7781 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9035 - loss: 0.2775 - val_auc: 0.7866 - val_binary_accuracy: 0.9069 - val_loss: 0.2650\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9054 - loss: 0.2721 - val_auc: 0.7931 - val_binary_accuracy: 0.9094 - val_loss: 0.2615\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.7949 - val_binary_accuracy: 0.9093 - val_loss: 0.2676\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9082 - loss: 0.2646 - val_auc: 0.7980 - val_binary_accuracy: 0.9094 - val_loss: 0.2644\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9094 - loss: 0.2627 - val_auc: 0.7995 - val_binary_accuracy: 0.9075 - val_loss: 0.2640\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9092 - loss: 0.2619 - val_auc: 0.8025 - val_binary_accuracy: 0.9112 - val_loss: 0.2585\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9097 - loss: 0.2623 - val_auc: 0.8021 - val_binary_accuracy: 0.9091 - val_loss: 0.2627\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9099 - loss: 0.2620 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2578\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9121 - loss: 0.2586\n",
      "Fold 3 Metrics: Loss = 0.2578, Accuracy = 0.9107, AUC = 0.8026\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6741 - binary_accuracy: 0.8865 - loss: 0.3803 - val_auc: 0.7838 - val_binary_accuracy: 0.9053 - val_loss: 0.2682\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9059 - loss: 0.2740 - val_auc: 0.7923 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9071 - loss: 0.2697 - val_auc: 0.7957 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9076 - loss: 0.2674 - val_auc: 0.7989 - val_binary_accuracy: 0.9062 - val_loss: 0.2605\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9080 - loss: 0.2638 - val_auc: 0.8016 - val_binary_accuracy: 0.9084 - val_loss: 0.2594\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9081 - loss: 0.2630 - val_auc: 0.8025 - val_binary_accuracy: 0.9084 - val_loss: 0.2579\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.8034 - val_binary_accuracy: 0.9062 - val_loss: 0.2580\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9098 - loss: 0.2608 - val_auc: 0.8053 - val_binary_accuracy: 0.9073 - val_loss: 0.2575\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.8054 - val_binary_accuracy: 0.9082 - val_loss: 0.2572\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9096 - loss: 0.2602 - val_auc: 0.8062 - val_binary_accuracy: 0.9088 - val_loss: 0.2559\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7868 - binary_accuracy: 0.9074 - loss: 0.2634\n",
      "Fold 4 Metrics: Loss = 0.2559, Accuracy = 0.9088, AUC = 0.8062\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7049 - binary_accuracy: 0.9019 - loss: 0.3049 - val_auc: 0.7936 - val_binary_accuracy: 0.8948 - val_loss: 0.2847\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7451 - binary_accuracy: 0.9022 - loss: 0.2836 - val_auc: 0.7960 - val_binary_accuracy: 0.9064 - val_loss: 0.2609\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7600 - binary_accuracy: 0.9063 - loss: 0.2748 - val_auc: 0.7998 - val_binary_accuracy: 0.9091 - val_loss: 0.2580\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9075 - loss: 0.2697 - val_auc: 0.8023 - val_binary_accuracy: 0.9014 - val_loss: 0.2655\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9061 - loss: 0.2675 - val_auc: 0.8047 - val_binary_accuracy: 0.9063 - val_loss: 0.2620\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9078 - loss: 0.2658 - val_auc: 0.8059 - val_binary_accuracy: 0.9045 - val_loss: 0.2639\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9081 - loss: 0.2652 - val_auc: 0.8069 - val_binary_accuracy: 0.9064 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9090 - loss: 0.2639 - val_auc: 0.8075 - val_binary_accuracy: 0.9075 - val_loss: 0.2598\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8081 - val_binary_accuracy: 0.9078 - val_loss: 0.2599\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9095 - loss: 0.2635 - val_auc: 0.8076 - val_binary_accuracy: 0.9094 - val_loss: 0.2566\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9087 - loss: 0.2541\n",
      "Fold 5 Metrics: Loss = 0.2566, Accuracy = 0.9094, AUC = 0.8076\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2578\n",
      "Average Accuracy: 0.9092\n",
      "Average AUC: 0.8040\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 4, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6876 - binary_accuracy: 0.8980 - loss: 0.3569 - val_auc: 0.7743 - val_binary_accuracy: 0.9050 - val_loss: 0.2731\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9083 - loss: 0.2651 - val_auc: 0.7793 - val_binary_accuracy: 0.9094 - val_loss: 0.2753\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9097 - loss: 0.2597 - val_auc: 0.7853 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9115 - loss: 0.2556 - val_auc: 0.7903 - val_binary_accuracy: 0.9069 - val_loss: 0.2635\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9118 - loss: 0.2535 - val_auc: 0.7921 - val_binary_accuracy: 0.9088 - val_loss: 0.2603\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8005 - binary_accuracy: 0.9122 - loss: 0.2525 - val_auc: 0.7940 - val_binary_accuracy: 0.9096 - val_loss: 0.2593\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9118 - loss: 0.2508 - val_auc: 0.7942 - val_binary_accuracy: 0.9094 - val_loss: 0.2607\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9121 - loss: 0.2510 - val_auc: 0.7926 - val_binary_accuracy: 0.9075 - val_loss: 0.2641\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8068 - binary_accuracy: 0.9132 - loss: 0.2497 - val_auc: 0.7980 - val_binary_accuracy: 0.9081 - val_loss: 0.2589\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8098 - binary_accuracy: 0.9131 - loss: 0.2479 - val_auc: 0.7973 - val_binary_accuracy: 0.9076 - val_loss: 0.2613\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7942 - binary_accuracy: 0.9109 - loss: 0.2531\n",
      "Fold 1 Metrics: Loss = 0.2613, Accuracy = 0.9076, AUC = 0.7973\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6711 - binary_accuracy: 0.8797 - loss: 0.5018 - val_auc: 0.8015 - val_binary_accuracy: 0.9056 - val_loss: 0.2718\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9027 - loss: 0.2744 - val_auc: 0.7999 - val_binary_accuracy: 0.9076 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9057 - loss: 0.2688 - val_auc: 0.8042 - val_binary_accuracy: 0.9076 - val_loss: 0.2603\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9064 - loss: 0.2659 - val_auc: 0.8051 - val_binary_accuracy: 0.9072 - val_loss: 0.2614\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9075 - loss: 0.2641 - val_auc: 0.8066 - val_binary_accuracy: 0.9091 - val_loss: 0.2605\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.8084 - val_binary_accuracy: 0.9091 - val_loss: 0.2640\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9075 - loss: 0.2617 - val_auc: 0.8021 - val_binary_accuracy: 0.9091 - val_loss: 0.2644\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8089 - val_binary_accuracy: 0.9099 - val_loss: 0.2613\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9089 - loss: 0.2604 - val_auc: 0.8110 - val_binary_accuracy: 0.9094 - val_loss: 0.2597\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8002 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.8073 - val_binary_accuracy: 0.9091 - val_loss: 0.2639\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8134 - binary_accuracy: 0.9130 - loss: 0.2549\n",
      "Fold 2 Metrics: Loss = 0.2639, Accuracy = 0.9091, AUC = 0.8073\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7087 - binary_accuracy: 0.8943 - loss: 0.3278 - val_auc: 0.7834 - val_binary_accuracy: 0.9068 - val_loss: 0.2663\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7614 - binary_accuracy: 0.9058 - loss: 0.2729 - val_auc: 0.7872 - val_binary_accuracy: 0.9088 - val_loss: 0.2684\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9084 - loss: 0.2662 - val_auc: 0.7947 - val_binary_accuracy: 0.9094 - val_loss: 0.2662\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9085 - loss: 0.2653 - val_auc: 0.7956 - val_binary_accuracy: 0.9097 - val_loss: 0.2623\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9079 - loss: 0.2651 - val_auc: 0.7958 - val_binary_accuracy: 0.9104 - val_loss: 0.2619\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9075 - loss: 0.2632 - val_auc: 0.8008 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9079 - loss: 0.2642 - val_auc: 0.7996 - val_binary_accuracy: 0.9106 - val_loss: 0.2593\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9090 - loss: 0.2615 - val_auc: 0.8014 - val_binary_accuracy: 0.9104 - val_loss: 0.2591\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9094 - loss: 0.2607 - val_auc: 0.8003 - val_binary_accuracy: 0.9110 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2612 - val_auc: 0.8013 - val_binary_accuracy: 0.9115 - val_loss: 0.2585\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7944 - binary_accuracy: 0.9129 - loss: 0.2589\n",
      "Fold 3 Metrics: Loss = 0.2585, Accuracy = 0.9115, AUC = 0.8013\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6414 - binary_accuracy: 0.8837 - loss: 0.4603 - val_auc: 0.7865 - val_binary_accuracy: 0.9048 - val_loss: 0.2691\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9071 - loss: 0.2743 - val_auc: 0.7921 - val_binary_accuracy: 0.9079 - val_loss: 0.2627\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9080 - loss: 0.2686 - val_auc: 0.7938 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9084 - loss: 0.2649 - val_auc: 0.7994 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.8044 - val_binary_accuracy: 0.9051 - val_loss: 0.2585\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9092 - loss: 0.2629 - val_auc: 0.8044 - val_binary_accuracy: 0.9075 - val_loss: 0.2573\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9098 - loss: 0.2614 - val_auc: 0.8047 - val_binary_accuracy: 0.9078 - val_loss: 0.2575\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.8072 - val_binary_accuracy: 0.9078 - val_loss: 0.2569\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9102 - loss: 0.2600 - val_auc: 0.8093 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8093 - val_binary_accuracy: 0.9079 - val_loss: 0.2554\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7897 - binary_accuracy: 0.9071 - loss: 0.2634\n",
      "Fold 4 Metrics: Loss = 0.2554, Accuracy = 0.9079, AUC = 0.8093\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6406 - binary_accuracy: 0.8849 - loss: 0.5232 - val_auc: 0.7915 - val_binary_accuracy: 0.9003 - val_loss: 0.2699\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7510 - binary_accuracy: 0.9013 - loss: 0.2806 - val_auc: 0.7973 - val_binary_accuracy: 0.9063 - val_loss: 0.2584\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7659 - binary_accuracy: 0.9040 - loss: 0.2732 - val_auc: 0.7997 - val_binary_accuracy: 0.9057 - val_loss: 0.2617\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9050 - loss: 0.2706 - val_auc: 0.8024 - val_binary_accuracy: 0.9075 - val_loss: 0.2551\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9059 - loss: 0.2685 - val_auc: 0.8049 - val_binary_accuracy: 0.9103 - val_loss: 0.2586\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9077 - loss: 0.2651 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2591\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9088 - loss: 0.2643 - val_auc: 0.8056 - val_binary_accuracy: 0.9110 - val_loss: 0.2556\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9072 - loss: 0.2652 - val_auc: 0.8070 - val_binary_accuracy: 0.9110 - val_loss: 0.2575\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8089 - val_binary_accuracy: 0.9112 - val_loss: 0.2575\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9096 - loss: 0.2636 - val_auc: 0.8088 - val_binary_accuracy: 0.9110 - val_loss: 0.2563\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9095 - loss: 0.2553\n",
      "Fold 5 Metrics: Loss = 0.2563, Accuracy = 0.9110, AUC = 0.8088\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2591\n",
      "Average Accuracy: 0.9094\n",
      "Average AUC: 0.8048\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 4, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6483 - binary_accuracy: 0.8755 - loss: 0.5879 - val_auc: 0.7742 - val_binary_accuracy: 0.9085 - val_loss: 0.2753\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.7806 - val_binary_accuracy: 0.9102 - val_loss: 0.2640\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9105 - loss: 0.2580 - val_auc: 0.7864 - val_binary_accuracy: 0.9104 - val_loss: 0.2625\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9110 - loss: 0.2549 - val_auc: 0.7909 - val_binary_accuracy: 0.9113 - val_loss: 0.2664\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9119 - loss: 0.2535 - val_auc: 0.7925 - val_binary_accuracy: 0.9100 - val_loss: 0.2614\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9126 - loss: 0.2514 - val_auc: 0.7936 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9129 - loss: 0.2511 - val_auc: 0.7957 - val_binary_accuracy: 0.9090 - val_loss: 0.2599\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8064 - binary_accuracy: 0.9132 - loss: 0.2499 - val_auc: 0.7953 - val_binary_accuracy: 0.9099 - val_loss: 0.2581\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9126 - loss: 0.2502 - val_auc: 0.7961 - val_binary_accuracy: 0.9082 - val_loss: 0.2605\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8092 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7959 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9107 - loss: 0.2537\n",
      "Fold 1 Metrics: Loss = 0.2621, Accuracy = 0.9078, AUC = 0.7959\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6642 - binary_accuracy: 0.8735 - loss: 0.5663 - val_auc: 0.7947 - val_binary_accuracy: 0.9085 - val_loss: 0.2929\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9033 - loss: 0.2770 - val_auc: 0.8037 - val_binary_accuracy: 0.9054 - val_loss: 0.2659\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.8057 - val_binary_accuracy: 0.9063 - val_loss: 0.2629\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9059 - loss: 0.2669 - val_auc: 0.7991 - val_binary_accuracy: 0.9079 - val_loss: 0.2624\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9068 - loss: 0.2656 - val_auc: 0.8044 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9083 - loss: 0.2644 - val_auc: 0.8036 - val_binary_accuracy: 0.9076 - val_loss: 0.2645\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9085 - loss: 0.2627 - val_auc: 0.8062 - val_binary_accuracy: 0.9088 - val_loss: 0.2634\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9090 - loss: 0.2620 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2604\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9091 - loss: 0.2608 - val_auc: 0.8073 - val_binary_accuracy: 0.9097 - val_loss: 0.2639\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9085 - loss: 0.2611 - val_auc: 0.8074 - val_binary_accuracy: 0.9087 - val_loss: 0.2623\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8090 - binary_accuracy: 0.9128 - loss: 0.2549\n",
      "Fold 2 Metrics: Loss = 0.2623, Accuracy = 0.9087, AUC = 0.8074\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6402 - binary_accuracy: 0.8750 - loss: 0.6017 - val_auc: 0.7788 - val_binary_accuracy: 0.9072 - val_loss: 0.2750\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9053 - loss: 0.2736 - val_auc: 0.7840 - val_binary_accuracy: 0.9087 - val_loss: 0.2655\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9067 - loss: 0.2696 - val_auc: 0.7891 - val_binary_accuracy: 0.9093 - val_loss: 0.2649\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9084 - loss: 0.2669 - val_auc: 0.7925 - val_binary_accuracy: 0.9096 - val_loss: 0.2627\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9084 - loss: 0.2645 - val_auc: 0.7955 - val_binary_accuracy: 0.9104 - val_loss: 0.2603\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.7969 - val_binary_accuracy: 0.9106 - val_loss: 0.2606\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9087 - loss: 0.2636 - val_auc: 0.8000 - val_binary_accuracy: 0.9110 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9090 - loss: 0.2628 - val_auc: 0.8008 - val_binary_accuracy: 0.9107 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.8026 - val_binary_accuracy: 0.9112 - val_loss: 0.2593\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2581\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9112 - loss: 0.2587\n",
      "Fold 3 Metrics: Loss = 0.2581, Accuracy = 0.9107, AUC = 0.8026\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6449 - binary_accuracy: 0.8701 - loss: 0.8217 - val_auc: 0.7858 - val_binary_accuracy: 0.9053 - val_loss: 0.2684\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7600 - binary_accuracy: 0.9066 - loss: 0.2741 - val_auc: 0.7921 - val_binary_accuracy: 0.9082 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9084 - loss: 0.2681 - val_auc: 0.7965 - val_binary_accuracy: 0.9069 - val_loss: 0.2615\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9081 - loss: 0.2654 - val_auc: 0.8006 - val_binary_accuracy: 0.9088 - val_loss: 0.2594\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8035 - val_binary_accuracy: 0.9095 - val_loss: 0.2571\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9103 - loss: 0.2614 - val_auc: 0.8059 - val_binary_accuracy: 0.9098 - val_loss: 0.2557\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9104 - loss: 0.2604 - val_auc: 0.8073 - val_binary_accuracy: 0.9097 - val_loss: 0.2552\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9107 - loss: 0.2595 - val_auc: 0.8074 - val_binary_accuracy: 0.9100 - val_loss: 0.2550\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9104 - loss: 0.2598 - val_auc: 0.8083 - val_binary_accuracy: 0.9094 - val_loss: 0.2547\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9109 - loss: 0.2590 - val_auc: 0.8102 - val_binary_accuracy: 0.9095 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9089 - loss: 0.2623\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9095, AUC = 0.8102\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6608 - binary_accuracy: 0.8902 - loss: 0.4149 - val_auc: 0.7908 - val_binary_accuracy: 0.8977 - val_loss: 0.2746\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7512 - binary_accuracy: 0.9027 - loss: 0.2799 - val_auc: 0.7955 - val_binary_accuracy: 0.9032 - val_loss: 0.2625\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9039 - loss: 0.2754 - val_auc: 0.7993 - val_binary_accuracy: 0.9107 - val_loss: 0.2599\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7739 - binary_accuracy: 0.9060 - loss: 0.2696 - val_auc: 0.8012 - val_binary_accuracy: 0.9098 - val_loss: 0.2597\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9080 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2635\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9084 - loss: 0.2662 - val_auc: 0.8046 - val_binary_accuracy: 0.9084 - val_loss: 0.2644\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9076 - loss: 0.2654 - val_auc: 0.8065 - val_binary_accuracy: 0.9121 - val_loss: 0.2636\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9084 - loss: 0.2641 - val_auc: 0.8061 - val_binary_accuracy: 0.9106 - val_loss: 0.2647\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9086 - loss: 0.2640 - val_auc: 0.8081 - val_binary_accuracy: 0.9112 - val_loss: 0.2596\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9091 - loss: 0.2622 - val_auc: 0.8080 - val_binary_accuracy: 0.9116 - val_loss: 0.2602\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9115 - loss: 0.2588\n",
      "Fold 5 Metrics: Loss = 0.2602, Accuracy = 0.9116, AUC = 0.8080\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2596\n",
      "Average Accuracy: 0.9097\n",
      "Average AUC: 0.8048\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 5, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7407 - binary_accuracy: 0.9073 - loss: 0.2764 - val_auc: 0.7709 - val_binary_accuracy: 0.9047 - val_loss: 0.2712\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9094 - loss: 0.2598 - val_auc: 0.7768 - val_binary_accuracy: 0.9069 - val_loss: 0.2681\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9099 - loss: 0.2563 - val_auc: 0.7825 - val_binary_accuracy: 0.9065 - val_loss: 0.2662\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9106 - loss: 0.2545 - val_auc: 0.7853 - val_binary_accuracy: 0.9078 - val_loss: 0.2640\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9117 - loss: 0.2531 - val_auc: 0.7872 - val_binary_accuracy: 0.9088 - val_loss: 0.2630\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9120 - loss: 0.2518 - val_auc: 0.7887 - val_binary_accuracy: 0.9090 - val_loss: 0.2622\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7905 - val_binary_accuracy: 0.9094 - val_loss: 0.2618\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8069 - binary_accuracy: 0.9127 - loss: 0.2499 - val_auc: 0.7915 - val_binary_accuracy: 0.9099 - val_loss: 0.2613\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8082 - binary_accuracy: 0.9133 - loss: 0.2488 - val_auc: 0.7916 - val_binary_accuracy: 0.9093 - val_loss: 0.2611\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8092 - binary_accuracy: 0.9135 - loss: 0.2479 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2607\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9125 - loss: 0.2542\n",
      "Fold 1 Metrics: Loss = 0.2607, Accuracy = 0.9093, AUC = 0.7919\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5360 - binary_accuracy: 0.6777 - loss: 2.9505 - val_auc: 0.7771 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9029 - loss: 0.2784 - val_auc: 0.7787 - val_binary_accuracy: 0.9047 - val_loss: 0.2716\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9032 - loss: 0.2736 - val_auc: 0.7911 - val_binary_accuracy: 0.9056 - val_loss: 0.2646\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9049 - loss: 0.2709 - val_auc: 0.7938 - val_binary_accuracy: 0.9072 - val_loss: 0.2632\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9066 - loss: 0.2694 - val_auc: 0.7963 - val_binary_accuracy: 0.9078 - val_loss: 0.2622\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9065 - loss: 0.2683 - val_auc: 0.7986 - val_binary_accuracy: 0.9079 - val_loss: 0.2607\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9072 - loss: 0.2669 - val_auc: 0.8014 - val_binary_accuracy: 0.9078 - val_loss: 0.2594\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9078 - loss: 0.2658 - val_auc: 0.8025 - val_binary_accuracy: 0.9075 - val_loss: 0.2588\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9080 - loss: 0.2650 - val_auc: 0.8050 - val_binary_accuracy: 0.9073 - val_loss: 0.2586\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9082 - loss: 0.2644 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2574\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8085 - binary_accuracy: 0.9125 - loss: 0.2485\n",
      "Fold 2 Metrics: Loss = 0.2574, Accuracy = 0.9078, AUC = 0.8073\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4992 - binary_accuracy: 0.8095 - loss: 0.6973 - val_auc: 0.7599 - val_binary_accuracy: 0.9042 - val_loss: 0.2772\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9051 - loss: 0.2758 - val_auc: 0.7685 - val_binary_accuracy: 0.9042 - val_loss: 0.2740\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9054 - loss: 0.2724 - val_auc: 0.7766 - val_binary_accuracy: 0.9041 - val_loss: 0.2729\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9060 - loss: 0.2703 - val_auc: 0.7790 - val_binary_accuracy: 0.9045 - val_loss: 0.2711\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9061 - loss: 0.2688 - val_auc: 0.7822 - val_binary_accuracy: 0.9054 - val_loss: 0.2697\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.7842 - val_binary_accuracy: 0.9072 - val_loss: 0.2678\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9071 - loss: 0.2675 - val_auc: 0.7862 - val_binary_accuracy: 0.9087 - val_loss: 0.2669\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9073 - loss: 0.2668 - val_auc: 0.7873 - val_binary_accuracy: 0.9094 - val_loss: 0.2664\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9078 - loss: 0.2661 - val_auc: 0.7886 - val_binary_accuracy: 0.9102 - val_loss: 0.2654\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9082 - loss: 0.2655 - val_auc: 0.7896 - val_binary_accuracy: 0.9103 - val_loss: 0.2650\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7849 - binary_accuracy: 0.9110 - loss: 0.2645\n",
      "Fold 3 Metrics: Loss = 0.2650, Accuracy = 0.9103, AUC = 0.7896\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6278 - binary_accuracy: 0.8020 - loss: 0.4701 - val_auc: 0.7498 - val_binary_accuracy: 0.9044 - val_loss: 0.2810\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7508 - binary_accuracy: 0.9047 - loss: 0.2777 - val_auc: 0.7720 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9057 - loss: 0.2705 - val_auc: 0.7820 - val_binary_accuracy: 0.9060 - val_loss: 0.2687\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9083 - loss: 0.2678 - val_auc: 0.7870 - val_binary_accuracy: 0.9069 - val_loss: 0.2682\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9088 - loss: 0.2652 - val_auc: 0.7895 - val_binary_accuracy: 0.9069 - val_loss: 0.2663\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9094 - loss: 0.2636 - val_auc: 0.7913 - val_binary_accuracy: 0.9078 - val_loss: 0.2656\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9093 - loss: 0.2625 - val_auc: 0.7928 - val_binary_accuracy: 0.9078 - val_loss: 0.2651\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9094 - loss: 0.2617 - val_auc: 0.7946 - val_binary_accuracy: 0.9081 - val_loss: 0.2644\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2610 - val_auc: 0.7955 - val_binary_accuracy: 0.9081 - val_loss: 0.2647\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9096 - loss: 0.2601 - val_auc: 0.7969 - val_binary_accuracy: 0.9081 - val_loss: 0.2640\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7745 - binary_accuracy: 0.9073 - loss: 0.2713\n",
      "Fold 4 Metrics: Loss = 0.2640, Accuracy = 0.9081, AUC = 0.7969\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7206 - binary_accuracy: 0.9042 - loss: 0.2886 - val_auc: 0.7822 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7582 - binary_accuracy: 0.9044 - loss: 0.2772 - val_auc: 0.7893 - val_binary_accuracy: 0.9057 - val_loss: 0.2700\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9049 - loss: 0.2742 - val_auc: 0.7929 - val_binary_accuracy: 0.9062 - val_loss: 0.2663\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9060 - loss: 0.2720 - val_auc: 0.7953 - val_binary_accuracy: 0.9072 - val_loss: 0.2619\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9071 - loss: 0.2701 - val_auc: 0.7964 - val_binary_accuracy: 0.9076 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9072 - loss: 0.2692 - val_auc: 0.7965 - val_binary_accuracy: 0.9078 - val_loss: 0.2588\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9075 - loss: 0.2673 - val_auc: 0.7999 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9075 - loss: 0.2661 - val_auc: 0.8008 - val_binary_accuracy: 0.9098 - val_loss: 0.2570\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9086 - loss: 0.2659 - val_auc: 0.8012 - val_binary_accuracy: 0.9100 - val_loss: 0.2566\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9082 - loss: 0.2651 - val_auc: 0.8018 - val_binary_accuracy: 0.9109 - val_loss: 0.2557\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8119 - binary_accuracy: 0.9096 - loss: 0.2539\n",
      "Fold 5 Metrics: Loss = 0.2557, Accuracy = 0.9109, AUC = 0.8018\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2606\n",
      "Average Accuracy: 0.9093\n",
      "Average AUC: 0.7975\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 5, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6768 - binary_accuracy: 0.9012 - loss: 0.3083 - val_auc: 0.7721 - val_binary_accuracy: 0.9045 - val_loss: 0.2709\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9083 - loss: 0.2637 - val_auc: 0.7824 - val_binary_accuracy: 0.9053 - val_loss: 0.2659\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2583 - val_auc: 0.7853 - val_binary_accuracy: 0.9078 - val_loss: 0.2627\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9106 - loss: 0.2559 - val_auc: 0.7875 - val_binary_accuracy: 0.9087 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9118 - loss: 0.2540 - val_auc: 0.7889 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9116 - loss: 0.2527 - val_auc: 0.7904 - val_binary_accuracy: 0.9069 - val_loss: 0.2629\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9119 - loss: 0.2515 - val_auc: 0.7939 - val_binary_accuracy: 0.9088 - val_loss: 0.2604\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9119 - loss: 0.2500 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9123 - loss: 0.2497 - val_auc: 0.7948 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8091 - binary_accuracy: 0.9122 - loss: 0.2490 - val_auc: 0.7953 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9118 - loss: 0.2518\n",
      "Fold 1 Metrics: Loss = 0.2594, Accuracy = 0.9085, AUC = 0.7953\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7273 - binary_accuracy: 0.9029 - loss: 0.2894 - val_auc: 0.7957 - val_binary_accuracy: 0.9044 - val_loss: 0.2647\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9034 - loss: 0.2712 - val_auc: 0.8002 - val_binary_accuracy: 0.9071 - val_loss: 0.2608\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9047 - loss: 0.2676 - val_auc: 0.8050 - val_binary_accuracy: 0.9066 - val_loss: 0.2592\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7906 - binary_accuracy: 0.9060 - loss: 0.2656 - val_auc: 0.8074 - val_binary_accuracy: 0.9081 - val_loss: 0.2573\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9077 - loss: 0.2643 - val_auc: 0.8084 - val_binary_accuracy: 0.9088 - val_loss: 0.2566\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9084 - loss: 0.2630 - val_auc: 0.8108 - val_binary_accuracy: 0.9090 - val_loss: 0.2543\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8112 - val_binary_accuracy: 0.9099 - val_loss: 0.2539\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9082 - loss: 0.2605 - val_auc: 0.8111 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8006 - binary_accuracy: 0.9083 - loss: 0.2604 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2532\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9086 - loss: 0.2593 - val_auc: 0.8105 - val_binary_accuracy: 0.9099 - val_loss: 0.2544\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9137 - loss: 0.2452\n",
      "Fold 2 Metrics: Loss = 0.2544, Accuracy = 0.9099, AUC = 0.8105\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6220 - binary_accuracy: 0.8580 - loss: 0.4961 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7602 - binary_accuracy: 0.9052 - loss: 0.2745 - val_auc: 0.7819 - val_binary_accuracy: 0.9048 - val_loss: 0.2688\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7672 - binary_accuracy: 0.9063 - loss: 0.2710 - val_auc: 0.7895 - val_binary_accuracy: 0.9091 - val_loss: 0.2644\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9057 - loss: 0.2686 - val_auc: 0.7913 - val_binary_accuracy: 0.9085 - val_loss: 0.2633\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9065 - loss: 0.2667 - val_auc: 0.7919 - val_binary_accuracy: 0.9096 - val_loss: 0.2624\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9067 - loss: 0.2656 - val_auc: 0.7946 - val_binary_accuracy: 0.9097 - val_loss: 0.2612\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9080 - loss: 0.2635 - val_auc: 0.7939 - val_binary_accuracy: 0.9102 - val_loss: 0.2604\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9080 - loss: 0.2637 - val_auc: 0.7963 - val_binary_accuracy: 0.9103 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9082 - loss: 0.2612 - val_auc: 0.7947 - val_binary_accuracy: 0.9082 - val_loss: 0.2605\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9081 - loss: 0.2621 - val_auc: 0.7952 - val_binary_accuracy: 0.9097 - val_loss: 0.2594\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7884 - binary_accuracy: 0.9120 - loss: 0.2604\n",
      "Fold 3 Metrics: Loss = 0.2594, Accuracy = 0.9097, AUC = 0.7952\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6633 - binary_accuracy: 0.9040 - loss: 0.3229 - val_auc: 0.7850 - val_binary_accuracy: 0.9048 - val_loss: 0.2676\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9048 - loss: 0.2722 - val_auc: 0.7925 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9057 - loss: 0.2683 - val_auc: 0.7943 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7988 - val_binary_accuracy: 0.9051 - val_loss: 0.2609\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9077 - loss: 0.2638 - val_auc: 0.8002 - val_binary_accuracy: 0.9057 - val_loss: 0.2599\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2619 - val_auc: 0.8020 - val_binary_accuracy: 0.9011 - val_loss: 0.2632\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9082 - loss: 0.2624 - val_auc: 0.8046 - val_binary_accuracy: 0.9022 - val_loss: 0.2611\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9090 - loss: 0.2608 - val_auc: 0.8046 - val_binary_accuracy: 0.9070 - val_loss: 0.2576\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9103 - loss: 0.2591 - val_auc: 0.8067 - val_binary_accuracy: 0.9059 - val_loss: 0.2580\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8067 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7872 - binary_accuracy: 0.9074 - loss: 0.2640\n",
      "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9087, AUC = 0.8067\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6249 - binary_accuracy: 0.8291 - loss: 0.4671 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9043 - loss: 0.2747 - val_auc: 0.7917 - val_binary_accuracy: 0.9003 - val_loss: 0.2738\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9041 - loss: 0.2734 - val_auc: 0.7943 - val_binary_accuracy: 0.8995 - val_loss: 0.2674\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7991 - val_binary_accuracy: 0.9067 - val_loss: 0.2655\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9060 - loss: 0.2693 - val_auc: 0.8004 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9080 - loss: 0.2660 - val_auc: 0.8007 - val_binary_accuracy: 0.9067 - val_loss: 0.2611\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9074 - loss: 0.2656 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2577\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9088 - loss: 0.2633 - val_auc: 0.8051 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8058 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9088 - loss: 0.2624 - val_auc: 0.8067 - val_binary_accuracy: 0.9103 - val_loss: 0.2563\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9101 - loss: 0.2536\n",
      "Fold 5 Metrics: Loss = 0.2563, Accuracy = 0.9103, AUC = 0.8067\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2571\n",
      "Average Accuracy: 0.9094\n",
      "Average AUC: 0.8029\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 5, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7065 - binary_accuracy: 0.9066 - loss: 0.2945 - val_auc: 0.7741 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9077 - loss: 0.2617 - val_auc: 0.7815 - val_binary_accuracy: 0.9050 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9095 - loss: 0.2581 - val_auc: 0.7843 - val_binary_accuracy: 0.9072 - val_loss: 0.2643\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9112 - loss: 0.2549 - val_auc: 0.7880 - val_binary_accuracy: 0.9072 - val_loss: 0.2635\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9112 - loss: 0.2535 - val_auc: 0.7885 - val_binary_accuracy: 0.9069 - val_loss: 0.2627\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9110 - loss: 0.2514 - val_auc: 0.7901 - val_binary_accuracy: 0.9094 - val_loss: 0.2613\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9117 - loss: 0.2508 - val_auc: 0.7918 - val_binary_accuracy: 0.9088 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9120 - loss: 0.2498 - val_auc: 0.7914 - val_binary_accuracy: 0.9081 - val_loss: 0.2612\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8099 - binary_accuracy: 0.9129 - loss: 0.2480 - val_auc: 0.7918 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8098 - binary_accuracy: 0.9131 - loss: 0.2480 - val_auc: 0.7914 - val_binary_accuracy: 0.9072 - val_loss: 0.2619\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7918 - binary_accuracy: 0.9114 - loss: 0.2528\n",
      "Fold 1 Metrics: Loss = 0.2619, Accuracy = 0.9072, AUC = 0.7914\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - auc: 0.6525 - binary_accuracy: 0.8688 - loss: 0.5184 - val_auc: 0.7926 - val_binary_accuracy: 0.9040 - val_loss: 0.2703\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9032 - loss: 0.2726 - val_auc: 0.7990 - val_binary_accuracy: 0.9047 - val_loss: 0.2685\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9047 - loss: 0.2679 - val_auc: 0.8014 - val_binary_accuracy: 0.9068 - val_loss: 0.2666\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9075 - loss: 0.2670 - val_auc: 0.8016 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9071 - loss: 0.2652 - val_auc: 0.8024 - val_binary_accuracy: 0.9069 - val_loss: 0.2633\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9076 - loss: 0.2636 - val_auc: 0.8017 - val_binary_accuracy: 0.9088 - val_loss: 0.2628\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9071 - loss: 0.2625 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2598\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9081 - loss: 0.2615 - val_auc: 0.8113 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9085 - loss: 0.2608 - val_auc: 0.8099 - val_binary_accuracy: 0.9093 - val_loss: 0.2587\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9091 - loss: 0.2603 - val_auc: 0.8159 - val_binary_accuracy: 0.9087 - val_loss: 0.2553\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8209 - binary_accuracy: 0.9127 - loss: 0.2465\n",
      "Fold 2 Metrics: Loss = 0.2553, Accuracy = 0.9087, AUC = 0.8159\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6395 - binary_accuracy: 0.8448 - loss: 0.8657 - val_auc: 0.7829 - val_binary_accuracy: 0.9059 - val_loss: 0.2744\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9073 - loss: 0.2715 - val_auc: 0.7891 - val_binary_accuracy: 0.9081 - val_loss: 0.2712\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9073 - loss: 0.2683 - val_auc: 0.7922 - val_binary_accuracy: 0.9050 - val_loss: 0.2667\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9076 - loss: 0.2681 - val_auc: 0.7940 - val_binary_accuracy: 0.9085 - val_loss: 0.2638\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9079 - loss: 0.2663 - val_auc: 0.7974 - val_binary_accuracy: 0.9084 - val_loss: 0.2618\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9078 - loss: 0.2643 - val_auc: 0.7991 - val_binary_accuracy: 0.9091 - val_loss: 0.2622\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9082 - loss: 0.2631 - val_auc: 0.8007 - val_binary_accuracy: 0.9090 - val_loss: 0.2607\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9089 - loss: 0.2625 - val_auc: 0.8027 - val_binary_accuracy: 0.9090 - val_loss: 0.2601\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9088 - loss: 0.2617 - val_auc: 0.8039 - val_binary_accuracy: 0.9073 - val_loss: 0.2604\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9095 - loss: 0.2615 - val_auc: 0.8035 - val_binary_accuracy: 0.9096 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7963 - binary_accuracy: 0.9118 - loss: 0.2593\n",
      "Fold 3 Metrics: Loss = 0.2587, Accuracy = 0.9096, AUC = 0.8035\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7178 - binary_accuracy: 0.9054 - loss: 0.2938 - val_auc: 0.7950 - val_binary_accuracy: 0.9076 - val_loss: 0.2615\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9079 - loss: 0.2668 - val_auc: 0.7960 - val_binary_accuracy: 0.9064 - val_loss: 0.2606\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9075 - loss: 0.2651 - val_auc: 0.7994 - val_binary_accuracy: 0.9053 - val_loss: 0.2609\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8033 - val_binary_accuracy: 0.9067 - val_loss: 0.2581\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9089 - loss: 0.2615 - val_auc: 0.8032 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9096 - loss: 0.2606 - val_auc: 0.7999 - val_binary_accuracy: 0.9088 - val_loss: 0.2583\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9105 - loss: 0.2601 - val_auc: 0.8074 - val_binary_accuracy: 0.9094 - val_loss: 0.2552\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8089 - val_binary_accuracy: 0.9087 - val_loss: 0.2560\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9107 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9107 - loss: 0.2571 - val_auc: 0.8107 - val_binary_accuracy: 0.9093 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7915 - binary_accuracy: 0.9094 - loss: 0.2624\n",
      "Fold 4 Metrics: Loss = 0.2551, Accuracy = 0.9093, AUC = 0.8107\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6953 - binary_accuracy: 0.9039 - loss: 0.2980 - val_auc: 0.7916 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9037 - loss: 0.2771 - val_auc: 0.7958 - val_binary_accuracy: 0.9053 - val_loss: 0.2638\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9051 - loss: 0.2717 - val_auc: 0.8012 - val_binary_accuracy: 0.9093 - val_loss: 0.2614\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.8033 - val_binary_accuracy: 0.9093 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9081 - loss: 0.2666 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2614\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9084 - loss: 0.2659 - val_auc: 0.8059 - val_binary_accuracy: 0.9093 - val_loss: 0.2613\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9076 - loss: 0.2644 - val_auc: 0.8071 - val_binary_accuracy: 0.9101 - val_loss: 0.2575\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.8085 - val_binary_accuracy: 0.9103 - val_loss: 0.2564\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9099 - loss: 0.2622 - val_auc: 0.8092 - val_binary_accuracy: 0.9107 - val_loss: 0.2549\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9100 - loss: 0.2624 - val_auc: 0.8099 - val_binary_accuracy: 0.9098 - val_loss: 0.2529\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9086 - loss: 0.2514\n",
      "Fold 5 Metrics: Loss = 0.2529, Accuracy = 0.9098, AUC = 0.8099\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2568\n",
      "Average Accuracy: 0.9089\n",
      "Average AUC: 0.8063\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 5, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6974 - binary_accuracy: 0.9006 - loss: 0.3307 - val_auc: 0.7742 - val_binary_accuracy: 0.9084 - val_loss: 0.2769\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.7827 - val_binary_accuracy: 0.9085 - val_loss: 0.2661\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9103 - loss: 0.2595 - val_auc: 0.7857 - val_binary_accuracy: 0.9091 - val_loss: 0.2629\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9110 - loss: 0.2545 - val_auc: 0.7854 - val_binary_accuracy: 0.9115 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9113 - loss: 0.2533 - val_auc: 0.7902 - val_binary_accuracy: 0.9088 - val_loss: 0.2597\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7908 - val_binary_accuracy: 0.9079 - val_loss: 0.2609\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9125 - loss: 0.2505 - val_auc: 0.7908 - val_binary_accuracy: 0.9084 - val_loss: 0.2633\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9130 - loss: 0.2494 - val_auc: 0.7945 - val_binary_accuracy: 0.9063 - val_loss: 0.2647\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9125 - loss: 0.2491 - val_auc: 0.7944 - val_binary_accuracy: 0.9072 - val_loss: 0.2648\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9126 - loss: 0.2485 - val_auc: 0.7941 - val_binary_accuracy: 0.9073 - val_loss: 0.2626\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7940 - binary_accuracy: 0.9106 - loss: 0.2539\n",
      "Fold 1 Metrics: Loss = 0.2626, Accuracy = 0.9073, AUC = 0.7941\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6998 - binary_accuracy: 0.8838 - loss: 0.3609 - val_auc: 0.7953 - val_binary_accuracy: 0.9045 - val_loss: 0.2826\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7627 - binary_accuracy: 0.9035 - loss: 0.2775 - val_auc: 0.7992 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9049 - loss: 0.2698 - val_auc: 0.8042 - val_binary_accuracy: 0.9066 - val_loss: 0.2631\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9058 - loss: 0.2670 - val_auc: 0.8063 - val_binary_accuracy: 0.9081 - val_loss: 0.2642\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9070 - loss: 0.2663 - val_auc: 0.8062 - val_binary_accuracy: 0.9073 - val_loss: 0.2653\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9077 - loss: 0.2641 - val_auc: 0.8034 - val_binary_accuracy: 0.9075 - val_loss: 0.2677\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8074 - val_binary_accuracy: 0.9093 - val_loss: 0.2652\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9081 - loss: 0.2617 - val_auc: 0.8063 - val_binary_accuracy: 0.9085 - val_loss: 0.2641\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9086 - loss: 0.2614 - val_auc: 0.8058 - val_binary_accuracy: 0.9091 - val_loss: 0.2637\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9082 - loss: 0.2606 - val_auc: 0.8082 - val_binary_accuracy: 0.9079 - val_loss: 0.2628\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8096 - binary_accuracy: 0.9121 - loss: 0.2547\n",
      "Fold 2 Metrics: Loss = 0.2628, Accuracy = 0.9079, AUC = 0.8082\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6591 - binary_accuracy: 0.8839 - loss: 0.5042 - val_auc: 0.7756 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7546 - binary_accuracy: 0.9049 - loss: 0.2768 - val_auc: 0.7852 - val_binary_accuracy: 0.9096 - val_loss: 0.2672\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9076 - loss: 0.2673 - val_auc: 0.7930 - val_binary_accuracy: 0.9103 - val_loss: 0.2622\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9080 - loss: 0.2657 - val_auc: 0.7946 - val_binary_accuracy: 0.9081 - val_loss: 0.2625\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9087 - loss: 0.2637 - val_auc: 0.7972 - val_binary_accuracy: 0.9102 - val_loss: 0.2609\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9084 - loss: 0.2633 - val_auc: 0.7994 - val_binary_accuracy: 0.9103 - val_loss: 0.2604\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9089 - loss: 0.2623 - val_auc: 0.8015 - val_binary_accuracy: 0.9110 - val_loss: 0.2616\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.8018 - val_binary_accuracy: 0.9107 - val_loss: 0.2612\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9088 - loss: 0.2616 - val_auc: 0.8027 - val_binary_accuracy: 0.9112 - val_loss: 0.2596\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8039 - val_binary_accuracy: 0.9109 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7971 - binary_accuracy: 0.9118 - loss: 0.2592\n",
      "Fold 3 Metrics: Loss = 0.2586, Accuracy = 0.9109, AUC = 0.8039\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6802 - binary_accuracy: 0.8869 - loss: 0.3484 - val_auc: 0.7851 - val_binary_accuracy: 0.9075 - val_loss: 0.2662\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9065 - loss: 0.2705 - val_auc: 0.7932 - val_binary_accuracy: 0.9038 - val_loss: 0.2647\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9072 - loss: 0.2670 - val_auc: 0.7967 - val_binary_accuracy: 0.9076 - val_loss: 0.2605\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.8005 - val_binary_accuracy: 0.9085 - val_loss: 0.2580\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9089 - loss: 0.2626 - val_auc: 0.8009 - val_binary_accuracy: 0.9098 - val_loss: 0.2574\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8040 - val_binary_accuracy: 0.9094 - val_loss: 0.2563\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9102 - loss: 0.2614 - val_auc: 0.8055 - val_binary_accuracy: 0.9097 - val_loss: 0.2563\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9101 - loss: 0.2600 - val_auc: 0.8064 - val_binary_accuracy: 0.9095 - val_loss: 0.2564\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9100 - loss: 0.2593 - val_auc: 0.8075 - val_binary_accuracy: 0.9098 - val_loss: 0.2562\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9106 - loss: 0.2585 - val_auc: 0.8080 - val_binary_accuracy: 0.9093 - val_loss: 0.2556\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9082 - loss: 0.2633\n",
      "Fold 4 Metrics: Loss = 0.2556, Accuracy = 0.9093, AUC = 0.8080\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6713 - binary_accuracy: 0.8885 - loss: 0.3562 - val_auc: 0.7881 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7560 - binary_accuracy: 0.9039 - loss: 0.2776 - val_auc: 0.7947 - val_binary_accuracy: 0.9079 - val_loss: 0.2627\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9065 - loss: 0.2729 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9060 - loss: 0.2705 - val_auc: 0.8007 - val_binary_accuracy: 0.9112 - val_loss: 0.2633\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9067 - loss: 0.2687 - val_auc: 0.8021 - val_binary_accuracy: 0.9104 - val_loss: 0.2590\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9071 - loss: 0.2674 - val_auc: 0.8048 - val_binary_accuracy: 0.9104 - val_loss: 0.2580\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.8060 - val_binary_accuracy: 0.9104 - val_loss: 0.2581\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2634 - val_auc: 0.8072 - val_binary_accuracy: 0.9113 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9094 - loss: 0.2623 - val_auc: 0.8063 - val_binary_accuracy: 0.9110 - val_loss: 0.2551\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9087 - loss: 0.2620 - val_auc: 0.8075 - val_binary_accuracy: 0.9113 - val_loss: 0.2542\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8159 - binary_accuracy: 0.9098 - loss: 0.2532\n",
      "Fold 5 Metrics: Loss = 0.2542, Accuracy = 0.9113, AUC = 0.8075\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2588\n",
      "Average Accuracy: 0.9093\n",
      "Average AUC: 0.8043\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 5, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6604 - binary_accuracy: 0.8799 - loss: 0.4752 - val_auc: 0.7722 - val_binary_accuracy: 0.9071 - val_loss: 0.2713\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9091 - loss: 0.2630 - val_auc: 0.7802 - val_binary_accuracy: 0.9078 - val_loss: 0.2715\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2572 - val_auc: 0.7870 - val_binary_accuracy: 0.9093 - val_loss: 0.2636\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9117 - loss: 0.2553 - val_auc: 0.7902 - val_binary_accuracy: 0.9099 - val_loss: 0.2630\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9121 - loss: 0.2537 - val_auc: 0.7928 - val_binary_accuracy: 0.9090 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9131 - loss: 0.2514 - val_auc: 0.7936 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9127 - loss: 0.2506 - val_auc: 0.7947 - val_binary_accuracy: 0.9088 - val_loss: 0.2592\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9133 - loss: 0.2493 - val_auc: 0.7947 - val_binary_accuracy: 0.9087 - val_loss: 0.2591\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8062 - binary_accuracy: 0.9130 - loss: 0.2492 - val_auc: 0.7944 - val_binary_accuracy: 0.9075 - val_loss: 0.2643\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9130 - loss: 0.2478 - val_auc: 0.7967 - val_binary_accuracy: 0.9075 - val_loss: 0.2624\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9105 - loss: 0.2539\n",
      "Fold 1 Metrics: Loss = 0.2624, Accuracy = 0.9075, AUC = 0.7967\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6583 - binary_accuracy: 0.8823 - loss: 0.5256 - val_auc: 0.7975 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9035 - loss: 0.2733 - val_auc: 0.8036 - val_binary_accuracy: 0.9063 - val_loss: 0.2675\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9057 - loss: 0.2684 - val_auc: 0.8062 - val_binary_accuracy: 0.9081 - val_loss: 0.2629\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9063 - loss: 0.2668 - val_auc: 0.8093 - val_binary_accuracy: 0.9062 - val_loss: 0.2619\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9068 - loss: 0.2650 - val_auc: 0.8026 - val_binary_accuracy: 0.9073 - val_loss: 0.2651\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9079 - loss: 0.2645 - val_auc: 0.8084 - val_binary_accuracy: 0.9071 - val_loss: 0.2659\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9067 - loss: 0.2632 - val_auc: 0.8118 - val_binary_accuracy: 0.9071 - val_loss: 0.2634\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9079 - loss: 0.2620 - val_auc: 0.8119 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9078 - loss: 0.2617 - val_auc: 0.8081 - val_binary_accuracy: 0.9082 - val_loss: 0.2628\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9088 - loss: 0.2612 - val_auc: 0.8066 - val_binary_accuracy: 0.9082 - val_loss: 0.2651\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8135 - binary_accuracy: 0.9126 - loss: 0.2562\n",
      "Fold 2 Metrics: Loss = 0.2651, Accuracy = 0.9082, AUC = 0.8066\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6539 - binary_accuracy: 0.8703 - loss: 0.4389 - val_auc: 0.7834 - val_binary_accuracy: 0.9063 - val_loss: 0.2737\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9068 - loss: 0.2708 - val_auc: 0.7899 - val_binary_accuracy: 0.9051 - val_loss: 0.2677\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9077 - loss: 0.2666 - val_auc: 0.7933 - val_binary_accuracy: 0.9053 - val_loss: 0.2636\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9085 - loss: 0.2650 - val_auc: 0.7966 - val_binary_accuracy: 0.9071 - val_loss: 0.2616\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9083 - loss: 0.2644 - val_auc: 0.7991 - val_binary_accuracy: 0.9054 - val_loss: 0.2626\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9095 - loss: 0.2624 - val_auc: 0.8015 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8019 - val_binary_accuracy: 0.9102 - val_loss: 0.2598\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8035 - val_binary_accuracy: 0.9109 - val_loss: 0.2575\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9096 - loss: 0.2620 - val_auc: 0.8041 - val_binary_accuracy: 0.9071 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9093 - loss: 0.2600 - val_auc: 0.8056 - val_binary_accuracy: 0.9097 - val_loss: 0.2588\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7988 - binary_accuracy: 0.9097 - loss: 0.2595\n",
      "Fold 3 Metrics: Loss = 0.2588, Accuracy = 0.9097, AUC = 0.8056\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6627 - binary_accuracy: 0.8852 - loss: 0.4744 - val_auc: 0.7887 - val_binary_accuracy: 0.9050 - val_loss: 0.2751\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9071 - loss: 0.2727 - val_auc: 0.7961 - val_binary_accuracy: 0.9069 - val_loss: 0.2627\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.8004 - val_binary_accuracy: 0.9081 - val_loss: 0.2597\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8025 - val_binary_accuracy: 0.9079 - val_loss: 0.2594\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9091 - loss: 0.2633 - val_auc: 0.8055 - val_binary_accuracy: 0.9093 - val_loss: 0.2563\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9095 - loss: 0.2620 - val_auc: 0.8067 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9103 - loss: 0.2612 - val_auc: 0.8094 - val_binary_accuracy: 0.9104 - val_loss: 0.2542\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9103 - loss: 0.2606 - val_auc: 0.8108 - val_binary_accuracy: 0.9097 - val_loss: 0.2539\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9103 - loss: 0.2600 - val_auc: 0.8101 - val_binary_accuracy: 0.9095 - val_loss: 0.2542\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9105 - loss: 0.2591 - val_auc: 0.8119 - val_binary_accuracy: 0.9097 - val_loss: 0.2532\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7929 - binary_accuracy: 0.9092 - loss: 0.2601\n",
      "Fold 4 Metrics: Loss = 0.2532, Accuracy = 0.9097, AUC = 0.8119\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6627 - binary_accuracy: 0.8900 - loss: 0.3801 - val_auc: 0.7908 - val_binary_accuracy: 0.9064 - val_loss: 0.2643\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9036 - loss: 0.2766 - val_auc: 0.7966 - val_binary_accuracy: 0.9022 - val_loss: 0.2604\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9040 - loss: 0.2731 - val_auc: 0.8000 - val_binary_accuracy: 0.9026 - val_loss: 0.2655\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9050 - loss: 0.2698 - val_auc: 0.8031 - val_binary_accuracy: 0.9098 - val_loss: 0.2657\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9076 - loss: 0.2673 - val_auc: 0.8038 - val_binary_accuracy: 0.9103 - val_loss: 0.2662\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9067 - loss: 0.2667 - val_auc: 0.8061 - val_binary_accuracy: 0.9101 - val_loss: 0.2626\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8078 - val_binary_accuracy: 0.9109 - val_loss: 0.2629\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9085 - loss: 0.2637 - val_auc: 0.8088 - val_binary_accuracy: 0.9113 - val_loss: 0.2612\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8093 - val_binary_accuracy: 0.9112 - val_loss: 0.2606\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9089 - loss: 0.2621 - val_auc: 0.8105 - val_binary_accuracy: 0.9110 - val_loss: 0.2592\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8180 - binary_accuracy: 0.9095 - loss: 0.2583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 33%|      | 1/3 [27:29<54:58, 1649.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Metrics: Loss = 0.2592, Accuracy = 0.9110, AUC = 0.8105\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2597\n",
      "Average Accuracy: 0.9092\n",
      "Average AUC: 0.8063\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 1, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5407 - binary_accuracy: 0.8881 - loss: 0.4453 - val_auc: 0.7252 - val_binary_accuracy: 0.9044 - val_loss: 0.2942\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7504 - binary_accuracy: 0.9069 - loss: 0.2838 - val_auc: 0.7611 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9069 - loss: 0.2731 - val_auc: 0.7639 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9069 - loss: 0.2694 - val_auc: 0.7680 - val_binary_accuracy: 0.9044 - val_loss: 0.2769\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.7680 - val_binary_accuracy: 0.9044 - val_loss: 0.2740\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9069 - loss: 0.2637 - val_auc: 0.7704 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7703 - val_binary_accuracy: 0.9044 - val_loss: 0.2711\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9069 - loss: 0.2606 - val_auc: 0.7728 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2597 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9069 - loss: 0.2591 - val_auc: 0.7754 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7695 - binary_accuracy: 0.9084 - loss: 0.2623\n",
      "Fold 1 Metrics: Loss = 0.2693, Accuracy = 0.9044, AUC = 0.7754\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5431 - binary_accuracy: 0.6690 - loss: 0.5823 - val_auc: 0.7283 - val_binary_accuracy: 0.9042 - val_loss: 0.2975\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7313 - binary_accuracy: 0.9029 - loss: 0.2964 - val_auc: 0.7698 - val_binary_accuracy: 0.9042 - val_loss: 0.2864\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7585 - binary_accuracy: 0.9029 - loss: 0.2881 - val_auc: 0.7775 - val_binary_accuracy: 0.9042 - val_loss: 0.2786\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9029 - loss: 0.2803 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2724\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2756 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9029 - loss: 0.2730 - val_auc: 0.7930 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9029 - loss: 0.2714 - val_auc: 0.7936 - val_binary_accuracy: 0.9042 - val_loss: 0.2647\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9029 - loss: 0.2702 - val_auc: 0.7938 - val_binary_accuracy: 0.9042 - val_loss: 0.2635\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9029 - loss: 0.2692 - val_auc: 0.7980 - val_binary_accuracy: 0.9042 - val_loss: 0.2621\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9029 - loss: 0.2683 - val_auc: 0.7988 - val_binary_accuracy: 0.9042 - val_loss: 0.2610\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7984 - binary_accuracy: 0.9092 - loss: 0.2522\n",
      "Fold 2 Metrics: Loss = 0.2610, Accuracy = 0.9042, AUC = 0.7988\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5566 - binary_accuracy: 0.8404 - loss: 0.4183 - val_auc: 0.7434 - val_binary_accuracy: 0.9042 - val_loss: 0.2893\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7448 - binary_accuracy: 0.9051 - loss: 0.2850 - val_auc: 0.7576 - val_binary_accuracy: 0.9042 - val_loss: 0.2785\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9051 - loss: 0.2765 - val_auc: 0.7733 - val_binary_accuracy: 0.9042 - val_loss: 0.2735\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9051 - loss: 0.2715 - val_auc: 0.7771 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9051 - loss: 0.2685 - val_auc: 0.7793 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7828 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9051 - loss: 0.2654 - val_auc: 0.7842 - val_binary_accuracy: 0.9042 - val_loss: 0.2678\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9051 - loss: 0.2646 - val_auc: 0.7856 - val_binary_accuracy: 0.9042 - val_loss: 0.2673\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9051 - loss: 0.2636 - val_auc: 0.7896 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7821 - binary_accuracy: 0.9046 - loss: 0.2672\n",
      "Fold 3 Metrics: Loss = 0.2663, Accuracy = 0.9042, AUC = 0.7896\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5240 - binary_accuracy: 0.7788 - loss: 0.5157 - val_auc: 0.7256 - val_binary_accuracy: 0.9044 - val_loss: 0.3122\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7287 - binary_accuracy: 0.9047 - loss: 0.3036 - val_auc: 0.7630 - val_binary_accuracy: 0.9044 - val_loss: 0.2779\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7619 - binary_accuracy: 0.9047 - loss: 0.2764 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9047 - loss: 0.2717 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7742 - binary_accuracy: 0.9047 - loss: 0.2695 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9047 - loss: 0.2683 - val_auc: 0.7825 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9047 - loss: 0.2676 - val_auc: 0.7815 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9047 - loss: 0.2670 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9047 - loss: 0.2665 - val_auc: 0.7827 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9047 - loss: 0.2660 - val_auc: 0.7825 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7576 - binary_accuracy: 0.9049 - loss: 0.2724\n",
      "Fold 4 Metrics: Loss = 0.2665, Accuracy = 0.9044, AUC = 0.7825\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5757 - binary_accuracy: 0.8772 - loss: 0.3729 - val_auc: 0.7388 - val_binary_accuracy: 0.9044 - val_loss: 0.2870\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7411 - binary_accuracy: 0.9040 - loss: 0.2862 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7650 - binary_accuracy: 0.9040 - loss: 0.2755 - val_auc: 0.7852 - val_binary_accuracy: 0.9044 - val_loss: 0.2646\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7720 - binary_accuracy: 0.9049 - loss: 0.2702 - val_auc: 0.7873 - val_binary_accuracy: 0.9067 - val_loss: 0.2615\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9062 - loss: 0.2676 - val_auc: 0.7915 - val_binary_accuracy: 0.9076 - val_loss: 0.2600\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9077 - loss: 0.2660 - val_auc: 0.7935 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7824 - binary_accuracy: 0.9084 - loss: 0.2650 - val_auc: 0.7944 - val_binary_accuracy: 0.9097 - val_loss: 0.2582\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9085 - loss: 0.2643 - val_auc: 0.7955 - val_binary_accuracy: 0.9100 - val_loss: 0.2578\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9086 - loss: 0.2637 - val_auc: 0.7962 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7852 - binary_accuracy: 0.9084 - loss: 0.2633 - val_auc: 0.7966 - val_binary_accuracy: 0.9100 - val_loss: 0.2568\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8049 - binary_accuracy: 0.9085 - loss: 0.2565\n",
      "Fold 5 Metrics: Loss = 0.2568, Accuracy = 0.9100, AUC = 0.7966\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2640\n",
      "Average Accuracy: 0.9055\n",
      "Average AUC: 0.7886\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 1, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5814 - binary_accuracy: 0.6433 - loss: 0.6112 - val_auc: 0.7338 - val_binary_accuracy: 0.9044 - val_loss: 0.2928\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7551 - binary_accuracy: 0.9069 - loss: 0.2785 - val_auc: 0.7602 - val_binary_accuracy: 0.9044 - val_loss: 0.2753\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9069 - loss: 0.2657 - val_auc: 0.7694 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7941 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7769 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7977 - binary_accuracy: 0.9069 - loss: 0.2567 - val_auc: 0.7788 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7992 - binary_accuracy: 0.9070 - loss: 0.2558 - val_auc: 0.7803 - val_binary_accuracy: 0.9060 - val_loss: 0.2648\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8003 - binary_accuracy: 0.9084 - loss: 0.2548 - val_auc: 0.7815 - val_binary_accuracy: 0.9071 - val_loss: 0.2641\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8019 - binary_accuracy: 0.9096 - loss: 0.2540 - val_auc: 0.7836 - val_binary_accuracy: 0.9076 - val_loss: 0.2635\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8027 - binary_accuracy: 0.9106 - loss: 0.2534 - val_auc: 0.7855 - val_binary_accuracy: 0.9088 - val_loss: 0.2629\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7808 - binary_accuracy: 0.9122 - loss: 0.2566\n",
      "Fold 1 Metrics: Loss = 0.2629, Accuracy = 0.9088, AUC = 0.7855\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5741 - binary_accuracy: 0.7016 - loss: 0.5321 - val_auc: 0.7599 - val_binary_accuracy: 0.9042 - val_loss: 0.2855\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7551 - binary_accuracy: 0.9029 - loss: 0.2834 - val_auc: 0.7829 - val_binary_accuracy: 0.9042 - val_loss: 0.2736\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9029 - loss: 0.2756 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7805 - binary_accuracy: 0.9029 - loss: 0.2717 - val_auc: 0.7976 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9029 - loss: 0.2694 - val_auc: 0.8017 - val_binary_accuracy: 0.9042 - val_loss: 0.2658\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9029 - loss: 0.2679 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2636\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9045 - loss: 0.2666 - val_auc: 0.8037 - val_binary_accuracy: 0.9048 - val_loss: 0.2610\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9054 - loss: 0.2651 - val_auc: 0.8046 - val_binary_accuracy: 0.9057 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9065 - loss: 0.2641 - val_auc: 0.8073 - val_binary_accuracy: 0.9066 - val_loss: 0.2590\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9070 - loss: 0.2632 - val_auc: 0.8092 - val_binary_accuracy: 0.9069 - val_loss: 0.2584\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8106 - binary_accuracy: 0.9109 - loss: 0.2493\n",
      "Fold 2 Metrics: Loss = 0.2584, Accuracy = 0.9069, AUC = 0.8092\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6599 - binary_accuracy: 0.9042 - loss: 0.3330 - val_auc: 0.7664 - val_binary_accuracy: 0.9042 - val_loss: 0.2731\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9051 - loss: 0.2704 - val_auc: 0.7746 - val_binary_accuracy: 0.9042 - val_loss: 0.2704\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9051 - loss: 0.2674 - val_auc: 0.7760 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9051 - loss: 0.2659 - val_auc: 0.7795 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7805 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2641 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2665\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9053 - loss: 0.2633 - val_auc: 0.7856 - val_binary_accuracy: 0.9057 - val_loss: 0.2654\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7857 - binary_accuracy: 0.9065 - loss: 0.2623 - val_auc: 0.7881 - val_binary_accuracy: 0.9069 - val_loss: 0.2643\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7871 - binary_accuracy: 0.9072 - loss: 0.2613 - val_auc: 0.7913 - val_binary_accuracy: 0.9090 - val_loss: 0.2630\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9075 - loss: 0.2604 - val_auc: 0.7932 - val_binary_accuracy: 0.9093 - val_loss: 0.2620\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7855 - binary_accuracy: 0.9099 - loss: 0.2633\n",
      "Fold 3 Metrics: Loss = 0.2620, Accuracy = 0.9093, AUC = 0.7932\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5827 - binary_accuracy: 0.6991 - loss: 0.5044 - val_auc: 0.7478 - val_binary_accuracy: 0.9044 - val_loss: 0.2858\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7446 - binary_accuracy: 0.9047 - loss: 0.2826 - val_auc: 0.7729 - val_binary_accuracy: 0.9044 - val_loss: 0.2749\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9047 - loss: 0.2730 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9047 - loss: 0.2686 - val_auc: 0.7858 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9047 - loss: 0.2663 - val_auc: 0.7884 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9048 - loss: 0.2643 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7868 - binary_accuracy: 0.9052 - loss: 0.2632 - val_auc: 0.7899 - val_binary_accuracy: 0.9047 - val_loss: 0.2660\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9070 - loss: 0.2623 - val_auc: 0.7910 - val_binary_accuracy: 0.9056 - val_loss: 0.2654\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9087 - loss: 0.2615 - val_auc: 0.7925 - val_binary_accuracy: 0.9070 - val_loss: 0.2648\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9089 - loss: 0.2606 - val_auc: 0.7934 - val_binary_accuracy: 0.9076 - val_loss: 0.2642\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7696 - binary_accuracy: 0.9062 - loss: 0.2695\n",
      "Fold 4 Metrics: Loss = 0.2642, Accuracy = 0.9076, AUC = 0.7934\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6358 - binary_accuracy: 0.9040 - loss: 0.3280 - val_auc: 0.7817 - val_binary_accuracy: 0.9044 - val_loss: 0.2685\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9040 - loss: 0.2742 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7746 - binary_accuracy: 0.9040 - loss: 0.2710 - val_auc: 0.7913 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.7956 - val_binary_accuracy: 0.9044 - val_loss: 0.2601\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7818 - binary_accuracy: 0.9040 - loss: 0.2679 - val_auc: 0.7975 - val_binary_accuracy: 0.9044 - val_loss: 0.2589\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9042 - loss: 0.2666 - val_auc: 0.7992 - val_binary_accuracy: 0.9048 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7997 - val_binary_accuracy: 0.9053 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9065 - loss: 0.2647 - val_auc: 0.8003 - val_binary_accuracy: 0.9073 - val_loss: 0.2565\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9070 - loss: 0.2638 - val_auc: 0.8006 - val_binary_accuracy: 0.9085 - val_loss: 0.2558\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9080 - loss: 0.2630 - val_auc: 0.8014 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8118 - binary_accuracy: 0.9068 - loss: 0.2537\n",
      "Fold 5 Metrics: Loss = 0.2550, Accuracy = 0.9090, AUC = 0.8014\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2605\n",
      "Average Accuracy: 0.9083\n",
      "Average AUC: 0.7965\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 1, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6186 - binary_accuracy: 0.8966 - loss: 0.3419 - val_auc: 0.7591 - val_binary_accuracy: 0.9044 - val_loss: 0.2778\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9069 - loss: 0.2665 - val_auc: 0.7716 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9070 - loss: 0.2587 - val_auc: 0.7766 - val_binary_accuracy: 0.9060 - val_loss: 0.2672\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9098 - loss: 0.2561 - val_auc: 0.7801 - val_binary_accuracy: 0.9073 - val_loss: 0.2654\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9113 - loss: 0.2543 - val_auc: 0.7829 - val_binary_accuracy: 0.9088 - val_loss: 0.2639\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9120 - loss: 0.2527 - val_auc: 0.7854 - val_binary_accuracy: 0.9099 - val_loss: 0.2624\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9123 - loss: 0.2513 - val_auc: 0.7874 - val_binary_accuracy: 0.9094 - val_loss: 0.2613\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9123 - loss: 0.2503 - val_auc: 0.7893 - val_binary_accuracy: 0.9093 - val_loss: 0.2608\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8094 - binary_accuracy: 0.9129 - loss: 0.2494 - val_auc: 0.7898 - val_binary_accuracy: 0.9091 - val_loss: 0.2603\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9128 - loss: 0.2486 - val_auc: 0.7912 - val_binary_accuracy: 0.9096 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7863 - binary_accuracy: 0.9139 - loss: 0.2541\n",
      "Fold 1 Metrics: Loss = 0.2599, Accuracy = 0.9096, AUC = 0.7912\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6473 - binary_accuracy: 0.9029 - loss: 0.3159 - val_auc: 0.7858 - val_binary_accuracy: 0.9042 - val_loss: 0.2720\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9029 - loss: 0.2745 - val_auc: 0.7967 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.7998 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9031 - loss: 0.2680 - val_auc: 0.8024 - val_binary_accuracy: 0.9044 - val_loss: 0.2627\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9045 - loss: 0.2662 - val_auc: 0.8050 - val_binary_accuracy: 0.9057 - val_loss: 0.2602\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9060 - loss: 0.2646 - val_auc: 0.8058 - val_binary_accuracy: 0.9060 - val_loss: 0.2592\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9070 - loss: 0.2627 - val_auc: 0.8070 - val_binary_accuracy: 0.9062 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9073 - loss: 0.2615 - val_auc: 0.8076 - val_binary_accuracy: 0.9071 - val_loss: 0.2590\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9080 - loss: 0.2604 - val_auc: 0.8090 - val_binary_accuracy: 0.9078 - val_loss: 0.2587\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8017 - binary_accuracy: 0.9078 - loss: 0.2596 - val_auc: 0.8100 - val_binary_accuracy: 0.9081 - val_loss: 0.2583\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8147 - binary_accuracy: 0.9118 - loss: 0.2477\n",
      "Fold 2 Metrics: Loss = 0.2583, Accuracy = 0.9081, AUC = 0.8100\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7156 - binary_accuracy: 0.9051 - loss: 0.2877 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7728 - binary_accuracy: 0.9051 - loss: 0.2691 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7798 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7847 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9053 - loss: 0.2639 - val_auc: 0.7893 - val_binary_accuracy: 0.9048 - val_loss: 0.2648\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7860 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.7926 - val_binary_accuracy: 0.9076 - val_loss: 0.2628\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9076 - loss: 0.2611 - val_auc: 0.7957 - val_binary_accuracy: 0.9094 - val_loss: 0.2615\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7907 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.7979 - val_binary_accuracy: 0.9100 - val_loss: 0.2604\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7916 - binary_accuracy: 0.9094 - loss: 0.2593 - val_auc: 0.7993 - val_binary_accuracy: 0.9102 - val_loss: 0.2594\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7931 - binary_accuracy: 0.9095 - loss: 0.2587 - val_auc: 0.8006 - val_binary_accuracy: 0.9103 - val_loss: 0.2587\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7939 - binary_accuracy: 0.9098 - loss: 0.2582 - val_auc: 0.8025 - val_binary_accuracy: 0.9104 - val_loss: 0.2580\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9120 - loss: 0.2587\n",
      "Fold 3 Metrics: Loss = 0.2580, Accuracy = 0.9104, AUC = 0.8025\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5983 - binary_accuracy: 0.7126 - loss: 0.5437 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2777\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7606 - binary_accuracy: 0.9047 - loss: 0.2754 - val_auc: 0.7823 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9047 - loss: 0.2678 - val_auc: 0.7875 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7826 - binary_accuracy: 0.9050 - loss: 0.2653 - val_auc: 0.7899 - val_binary_accuracy: 0.9045 - val_loss: 0.2673\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9062 - loss: 0.2637 - val_auc: 0.7929 - val_binary_accuracy: 0.9057 - val_loss: 0.2662\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9083 - loss: 0.2622 - val_auc: 0.7957 - val_binary_accuracy: 0.9070 - val_loss: 0.2653\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.7975 - val_binary_accuracy: 0.9079 - val_loss: 0.2640\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9091 - loss: 0.2601 - val_auc: 0.7994 - val_binary_accuracy: 0.9085 - val_loss: 0.2632\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9096 - loss: 0.2593 - val_auc: 0.8001 - val_binary_accuracy: 0.9091 - val_loss: 0.2626\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9100 - loss: 0.2586 - val_auc: 0.8017 - val_binary_accuracy: 0.9094 - val_loss: 0.2622\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7809 - binary_accuracy: 0.9092 - loss: 0.2677\n",
      "Fold 4 Metrics: Loss = 0.2622, Accuracy = 0.9094, AUC = 0.8017\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6977 - binary_accuracy: 0.9040 - loss: 0.2969 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9040 - loss: 0.2689 - val_auc: 0.7955 - val_binary_accuracy: 0.9047 - val_loss: 0.2596\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9045 - loss: 0.2668 - val_auc: 0.7981 - val_binary_accuracy: 0.9060 - val_loss: 0.2578\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9057 - loss: 0.2653 - val_auc: 0.8018 - val_binary_accuracy: 0.9087 - val_loss: 0.2560\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.8029 - val_binary_accuracy: 0.9087 - val_loss: 0.2553\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9084 - loss: 0.2627 - val_auc: 0.8040 - val_binary_accuracy: 0.9093 - val_loss: 0.2545\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9087 - loss: 0.2618 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2537\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9094 - loss: 0.2611 - val_auc: 0.8062 - val_binary_accuracy: 0.9104 - val_loss: 0.2530\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9100 - loss: 0.2602 - val_auc: 0.8068 - val_binary_accuracy: 0.9104 - val_loss: 0.2525\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9084 - loss: 0.2513\n",
      "Fold 5 Metrics: Loss = 0.2525, Accuracy = 0.9104, AUC = 0.8068\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2582\n",
      "Average Accuracy: 0.9096\n",
      "Average AUC: 0.8025\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 1, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6868 - binary_accuracy: 0.9069 - loss: 0.2956 - val_auc: 0.7720 - val_binary_accuracy: 0.9044 - val_loss: 0.2714\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9075 - loss: 0.2586 - val_auc: 0.7812 - val_binary_accuracy: 0.9069 - val_loss: 0.2663\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9093 - loss: 0.2549 - val_auc: 0.7856 - val_binary_accuracy: 0.9082 - val_loss: 0.2640\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9118 - loss: 0.2526 - val_auc: 0.7884 - val_binary_accuracy: 0.9079 - val_loss: 0.2622\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9130 - loss: 0.2509 - val_auc: 0.7903 - val_binary_accuracy: 0.9085 - val_loss: 0.2610\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9129 - loss: 0.2493 - val_auc: 0.7918 - val_binary_accuracy: 0.9085 - val_loss: 0.2604\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9128 - loss: 0.2484 - val_auc: 0.7930 - val_binary_accuracy: 0.9085 - val_loss: 0.2600\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9127 - loss: 0.2475 - val_auc: 0.7938 - val_binary_accuracy: 0.9087 - val_loss: 0.2597\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8133 - binary_accuracy: 0.9127 - loss: 0.2469 - val_auc: 0.7941 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9126 - loss: 0.2463 - val_auc: 0.7949 - val_binary_accuracy: 0.9090 - val_loss: 0.2591\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7946 - binary_accuracy: 0.9128 - loss: 0.2521\n",
      "Fold 1 Metrics: Loss = 0.2591, Accuracy = 0.9090, AUC = 0.7949\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6517 - binary_accuracy: 0.8179 - loss: 0.3826 - val_auc: 0.7930 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8002 - val_binary_accuracy: 0.9042 - val_loss: 0.2628\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9042 - loss: 0.2661 - val_auc: 0.8058 - val_binary_accuracy: 0.9048 - val_loss: 0.2597\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9064 - loss: 0.2636 - val_auc: 0.8082 - val_binary_accuracy: 0.9060 - val_loss: 0.2586\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9069 - loss: 0.2619 - val_auc: 0.8095 - val_binary_accuracy: 0.9062 - val_loss: 0.2579\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.8110 - val_binary_accuracy: 0.9072 - val_loss: 0.2570\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9081 - loss: 0.2598 - val_auc: 0.8115 - val_binary_accuracy: 0.9073 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9080 - loss: 0.2591 - val_auc: 0.8116 - val_binary_accuracy: 0.9076 - val_loss: 0.2568\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9079 - loss: 0.2584 - val_auc: 0.8129 - val_binary_accuracy: 0.9082 - val_loss: 0.2565\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9083 - loss: 0.2578 - val_auc: 0.8133 - val_binary_accuracy: 0.9084 - val_loss: 0.2565\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8198 - binary_accuracy: 0.9127 - loss: 0.2454\n",
      "Fold 2 Metrics: Loss = 0.2565, Accuracy = 0.9084, AUC = 0.8133\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6423 - binary_accuracy: 0.8182 - loss: 0.3870 - val_auc: 0.7731 - val_binary_accuracy: 0.9042 - val_loss: 0.2711\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9052 - loss: 0.2688 - val_auc: 0.7804 - val_binary_accuracy: 0.9045 - val_loss: 0.2677\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9071 - loss: 0.2651 - val_auc: 0.7852 - val_binary_accuracy: 0.9079 - val_loss: 0.2652\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9081 - loss: 0.2633 - val_auc: 0.7890 - val_binary_accuracy: 0.9102 - val_loss: 0.2631\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9090 - loss: 0.2618 - val_auc: 0.7941 - val_binary_accuracy: 0.9099 - val_loss: 0.2611\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9095 - loss: 0.2605 - val_auc: 0.7981 - val_binary_accuracy: 0.9103 - val_loss: 0.2593\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9094 - loss: 0.2595 - val_auc: 0.8009 - val_binary_accuracy: 0.9113 - val_loss: 0.2581\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9096 - loss: 0.2587 - val_auc: 0.8031 - val_binary_accuracy: 0.9113 - val_loss: 0.2570\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9094 - loss: 0.2581 - val_auc: 0.8049 - val_binary_accuracy: 0.9115 - val_loss: 0.2562\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9096 - loss: 0.2576 - val_auc: 0.8059 - val_binary_accuracy: 0.9113 - val_loss: 0.2557\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9125 - loss: 0.2569\n",
      "Fold 3 Metrics: Loss = 0.2557, Accuracy = 0.9113, AUC = 0.8059\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6984 - binary_accuracy: 0.9049 - loss: 0.2910 - val_auc: 0.7864 - val_binary_accuracy: 0.9051 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7942 - val_binary_accuracy: 0.9066 - val_loss: 0.2623\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.7989 - val_binary_accuracy: 0.9078 - val_loss: 0.2601\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9095 - loss: 0.2601 - val_auc: 0.8015 - val_binary_accuracy: 0.9084 - val_loss: 0.2583\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9104 - loss: 0.2586 - val_auc: 0.8059 - val_binary_accuracy: 0.9087 - val_loss: 0.2570\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9109 - loss: 0.2575 - val_auc: 0.8062 - val_binary_accuracy: 0.9093 - val_loss: 0.2563\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9107 - loss: 0.2567 - val_auc: 0.8087 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7990 - binary_accuracy: 0.9108 - loss: 0.2559 - val_auc: 0.8093 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9110 - loss: 0.2555 - val_auc: 0.8103 - val_binary_accuracy: 0.9095 - val_loss: 0.2552\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9113 - loss: 0.2550 - val_auc: 0.8101 - val_binary_accuracy: 0.9095 - val_loss: 0.2549\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7899 - binary_accuracy: 0.9090 - loss: 0.2617\n",
      "Fold 4 Metrics: Loss = 0.2549, Accuracy = 0.9095, AUC = 0.8101\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6479 - binary_accuracy: 0.8353 - loss: 0.3740 - val_auc: 0.7840 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9040 - loss: 0.2720 - val_auc: 0.7910 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9044 - loss: 0.2683 - val_auc: 0.7960 - val_binary_accuracy: 0.9067 - val_loss: 0.2589\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9064 - loss: 0.2662 - val_auc: 0.7995 - val_binary_accuracy: 0.9079 - val_loss: 0.2572\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7868 - binary_accuracy: 0.9084 - loss: 0.2645 - val_auc: 0.8025 - val_binary_accuracy: 0.9095 - val_loss: 0.2556\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7902 - binary_accuracy: 0.9086 - loss: 0.2630 - val_auc: 0.8039 - val_binary_accuracy: 0.9100 - val_loss: 0.2545\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7913 - binary_accuracy: 0.9089 - loss: 0.2617 - val_auc: 0.8054 - val_binary_accuracy: 0.9101 - val_loss: 0.2537\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7936 - binary_accuracy: 0.9093 - loss: 0.2608 - val_auc: 0.8058 - val_binary_accuracy: 0.9107 - val_loss: 0.2531\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9098 - loss: 0.2600 - val_auc: 0.8060 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9102 - loss: 0.2594 - val_auc: 0.8069 - val_binary_accuracy: 0.9107 - val_loss: 0.2522\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8153 - binary_accuracy: 0.9089 - loss: 0.2510\n",
      "Fold 5 Metrics: Loss = 0.2522, Accuracy = 0.9107, AUC = 0.8069\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2557\n",
      "Average Accuracy: 0.9098\n",
      "Average AUC: 0.8062\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 1, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6850 - binary_accuracy: 0.8710 - loss: 0.3234 - val_auc: 0.7733 - val_binary_accuracy: 0.9051 - val_loss: 0.2710\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.7813 - val_binary_accuracy: 0.9076 - val_loss: 0.2667\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9107 - loss: 0.2548 - val_auc: 0.7862 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7903 - val_binary_accuracy: 0.9088 - val_loss: 0.2613\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9128 - loss: 0.2501 - val_auc: 0.7922 - val_binary_accuracy: 0.9087 - val_loss: 0.2602\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8095 - binary_accuracy: 0.9126 - loss: 0.2488 - val_auc: 0.7933 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9127 - loss: 0.2477 - val_auc: 0.7948 - val_binary_accuracy: 0.9088 - val_loss: 0.2590\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8135 - binary_accuracy: 0.9127 - loss: 0.2469 - val_auc: 0.7953 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8146 - binary_accuracy: 0.9128 - loss: 0.2462 - val_auc: 0.7952 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8154 - binary_accuracy: 0.9127 - loss: 0.2457 - val_auc: 0.7962 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7961 - binary_accuracy: 0.9129 - loss: 0.2514\n",
      "Fold 1 Metrics: Loss = 0.2586, Accuracy = 0.9088, AUC = 0.7962\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6677 - binary_accuracy: 0.8441 - loss: 0.3601 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2654\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9036 - loss: 0.2691 - val_auc: 0.8037 - val_binary_accuracy: 0.9054 - val_loss: 0.2597\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9055 - loss: 0.2651 - val_auc: 0.8071 - val_binary_accuracy: 0.9068 - val_loss: 0.2577\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9074 - loss: 0.2630 - val_auc: 0.8099 - val_binary_accuracy: 0.9073 - val_loss: 0.2569\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9077 - loss: 0.2616 - val_auc: 0.8116 - val_binary_accuracy: 0.9078 - val_loss: 0.2558\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9078 - loss: 0.2605 - val_auc: 0.8123 - val_binary_accuracy: 0.9079 - val_loss: 0.2555\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9085 - loss: 0.2597 - val_auc: 0.8131 - val_binary_accuracy: 0.9081 - val_loss: 0.2549\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9084 - loss: 0.2589 - val_auc: 0.8136 - val_binary_accuracy: 0.9084 - val_loss: 0.2546\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9085 - loss: 0.2582 - val_auc: 0.8140 - val_binary_accuracy: 0.9090 - val_loss: 0.2543\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9084 - loss: 0.2576 - val_auc: 0.8145 - val_binary_accuracy: 0.9088 - val_loss: 0.2541\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8208 - binary_accuracy: 0.9133 - loss: 0.2435\n",
      "Fold 2 Metrics: Loss = 0.2541, Accuracy = 0.9088, AUC = 0.8145\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6643 - binary_accuracy: 0.8778 - loss: 0.3242 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9067 - loss: 0.2680 - val_auc: 0.7863 - val_binary_accuracy: 0.9075 - val_loss: 0.2657\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9081 - loss: 0.2653 - val_auc: 0.7920 - val_binary_accuracy: 0.9097 - val_loss: 0.2632\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9085 - loss: 0.2632 - val_auc: 0.7953 - val_binary_accuracy: 0.9100 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9092 - loss: 0.2618 - val_auc: 0.7988 - val_binary_accuracy: 0.9107 - val_loss: 0.2594\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9092 - loss: 0.2609 - val_auc: 0.8003 - val_binary_accuracy: 0.9110 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9096 - loss: 0.2600 - val_auc: 0.8029 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9099 - loss: 0.2594 - val_auc: 0.8035 - val_binary_accuracy: 0.9112 - val_loss: 0.2564\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9098 - loss: 0.2589 - val_auc: 0.8053 - val_binary_accuracy: 0.9110 - val_loss: 0.2557\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7922 - binary_accuracy: 0.9098 - loss: 0.2585 - val_auc: 0.8063 - val_binary_accuracy: 0.9109 - val_loss: 0.2553\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9118 - loss: 0.2562\n",
      "Fold 3 Metrics: Loss = 0.2553, Accuracy = 0.9109, AUC = 0.8063\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7242 - binary_accuracy: 0.9052 - loss: 0.2848 - val_auc: 0.7915 - val_binary_accuracy: 0.9070 - val_loss: 0.2633\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9078 - loss: 0.2645 - val_auc: 0.7983 - val_binary_accuracy: 0.9081 - val_loss: 0.2597\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9098 - loss: 0.2612 - val_auc: 0.8017 - val_binary_accuracy: 0.9094 - val_loss: 0.2577\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9100 - loss: 0.2594 - val_auc: 0.8051 - val_binary_accuracy: 0.9098 - val_loss: 0.2564\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9106 - loss: 0.2580 - val_auc: 0.8077 - val_binary_accuracy: 0.9097 - val_loss: 0.2554\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9111 - loss: 0.2572 - val_auc: 0.8084 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9109 - loss: 0.2566 - val_auc: 0.8094 - val_binary_accuracy: 0.9091 - val_loss: 0.2543\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9109 - loss: 0.2561 - val_auc: 0.8105 - val_binary_accuracy: 0.9093 - val_loss: 0.2539\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9111 - loss: 0.2557 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2536\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9110 - loss: 0.2553 - val_auc: 0.8117 - val_binary_accuracy: 0.9093 - val_loss: 0.2535\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7926 - binary_accuracy: 0.9089 - loss: 0.2605\n",
      "Fold 4 Metrics: Loss = 0.2535, Accuracy = 0.9093, AUC = 0.8117\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6878 - binary_accuracy: 0.8724 - loss: 0.3236 - val_auc: 0.7872 - val_binary_accuracy: 0.9045 - val_loss: 0.2643\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9059 - loss: 0.2700 - val_auc: 0.7952 - val_binary_accuracy: 0.9081 - val_loss: 0.2600\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9086 - loss: 0.2667 - val_auc: 0.7990 - val_binary_accuracy: 0.9090 - val_loss: 0.2569\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9090 - loss: 0.2644 - val_auc: 0.8026 - val_binary_accuracy: 0.9098 - val_loss: 0.2549\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9092 - loss: 0.2627 - val_auc: 0.8057 - val_binary_accuracy: 0.9103 - val_loss: 0.2531\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9095 - loss: 0.2615 - val_auc: 0.8067 - val_binary_accuracy: 0.9106 - val_loss: 0.2527\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9097 - loss: 0.2605 - val_auc: 0.8076 - val_binary_accuracy: 0.9109 - val_loss: 0.2521\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9102 - loss: 0.2598 - val_auc: 0.8080 - val_binary_accuracy: 0.9109 - val_loss: 0.2519\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9105 - loss: 0.2593 - val_auc: 0.8081 - val_binary_accuracy: 0.9112 - val_loss: 0.2518\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9105 - loss: 0.2589 - val_auc: 0.8085 - val_binary_accuracy: 0.9112 - val_loss: 0.2518\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9094 - loss: 0.2510\n",
      "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9112, AUC = 0.8085\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2547\n",
      "Average Accuracy: 0.9098\n",
      "Average AUC: 0.8074\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 2, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5174 - binary_accuracy: 0.5824 - loss: 0.6365 - val_auc: 0.7352 - val_binary_accuracy: 0.9044 - val_loss: 0.3114\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7387 - binary_accuracy: 0.9069 - loss: 0.2987 - val_auc: 0.7471 - val_binary_accuracy: 0.9044 - val_loss: 0.2900\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9069 - loss: 0.2792 - val_auc: 0.7612 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9069 - loss: 0.2687 - val_auc: 0.7653 - val_binary_accuracy: 0.9044 - val_loss: 0.2737\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.7718 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9069 - loss: 0.2593 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9069 - loss: 0.2575 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9069 - loss: 0.2563 - val_auc: 0.7763 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9069 - loss: 0.2556 - val_auc: 0.7774 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9070 - loss: 0.2550 - val_auc: 0.7796 - val_binary_accuracy: 0.9045 - val_loss: 0.2656\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7781 - binary_accuracy: 0.9086 - loss: 0.2584\n",
      "Fold 1 Metrics: Loss = 0.2656, Accuracy = 0.9045, AUC = 0.7796\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.4830 - binary_accuracy: 0.8103 - loss: 0.4890 - val_auc: 0.6652 - val_binary_accuracy: 0.9042 - val_loss: 0.3137\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.6821 - binary_accuracy: 0.9029 - loss: 0.3148 - val_auc: 0.7370 - val_binary_accuracy: 0.9042 - val_loss: 0.3088\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7247 - binary_accuracy: 0.9029 - loss: 0.3110 - val_auc: 0.7555 - val_binary_accuracy: 0.9042 - val_loss: 0.3041\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7427 - binary_accuracy: 0.9029 - loss: 0.3017 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2867\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9029 - loss: 0.2871 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2750\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9029 - loss: 0.2775 - val_auc: 0.7827 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9029 - loss: 0.2730 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2709 - val_auc: 0.7922 - val_binary_accuracy: 0.9042 - val_loss: 0.2637\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9029 - loss: 0.2699 - val_auc: 0.7948 - val_binary_accuracy: 0.9042 - val_loss: 0.2627\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9029 - loss: 0.2693 - val_auc: 0.8002 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7975 - binary_accuracy: 0.9092 - loss: 0.2542\n",
      "Fold 2 Metrics: Loss = 0.2623, Accuracy = 0.9042, AUC = 0.8002\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5581 - binary_accuracy: 0.6994 - loss: 0.5267 - val_auc: 0.7585 - val_binary_accuracy: 0.9042 - val_loss: 0.2914\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7546 - binary_accuracy: 0.9051 - loss: 0.2867 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2786\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9051 - loss: 0.2750 - val_auc: 0.7714 - val_binary_accuracy: 0.9042 - val_loss: 0.2728\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9051 - loss: 0.2698 - val_auc: 0.7789 - val_binary_accuracy: 0.9042 - val_loss: 0.2709\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7759 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9051 - loss: 0.2662 - val_auc: 0.7798 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9051 - loss: 0.2650 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7838 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9051 - loss: 0.2629 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9051 - loss: 0.2620 - val_auc: 0.7877 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7815 - binary_accuracy: 0.9046 - loss: 0.2655\n",
      "Fold 3 Metrics: Loss = 0.2652, Accuracy = 0.9042, AUC = 0.7877\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5508 - binary_accuracy: 0.8437 - loss: 0.4380 - val_auc: 0.7529 - val_binary_accuracy: 0.9044 - val_loss: 0.2950\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7393 - binary_accuracy: 0.9047 - loss: 0.2905 - val_auc: 0.7674 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9047 - loss: 0.2774 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2739\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9047 - loss: 0.2707 - val_auc: 0.7860 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9047 - loss: 0.2674 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9047 - loss: 0.2660 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9047 - loss: 0.2650 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9047 - loss: 0.2643 - val_auc: 0.7931 - val_binary_accuracy: 0.9044 - val_loss: 0.2653\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9047 - loss: 0.2636 - val_auc: 0.7944 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9047 - loss: 0.2630 - val_auc: 0.7947 - val_binary_accuracy: 0.9044 - val_loss: 0.2644\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7729 - binary_accuracy: 0.9049 - loss: 0.2691\n",
      "Fold 4 Metrics: Loss = 0.2644, Accuracy = 0.9044, AUC = 0.7947\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5074 - binary_accuracy: 0.7590 - loss: 0.4816 - val_auc: 0.7335 - val_binary_accuracy: 0.9044 - val_loss: 0.3036\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7281 - binary_accuracy: 0.9040 - loss: 0.3030 - val_auc: 0.7601 - val_binary_accuracy: 0.9044 - val_loss: 0.2946\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7483 - binary_accuracy: 0.9040 - loss: 0.2945 - val_auc: 0.7685 - val_binary_accuracy: 0.9044 - val_loss: 0.2823\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9040 - loss: 0.2834 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2738\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9040 - loss: 0.2769 - val_auc: 0.7779 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9040 - loss: 0.2725 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9040 - loss: 0.2719 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7885 - val_binary_accuracy: 0.9044 - val_loss: 0.2632\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9040 - loss: 0.2711 - val_auc: 0.7895 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7987 - binary_accuracy: 0.9013 - loss: 0.2630\n",
      "Fold 5 Metrics: Loss = 0.2626, Accuracy = 0.9044, AUC = 0.7895\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2640\n",
      "Average Accuracy: 0.9044\n",
      "Average AUC: 0.7904\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 2, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - auc: 0.5151 - binary_accuracy: 0.6644 - loss: 0.5768 - val_auc: 0.7096 - val_binary_accuracy: 0.9044 - val_loss: 0.3085\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7242 - binary_accuracy: 0.9069 - loss: 0.2999 - val_auc: 0.7472 - val_binary_accuracy: 0.9044 - val_loss: 0.2943\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9069 - loss: 0.2826 - val_auc: 0.7603 - val_binary_accuracy: 0.9044 - val_loss: 0.2804\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9069 - loss: 0.2683 - val_auc: 0.7607 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9069 - loss: 0.2616 - val_auc: 0.7689 - val_binary_accuracy: 0.9044 - val_loss: 0.2704\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2596 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2696\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9069 - loss: 0.2587 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9069 - loss: 0.2581 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9069 - loss: 0.2576 - val_auc: 0.7752 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9069 - loss: 0.2571 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7735 - binary_accuracy: 0.9084 - loss: 0.2604\n",
      "Fold 1 Metrics: Loss = 0.2680, Accuracy = 0.9044, AUC = 0.7751\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5828 - binary_accuracy: 0.9020 - loss: 0.3681 - val_auc: 0.7650 - val_binary_accuracy: 0.9042 - val_loss: 0.2861\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9029 - loss: 0.2832 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2711 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2650\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9029 - loss: 0.2675 - val_auc: 0.8000 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9048 - loss: 0.2648 - val_auc: 0.8026 - val_binary_accuracy: 0.9047 - val_loss: 0.2616\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9063 - loss: 0.2628 - val_auc: 0.8053 - val_binary_accuracy: 0.9062 - val_loss: 0.2609\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.8073 - val_binary_accuracy: 0.9069 - val_loss: 0.2602\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9075 - loss: 0.2603 - val_auc: 0.8085 - val_binary_accuracy: 0.9075 - val_loss: 0.2595\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9078 - loss: 0.2594 - val_auc: 0.8092 - val_binary_accuracy: 0.9079 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.8113 - val_binary_accuracy: 0.9082 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8159 - binary_accuracy: 0.9121 - loss: 0.2488\n",
      "Fold 2 Metrics: Loss = 0.2587, Accuracy = 0.9082, AUC = 0.8113\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5187 - binary_accuracy: 0.7906 - loss: 0.4414 - val_auc: 0.7587 - val_binary_accuracy: 0.9042 - val_loss: 0.2873\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9051 - loss: 0.2828 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7817 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9051 - loss: 0.2665 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2673\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9051 - loss: 0.2635 - val_auc: 0.7881 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9051 - loss: 0.2629 - val_auc: 0.7891 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9051 - loss: 0.2624 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2649\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9058 - loss: 0.2616 - val_auc: 0.7917 - val_binary_accuracy: 0.9079 - val_loss: 0.2639\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9074 - loss: 0.2644\n",
      "Fold 3 Metrics: Loss = 0.2639, Accuracy = 0.9079, AUC = 0.7917\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5575 - binary_accuracy: 0.9047 - loss: 0.3670 - val_auc: 0.7704 - val_binary_accuracy: 0.9044 - val_loss: 0.2877\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7604 - binary_accuracy: 0.9047 - loss: 0.2814 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9047 - loss: 0.2677 - val_auc: 0.7826 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9047 - loss: 0.2653 - val_auc: 0.7867 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9050 - loss: 0.2641 - val_auc: 0.7887 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9066 - loss: 0.2633 - val_auc: 0.7932 - val_binary_accuracy: 0.9053 - val_loss: 0.2648\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9083 - loss: 0.2622 - val_auc: 0.7934 - val_binary_accuracy: 0.9067 - val_loss: 0.2640\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9091 - loss: 0.2612 - val_auc: 0.7963 - val_binary_accuracy: 0.9070 - val_loss: 0.2631\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9094 - loss: 0.2602 - val_auc: 0.7984 - val_binary_accuracy: 0.9078 - val_loss: 0.2622\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9097 - loss: 0.2593 - val_auc: 0.8003 - val_binary_accuracy: 0.9088 - val_loss: 0.2612\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7793 - binary_accuracy: 0.9080 - loss: 0.2669\n",
      "Fold 4 Metrics: Loss = 0.2612, Accuracy = 0.9088, AUC = 0.8003\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5635 - binary_accuracy: 0.8763 - loss: 0.3911 - val_auc: 0.7609 - val_binary_accuracy: 0.9044 - val_loss: 0.2932\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7480 - binary_accuracy: 0.9040 - loss: 0.2910 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2742\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9040 - loss: 0.2766 - val_auc: 0.7842 - val_binary_accuracy: 0.9044 - val_loss: 0.2644\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9040 - loss: 0.2706 - val_auc: 0.7881 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9040 - loss: 0.2687 - val_auc: 0.7936 - val_binary_accuracy: 0.9044 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9040 - loss: 0.2671 - val_auc: 0.7967 - val_binary_accuracy: 0.9060 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9058 - loss: 0.2654 - val_auc: 0.7970 - val_binary_accuracy: 0.9084 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9079 - loss: 0.2640 - val_auc: 0.7987 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9083 - loss: 0.2627 - val_auc: 0.7978 - val_binary_accuracy: 0.9097 - val_loss: 0.2558\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9090 - loss: 0.2615 - val_auc: 0.7997 - val_binary_accuracy: 0.9101 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8093 - binary_accuracy: 0.9079 - loss: 0.2532\n",
      "Fold 5 Metrics: Loss = 0.2552, Accuracy = 0.9101, AUC = 0.7997\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2614\n",
      "Average Accuracy: 0.9079\n",
      "Average AUC: 0.7956\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 2, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6283 - binary_accuracy: 0.9033 - loss: 0.3333 - val_auc: 0.7664 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9069 - loss: 0.2620 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9069 - loss: 0.2575 - val_auc: 0.7791 - val_binary_accuracy: 0.9041 - val_loss: 0.2672\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9072 - loss: 0.2550 - val_auc: 0.7825 - val_binary_accuracy: 0.9065 - val_loss: 0.2653\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9093 - loss: 0.2530 - val_auc: 0.7846 - val_binary_accuracy: 0.9079 - val_loss: 0.2638\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9110 - loss: 0.2512 - val_auc: 0.7873 - val_binary_accuracy: 0.9088 - val_loss: 0.2625\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9120 - loss: 0.2498 - val_auc: 0.7885 - val_binary_accuracy: 0.9084 - val_loss: 0.2616\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9123 - loss: 0.2487 - val_auc: 0.7895 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8114 - binary_accuracy: 0.9124 - loss: 0.2480 - val_auc: 0.7895 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8123 - binary_accuracy: 0.9124 - loss: 0.2473 - val_auc: 0.7904 - val_binary_accuracy: 0.9085 - val_loss: 0.2603\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7897 - binary_accuracy: 0.9113 - loss: 0.2530\n",
      "Fold 1 Metrics: Loss = 0.2603, Accuracy = 0.9085, AUC = 0.7904\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6523 - binary_accuracy: 0.9029 - loss: 0.3193 - val_auc: 0.7889 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9029 - loss: 0.2714 - val_auc: 0.7968 - val_binary_accuracy: 0.9042 - val_loss: 0.2625\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9038 - loss: 0.2674 - val_auc: 0.8027 - val_binary_accuracy: 0.9045 - val_loss: 0.2602\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9052 - loss: 0.2644 - val_auc: 0.8057 - val_binary_accuracy: 0.9065 - val_loss: 0.2578\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9068 - loss: 0.2623 - val_auc: 0.8072 - val_binary_accuracy: 0.9071 - val_loss: 0.2577\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9074 - loss: 0.2611 - val_auc: 0.8076 - val_binary_accuracy: 0.9078 - val_loss: 0.2574\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9079 - loss: 0.2602 - val_auc: 0.8087 - val_binary_accuracy: 0.9078 - val_loss: 0.2569\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9081 - loss: 0.2595 - val_auc: 0.8086 - val_binary_accuracy: 0.9084 - val_loss: 0.2570\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9087 - loss: 0.2589 - val_auc: 0.8100 - val_binary_accuracy: 0.9082 - val_loss: 0.2566\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9088 - loss: 0.2582 - val_auc: 0.8098 - val_binary_accuracy: 0.9087 - val_loss: 0.2568\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8164 - binary_accuracy: 0.9116 - loss: 0.2460\n",
      "Fold 2 Metrics: Loss = 0.2568, Accuracy = 0.9087, AUC = 0.8098\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6286 - binary_accuracy: 0.8816 - loss: 0.3469 - val_auc: 0.7731 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9051 - loss: 0.2696 - val_auc: 0.7800 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9059 - loss: 0.2659 - val_auc: 0.7851 - val_binary_accuracy: 0.9072 - val_loss: 0.2658\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9076 - loss: 0.2641 - val_auc: 0.7897 - val_binary_accuracy: 0.9093 - val_loss: 0.2637\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9081 - loss: 0.2629 - val_auc: 0.7945 - val_binary_accuracy: 0.9100 - val_loss: 0.2616\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.7986 - val_binary_accuracy: 0.9109 - val_loss: 0.2597\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9091 - loss: 0.2604 - val_auc: 0.8017 - val_binary_accuracy: 0.9109 - val_loss: 0.2583\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9094 - loss: 0.2597 - val_auc: 0.8042 - val_binary_accuracy: 0.9113 - val_loss: 0.2573\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9094 - loss: 0.2591 - val_auc: 0.8054 - val_binary_accuracy: 0.9113 - val_loss: 0.2566\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9099 - loss: 0.2587 - val_auc: 0.8057 - val_binary_accuracy: 0.9113 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7978 - binary_accuracy: 0.9127 - loss: 0.2572\n",
      "Fold 3 Metrics: Loss = 0.2561, Accuracy = 0.9113, AUC = 0.8057\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6091 - binary_accuracy: 0.8293 - loss: 0.3819 - val_auc: 0.7752 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9047 - loss: 0.2691 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9050 - loss: 0.2652 - val_auc: 0.7943 - val_binary_accuracy: 0.9047 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9079 - loss: 0.2629 - val_auc: 0.7995 - val_binary_accuracy: 0.9070 - val_loss: 0.2615\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9097 - loss: 0.2606 - val_auc: 0.8024 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9105 - loss: 0.2594 - val_auc: 0.8044 - val_binary_accuracy: 0.9082 - val_loss: 0.2582\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9111 - loss: 0.2584 - val_auc: 0.8060 - val_binary_accuracy: 0.9084 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9114 - loss: 0.2575 - val_auc: 0.8074 - val_binary_accuracy: 0.9084 - val_loss: 0.2569\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9113 - loss: 0.2567 - val_auc: 0.8085 - val_binary_accuracy: 0.9081 - val_loss: 0.2567\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9112 - loss: 0.2562 - val_auc: 0.8098 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9084 - loss: 0.2616\n",
      "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9087, AUC = 0.8098\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6192 - binary_accuracy: 0.9038 - loss: 0.3399 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9040 - loss: 0.2737 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2611\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9048 - loss: 0.2690 - val_auc: 0.7961 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7984 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9087 - loss: 0.2644 - val_auc: 0.8018 - val_binary_accuracy: 0.9101 - val_loss: 0.2547\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9089 - loss: 0.2628 - val_auc: 0.8031 - val_binary_accuracy: 0.9107 - val_loss: 0.2539\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8042 - val_binary_accuracy: 0.9107 - val_loss: 0.2533\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9094 - loss: 0.2609 - val_auc: 0.8044 - val_binary_accuracy: 0.9106 - val_loss: 0.2532\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8049 - val_binary_accuracy: 0.9109 - val_loss: 0.2530\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8049 - val_binary_accuracy: 0.9110 - val_loss: 0.2528\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8138 - binary_accuracy: 0.9091 - loss: 0.2512\n",
      "Fold 5 Metrics: Loss = 0.2528, Accuracy = 0.9110, AUC = 0.8049\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2564\n",
      "Average Accuracy: 0.9096\n",
      "Average AUC: 0.8041\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 2, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6988 - binary_accuracy: 0.9069 - loss: 0.2914 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9072 - loss: 0.2590 - val_auc: 0.7819 - val_binary_accuracy: 0.9048 - val_loss: 0.2660\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9094 - loss: 0.2551 - val_auc: 0.7877 - val_binary_accuracy: 0.9060 - val_loss: 0.2628\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8045 - binary_accuracy: 0.9112 - loss: 0.2520 - val_auc: 0.7907 - val_binary_accuracy: 0.9076 - val_loss: 0.2610\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9123 - loss: 0.2499 - val_auc: 0.7921 - val_binary_accuracy: 0.9078 - val_loss: 0.2601\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9125 - loss: 0.2485 - val_auc: 0.7936 - val_binary_accuracy: 0.9087 - val_loss: 0.2592\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8116 - binary_accuracy: 0.9124 - loss: 0.2475 - val_auc: 0.7944 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8131 - binary_accuracy: 0.9128 - loss: 0.2468 - val_auc: 0.7945 - val_binary_accuracy: 0.9091 - val_loss: 0.2586\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9129 - loss: 0.2462 - val_auc: 0.7945 - val_binary_accuracy: 0.9093 - val_loss: 0.2586\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8148 - binary_accuracy: 0.9125 - loss: 0.2457 - val_auc: 0.7951 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7937 - binary_accuracy: 0.9128 - loss: 0.2518\n",
      "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9091, AUC = 0.7951\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6524 - binary_accuracy: 0.8633 - loss: 0.3412 - val_auc: 0.7960 - val_binary_accuracy: 0.9042 - val_loss: 0.2636\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9040 - loss: 0.2687 - val_auc: 0.8037 - val_binary_accuracy: 0.9056 - val_loss: 0.2591\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9053 - loss: 0.2643 - val_auc: 0.8077 - val_binary_accuracy: 0.9068 - val_loss: 0.2571\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9072 - loss: 0.2621 - val_auc: 0.8092 - val_binary_accuracy: 0.9076 - val_loss: 0.2560\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9077 - loss: 0.2607 - val_auc: 0.8105 - val_binary_accuracy: 0.9079 - val_loss: 0.2554\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8005 - binary_accuracy: 0.9079 - loss: 0.2598 - val_auc: 0.8100 - val_binary_accuracy: 0.9085 - val_loss: 0.2552\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8020 - binary_accuracy: 0.9083 - loss: 0.2592 - val_auc: 0.8104 - val_binary_accuracy: 0.9085 - val_loss: 0.2550\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9081 - loss: 0.2587 - val_auc: 0.8103 - val_binary_accuracy: 0.9085 - val_loss: 0.2549\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9080 - loss: 0.2581 - val_auc: 0.8106 - val_binary_accuracy: 0.9087 - val_loss: 0.2548\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9083 - loss: 0.2576 - val_auc: 0.8106 - val_binary_accuracy: 0.9085 - val_loss: 0.2550\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9121 - loss: 0.2445\n",
      "Fold 2 Metrics: Loss = 0.2550, Accuracy = 0.9085, AUC = 0.8106\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6260 - binary_accuracy: 0.8325 - loss: 0.3854 - val_auc: 0.7763 - val_binary_accuracy: 0.9042 - val_loss: 0.2705\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9055 - loss: 0.2685 - val_auc: 0.7850 - val_binary_accuracy: 0.9053 - val_loss: 0.2663\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9072 - loss: 0.2656 - val_auc: 0.7905 - val_binary_accuracy: 0.9087 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9079 - loss: 0.2643 - val_auc: 0.7946 - val_binary_accuracy: 0.9106 - val_loss: 0.2615\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.7972 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9094 - loss: 0.2625 - val_auc: 0.7997 - val_binary_accuracy: 0.9110 - val_loss: 0.2584\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9096 - loss: 0.2619 - val_auc: 0.8014 - val_binary_accuracy: 0.9113 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9101 - loss: 0.2614 - val_auc: 0.8029 - val_binary_accuracy: 0.9116 - val_loss: 0.2568\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9103 - loss: 0.2609 - val_auc: 0.8046 - val_binary_accuracy: 0.9116 - val_loss: 0.2563\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9103 - loss: 0.2603 - val_auc: 0.8062 - val_binary_accuracy: 0.9115 - val_loss: 0.2559\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7977 - binary_accuracy: 0.9130 - loss: 0.2568\n",
      "Fold 3 Metrics: Loss = 0.2559, Accuracy = 0.9115, AUC = 0.8062\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6158 - binary_accuracy: 0.8419 - loss: 0.3678 - val_auc: 0.7857 - val_binary_accuracy: 0.9048 - val_loss: 0.2655\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9065 - loss: 0.2662 - val_auc: 0.7949 - val_binary_accuracy: 0.9087 - val_loss: 0.2609\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9083 - loss: 0.2627 - val_auc: 0.8004 - val_binary_accuracy: 0.9088 - val_loss: 0.2583\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9098 - loss: 0.2606 - val_auc: 0.8030 - val_binary_accuracy: 0.9095 - val_loss: 0.2569\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9103 - loss: 0.2594 - val_auc: 0.8044 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7929 - binary_accuracy: 0.9106 - loss: 0.2585 - val_auc: 0.8063 - val_binary_accuracy: 0.9093 - val_loss: 0.2554\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9112 - loss: 0.2577 - val_auc: 0.8084 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9118 - loss: 0.2571 - val_auc: 0.8090 - val_binary_accuracy: 0.9097 - val_loss: 0.2542\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9117 - loss: 0.2568 - val_auc: 0.8098 - val_binary_accuracy: 0.9097 - val_loss: 0.2539\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9119 - loss: 0.2564 - val_auc: 0.8104 - val_binary_accuracy: 0.9097 - val_loss: 0.2537\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7914 - binary_accuracy: 0.9099 - loss: 0.2603\n",
      "Fold 4 Metrics: Loss = 0.2537, Accuracy = 0.9097, AUC = 0.8104\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6509 - binary_accuracy: 0.8786 - loss: 0.3291 - val_auc: 0.7903 - val_binary_accuracy: 0.9045 - val_loss: 0.2618\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.7960 - val_binary_accuracy: 0.9082 - val_loss: 0.2584\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9070 - loss: 0.2680 - val_auc: 0.7986 - val_binary_accuracy: 0.9084 - val_loss: 0.2561\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9087 - loss: 0.2659 - val_auc: 0.8028 - val_binary_accuracy: 0.9094 - val_loss: 0.2543\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9091 - loss: 0.2642 - val_auc: 0.8048 - val_binary_accuracy: 0.9101 - val_loss: 0.2530\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9091 - loss: 0.2629 - val_auc: 0.8060 - val_binary_accuracy: 0.9109 - val_loss: 0.2522\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8063 - val_binary_accuracy: 0.9109 - val_loss: 0.2517\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9098 - loss: 0.2611 - val_auc: 0.8072 - val_binary_accuracy: 0.9110 - val_loss: 0.2515\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9103 - loss: 0.2605 - val_auc: 0.8070 - val_binary_accuracy: 0.9112 - val_loss: 0.2513\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9100 - loss: 0.2600 - val_auc: 0.8078 - val_binary_accuracy: 0.9110 - val_loss: 0.2511\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9094 - loss: 0.2501\n",
      "Fold 5 Metrics: Loss = 0.2511, Accuracy = 0.9110, AUC = 0.8078\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2549\n",
      "Average Accuracy: 0.9100\n",
      "Average AUC: 0.8060\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 2, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7176 - binary_accuracy: 0.9069 - loss: 0.2854 - val_auc: 0.7773 - val_binary_accuracy: 0.9048 - val_loss: 0.2695\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9097 - loss: 0.2587 - val_auc: 0.7868 - val_binary_accuracy: 0.9066 - val_loss: 0.2653\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9119 - loss: 0.2544 - val_auc: 0.7917 - val_binary_accuracy: 0.9078 - val_loss: 0.2632\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9115 - loss: 0.2520 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2631\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9121 - loss: 0.2503 - val_auc: 0.7946 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8084 - binary_accuracy: 0.9123 - loss: 0.2491 - val_auc: 0.7955 - val_binary_accuracy: 0.9078 - val_loss: 0.2616\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8101 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7961 - val_binary_accuracy: 0.9082 - val_loss: 0.2606\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9127 - loss: 0.2474 - val_auc: 0.7959 - val_binary_accuracy: 0.9082 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8131 - binary_accuracy: 0.9123 - loss: 0.2468 - val_auc: 0.7962 - val_binary_accuracy: 0.9082 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8138 - binary_accuracy: 0.9127 - loss: 0.2464 - val_auc: 0.7964 - val_binary_accuracy: 0.9082 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7964 - binary_accuracy: 0.9118 - loss: 0.2504\n",
      "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9082, AUC = 0.7964\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6800 - binary_accuracy: 0.8850 - loss: 0.3162 - val_auc: 0.7986 - val_binary_accuracy: 0.9047 - val_loss: 0.2627\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9045 - loss: 0.2695 - val_auc: 0.8064 - val_binary_accuracy: 0.9060 - val_loss: 0.2596\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9060 - loss: 0.2654 - val_auc: 0.8089 - val_binary_accuracy: 0.9082 - val_loss: 0.2580\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9076 - loss: 0.2627 - val_auc: 0.8092 - val_binary_accuracy: 0.9096 - val_loss: 0.2566\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9085 - loss: 0.2609 - val_auc: 0.8099 - val_binary_accuracy: 0.9103 - val_loss: 0.2556\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9087 - loss: 0.2600 - val_auc: 0.8100 - val_binary_accuracy: 0.9099 - val_loss: 0.2546\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9081 - loss: 0.2592 - val_auc: 0.8112 - val_binary_accuracy: 0.9103 - val_loss: 0.2539\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9078 - loss: 0.2586 - val_auc: 0.8109 - val_binary_accuracy: 0.9102 - val_loss: 0.2535\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9079 - loss: 0.2581 - val_auc: 0.8131 - val_binary_accuracy: 0.9103 - val_loss: 0.2529\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8050 - binary_accuracy: 0.9078 - loss: 0.2577 - val_auc: 0.8121 - val_binary_accuracy: 0.9100 - val_loss: 0.2533\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8181 - binary_accuracy: 0.9130 - loss: 0.2431\n",
      "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9100, AUC = 0.8121\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6425 - binary_accuracy: 0.8758 - loss: 0.3350 - val_auc: 0.7791 - val_binary_accuracy: 0.9051 - val_loss: 0.2682\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7620 - binary_accuracy: 0.9071 - loss: 0.2725 - val_auc: 0.7861 - val_binary_accuracy: 0.9082 - val_loss: 0.2651\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7685 - binary_accuracy: 0.9073 - loss: 0.2692 - val_auc: 0.7920 - val_binary_accuracy: 0.9102 - val_loss: 0.2624\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9085 - loss: 0.2666 - val_auc: 0.7964 - val_binary_accuracy: 0.9104 - val_loss: 0.2602\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9090 - loss: 0.2646 - val_auc: 0.7996 - val_binary_accuracy: 0.9112 - val_loss: 0.2583\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9096 - loss: 0.2639 - val_auc: 0.8011 - val_binary_accuracy: 0.9115 - val_loss: 0.2571\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9097 - loss: 0.2631 - val_auc: 0.8029 - val_binary_accuracy: 0.9116 - val_loss: 0.2562\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9100 - loss: 0.2625 - val_auc: 0.8047 - val_binary_accuracy: 0.9115 - val_loss: 0.2556\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9110 - loss: 0.2618 - val_auc: 0.8052 - val_binary_accuracy: 0.9116 - val_loss: 0.2553\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9108 - loss: 0.2612 - val_auc: 0.8055 - val_binary_accuracy: 0.9116 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7976 - binary_accuracy: 0.9134 - loss: 0.2556\n",
      "Fold 3 Metrics: Loss = 0.2551, Accuracy = 0.9116, AUC = 0.8055\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6487 - binary_accuracy: 0.8869 - loss: 0.3241 - val_auc: 0.7897 - val_binary_accuracy: 0.9063 - val_loss: 0.2639\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9071 - loss: 0.2666 - val_auc: 0.7988 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9088 - loss: 0.2630 - val_auc: 0.8036 - val_binary_accuracy: 0.9087 - val_loss: 0.2572\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9097 - loss: 0.2610 - val_auc: 0.8060 - val_binary_accuracy: 0.9081 - val_loss: 0.2559\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9102 - loss: 0.2597 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2552\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9106 - loss: 0.2588 - val_auc: 0.8088 - val_binary_accuracy: 0.9091 - val_loss: 0.2546\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9107 - loss: 0.2581 - val_auc: 0.8095 - val_binary_accuracy: 0.9093 - val_loss: 0.2543\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9109 - loss: 0.2575 - val_auc: 0.8100 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9110 - loss: 0.2570 - val_auc: 0.8105 - val_binary_accuracy: 0.9094 - val_loss: 0.2539\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9113 - loss: 0.2566 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2538\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9083 - loss: 0.2609\n",
      "Fold 4 Metrics: Loss = 0.2538, Accuracy = 0.9091, AUC = 0.8113\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6596 - binary_accuracy: 0.8855 - loss: 0.3214 - val_auc: 0.7902 - val_binary_accuracy: 0.9041 - val_loss: 0.2671\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9043 - loss: 0.2730 - val_auc: 0.7974 - val_binary_accuracy: 0.9053 - val_loss: 0.2647\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9062 - loss: 0.2696 - val_auc: 0.8024 - val_binary_accuracy: 0.9090 - val_loss: 0.2619\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9069 - loss: 0.2669 - val_auc: 0.8047 - val_binary_accuracy: 0.9094 - val_loss: 0.2594\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8062 - val_binary_accuracy: 0.9107 - val_loss: 0.2573\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9083 - loss: 0.2640 - val_auc: 0.8075 - val_binary_accuracy: 0.9116 - val_loss: 0.2554\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2630 - val_auc: 0.8076 - val_binary_accuracy: 0.9115 - val_loss: 0.2539\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8082 - val_binary_accuracy: 0.9113 - val_loss: 0.2529\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8086 - val_binary_accuracy: 0.9115 - val_loss: 0.2519\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9093 - loss: 0.2607 - val_auc: 0.8095 - val_binary_accuracy: 0.9118 - val_loss: 0.2515\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9096 - loss: 0.2499\n",
      "Fold 5 Metrics: Loss = 0.2515, Accuracy = 0.9118, AUC = 0.8095\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2545\n",
      "Average Accuracy: 0.9101\n",
      "Average AUC: 0.8070\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 3, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5016 - binary_accuracy: 0.6917 - loss: 0.5461 - val_auc: 0.7261 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6942 - binary_accuracy: 0.9069 - loss: 0.3066 - val_auc: 0.7271 - val_binary_accuracy: 0.9044 - val_loss: 0.3083\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9069 - loss: 0.3004 - val_auc: 0.7529 - val_binary_accuracy: 0.9044 - val_loss: 0.2989\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9069 - loss: 0.2879 - val_auc: 0.7558 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9069 - loss: 0.2709 - val_auc: 0.7661 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7747 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9069 - loss: 0.2585 - val_auc: 0.7771 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9069 - loss: 0.2570 - val_auc: 0.7775 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9069 - loss: 0.2563 - val_auc: 0.7803 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9069 - loss: 0.2557 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7775 - binary_accuracy: 0.9084 - loss: 0.2589\n",
      "Fold 1 Metrics: Loss = 0.2662, Accuracy = 0.9044, AUC = 0.7814\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5037 - binary_accuracy: 0.5797 - loss: 0.6377 - val_auc: 0.6403 - val_binary_accuracy: 0.9042 - val_loss: 0.3163\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6298 - binary_accuracy: 0.9029 - loss: 0.3170 - val_auc: 0.7354 - val_binary_accuracy: 0.9042 - val_loss: 0.3102\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7345 - binary_accuracy: 0.9029 - loss: 0.3117 - val_auc: 0.7564 - val_binary_accuracy: 0.9042 - val_loss: 0.3024\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7552 - binary_accuracy: 0.9029 - loss: 0.3026 - val_auc: 0.7788 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9029 - loss: 0.2889 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2743\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9029 - loss: 0.2769 - val_auc: 0.7942 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2729 - val_auc: 0.7966 - val_binary_accuracy: 0.9042 - val_loss: 0.2640\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9029 - loss: 0.2695 - val_auc: 0.7981 - val_binary_accuracy: 0.9042 - val_loss: 0.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9029 - loss: 0.2679 - val_auc: 0.8014 - val_binary_accuracy: 0.9042 - val_loss: 0.2612\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9029 - loss: 0.2666 - val_auc: 0.8023 - val_binary_accuracy: 0.9042 - val_loss: 0.2609\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8054 - binary_accuracy: 0.9092 - loss: 0.2511\n",
      "Fold 2 Metrics: Loss = 0.2609, Accuracy = 0.9042, AUC = 0.8023\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5094 - binary_accuracy: 0.9051 - loss: 0.4287 - val_auc: 0.7078 - val_binary_accuracy: 0.9042 - val_loss: 0.3112\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7050 - binary_accuracy: 0.9051 - loss: 0.3059 - val_auc: 0.7609 - val_binary_accuracy: 0.9042 - val_loss: 0.2882\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7575 - binary_accuracy: 0.9051 - loss: 0.2824 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2735\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9051 - loss: 0.2706 - val_auc: 0.7745 - val_binary_accuracy: 0.9042 - val_loss: 0.2705\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9051 - loss: 0.2681 - val_auc: 0.7803 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9051 - loss: 0.2664 - val_auc: 0.7845 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7839 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9051 - loss: 0.2650 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2670\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9051 - loss: 0.2643 - val_auc: 0.7866 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9051 - loss: 0.2635 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7821 - binary_accuracy: 0.9046 - loss: 0.2655\n",
      "Fold 3 Metrics: Loss = 0.2657, Accuracy = 0.9042, AUC = 0.7876\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5206 - binary_accuracy: 0.9047 - loss: 0.3544 - val_auc: 0.7491 - val_binary_accuracy: 0.9044 - val_loss: 0.3113\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7073 - binary_accuracy: 0.9047 - loss: 0.3089 - val_auc: 0.7533 - val_binary_accuracy: 0.9044 - val_loss: 0.3009\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7386 - binary_accuracy: 0.9047 - loss: 0.2960 - val_auc: 0.7657 - val_binary_accuracy: 0.9044 - val_loss: 0.2825\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9047 - loss: 0.2777 - val_auc: 0.7776 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9047 - loss: 0.2692 - val_auc: 0.7773 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9047 - loss: 0.2675 - val_auc: 0.7821 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9047 - loss: 0.2670 - val_auc: 0.7812 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9047 - loss: 0.2666 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9047 - loss: 0.2659 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7650 - binary_accuracy: 0.9049 - loss: 0.2728\n",
      "Fold 4 Metrics: Loss = 0.2692, Accuracy = 0.9044, AUC = 0.7828\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5026 - binary_accuracy: 0.6269 - loss: 0.5922 - val_auc: 0.7004 - val_binary_accuracy: 0.9044 - val_loss: 0.3140\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6943 - binary_accuracy: 0.9040 - loss: 0.3128 - val_auc: 0.7520 - val_binary_accuracy: 0.9044 - val_loss: 0.3028\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7483 - binary_accuracy: 0.9040 - loss: 0.3011 - val_auc: 0.7717 - val_binary_accuracy: 0.9044 - val_loss: 0.2867\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7598 - binary_accuracy: 0.9040 - loss: 0.2865 - val_auc: 0.7743 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2758 - val_auc: 0.7890 - val_binary_accuracy: 0.9044 - val_loss: 0.2651\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7925 - val_binary_accuracy: 0.9044 - val_loss: 0.2629\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9040 - loss: 0.2702 - val_auc: 0.7928 - val_binary_accuracy: 0.9044 - val_loss: 0.2619\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9040 - loss: 0.2694 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2612\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9040 - loss: 0.2688 - val_auc: 0.7941 - val_binary_accuracy: 0.9044 - val_loss: 0.2605\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9040 - loss: 0.2681 - val_auc: 0.7955 - val_binary_accuracy: 0.9044 - val_loss: 0.2600\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8072 - binary_accuracy: 0.9013 - loss: 0.2585\n",
      "Fold 5 Metrics: Loss = 0.2600, Accuracy = 0.9044, AUC = 0.7955\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2644\n",
      "Average Accuracy: 0.9043\n",
      "Average AUC: 0.7899\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 3, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5001 - binary_accuracy: 0.6835 - loss: 0.5494 - val_auc: 0.6707 - val_binary_accuracy: 0.9044 - val_loss: 0.3132\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6898 - binary_accuracy: 0.9069 - loss: 0.3056 - val_auc: 0.7449 - val_binary_accuracy: 0.9044 - val_loss: 0.3041\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7515 - binary_accuracy: 0.9069 - loss: 0.2922 - val_auc: 0.7589 - val_binary_accuracy: 0.9044 - val_loss: 0.2818\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9069 - loss: 0.2695 - val_auc: 0.7672 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9069 - loss: 0.2617 - val_auc: 0.7753 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9069 - loss: 0.2589 - val_auc: 0.7799 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9069 - loss: 0.2572 - val_auc: 0.7831 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9069 - loss: 0.2562 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2648\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9069 - loss: 0.2551 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8045 - binary_accuracy: 0.9069 - loss: 0.2539 - val_auc: 0.7895 - val_binary_accuracy: 0.9044 - val_loss: 0.2628\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9084 - loss: 0.2555\n",
      "Fold 1 Metrics: Loss = 0.2628, Accuracy = 0.9044, AUC = 0.7895\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5494 - binary_accuracy: 0.8115 - loss: 0.4208 - val_auc: 0.7633 - val_binary_accuracy: 0.9042 - val_loss: 0.2972\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7539 - binary_accuracy: 0.9029 - loss: 0.2931 - val_auc: 0.7887 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9029 - loss: 0.2732 - val_auc: 0.7956 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8009 - val_binary_accuracy: 0.9042 - val_loss: 0.2638\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9029 - loss: 0.2683 - val_auc: 0.8026 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9029 - loss: 0.2668 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9036 - loss: 0.2652 - val_auc: 0.8050 - val_binary_accuracy: 0.9042 - val_loss: 0.2616\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9052 - loss: 0.2638 - val_auc: 0.8064 - val_binary_accuracy: 0.9051 - val_loss: 0.2616\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9063 - loss: 0.2625 - val_auc: 0.8069 - val_binary_accuracy: 0.9059 - val_loss: 0.2612\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9075 - loss: 0.2614 - val_auc: 0.8078 - val_binary_accuracy: 0.9068 - val_loss: 0.2607\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8112 - binary_accuracy: 0.9104 - loss: 0.2513\n",
      "Fold 2 Metrics: Loss = 0.2607, Accuracy = 0.9068, AUC = 0.8078\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5586 - binary_accuracy: 0.9051 - loss: 0.3586 - val_auc: 0.7628 - val_binary_accuracy: 0.9042 - val_loss: 0.2854\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7576 - binary_accuracy: 0.9051 - loss: 0.2787 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9051 - loss: 0.2676 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9051 - loss: 0.2660 - val_auc: 0.7837 - val_binary_accuracy: 0.9042 - val_loss: 0.2676\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9051 - loss: 0.2648 - val_auc: 0.7870 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9051 - loss: 0.2636 - val_auc: 0.7890 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9053 - loss: 0.2624 - val_auc: 0.7912 - val_binary_accuracy: 0.9042 - val_loss: 0.2644\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9070 - loss: 0.2615 - val_auc: 0.7935 - val_binary_accuracy: 0.9090 - val_loss: 0.2633\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9086 - loss: 0.2608 - val_auc: 0.7945 - val_binary_accuracy: 0.9093 - val_loss: 0.2621\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9095 - loss: 0.2600 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2609\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2619\n",
      "Fold 3 Metrics: Loss = 0.2609, Accuracy = 0.9094, AUC = 0.7978\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5424 - binary_accuracy: 0.9047 - loss: 0.3808 - val_auc: 0.7546 - val_binary_accuracy: 0.9044 - val_loss: 0.2978\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7434 - binary_accuracy: 0.9047 - loss: 0.2896 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9047 - loss: 0.2698 - val_auc: 0.7893 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9047 - loss: 0.2653 - val_auc: 0.7930 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9047 - loss: 0.2639 - val_auc: 0.7951 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9048 - loss: 0.2629 - val_auc: 0.7961 - val_binary_accuracy: 0.9044 - val_loss: 0.2652\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9059 - loss: 0.2616 - val_auc: 0.7985 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9086 - loss: 0.2603 - val_auc: 0.8002 - val_binary_accuracy: 0.9060 - val_loss: 0.2621\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9100 - loss: 0.2592 - val_auc: 0.8014 - val_binary_accuracy: 0.9081 - val_loss: 0.2608\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9101 - loss: 0.2583 - val_auc: 0.8034 - val_binary_accuracy: 0.9088 - val_loss: 0.2598\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7852 - binary_accuracy: 0.9078 - loss: 0.2646\n",
      "Fold 4 Metrics: Loss = 0.2598, Accuracy = 0.9088, AUC = 0.8034\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5186 - binary_accuracy: 0.6762 - loss: 0.5585 - val_auc: 0.7575 - val_binary_accuracy: 0.9044 - val_loss: 0.3071\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7405 - binary_accuracy: 0.9040 - loss: 0.3036 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2812\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9040 - loss: 0.2809 - val_auc: 0.7861 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9040 - loss: 0.2711 - val_auc: 0.7940 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9040 - loss: 0.2684 - val_auc: 0.7970 - val_binary_accuracy: 0.9044 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9040 - loss: 0.2667 - val_auc: 0.7980 - val_binary_accuracy: 0.9044 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9043 - loss: 0.2650 - val_auc: 0.7993 - val_binary_accuracy: 0.9084 - val_loss: 0.2575\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9073 - loss: 0.2638 - val_auc: 0.8002 - val_binary_accuracy: 0.9100 - val_loss: 0.2566\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8002 - val_binary_accuracy: 0.9101 - val_loss: 0.2559\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9088 - loss: 0.2622 - val_auc: 0.8009 - val_binary_accuracy: 0.9094 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8121 - binary_accuracy: 0.9078 - loss: 0.2525\n",
      "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9094, AUC = 0.8009\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2598\n",
      "Average Accuracy: 0.9078\n",
      "Average AUC: 0.7999\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 3, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6031 - binary_accuracy: 0.9069 - loss: 0.3197 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2756\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9069 - loss: 0.2629 - val_auc: 0.7730 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9070 - loss: 0.2584 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9072 - loss: 0.2563 - val_auc: 0.7797 - val_binary_accuracy: 0.9062 - val_loss: 0.2662\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9104 - loss: 0.2543 - val_auc: 0.7826 - val_binary_accuracy: 0.9075 - val_loss: 0.2648\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9123 - loss: 0.2523 - val_auc: 0.7852 - val_binary_accuracy: 0.9078 - val_loss: 0.2636\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7873 - val_binary_accuracy: 0.9087 - val_loss: 0.2624\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9124 - loss: 0.2491 - val_auc: 0.7896 - val_binary_accuracy: 0.9085 - val_loss: 0.2614\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8104 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7899 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8115 - binary_accuracy: 0.9130 - loss: 0.2474 - val_auc: 0.7907 - val_binary_accuracy: 0.9088 - val_loss: 0.2606\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9132 - loss: 0.2533\n",
      "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9088, AUC = 0.7907\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5975 - binary_accuracy: 0.8692 - loss: 0.3589 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9029 - loss: 0.2736 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9030 - loss: 0.2682 - val_auc: 0.8016 - val_binary_accuracy: 0.9042 - val_loss: 0.2607\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9038 - loss: 0.2656 - val_auc: 0.8044 - val_binary_accuracy: 0.9050 - val_loss: 0.2588\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9063 - loss: 0.2629 - val_auc: 0.8071 - val_binary_accuracy: 0.9066 - val_loss: 0.2583\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9070 - loss: 0.2611 - val_auc: 0.8083 - val_binary_accuracy: 0.9073 - val_loss: 0.2578\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9075 - loss: 0.2599 - val_auc: 0.8082 - val_binary_accuracy: 0.9078 - val_loss: 0.2577\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9077 - loss: 0.2591 - val_auc: 0.8086 - val_binary_accuracy: 0.9078 - val_loss: 0.2578\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9079 - loss: 0.2585 - val_auc: 0.8084 - val_binary_accuracy: 0.9085 - val_loss: 0.2580\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9078 - loss: 0.2579 - val_auc: 0.8094 - val_binary_accuracy: 0.9087 - val_loss: 0.2580\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8141 - binary_accuracy: 0.9121 - loss: 0.2476\n",
      "Fold 2 Metrics: Loss = 0.2580, Accuracy = 0.9087, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5699 - binary_accuracy: 0.8448 - loss: 0.3757 - val_auc: 0.7576 - val_binary_accuracy: 0.9042 - val_loss: 0.2835\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9051 - loss: 0.2760 - val_auc: 0.7803 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9052 - loss: 0.2670 - val_auc: 0.7852 - val_binary_accuracy: 0.9048 - val_loss: 0.2661\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9068 - loss: 0.2648 - val_auc: 0.7893 - val_binary_accuracy: 0.9088 - val_loss: 0.2642\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.7928 - val_binary_accuracy: 0.9099 - val_loss: 0.2626\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9090 - loss: 0.2623 - val_auc: 0.7958 - val_binary_accuracy: 0.9104 - val_loss: 0.2610\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9095 - loss: 0.2614 - val_auc: 0.7977 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9092 - loss: 0.2607 - val_auc: 0.7994 - val_binary_accuracy: 0.9109 - val_loss: 0.2586\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9094 - loss: 0.2600 - val_auc: 0.8016 - val_binary_accuracy: 0.9110 - val_loss: 0.2575\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9095 - loss: 0.2595 - val_auc: 0.8036 - val_binary_accuracy: 0.9112 - val_loss: 0.2567\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7953 - binary_accuracy: 0.9127 - loss: 0.2575\n",
      "Fold 3 Metrics: Loss = 0.2567, Accuracy = 0.9112, AUC = 0.8036\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5847 - binary_accuracy: 0.8714 - loss: 0.3584 - val_auc: 0.7733 - val_binary_accuracy: 0.9044 - val_loss: 0.2755\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9047 - loss: 0.2713 - val_auc: 0.7870 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9049 - loss: 0.2652 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9068 - loss: 0.2631 - val_auc: 0.7971 - val_binary_accuracy: 0.9056 - val_loss: 0.2607\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9090 - loss: 0.2613 - val_auc: 0.8003 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9090 - loss: 0.2599 - val_auc: 0.8023 - val_binary_accuracy: 0.9082 - val_loss: 0.2579\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9096 - loss: 0.2589 - val_auc: 0.8048 - val_binary_accuracy: 0.9087 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9100 - loss: 0.2583 - val_auc: 0.8058 - val_binary_accuracy: 0.9094 - val_loss: 0.2569\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7958 - binary_accuracy: 0.9097 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9100 - loss: 0.2572 - val_auc: 0.8083 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7889 - binary_accuracy: 0.9088 - loss: 0.2624\n",
      "Fold 4 Metrics: Loss = 0.2562, Accuracy = 0.9093, AUC = 0.8083\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6027 - binary_accuracy: 0.8854 - loss: 0.3512 - val_auc: 0.7779 - val_binary_accuracy: 0.9044 - val_loss: 0.2725\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9040 - loss: 0.2747 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9040 - loss: 0.2703 - val_auc: 0.7929 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9040 - loss: 0.2686 - val_auc: 0.7954 - val_binary_accuracy: 0.9044 - val_loss: 0.2588\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9047 - loss: 0.2667 - val_auc: 0.7974 - val_binary_accuracy: 0.9085 - val_loss: 0.2572\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9078 - loss: 0.2652 - val_auc: 0.8014 - val_binary_accuracy: 0.9093 - val_loss: 0.2560\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8041 - val_binary_accuracy: 0.9093 - val_loss: 0.2548\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9094 - loss: 0.2625 - val_auc: 0.8067 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9094 - loss: 0.2615 - val_auc: 0.8085 - val_binary_accuracy: 0.9100 - val_loss: 0.2525\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9096 - loss: 0.2606 - val_auc: 0.8098 - val_binary_accuracy: 0.9103 - val_loss: 0.2516\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8184 - binary_accuracy: 0.9086 - loss: 0.2501\n",
      "Fold 5 Metrics: Loss = 0.2516, Accuracy = 0.9103, AUC = 0.8098\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2566\n",
      "Average Accuracy: 0.9096\n",
      "Average AUC: 0.8044\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 3, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6540 - binary_accuracy: 0.9069 - loss: 0.3076 - val_auc: 0.7724 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9071 - loss: 0.2598 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9089 - loss: 0.2558 - val_auc: 0.7864 - val_binary_accuracy: 0.9051 - val_loss: 0.2639\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9105 - loss: 0.2528 - val_auc: 0.7896 - val_binary_accuracy: 0.9068 - val_loss: 0.2623\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9116 - loss: 0.2507 - val_auc: 0.7923 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9119 - loss: 0.2493 - val_auc: 0.7935 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9126 - loss: 0.2482 - val_auc: 0.7942 - val_binary_accuracy: 0.9084 - val_loss: 0.2594\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9125 - loss: 0.2474 - val_auc: 0.7944 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8133 - binary_accuracy: 0.9127 - loss: 0.2466 - val_auc: 0.7948 - val_binary_accuracy: 0.9088 - val_loss: 0.2588\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8141 - binary_accuracy: 0.9129 - loss: 0.2461 - val_auc: 0.7951 - val_binary_accuracy: 0.9085 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7937 - binary_accuracy: 0.9122 - loss: 0.2515\n",
      "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9085, AUC = 0.7951\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6455 - binary_accuracy: 0.9029 - loss: 0.3099 - val_auc: 0.7958 - val_binary_accuracy: 0.9042 - val_loss: 0.2653\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9040 - loss: 0.2706 - val_auc: 0.8024 - val_binary_accuracy: 0.9053 - val_loss: 0.2601\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9055 - loss: 0.2660 - val_auc: 0.8055 - val_binary_accuracy: 0.9065 - val_loss: 0.2584\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9069 - loss: 0.2634 - val_auc: 0.8074 - val_binary_accuracy: 0.9072 - val_loss: 0.2561\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8087 - val_binary_accuracy: 0.9087 - val_loss: 0.2550\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9082 - loss: 0.2602 - val_auc: 0.8090 - val_binary_accuracy: 0.9088 - val_loss: 0.2547\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9082 - loss: 0.2594 - val_auc: 0.8096 - val_binary_accuracy: 0.9088 - val_loss: 0.2548\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9085 - loss: 0.2587 - val_auc: 0.8089 - val_binary_accuracy: 0.9087 - val_loss: 0.2550\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9085 - loss: 0.2582 - val_auc: 0.8093 - val_binary_accuracy: 0.9087 - val_loss: 0.2549\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9087 - loss: 0.2578 - val_auc: 0.8095 - val_binary_accuracy: 0.9088 - val_loss: 0.2548\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8161 - binary_accuracy: 0.9127 - loss: 0.2442\n",
      "Fold 2 Metrics: Loss = 0.2548, Accuracy = 0.9088, AUC = 0.8095\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6080 - binary_accuracy: 0.8568 - loss: 0.3631 - val_auc: 0.7791 - val_binary_accuracy: 0.9042 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9053 - loss: 0.2690 - val_auc: 0.7862 - val_binary_accuracy: 0.9050 - val_loss: 0.2660\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9073 - loss: 0.2666 - val_auc: 0.7899 - val_binary_accuracy: 0.9088 - val_loss: 0.2636\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9081 - loss: 0.2650 - val_auc: 0.7936 - val_binary_accuracy: 0.9096 - val_loss: 0.2615\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.7955 - val_binary_accuracy: 0.9103 - val_loss: 0.2599\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9090 - loss: 0.2633 - val_auc: 0.7979 - val_binary_accuracy: 0.9107 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9094 - loss: 0.2626 - val_auc: 0.7990 - val_binary_accuracy: 0.9109 - val_loss: 0.2578\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9095 - loss: 0.2619 - val_auc: 0.8009 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9096 - loss: 0.2613 - val_auc: 0.8020 - val_binary_accuracy: 0.9115 - val_loss: 0.2565\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.8031 - val_binary_accuracy: 0.9115 - val_loss: 0.2560\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9134 - loss: 0.2566\n",
      "Fold 3 Metrics: Loss = 0.2560, Accuracy = 0.9115, AUC = 0.8031\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5836 - binary_accuracy: 0.8179 - loss: 0.4140 - val_auc: 0.7830 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9047 - loss: 0.2675 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9065 - loss: 0.2640 - val_auc: 0.7958 - val_binary_accuracy: 0.9064 - val_loss: 0.2612\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2618 - val_auc: 0.7993 - val_binary_accuracy: 0.9088 - val_loss: 0.2591\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9094 - loss: 0.2601 - val_auc: 0.8026 - val_binary_accuracy: 0.9091 - val_loss: 0.2571\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9103 - loss: 0.2588 - val_auc: 0.8045 - val_binary_accuracy: 0.9095 - val_loss: 0.2560\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9107 - loss: 0.2580 - val_auc: 0.8057 - val_binary_accuracy: 0.9094 - val_loss: 0.2554\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9108 - loss: 0.2573 - val_auc: 0.8067 - val_binary_accuracy: 0.9098 - val_loss: 0.2551\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.8079 - val_binary_accuracy: 0.9097 - val_loss: 0.2547\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9115 - loss: 0.2564 - val_auc: 0.8084 - val_binary_accuracy: 0.9095 - val_loss: 0.2544\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7896 - binary_accuracy: 0.9085 - loss: 0.2608\n",
      "Fold 4 Metrics: Loss = 0.2544, Accuracy = 0.9095, AUC = 0.8084\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6257 - binary_accuracy: 0.9040 - loss: 0.3208 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9043 - loss: 0.2727 - val_auc: 0.7930 - val_binary_accuracy: 0.9079 - val_loss: 0.2598\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9061 - loss: 0.2698 - val_auc: 0.7960 - val_binary_accuracy: 0.9081 - val_loss: 0.2577\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9084 - loss: 0.2675 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2560\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9086 - loss: 0.2656 - val_auc: 0.8022 - val_binary_accuracy: 0.9094 - val_loss: 0.2547\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9092 - loss: 0.2641 - val_auc: 0.8050 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9092 - loss: 0.2628 - val_auc: 0.8059 - val_binary_accuracy: 0.9106 - val_loss: 0.2528\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9094 - loss: 0.2619 - val_auc: 0.8069 - val_binary_accuracy: 0.9107 - val_loss: 0.2521\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9095 - loss: 0.2611 - val_auc: 0.8078 - val_binary_accuracy: 0.9113 - val_loss: 0.2516\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8084 - val_binary_accuracy: 0.9115 - val_loss: 0.2513\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9096 - loss: 0.2489\n",
      "Fold 5 Metrics: Loss = 0.2513, Accuracy = 0.9115, AUC = 0.8084\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2551\n",
      "Average Accuracy: 0.9100\n",
      "Average AUC: 0.8049\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 3, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6561 - binary_accuracy: 0.8901 - loss: 0.3053 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9076 - loss: 0.2608 - val_auc: 0.7809 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9097 - loss: 0.2570 - val_auc: 0.7871 - val_binary_accuracy: 0.9054 - val_loss: 0.2666\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9108 - loss: 0.2539 - val_auc: 0.7910 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8040 - binary_accuracy: 0.9117 - loss: 0.2515 - val_auc: 0.7933 - val_binary_accuracy: 0.9075 - val_loss: 0.2631\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9119 - loss: 0.2498 - val_auc: 0.7942 - val_binary_accuracy: 0.9081 - val_loss: 0.2620\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8095 - binary_accuracy: 0.9125 - loss: 0.2486 - val_auc: 0.7946 - val_binary_accuracy: 0.9087 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8115 - binary_accuracy: 0.9128 - loss: 0.2476 - val_auc: 0.7958 - val_binary_accuracy: 0.9087 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8130 - binary_accuracy: 0.9132 - loss: 0.2468 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2593\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8140 - binary_accuracy: 0.9131 - loss: 0.2462 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2589\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9118 - loss: 0.2508\n",
      "Fold 1 Metrics: Loss = 0.2589, Accuracy = 0.9084, AUC = 0.7962\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6743 - binary_accuracy: 0.9031 - loss: 0.3031 - val_auc: 0.7991 - val_binary_accuracy: 0.9042 - val_loss: 0.2653\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9043 - loss: 0.2697 - val_auc: 0.8052 - val_binary_accuracy: 0.9060 - val_loss: 0.2627\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9065 - loss: 0.2656 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2609\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9079 - loss: 0.2630 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2599\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8083 - val_binary_accuracy: 0.9090 - val_loss: 0.2589\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7987 - binary_accuracy: 0.9082 - loss: 0.2606 - val_auc: 0.8086 - val_binary_accuracy: 0.9093 - val_loss: 0.2580\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8008 - binary_accuracy: 0.9084 - loss: 0.2599 - val_auc: 0.8092 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9083 - loss: 0.2593 - val_auc: 0.8100 - val_binary_accuracy: 0.9094 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9083 - loss: 0.2587 - val_auc: 0.8103 - val_binary_accuracy: 0.9093 - val_loss: 0.2555\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9083 - loss: 0.2583 - val_auc: 0.8105 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9124 - loss: 0.2453\n",
      "Fold 2 Metrics: Loss = 0.2550, Accuracy = 0.9093, AUC = 0.8105\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6393 - binary_accuracy: 0.8865 - loss: 0.3228 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7624 - binary_accuracy: 0.9060 - loss: 0.2722 - val_auc: 0.7872 - val_binary_accuracy: 0.9073 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9076 - loss: 0.2690 - val_auc: 0.7918 - val_binary_accuracy: 0.9102 - val_loss: 0.2628\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9085 - loss: 0.2667 - val_auc: 0.7959 - val_binary_accuracy: 0.9110 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9090 - loss: 0.2650 - val_auc: 0.7991 - val_binary_accuracy: 0.9113 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9093 - loss: 0.2638 - val_auc: 0.8011 - val_binary_accuracy: 0.9113 - val_loss: 0.2582\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9094 - loss: 0.2629 - val_auc: 0.8033 - val_binary_accuracy: 0.9113 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9099 - loss: 0.2621 - val_auc: 0.8050 - val_binary_accuracy: 0.9115 - val_loss: 0.2563\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9100 - loss: 0.2615 - val_auc: 0.8059 - val_binary_accuracy: 0.9118 - val_loss: 0.2557\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9098 - loss: 0.2609 - val_auc: 0.8069 - val_binary_accuracy: 0.9115 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7990 - binary_accuracy: 0.9130 - loss: 0.2559\n",
      "Fold 3 Metrics: Loss = 0.2552, Accuracy = 0.9115, AUC = 0.8069\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6251 - binary_accuracy: 0.8866 - loss: 0.3383 - val_auc: 0.7882 - val_binary_accuracy: 0.9051 - val_loss: 0.2648\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9059 - loss: 0.2676 - val_auc: 0.7959 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9081 - loss: 0.2646 - val_auc: 0.8012 - val_binary_accuracy: 0.9085 - val_loss: 0.2582\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9090 - loss: 0.2622 - val_auc: 0.8046 - val_binary_accuracy: 0.9085 - val_loss: 0.2566\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9100 - loss: 0.2605 - val_auc: 0.8065 - val_binary_accuracy: 0.9087 - val_loss: 0.2557\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9100 - loss: 0.2595 - val_auc: 0.8072 - val_binary_accuracy: 0.9085 - val_loss: 0.2551\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8085 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9107 - loss: 0.2580 - val_auc: 0.8092 - val_binary_accuracy: 0.9093 - val_loss: 0.2544\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9107 - loss: 0.2575 - val_auc: 0.8100 - val_binary_accuracy: 0.9091 - val_loss: 0.2542\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9109 - loss: 0.2571 - val_auc: 0.8101 - val_binary_accuracy: 0.9093 - val_loss: 0.2540\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7920 - binary_accuracy: 0.9086 - loss: 0.2607\n",
      "Fold 4 Metrics: Loss = 0.2540, Accuracy = 0.9093, AUC = 0.8101\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6250 - binary_accuracy: 0.8698 - loss: 0.3534 - val_auc: 0.7891 - val_binary_accuracy: 0.9075 - val_loss: 0.2658\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9045 - loss: 0.2732 - val_auc: 0.7945 - val_binary_accuracy: 0.9082 - val_loss: 0.2639\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9057 - loss: 0.2704 - val_auc: 0.7990 - val_binary_accuracy: 0.9081 - val_loss: 0.2625\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9074 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9085 - val_loss: 0.2616\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9082 - loss: 0.2662 - val_auc: 0.8042 - val_binary_accuracy: 0.9087 - val_loss: 0.2600\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9085 - loss: 0.2648 - val_auc: 0.8050 - val_binary_accuracy: 0.9101 - val_loss: 0.2582\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9087 - loss: 0.2638 - val_auc: 0.8062 - val_binary_accuracy: 0.9103 - val_loss: 0.2564\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9092 - loss: 0.2630 - val_auc: 0.8072 - val_binary_accuracy: 0.9115 - val_loss: 0.2547\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9092 - loss: 0.2622 - val_auc: 0.8072 - val_binary_accuracy: 0.9121 - val_loss: 0.2537\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9096 - loss: 0.2615 - val_auc: 0.8083 - val_binary_accuracy: 0.9116 - val_loss: 0.2527\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9095 - loss: 0.2509\n",
      "Fold 5 Metrics: Loss = 0.2527, Accuracy = 0.9116, AUC = 0.8083\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2552\n",
      "Average Accuracy: 0.9100\n",
      "Average AUC: 0.8064\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 4, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4969 - binary_accuracy: 0.3356 - loss: 1.0198 - val_auc: 0.4997 - val_binary_accuracy: 0.9044 - val_loss: 0.3583\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4961 - binary_accuracy: 0.9069 - loss: 0.3372 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3189\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5076 - binary_accuracy: 0.9069 - loss: 0.3124 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3155\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5098 - binary_accuracy: 0.9069 - loss: 0.3099 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3151\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5093 - binary_accuracy: 0.9069 - loss: 0.3095 - val_auc: 0.4999 - val_binary_accuracy: 0.9044 - val_loss: 0.3150\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5691 - binary_accuracy: 0.9069 - loss: 0.3093 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5973 - binary_accuracy: 0.9069 - loss: 0.3088 - val_auc: 0.7049 - val_binary_accuracy: 0.9044 - val_loss: 0.3133\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7355 - binary_accuracy: 0.9069 - loss: 0.3064 - val_auc: 0.7475 - val_binary_accuracy: 0.9044 - val_loss: 0.3039\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9069 - loss: 0.2901 - val_auc: 0.7627 - val_binary_accuracy: 0.9044 - val_loss: 0.2786\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7697 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7680 - binary_accuracy: 0.9084 - loss: 0.2622\n",
      "Fold 1 Metrics: Loss = 0.2700, Accuracy = 0.9044, AUC = 0.7697\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5046 - binary_accuracy: 0.9029 - loss: 0.3812 - val_auc: 0.6797 - val_binary_accuracy: 0.9042 - val_loss: 0.3142\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6695 - binary_accuracy: 0.9029 - loss: 0.3158 - val_auc: 0.7519 - val_binary_accuracy: 0.9042 - val_loss: 0.3039\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7421 - binary_accuracy: 0.9029 - loss: 0.2995 - val_auc: 0.7911 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2751 - val_auc: 0.7948 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9029 - loss: 0.2696 - val_auc: 0.8021 - val_binary_accuracy: 0.9042 - val_loss: 0.2644\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9029 - loss: 0.2673 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2635\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9029 - loss: 0.2657 - val_auc: 0.8057 - val_binary_accuracy: 0.9042 - val_loss: 0.2629\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9030 - loss: 0.2643 - val_auc: 0.8063 - val_binary_accuracy: 0.9042 - val_loss: 0.2622\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7975 - binary_accuracy: 0.9047 - loss: 0.2632 - val_auc: 0.8064 - val_binary_accuracy: 0.9051 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9061 - loss: 0.2622 - val_auc: 0.8080 - val_binary_accuracy: 0.9056 - val_loss: 0.2609\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8113 - binary_accuracy: 0.9099 - loss: 0.2505\n",
      "Fold 2 Metrics: Loss = 0.2609, Accuracy = 0.9056, AUC = 0.8080\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5037 - binary_accuracy: 0.8728 - loss: 0.4521 - val_auc: 0.6925 - val_binary_accuracy: 0.9042 - val_loss: 0.3140\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6814 - binary_accuracy: 0.9051 - loss: 0.3107 - val_auc: 0.7450 - val_binary_accuracy: 0.9042 - val_loss: 0.3009\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7463 - binary_accuracy: 0.9051 - loss: 0.2936 - val_auc: 0.7699 - val_binary_accuracy: 0.9042 - val_loss: 0.2784\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9051 - loss: 0.2740 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9051 - loss: 0.2682 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7799 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7802 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9051 - loss: 0.2645 - val_auc: 0.7831 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9051 - loss: 0.2639 - val_auc: 0.7844 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7804 - binary_accuracy: 0.9046 - loss: 0.2672\n",
      "Fold 3 Metrics: Loss = 0.2674, Accuracy = 0.9042, AUC = 0.7844\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - auc: 0.4974 - binary_accuracy: 0.6128 - loss: 0.6017 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3166\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4971 - binary_accuracy: 0.9047 - loss: 0.3151 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3153\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5004 - binary_accuracy: 0.9047 - loss: 0.3146 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3152\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5160 - binary_accuracy: 0.9047 - loss: 0.3144 - val_auc: 0.6853 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6210 - binary_accuracy: 0.9047 - loss: 0.3129 - val_auc: 0.7450 - val_binary_accuracy: 0.9044 - val_loss: 0.3091\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7349 - binary_accuracy: 0.9047 - loss: 0.3057 - val_auc: 0.7712 - val_binary_accuracy: 0.9044 - val_loss: 0.2949\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7509 - binary_accuracy: 0.9047 - loss: 0.2897 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2800\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7627 - binary_accuracy: 0.9047 - loss: 0.2754 - val_auc: 0.7768 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9047 - loss: 0.2701 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2726\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9047 - loss: 0.2681 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7635 - binary_accuracy: 0.9049 - loss: 0.2743\n",
      "Fold 4 Metrics: Loss = 0.2712, Accuracy = 0.9044, AUC = 0.7828\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5041 - binary_accuracy: 0.7764 - loss: 0.4915 - val_auc: 0.6729 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5882 - binary_accuracy: 0.9040 - loss: 0.3149 - val_auc: 0.7296 - val_binary_accuracy: 0.9044 - val_loss: 0.3122\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7166 - binary_accuracy: 0.9040 - loss: 0.3122 - val_auc: 0.7463 - val_binary_accuracy: 0.9044 - val_loss: 0.3044\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7387 - binary_accuracy: 0.9040 - loss: 0.3013 - val_auc: 0.7674 - val_binary_accuracy: 0.9044 - val_loss: 0.2817\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7552 - binary_accuracy: 0.9040 - loss: 0.2832 - val_auc: 0.7707 - val_binary_accuracy: 0.9044 - val_loss: 0.2714\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7643 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9040 - loss: 0.2729 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2655\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9040 - loss: 0.2717 - val_auc: 0.7822 - val_binary_accuracy: 0.9044 - val_loss: 0.2646\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9040 - loss: 0.2710 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2640\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9040 - loss: 0.2705 - val_auc: 0.7897 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8000 - binary_accuracy: 0.9013 - loss: 0.2621\n",
      "Fold 5 Metrics: Loss = 0.2635, Accuracy = 0.9044, AUC = 0.7897\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2666\n",
      "Average Accuracy: 0.9046\n",
      "Average AUC: 0.7869\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 4, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4990 - binary_accuracy: 0.7259 - loss: 0.4959 - val_auc: 0.6752 - val_binary_accuracy: 0.9044 - val_loss: 0.3144\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6313 - binary_accuracy: 0.9069 - loss: 0.3070 - val_auc: 0.7469 - val_binary_accuracy: 0.9044 - val_loss: 0.2975\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9069 - loss: 0.2813 - val_auc: 0.7646 - val_binary_accuracy: 0.9044 - val_loss: 0.2733\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9069 - loss: 0.2623 - val_auc: 0.7768 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9069 - loss: 0.2584 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9069 - loss: 0.2567 - val_auc: 0.7826 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7997 - binary_accuracy: 0.9069 - loss: 0.2556 - val_auc: 0.7866 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9069 - loss: 0.2546 - val_auc: 0.7901 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9070 - loss: 0.2536 - val_auc: 0.7907 - val_binary_accuracy: 0.9044 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9078 - loss: 0.2525 - val_auc: 0.7926 - val_binary_accuracy: 0.9069 - val_loss: 0.2607\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7934 - binary_accuracy: 0.9111 - loss: 0.2528\n",
      "Fold 1 Metrics: Loss = 0.2607, Accuracy = 0.9069, AUC = 0.7926\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5150 - binary_accuracy: 0.9029 - loss: 0.3443 - val_auc: 0.7261 - val_binary_accuracy: 0.9042 - val_loss: 0.3104\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7228 - binary_accuracy: 0.9029 - loss: 0.3022 - val_auc: 0.7919 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9029 - loss: 0.2716 - val_auc: 0.8001 - val_binary_accuracy: 0.9042 - val_loss: 0.2641\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9029 - loss: 0.2686 - val_auc: 0.8026 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9037 - loss: 0.2671 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9046 - loss: 0.2655 - val_auc: 0.8045 - val_binary_accuracy: 0.9056 - val_loss: 0.2614\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9066 - loss: 0.2639 - val_auc: 0.8050 - val_binary_accuracy: 0.9063 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.8069 - val_binary_accuracy: 0.9069 - val_loss: 0.2594\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9075 - loss: 0.2612 - val_auc: 0.8076 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9078 - loss: 0.2604 - val_auc: 0.8076 - val_binary_accuracy: 0.9082 - val_loss: 0.2588\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8108 - binary_accuracy: 0.9118 - loss: 0.2494\n",
      "Fold 2 Metrics: Loss = 0.2588, Accuracy = 0.9082, AUC = 0.8076\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5068 - binary_accuracy: 0.8865 - loss: 0.3881 - val_auc: 0.7022 - val_binary_accuracy: 0.9042 - val_loss: 0.3133\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6946 - binary_accuracy: 0.9051 - loss: 0.3082 - val_auc: 0.7682 - val_binary_accuracy: 0.9042 - val_loss: 0.2854\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7616 - binary_accuracy: 0.9051 - loss: 0.2770 - val_auc: 0.7730 - val_binary_accuracy: 0.9042 - val_loss: 0.2713\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9051 - loss: 0.2686 - val_auc: 0.7775 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7823 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9051 - loss: 0.2659 - val_auc: 0.7843 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9059 - loss: 0.2647 - val_auc: 0.7862 - val_binary_accuracy: 0.9082 - val_loss: 0.2654\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9079 - loss: 0.2636 - val_auc: 0.7873 - val_binary_accuracy: 0.9097 - val_loss: 0.2646\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9084 - loss: 0.2631 - val_auc: 0.7884 - val_binary_accuracy: 0.9102 - val_loss: 0.2638\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.7900 - val_binary_accuracy: 0.9103 - val_loss: 0.2632\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7847 - binary_accuracy: 0.9115 - loss: 0.2633\n",
      "Fold 3 Metrics: Loss = 0.2632, Accuracy = 0.9103, AUC = 0.7900\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5048 - binary_accuracy: 0.6734 - loss: 0.5628 - val_auc: 0.7008 - val_binary_accuracy: 0.9044 - val_loss: 0.3131\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6866 - binary_accuracy: 0.9047 - loss: 0.3106 - val_auc: 0.7548 - val_binary_accuracy: 0.9044 - val_loss: 0.2990\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7447 - binary_accuracy: 0.9047 - loss: 0.2920 - val_auc: 0.7681 - val_binary_accuracy: 0.9044 - val_loss: 0.2774\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9047 - loss: 0.2733 - val_auc: 0.7790 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9047 - loss: 0.2688 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2734\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9047 - loss: 0.2679 - val_auc: 0.7866 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9047 - loss: 0.2674 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9047 - loss: 0.2665 - val_auc: 0.7878 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9047 - loss: 0.2658 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9047 - loss: 0.2650 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7716 - binary_accuracy: 0.9049 - loss: 0.2734\n",
      "Fold 4 Metrics: Loss = 0.2680, Accuracy = 0.9044, AUC = 0.7924\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5250 - binary_accuracy: 0.9040 - loss: 0.3465 - val_auc: 0.7361 - val_binary_accuracy: 0.9044 - val_loss: 0.3061\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7318 - binary_accuracy: 0.9040 - loss: 0.2972 - val_auc: 0.7815 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7854 - val_binary_accuracy: 0.9044 - val_loss: 0.2632\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9040 - loss: 0.2719 - val_auc: 0.7871 - val_binary_accuracy: 0.9044 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9040 - loss: 0.2690 - val_auc: 0.7925 - val_binary_accuracy: 0.9044 - val_loss: 0.2590\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9041 - loss: 0.2673 - val_auc: 0.7960 - val_binary_accuracy: 0.9072 - val_loss: 0.2575\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.7983 - val_binary_accuracy: 0.9093 - val_loss: 0.2560\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2642 - val_auc: 0.8011 - val_binary_accuracy: 0.9100 - val_loss: 0.2547\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9087 - loss: 0.2630 - val_auc: 0.8025 - val_binary_accuracy: 0.9107 - val_loss: 0.2537\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8133 - binary_accuracy: 0.9093 - loss: 0.2513\n",
      "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9107, AUC = 0.8025\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2609\n",
      "Average Accuracy: 0.9081\n",
      "Average AUC: 0.7970\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 4, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5312 - binary_accuracy: 0.8037 - loss: 0.4185 - val_auc: 0.7559 - val_binary_accuracy: 0.9044 - val_loss: 0.2886\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9069 - loss: 0.2722 - val_auc: 0.7699 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7748 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9070 - loss: 0.2568 - val_auc: 0.7811 - val_binary_accuracy: 0.9044 - val_loss: 0.2661\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9078 - loss: 0.2548 - val_auc: 0.7855 - val_binary_accuracy: 0.9071 - val_loss: 0.2647\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9101 - loss: 0.2532 - val_auc: 0.7873 - val_binary_accuracy: 0.9085 - val_loss: 0.2635\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9121 - loss: 0.2518 - val_auc: 0.7886 - val_binary_accuracy: 0.9096 - val_loss: 0.2626\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8066 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7890 - val_binary_accuracy: 0.9100 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9131 - loss: 0.2495 - val_auc: 0.7893 - val_binary_accuracy: 0.9099 - val_loss: 0.2610\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7880 - binary_accuracy: 0.9131 - loss: 0.2545\n",
      "Fold 1 Metrics: Loss = 0.2610, Accuracy = 0.9099, AUC = 0.7893\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5575 - binary_accuracy: 0.9029 - loss: 0.3253 - val_auc: 0.7887 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9029 - loss: 0.2727 - val_auc: 0.8010 - val_binary_accuracy: 0.9042 - val_loss: 0.2620\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9036 - loss: 0.2681 - val_auc: 0.8052 - val_binary_accuracy: 0.9042 - val_loss: 0.2599\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9044 - loss: 0.2652 - val_auc: 0.8097 - val_binary_accuracy: 0.9051 - val_loss: 0.2574\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9052 - loss: 0.2629 - val_auc: 0.8098 - val_binary_accuracy: 0.9065 - val_loss: 0.2565\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9065 - loss: 0.2613 - val_auc: 0.8099 - val_binary_accuracy: 0.9071 - val_loss: 0.2560\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9067 - loss: 0.2602 - val_auc: 0.8104 - val_binary_accuracy: 0.9076 - val_loss: 0.2560\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9078 - loss: 0.2595 - val_auc: 0.8109 - val_binary_accuracy: 0.9084 - val_loss: 0.2557\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9073 - loss: 0.2589 - val_auc: 0.8114 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9075 - loss: 0.2584 - val_auc: 0.8107 - val_binary_accuracy: 0.9090 - val_loss: 0.2563\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8160 - binary_accuracy: 0.9130 - loss: 0.2456\n",
      "Fold 2 Metrics: Loss = 0.2563, Accuracy = 0.9090, AUC = 0.8107\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5587 - binary_accuracy: 0.8865 - loss: 0.3486 - val_auc: 0.7627 - val_binary_accuracy: 0.9042 - val_loss: 0.2795\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9051 - loss: 0.2726 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9051 - loss: 0.2673 - val_auc: 0.7875 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9052 - loss: 0.2654 - val_auc: 0.7923 - val_binary_accuracy: 0.9059 - val_loss: 0.2640\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9061 - loss: 0.2636 - val_auc: 0.7946 - val_binary_accuracy: 0.9097 - val_loss: 0.2620\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9085 - loss: 0.2626 - val_auc: 0.7963 - val_binary_accuracy: 0.9100 - val_loss: 0.2603\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9089 - loss: 0.2616 - val_auc: 0.7992 - val_binary_accuracy: 0.9102 - val_loss: 0.2591\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9091 - loss: 0.2610 - val_auc: 0.7993 - val_binary_accuracy: 0.9115 - val_loss: 0.2584\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.7996 - val_binary_accuracy: 0.9113 - val_loss: 0.2578\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9101 - loss: 0.2599 - val_auc: 0.8005 - val_binary_accuracy: 0.9110 - val_loss: 0.2574\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7935 - binary_accuracy: 0.9123 - loss: 0.2578\n",
      "Fold 3 Metrics: Loss = 0.2574, Accuracy = 0.9110, AUC = 0.8005\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5406 - binary_accuracy: 0.9043 - loss: 0.3519 - val_auc: 0.7755 - val_binary_accuracy: 0.9044 - val_loss: 0.2751\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9047 - loss: 0.2710 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7918 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9060 - loss: 0.2643 - val_auc: 0.7959 - val_binary_accuracy: 0.9072 - val_loss: 0.2626\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9085 - loss: 0.2623 - val_auc: 0.7982 - val_binary_accuracy: 0.9076 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9097 - loss: 0.2608 - val_auc: 0.8011 - val_binary_accuracy: 0.9085 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9104 - loss: 0.2596 - val_auc: 0.8037 - val_binary_accuracy: 0.9097 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9110 - loss: 0.2586 - val_auc: 0.8063 - val_binary_accuracy: 0.9104 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9112 - loss: 0.2579 - val_auc: 0.8073 - val_binary_accuracy: 0.9106 - val_loss: 0.2554\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9114 - loss: 0.2573 - val_auc: 0.8079 - val_binary_accuracy: 0.9104 - val_loss: 0.2549\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7903 - binary_accuracy: 0.9099 - loss: 0.2603\n",
      "Fold 4 Metrics: Loss = 0.2549, Accuracy = 0.9104, AUC = 0.8079\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5695 - binary_accuracy: 0.9040 - loss: 0.3262 - val_auc: 0.7827 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.7938 - val_binary_accuracy: 0.9044 - val_loss: 0.2604\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9041 - loss: 0.2694 - val_auc: 0.7970 - val_binary_accuracy: 0.9073 - val_loss: 0.2585\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9066 - loss: 0.2670 - val_auc: 0.7983 - val_binary_accuracy: 0.9081 - val_loss: 0.2575\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9079 - loss: 0.2656 - val_auc: 0.8006 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8025 - val_binary_accuracy: 0.9095 - val_loss: 0.2547\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8033 - val_binary_accuracy: 0.9104 - val_loss: 0.2539\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9089 - loss: 0.2623 - val_auc: 0.8048 - val_binary_accuracy: 0.9107 - val_loss: 0.2533\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9088 - loss: 0.2617 - val_auc: 0.8058 - val_binary_accuracy: 0.9109 - val_loss: 0.2529\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9087 - loss: 0.2611 - val_auc: 0.8069 - val_binary_accuracy: 0.9109 - val_loss: 0.2526\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8163 - binary_accuracy: 0.9092 - loss: 0.2503\n",
      "Fold 5 Metrics: Loss = 0.2526, Accuracy = 0.9109, AUC = 0.8069\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2565\n",
      "Average Accuracy: 0.9102\n",
      "Average AUC: 0.8031\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 4, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6197 - binary_accuracy: 0.9069 - loss: 0.3147 - val_auc: 0.7702 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9069 - loss: 0.2611 - val_auc: 0.7781 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9071 - loss: 0.2578 - val_auc: 0.7843 - val_binary_accuracy: 0.9044 - val_loss: 0.2651\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9092 - loss: 0.2548 - val_auc: 0.7886 - val_binary_accuracy: 0.9062 - val_loss: 0.2639\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9116 - loss: 0.2522 - val_auc: 0.7908 - val_binary_accuracy: 0.9081 - val_loss: 0.2624\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8073 - binary_accuracy: 0.9117 - loss: 0.2502 - val_auc: 0.7922 - val_binary_accuracy: 0.9085 - val_loss: 0.2612\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9122 - loss: 0.2488 - val_auc: 0.7934 - val_binary_accuracy: 0.9084 - val_loss: 0.2602\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8111 - binary_accuracy: 0.9129 - loss: 0.2479 - val_auc: 0.7930 - val_binary_accuracy: 0.9082 - val_loss: 0.2595\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9133 - loss: 0.2472 - val_auc: 0.7943 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8130 - binary_accuracy: 0.9133 - loss: 0.2466 - val_auc: 0.7937 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7931 - binary_accuracy: 0.9124 - loss: 0.2511\n",
      "Fold 1 Metrics: Loss = 0.2588, Accuracy = 0.9085, AUC = 0.7937\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5774 - binary_accuracy: 0.8554 - loss: 0.3685 - val_auc: 0.7944 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2710 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2600\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9040 - loss: 0.2665 - val_auc: 0.8060 - val_binary_accuracy: 0.9050 - val_loss: 0.2584\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9055 - loss: 0.2638 - val_auc: 0.8064 - val_binary_accuracy: 0.9066 - val_loss: 0.2574\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9068 - loss: 0.2621 - val_auc: 0.8075 - val_binary_accuracy: 0.9075 - val_loss: 0.2561\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9075 - loss: 0.2608 - val_auc: 0.8077 - val_binary_accuracy: 0.9082 - val_loss: 0.2557\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9075 - loss: 0.2600 - val_auc: 0.8078 - val_binary_accuracy: 0.9081 - val_loss: 0.2555\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9077 - loss: 0.2593 - val_auc: 0.8079 - val_binary_accuracy: 0.9081 - val_loss: 0.2552\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.8088 - val_binary_accuracy: 0.9084 - val_loss: 0.2550\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9080 - loss: 0.2582 - val_auc: 0.8093 - val_binary_accuracy: 0.9085 - val_loss: 0.2549\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9118 - loss: 0.2445\n",
      "Fold 2 Metrics: Loss = 0.2549, Accuracy = 0.9085, AUC = 0.8093\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6086 - binary_accuracy: 0.9051 - loss: 0.3213 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9051 - loss: 0.2719 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9057 - loss: 0.2687 - val_auc: 0.7903 - val_binary_accuracy: 0.9060 - val_loss: 0.2641\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9075 - loss: 0.2669 - val_auc: 0.7944 - val_binary_accuracy: 0.9093 - val_loss: 0.2616\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9084 - loss: 0.2655 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9088 - loss: 0.2644 - val_auc: 0.8006 - val_binary_accuracy: 0.9102 - val_loss: 0.2583\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9094 - loss: 0.2633 - val_auc: 0.8016 - val_binary_accuracy: 0.9109 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9098 - loss: 0.2625 - val_auc: 0.8036 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9096 - loss: 0.2618 - val_auc: 0.8048 - val_binary_accuracy: 0.9109 - val_loss: 0.2558\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8052 - val_binary_accuracy: 0.9112 - val_loss: 0.2554\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7985 - binary_accuracy: 0.9124 - loss: 0.2559\n",
      "Fold 3 Metrics: Loss = 0.2554, Accuracy = 0.9112, AUC = 0.8052\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5807 - binary_accuracy: 0.9047 - loss: 0.3278 - val_auc: 0.7863 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9050 - loss: 0.2676 - val_auc: 0.7948 - val_binary_accuracy: 0.9057 - val_loss: 0.2624\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9071 - loss: 0.2640 - val_auc: 0.7995 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9095 - loss: 0.2618 - val_auc: 0.8028 - val_binary_accuracy: 0.9097 - val_loss: 0.2571\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9104 - loss: 0.2604 - val_auc: 0.8042 - val_binary_accuracy: 0.9097 - val_loss: 0.2562\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9106 - loss: 0.2595 - val_auc: 0.8053 - val_binary_accuracy: 0.9095 - val_loss: 0.2558\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9108 - loss: 0.2588 - val_auc: 0.8070 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9110 - loss: 0.2582 - val_auc: 0.8077 - val_binary_accuracy: 0.9091 - val_loss: 0.2552\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9112 - loss: 0.2578 - val_auc: 0.8083 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9113 - loss: 0.2574 - val_auc: 0.8093 - val_binary_accuracy: 0.9090 - val_loss: 0.2547\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7916 - binary_accuracy: 0.9077 - loss: 0.2608\n",
      "Fold 4 Metrics: Loss = 0.2547, Accuracy = 0.9090, AUC = 0.8093\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5985 - binary_accuracy: 0.9040 - loss: 0.3231 - val_auc: 0.7888 - val_binary_accuracy: 0.9044 - val_loss: 0.2640\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9041 - loss: 0.2728 - val_auc: 0.7949 - val_binary_accuracy: 0.9079 - val_loss: 0.2604\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9053 - loss: 0.2700 - val_auc: 0.7979 - val_binary_accuracy: 0.9082 - val_loss: 0.2588\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9075 - loss: 0.2680 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9080 - loss: 0.2666 - val_auc: 0.8024 - val_binary_accuracy: 0.9106 - val_loss: 0.2561\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.8038 - val_binary_accuracy: 0.9104 - val_loss: 0.2549\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.8046 - val_binary_accuracy: 0.9112 - val_loss: 0.2540\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9093 - loss: 0.2630 - val_auc: 0.8059 - val_binary_accuracy: 0.9104 - val_loss: 0.2532\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.8061 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9093 - loss: 0.2615 - val_auc: 0.8066 - val_binary_accuracy: 0.9109 - val_loss: 0.2522\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9086 - loss: 0.2498\n",
      "Fold 5 Metrics: Loss = 0.2522, Accuracy = 0.9109, AUC = 0.8066\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2552\n",
      "Average Accuracy: 0.9096\n",
      "Average AUC: 0.8048\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 4, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6381 - binary_accuracy: 0.8901 - loss: 0.3081 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9076 - loss: 0.2585 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9098 - loss: 0.2556 - val_auc: 0.7888 - val_binary_accuracy: 0.9062 - val_loss: 0.2658\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9115 - loss: 0.2531 - val_auc: 0.7911 - val_binary_accuracy: 0.9075 - val_loss: 0.2642\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9120 - loss: 0.2511 - val_auc: 0.7925 - val_binary_accuracy: 0.9078 - val_loss: 0.2633\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8077 - binary_accuracy: 0.9122 - loss: 0.2497 - val_auc: 0.7945 - val_binary_accuracy: 0.9084 - val_loss: 0.2617\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9128 - loss: 0.2485 - val_auc: 0.7945 - val_binary_accuracy: 0.9084 - val_loss: 0.2607\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8114 - binary_accuracy: 0.9130 - loss: 0.2476 - val_auc: 0.7954 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9129 - loss: 0.2470 - val_auc: 0.7955 - val_binary_accuracy: 0.9081 - val_loss: 0.2596\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7946 - binary_accuracy: 0.9114 - loss: 0.2515\n",
      "Fold 1 Metrics: Loss = 0.2596, Accuracy = 0.9081, AUC = 0.7955\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5940 - binary_accuracy: 0.8692 - loss: 0.3557 - val_auc: 0.7984 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9033 - loss: 0.2711 - val_auc: 0.8041 - val_binary_accuracy: 0.9044 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9048 - loss: 0.2683 - val_auc: 0.8066 - val_binary_accuracy: 0.9062 - val_loss: 0.2617\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9061 - loss: 0.2657 - val_auc: 0.8072 - val_binary_accuracy: 0.9069 - val_loss: 0.2608\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8071 - val_binary_accuracy: 0.9075 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9081 - loss: 0.2622 - val_auc: 0.8075 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9085 - loss: 0.2611 - val_auc: 0.8068 - val_binary_accuracy: 0.9085 - val_loss: 0.2600\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9088 - loss: 0.2603 - val_auc: 0.8077 - val_binary_accuracy: 0.9087 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9089 - loss: 0.2596 - val_auc: 0.8080 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9091 - loss: 0.2591 - val_auc: 0.8089 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9129 - loss: 0.2485\n",
      "Fold 2 Metrics: Loss = 0.2582, Accuracy = 0.9091, AUC = 0.8089\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6086 - binary_accuracy: 0.8865 - loss: 0.3291 - val_auc: 0.7805 - val_binary_accuracy: 0.9042 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9051 - loss: 0.2737 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9052 - loss: 0.2709 - val_auc: 0.7893 - val_binary_accuracy: 0.9057 - val_loss: 0.2650\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.7923 - val_binary_accuracy: 0.9097 - val_loss: 0.2637\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9076 - loss: 0.2675 - val_auc: 0.7948 - val_binary_accuracy: 0.9102 - val_loss: 0.2625\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9085 - loss: 0.2661 - val_auc: 0.7970 - val_binary_accuracy: 0.9106 - val_loss: 0.2612\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9089 - loss: 0.2650 - val_auc: 0.7995 - val_binary_accuracy: 0.9110 - val_loss: 0.2600\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9093 - loss: 0.2640 - val_auc: 0.8004 - val_binary_accuracy: 0.9109 - val_loss: 0.2589\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9093 - loss: 0.2633 - val_auc: 0.8019 - val_binary_accuracy: 0.9109 - val_loss: 0.2580\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9096 - loss: 0.2628 - val_auc: 0.8033 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7952 - binary_accuracy: 0.9124 - loss: 0.2578\n",
      "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9109, AUC = 0.8033\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5841 - binary_accuracy: 0.8714 - loss: 0.3610 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9055 - loss: 0.2683 - val_auc: 0.7940 - val_binary_accuracy: 0.9070 - val_loss: 0.2619\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9078 - loss: 0.2653 - val_auc: 0.7998 - val_binary_accuracy: 0.9085 - val_loss: 0.2591\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9090 - loss: 0.2630 - val_auc: 0.8024 - val_binary_accuracy: 0.9094 - val_loss: 0.2571\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9099 - loss: 0.2615 - val_auc: 0.8052 - val_binary_accuracy: 0.9082 - val_loss: 0.2561\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9099 - loss: 0.2604 - val_auc: 0.8064 - val_binary_accuracy: 0.9088 - val_loss: 0.2554\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9103 - loss: 0.2597 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9107 - loss: 0.2590 - val_auc: 0.8081 - val_binary_accuracy: 0.9090 - val_loss: 0.2547\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9108 - loss: 0.2585 - val_auc: 0.8087 - val_binary_accuracy: 0.9091 - val_loss: 0.2545\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9108 - loss: 0.2580 - val_auc: 0.8094 - val_binary_accuracy: 0.9091 - val_loss: 0.2543\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7911 - binary_accuracy: 0.9087 - loss: 0.2614\n",
      "Fold 4 Metrics: Loss = 0.2543, Accuracy = 0.9091, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6132 - binary_accuracy: 0.9040 - loss: 0.3212 - val_auc: 0.7890 - val_binary_accuracy: 0.9048 - val_loss: 0.2685\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9041 - loss: 0.2740 - val_auc: 0.7950 - val_binary_accuracy: 0.9078 - val_loss: 0.2656\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9052 - loss: 0.2709 - val_auc: 0.7987 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9073 - loss: 0.2684 - val_auc: 0.8017 - val_binary_accuracy: 0.9076 - val_loss: 0.2627\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9078 - loss: 0.2667 - val_auc: 0.8041 - val_binary_accuracy: 0.9087 - val_loss: 0.2610\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9084 - loss: 0.2653 - val_auc: 0.8053 - val_binary_accuracy: 0.9091 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9089 - loss: 0.2641 - val_auc: 0.8064 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9098 - loss: 0.2631 - val_auc: 0.8077 - val_binary_accuracy: 0.9106 - val_loss: 0.2553\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9096 - loss: 0.2622 - val_auc: 0.8074 - val_binary_accuracy: 0.9112 - val_loss: 0.2541\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9098 - loss: 0.2615 - val_auc: 0.8082 - val_binary_accuracy: 0.9113 - val_loss: 0.2531\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9092 - loss: 0.2512\n",
      "Fold 5 Metrics: Loss = 0.2531, Accuracy = 0.9113, AUC = 0.8082\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2564\n",
      "Average Accuracy: 0.9097\n",
      "Average AUC: 0.8051\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 5, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4973 - binary_accuracy: 0.7440 - loss: 0.5121 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3162\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5044 - binary_accuracy: 0.9069 - loss: 0.3101 - val_auc: 0.4999 - val_binary_accuracy: 0.9044 - val_loss: 0.3150\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5662 - binary_accuracy: 0.9069 - loss: 0.3091 - val_auc: 0.7259 - val_binary_accuracy: 0.9044 - val_loss: 0.3125\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7352 - binary_accuracy: 0.9069 - loss: 0.3041 - val_auc: 0.7583 - val_binary_accuracy: 0.9044 - val_loss: 0.2982\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7614 - binary_accuracy: 0.9069 - loss: 0.2857 - val_auc: 0.7465 - val_binary_accuracy: 0.9044 - val_loss: 0.2798\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.7755 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9069 - loss: 0.2613 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9069 - loss: 0.2595 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9069 - loss: 0.2578 - val_auc: 0.7835 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9069 - loss: 0.2569 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7856 - binary_accuracy: 0.9084 - loss: 0.2585\n",
      "Fold 1 Metrics: Loss = 0.2671, Accuracy = 0.9044, AUC = 0.7839\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5018 - binary_accuracy: 0.9029 - loss: 0.4375 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3155\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5285 - binary_accuracy: 0.9029 - loss: 0.3185 - val_auc: 0.7104 - val_binary_accuracy: 0.9042 - val_loss: 0.3150\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6496 - binary_accuracy: 0.9029 - loss: 0.3174 - val_auc: 0.7353 - val_binary_accuracy: 0.9042 - val_loss: 0.3104\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7362 - binary_accuracy: 0.9029 - loss: 0.3084 - val_auc: 0.7837 - val_binary_accuracy: 0.9042 - val_loss: 0.2815\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9029 - loss: 0.2819 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9029 - loss: 0.2731 - val_auc: 0.7931 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9029 - loss: 0.2711 - val_auc: 0.7961 - val_binary_accuracy: 0.9042 - val_loss: 0.2643\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9029 - loss: 0.2700 - val_auc: 0.7974 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2689 - val_auc: 0.7995 - val_binary_accuracy: 0.9042 - val_loss: 0.2621\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9029 - loss: 0.2681 - val_auc: 0.8006 - val_binary_accuracy: 0.9042 - val_loss: 0.2611\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8018 - binary_accuracy: 0.9092 - loss: 0.2522\n",
      "Fold 2 Metrics: Loss = 0.2611, Accuracy = 0.9042, AUC = 0.8006\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4998 - binary_accuracy: 0.7474 - loss: 0.4956 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3158\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4981 - binary_accuracy: 0.9051 - loss: 0.3138 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3155\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5111 - binary_accuracy: 0.9051 - loss: 0.3136 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3153\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5305 - binary_accuracy: 0.9051 - loss: 0.3133 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3146\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5968 - binary_accuracy: 0.9051 - loss: 0.3124 - val_auc: 0.7238 - val_binary_accuracy: 0.9042 - val_loss: 0.3115\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7208 - binary_accuracy: 0.9051 - loss: 0.3061 - val_auc: 0.7651 - val_binary_accuracy: 0.9042 - val_loss: 0.2848\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7559 - binary_accuracy: 0.9051 - loss: 0.2801 - val_auc: 0.7686 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9051 - loss: 0.2730 - val_auc: 0.7718 - val_binary_accuracy: 0.9042 - val_loss: 0.2725\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7622 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2725\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9051 - loss: 0.2691 - val_auc: 0.7719 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7689 - binary_accuracy: 0.9046 - loss: 0.2724\n",
      "Fold 3 Metrics: Loss = 0.2723, Accuracy = 0.9042, AUC = 0.7719\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4987 - binary_accuracy: 0.9047 - loss: 0.3930 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5932 - binary_accuracy: 0.9047 - loss: 0.3133 - val_auc: 0.7478 - val_binary_accuracy: 0.9044 - val_loss: 0.3086\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7324 - binary_accuracy: 0.9047 - loss: 0.3026 - val_auc: 0.7721 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9047 - loss: 0.2778 - val_auc: 0.7746 - val_binary_accuracy: 0.9044 - val_loss: 0.2757\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9047 - loss: 0.2697 - val_auc: 0.7784 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9047 - loss: 0.2678 - val_auc: 0.7677 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9047 - loss: 0.2673 - val_auc: 0.7790 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7833 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2655 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2678\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9047 - loss: 0.2652 - val_auc: 0.7777 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7564 - binary_accuracy: 0.9049 - loss: 0.2730\n",
      "Fold 4 Metrics: Loss = 0.2683, Accuracy = 0.9044, AUC = 0.7777\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5013 - binary_accuracy: 0.9040 - loss: 0.4339 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3152\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5197 - binary_accuracy: 0.9040 - loss: 0.3159 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6066 - binary_accuracy: 0.9040 - loss: 0.3148 - val_auc: 0.7457 - val_binary_accuracy: 0.9044 - val_loss: 0.3095\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7343 - binary_accuracy: 0.9040 - loss: 0.3048 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2764\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9040 - loss: 0.2780 - val_auc: 0.7844 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9040 - loss: 0.2727 - val_auc: 0.7884 - val_binary_accuracy: 0.9044 - val_loss: 0.2636\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9040 - loss: 0.2714 - val_auc: 0.7879 - val_binary_accuracy: 0.9044 - val_loss: 0.2630\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9040 - loss: 0.2703 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2625\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9040 - loss: 0.2696 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2625\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9040 - loss: 0.2692 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2619\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8004 - binary_accuracy: 0.9013 - loss: 0.2606\n",
      "Fold 5 Metrics: Loss = 0.2619, Accuracy = 0.9044, AUC = 0.7917\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2662\n",
      "Average Accuracy: 0.9043\n",
      "Average AUC: 0.7852\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 5, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5026 - binary_accuracy: 0.9069 - loss: 0.3597 - val_auc: 0.6572 - val_binary_accuracy: 0.9044 - val_loss: 0.3142\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6451 - binary_accuracy: 0.9069 - loss: 0.3047 - val_auc: 0.7599 - val_binary_accuracy: 0.9044 - val_loss: 0.2794\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.7708 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9069 - loss: 0.2602 - val_auc: 0.7748 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9069 - loss: 0.2587 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9069 - loss: 0.2579 - val_auc: 0.7780 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9069 - loss: 0.2572 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9069 - loss: 0.2566 - val_auc: 0.7803 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9069 - loss: 0.2560 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9069 - loss: 0.2551 - val_auc: 0.7861 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7829 - binary_accuracy: 0.9084 - loss: 0.2585\n",
      "Fold 1 Metrics: Loss = 0.2649, Accuracy = 0.9044, AUC = 0.7861\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5047 - binary_accuracy: 0.9029 - loss: 0.3619 - val_auc: 0.7054 - val_binary_accuracy: 0.9042 - val_loss: 0.3143\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6909 - binary_accuracy: 0.9029 - loss: 0.3084 - val_auc: 0.7925 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9029 - loss: 0.2722 - val_auc: 0.7999 - val_binary_accuracy: 0.9042 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9029 - loss: 0.2690 - val_auc: 0.8028 - val_binary_accuracy: 0.9042 - val_loss: 0.2633\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9029 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9042 - val_loss: 0.2633\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9029 - loss: 0.2669 - val_auc: 0.8054 - val_binary_accuracy: 0.9042 - val_loss: 0.2627\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9029 - loss: 0.2664 - val_auc: 0.8052 - val_binary_accuracy: 0.9042 - val_loss: 0.2626\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7906 - binary_accuracy: 0.9035 - loss: 0.2658 - val_auc: 0.8054 - val_binary_accuracy: 0.9042 - val_loss: 0.2625\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9049 - loss: 0.2650 - val_auc: 0.8058 - val_binary_accuracy: 0.9050 - val_loss: 0.2620\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9062 - loss: 0.2642 - val_auc: 0.8061 - val_binary_accuracy: 0.9062 - val_loss: 0.2615\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8058 - binary_accuracy: 0.9101 - loss: 0.2528\n",
      "Fold 2 Metrics: Loss = 0.2615, Accuracy = 0.9062, AUC = 0.8061\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5010 - binary_accuracy: 0.7300 - loss: 0.4890 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3154\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5254 - binary_accuracy: 0.9051 - loss: 0.3129 - val_auc: 0.7501 - val_binary_accuracy: 0.9042 - val_loss: 0.3068\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7356 - binary_accuracy: 0.9051 - loss: 0.2949 - val_auc: 0.7756 - val_binary_accuracy: 0.9042 - val_loss: 0.2748\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9051 - loss: 0.2704 - val_auc: 0.7812 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9051 - loss: 0.2673 - val_auc: 0.7856 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2676\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9051 - loss: 0.2654 - val_auc: 0.7883 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9051 - loss: 0.2651 - val_auc: 0.7908 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9052 - loss: 0.2643 - val_auc: 0.7913 - val_binary_accuracy: 0.9063 - val_loss: 0.2643\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9062 - loss: 0.2637 - val_auc: 0.7925 - val_binary_accuracy: 0.9100 - val_loss: 0.2632\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7864 - binary_accuracy: 0.9103 - loss: 0.2638\n",
      "Fold 3 Metrics: Loss = 0.2632, Accuracy = 0.9100, AUC = 0.7925\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4988 - binary_accuracy: 0.8179 - loss: 0.4269 - val_auc: 0.6953 - val_binary_accuracy: 0.9044 - val_loss: 0.3144\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6380 - binary_accuracy: 0.9047 - loss: 0.3116 - val_auc: 0.7670 - val_binary_accuracy: 0.9044 - val_loss: 0.2962\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7441 - binary_accuracy: 0.9047 - loss: 0.2865 - val_auc: 0.7732 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9047 - loss: 0.2683 - val_auc: 0.7796 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9047 - loss: 0.2664 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9050 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9045 - val_loss: 0.2640\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9076 - loss: 0.2622 - val_auc: 0.7892 - val_binary_accuracy: 0.9073 - val_loss: 0.2642\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9091 - loss: 0.2608 - val_auc: 0.7937 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9097 - loss: 0.2598 - val_auc: 0.7958 - val_binary_accuracy: 0.9082 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.7973 - val_binary_accuracy: 0.9088 - val_loss: 0.2603\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7782 - binary_accuracy: 0.9085 - loss: 0.2655\n",
      "Fold 4 Metrics: Loss = 0.2603, Accuracy = 0.9088, AUC = 0.7973\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5080 - binary_accuracy: 0.7764 - loss: 0.4473 - val_auc: 0.6901 - val_binary_accuracy: 0.9044 - val_loss: 0.3133\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6971 - binary_accuracy: 0.9040 - loss: 0.3102 - val_auc: 0.7698 - val_binary_accuracy: 0.9044 - val_loss: 0.2806\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7589 - binary_accuracy: 0.9040 - loss: 0.2803 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2645\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9040 - loss: 0.2713 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9040 - loss: 0.2694 - val_auc: 0.7942 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9040 - loss: 0.2682 - val_auc: 0.7950 - val_binary_accuracy: 0.9044 - val_loss: 0.2599\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9040 - loss: 0.2674 - val_auc: 0.7961 - val_binary_accuracy: 0.9044 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9040 - loss: 0.2667 - val_auc: 0.7972 - val_binary_accuracy: 0.9044 - val_loss: 0.2589\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9040 - loss: 0.2659 - val_auc: 0.7993 - val_binary_accuracy: 0.9044 - val_loss: 0.2581\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9044 - loss: 0.2653 - val_auc: 0.7986 - val_binary_accuracy: 0.9081 - val_loss: 0.2576\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8077 - binary_accuracy: 0.9069 - loss: 0.2551\n",
      "Fold 5 Metrics: Loss = 0.2576, Accuracy = 0.9081, AUC = 0.7986\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2615\n",
      "Average Accuracy: 0.9075\n",
      "Average AUC: 0.7961\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 5, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5420 - binary_accuracy: 0.9069 - loss: 0.3254 - val_auc: 0.7619 - val_binary_accuracy: 0.9044 - val_loss: 0.2807\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9069 - loss: 0.2660 - val_auc: 0.7734 - val_binary_accuracy: 0.9044 - val_loss: 0.2726\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9069 - loss: 0.2603 - val_auc: 0.7774 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9069 - loss: 0.2581 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9071 - loss: 0.2562 - val_auc: 0.7832 - val_binary_accuracy: 0.9056 - val_loss: 0.2658\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8002 - binary_accuracy: 0.9091 - loss: 0.2545 - val_auc: 0.7851 - val_binary_accuracy: 0.9078 - val_loss: 0.2641\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9118 - loss: 0.2532 - val_auc: 0.7867 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9122 - loss: 0.2518 - val_auc: 0.7875 - val_binary_accuracy: 0.9090 - val_loss: 0.2609\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9129 - loss: 0.2507 - val_auc: 0.7894 - val_binary_accuracy: 0.9091 - val_loss: 0.2602\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9132 - loss: 0.2496 - val_auc: 0.7899 - val_binary_accuracy: 0.9088 - val_loss: 0.2597\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7861 - binary_accuracy: 0.9128 - loss: 0.2532\n",
      "Fold 1 Metrics: Loss = 0.2597, Accuracy = 0.9088, AUC = 0.7899\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5275 - binary_accuracy: 0.8436 - loss: 0.3803 - val_auc: 0.7777 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9029 - loss: 0.2805 - val_auc: 0.7999 - val_binary_accuracy: 0.9042 - val_loss: 0.2628\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2687 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2598\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9031 - loss: 0.2663 - val_auc: 0.8063 - val_binary_accuracy: 0.9042 - val_loss: 0.2588\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9057 - loss: 0.2644 - val_auc: 0.8079 - val_binary_accuracy: 0.9066 - val_loss: 0.2587\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9068 - loss: 0.2629 - val_auc: 0.8081 - val_binary_accuracy: 0.9075 - val_loss: 0.2586\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9076 - loss: 0.2617 - val_auc: 0.8057 - val_binary_accuracy: 0.9072 - val_loss: 0.2591\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9083 - loss: 0.2609 - val_auc: 0.8058 - val_binary_accuracy: 0.9072 - val_loss: 0.2594\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9083 - loss: 0.2603 - val_auc: 0.8066 - val_binary_accuracy: 0.9075 - val_loss: 0.2598\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9084 - loss: 0.2597 - val_auc: 0.8069 - val_binary_accuracy: 0.9082 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9128 - loss: 0.2491\n",
      "Fold 2 Metrics: Loss = 0.2599, Accuracy = 0.9082, AUC = 0.8069\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5089 - binary_accuracy: 0.7474 - loss: 0.4985 - val_auc: 0.7218 - val_binary_accuracy: 0.9042 - val_loss: 0.3102\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7207 - binary_accuracy: 0.9051 - loss: 0.2970 - val_auc: 0.7743 - val_binary_accuracy: 0.9042 - val_loss: 0.2752\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9051 - loss: 0.2705 - val_auc: 0.7817 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7897 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9059 - loss: 0.2653 - val_auc: 0.7896 - val_binary_accuracy: 0.9097 - val_loss: 0.2642\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.7916 - val_binary_accuracy: 0.9099 - val_loss: 0.2625\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9088 - loss: 0.2635 - val_auc: 0.7947 - val_binary_accuracy: 0.9104 - val_loss: 0.2607\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7970 - val_binary_accuracy: 0.9112 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9090 - loss: 0.2620 - val_auc: 0.7987 - val_binary_accuracy: 0.9116 - val_loss: 0.2582\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9134 - loss: 0.2586\n",
      "Fold 3 Metrics: Loss = 0.2582, Accuracy = 0.9116, AUC = 0.7987\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5045 - binary_accuracy: 0.9047 - loss: 0.3483 - val_auc: 0.7596 - val_binary_accuracy: 0.9044 - val_loss: 0.2908\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7565 - binary_accuracy: 0.9047 - loss: 0.2779 - val_auc: 0.7874 - val_binary_accuracy: 0.9044 - val_loss: 0.2658\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9047 - loss: 0.2657 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2642\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9049 - loss: 0.2636 - val_auc: 0.7943 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9064 - loss: 0.2620 - val_auc: 0.7993 - val_binary_accuracy: 0.9066 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9089 - loss: 0.2606 - val_auc: 0.8023 - val_binary_accuracy: 0.9082 - val_loss: 0.2580\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9098 - loss: 0.2597 - val_auc: 0.8035 - val_binary_accuracy: 0.9085 - val_loss: 0.2568\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9093 - loss: 0.2589 - val_auc: 0.8057 - val_binary_accuracy: 0.9087 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9098 - loss: 0.2586 - val_auc: 0.8056 - val_binary_accuracy: 0.9088 - val_loss: 0.2560\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9102 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9091 - val_loss: 0.2557\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9087 - loss: 0.2614\n",
      "Fold 4 Metrics: Loss = 0.2557, Accuracy = 0.9091, AUC = 0.8071\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5529 - binary_accuracy: 0.9040 - loss: 0.3187 - val_auc: 0.7836 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.7918 - val_binary_accuracy: 0.9044 - val_loss: 0.2614\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9040 - loss: 0.2702 - val_auc: 0.7938 - val_binary_accuracy: 0.9045 - val_loss: 0.2605\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9047 - loss: 0.2684 - val_auc: 0.7953 - val_binary_accuracy: 0.9079 - val_loss: 0.2590\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9073 - loss: 0.2670 - val_auc: 0.7974 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9083 - loss: 0.2658 - val_auc: 0.7999 - val_binary_accuracy: 0.9091 - val_loss: 0.2565\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9083 - loss: 0.2648 - val_auc: 0.8004 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8026 - val_binary_accuracy: 0.9091 - val_loss: 0.2548\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9089 - loss: 0.2631 - val_auc: 0.8036 - val_binary_accuracy: 0.9098 - val_loss: 0.2541\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8037 - val_binary_accuracy: 0.9103 - val_loss: 0.2536\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8138 - binary_accuracy: 0.9081 - loss: 0.2509\n",
      "Fold 5 Metrics: Loss = 0.2536, Accuracy = 0.9103, AUC = 0.8037\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2574\n",
      "Average Accuracy: 0.9096\n",
      "Average AUC: 0.8013\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 5, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5788 - binary_accuracy: 0.8757 - loss: 0.3350 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9069 - loss: 0.2623 - val_auc: 0.7760 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9069 - loss: 0.2591 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9071 - loss: 0.2567 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9089 - loss: 0.2543 - val_auc: 0.7881 - val_binary_accuracy: 0.9065 - val_loss: 0.2633\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8040 - binary_accuracy: 0.9113 - loss: 0.2522 - val_auc: 0.7906 - val_binary_accuracy: 0.9079 - val_loss: 0.2618\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9121 - loss: 0.2505 - val_auc: 0.7912 - val_binary_accuracy: 0.9087 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8085 - binary_accuracy: 0.9120 - loss: 0.2494 - val_auc: 0.7919 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8105 - binary_accuracy: 0.9127 - loss: 0.2484 - val_auc: 0.7918 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8116 - binary_accuracy: 0.9131 - loss: 0.2476 - val_auc: 0.7925 - val_binary_accuracy: 0.9090 - val_loss: 0.2592\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7916 - binary_accuracy: 0.9130 - loss: 0.2516\n",
      "Fold 1 Metrics: Loss = 0.2592, Accuracy = 0.9090, AUC = 0.7925\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5215 - binary_accuracy: 0.8554 - loss: 0.3773 - val_auc: 0.7895 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9029 - loss: 0.2742 - val_auc: 0.7998 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8044 - val_binary_accuracy: 0.9042 - val_loss: 0.2604\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9030 - loss: 0.2676 - val_auc: 0.8065 - val_binary_accuracy: 0.9042 - val_loss: 0.2592\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9052 - loss: 0.2652 - val_auc: 0.8082 - val_binary_accuracy: 0.9062 - val_loss: 0.2580\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9064 - loss: 0.2632 - val_auc: 0.8087 - val_binary_accuracy: 0.9075 - val_loss: 0.2570\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9075 - loss: 0.2616 - val_auc: 0.8086 - val_binary_accuracy: 0.9078 - val_loss: 0.2564\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9081 - loss: 0.2606 - val_auc: 0.8084 - val_binary_accuracy: 0.9078 - val_loss: 0.2559\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9080 - loss: 0.2598 - val_auc: 0.8092 - val_binary_accuracy: 0.9084 - val_loss: 0.2555\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9084 - loss: 0.2592 - val_auc: 0.8089 - val_binary_accuracy: 0.9084 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9123 - loss: 0.2447\n",
      "Fold 2 Metrics: Loss = 0.2551, Accuracy = 0.9084, AUC = 0.8089\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5237 - binary_accuracy: 0.8325 - loss: 0.4001 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2727\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7596 - binary_accuracy: 0.9051 - loss: 0.2740 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2702 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2665\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9053 - loss: 0.2684 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9068 - loss: 0.2673 - val_auc: 0.7928 - val_binary_accuracy: 0.9100 - val_loss: 0.2627\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7952 - val_binary_accuracy: 0.9103 - val_loss: 0.2610\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9083 - loss: 0.2653 - val_auc: 0.7984 - val_binary_accuracy: 0.9110 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9085 - loss: 0.2646 - val_auc: 0.8002 - val_binary_accuracy: 0.9113 - val_loss: 0.2585\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8018 - val_binary_accuracy: 0.9112 - val_loss: 0.2576\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9089 - loss: 0.2632 - val_auc: 0.8034 - val_binary_accuracy: 0.9112 - val_loss: 0.2570\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7960 - binary_accuracy: 0.9128 - loss: 0.2577\n",
      "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9112, AUC = 0.8034\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5373 - binary_accuracy: 0.8714 - loss: 0.3583 - val_auc: 0.7820 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9047 - loss: 0.2687 - val_auc: 0.7899 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9065 - loss: 0.2651 - val_auc: 0.7940 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9094 - loss: 0.2631 - val_auc: 0.7965 - val_binary_accuracy: 0.9090 - val_loss: 0.2596\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.7982 - val_binary_accuracy: 0.9093 - val_loss: 0.2586\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9099 - loss: 0.2606 - val_auc: 0.8004 - val_binary_accuracy: 0.9097 - val_loss: 0.2578\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9106 - loss: 0.2599 - val_auc: 0.8022 - val_binary_accuracy: 0.9095 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9106 - loss: 0.2593 - val_auc: 0.8034 - val_binary_accuracy: 0.9098 - val_loss: 0.2566\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9110 - loss: 0.2589 - val_auc: 0.8048 - val_binary_accuracy: 0.9095 - val_loss: 0.2562\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9112 - loss: 0.2584 - val_auc: 0.8057 - val_binary_accuracy: 0.9097 - val_loss: 0.2557\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7869 - binary_accuracy: 0.9091 - loss: 0.2618\n",
      "Fold 4 Metrics: Loss = 0.2557, Accuracy = 0.9097, AUC = 0.8057\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5867 - binary_accuracy: 0.9040 - loss: 0.3168 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9041 - loss: 0.2742 - val_auc: 0.7943 - val_binary_accuracy: 0.9073 - val_loss: 0.2612\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9042 - loss: 0.2710 - val_auc: 0.7981 - val_binary_accuracy: 0.9069 - val_loss: 0.2596\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9065 - loss: 0.2689 - val_auc: 0.8007 - val_binary_accuracy: 0.9091 - val_loss: 0.2583\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9083 - loss: 0.2673 - val_auc: 0.8028 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9082 - loss: 0.2659 - val_auc: 0.8045 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9090 - loss: 0.2647 - val_auc: 0.8057 - val_binary_accuracy: 0.9106 - val_loss: 0.2546\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.8075 - val_binary_accuracy: 0.9110 - val_loss: 0.2534\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9094 - loss: 0.2629 - val_auc: 0.8077 - val_binary_accuracy: 0.9115 - val_loss: 0.2524\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9095 - loss: 0.2620 - val_auc: 0.8085 - val_binary_accuracy: 0.9121 - val_loss: 0.2518\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9102 - loss: 0.2490\n",
      "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9121, AUC = 0.8085\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2558\n",
      "Average Accuracy: 0.9101\n",
      "Average AUC: 0.8038\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 5, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5900 - binary_accuracy: 0.8901 - loss: 0.3228 - val_auc: 0.7708 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2701\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2596 - val_auc: 0.7834 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9072 - loss: 0.2571 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9102 - loss: 0.2549 - val_auc: 0.7906 - val_binary_accuracy: 0.9065 - val_loss: 0.2654\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9115 - loss: 0.2530 - val_auc: 0.7923 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8049 - binary_accuracy: 0.9119 - loss: 0.2514 - val_auc: 0.7938 - val_binary_accuracy: 0.9088 - val_loss: 0.2632\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9124 - loss: 0.2502 - val_auc: 0.7938 - val_binary_accuracy: 0.9087 - val_loss: 0.2623\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9131 - loss: 0.2493 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2613\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9128 - loss: 0.2484 - val_auc: 0.7945 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7941 - binary_accuracy: 0.9117 - loss: 0.2521\n",
      "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9085, AUC = 0.7945\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5756 - binary_accuracy: 0.8847 - loss: 0.3358 - val_auc: 0.7968 - val_binary_accuracy: 0.9042 - val_loss: 0.2679\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.8036 - val_binary_accuracy: 0.9042 - val_loss: 0.2654\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9041 - loss: 0.2690 - val_auc: 0.8057 - val_binary_accuracy: 0.9047 - val_loss: 0.2633\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9062 - loss: 0.2658 - val_auc: 0.8066 - val_binary_accuracy: 0.9066 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9066 - loss: 0.2637 - val_auc: 0.8076 - val_binary_accuracy: 0.9068 - val_loss: 0.2605\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9075 - loss: 0.2621 - val_auc: 0.8079 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9077 - loss: 0.2610 - val_auc: 0.8076 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9080 - loss: 0.2603 - val_auc: 0.8082 - val_binary_accuracy: 0.9079 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8012 - binary_accuracy: 0.9078 - loss: 0.2597 - val_auc: 0.8088 - val_binary_accuracy: 0.9079 - val_loss: 0.2595\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9080 - loss: 0.2593 - val_auc: 0.8085 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9116 - loss: 0.2494\n",
      "Fold 2 Metrics: Loss = 0.2590, Accuracy = 0.9078, AUC = 0.8085\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - auc: 0.5779 - binary_accuracy: 0.8865 - loss: 0.3352 - val_auc: 0.7785 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7545 - binary_accuracy: 0.9051 - loss: 0.2757 - val_auc: 0.7834 - val_binary_accuracy: 0.9042 - val_loss: 0.2678\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9051 - loss: 0.2719 - val_auc: 0.7873 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9051 - loss: 0.2700 - val_auc: 0.7896 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9054 - loss: 0.2687 - val_auc: 0.7923 - val_binary_accuracy: 0.9090 - val_loss: 0.2638\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9068 - loss: 0.2675 - val_auc: 0.7952 - val_binary_accuracy: 0.9099 - val_loss: 0.2624\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9082 - loss: 0.2664 - val_auc: 0.7980 - val_binary_accuracy: 0.9109 - val_loss: 0.2612\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9087 - loss: 0.2653 - val_auc: 0.7999 - val_binary_accuracy: 0.9107 - val_loss: 0.2601\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9091 - loss: 0.2644 - val_auc: 0.8019 - val_binary_accuracy: 0.9107 - val_loss: 0.2591\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8037 - val_binary_accuracy: 0.9112 - val_loss: 0.2580\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9126 - loss: 0.2589\n",
      "Fold 3 Metrics: Loss = 0.2580, Accuracy = 0.9112, AUC = 0.8037\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5519 - binary_accuracy: 0.8866 - loss: 0.3507 - val_auc: 0.7860 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9047 - loss: 0.2698 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2636\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9054 - loss: 0.2668 - val_auc: 0.7966 - val_binary_accuracy: 0.9081 - val_loss: 0.2608\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9080 - loss: 0.2648 - val_auc: 0.7992 - val_binary_accuracy: 0.9094 - val_loss: 0.2593\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8004 - val_binary_accuracy: 0.9090 - val_loss: 0.2582\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9098 - loss: 0.2620 - val_auc: 0.8016 - val_binary_accuracy: 0.9090 - val_loss: 0.2577\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9104 - loss: 0.2611 - val_auc: 0.8030 - val_binary_accuracy: 0.9084 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9107 - loss: 0.2603 - val_auc: 0.8049 - val_binary_accuracy: 0.9091 - val_loss: 0.2563\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9109 - loss: 0.2596 - val_auc: 0.8061 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9112 - loss: 0.2591 - val_auc: 0.8070 - val_binary_accuracy: 0.9093 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9092 - loss: 0.2622\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9093, AUC = 0.8070\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5931 - binary_accuracy: 0.9040 - loss: 0.3197 - val_auc: 0.7878 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9040 - loss: 0.2748 - val_auc: 0.7934 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9041 - loss: 0.2720 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2633\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9048 - loss: 0.2699 - val_auc: 0.7999 - val_binary_accuracy: 0.9093 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9070 - loss: 0.2679 - val_auc: 0.8018 - val_binary_accuracy: 0.9091 - val_loss: 0.2620\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9085 - loss: 0.2664 - val_auc: 0.8035 - val_binary_accuracy: 0.9097 - val_loss: 0.2618\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9081 - loss: 0.2652 - val_auc: 0.8056 - val_binary_accuracy: 0.9097 - val_loss: 0.2613\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9090 - loss: 0.2642 - val_auc: 0.8070 - val_binary_accuracy: 0.9101 - val_loss: 0.2605\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9092 - loss: 0.2633 - val_auc: 0.8072 - val_binary_accuracy: 0.9097 - val_loss: 0.2595\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9093 - loss: 0.2627 - val_auc: 0.8085 - val_binary_accuracy: 0.9103 - val_loss: 0.2583\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8171 - binary_accuracy: 0.9119 - loss: 0.2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 67%|   | 2/3 [55:17<27:40, 1660.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Metrics: Loss = 0.2583, Accuracy = 0.9103, AUC = 0.8085\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2582\n",
      "Average Accuracy: 0.9094\n",
      "Average AUC: 0.8044\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 1, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5266 - binary_accuracy: 0.6977 - loss: 0.5188 - val_auc: 0.6882 - val_binary_accuracy: 0.9041 - val_loss: 0.2958\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7066 - binary_accuracy: 0.9069 - loss: 0.2843 - val_auc: 0.7156 - val_binary_accuracy: 0.9044 - val_loss: 0.2857\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7444 - binary_accuracy: 0.9069 - loss: 0.2756 - val_auc: 0.7374 - val_binary_accuracy: 0.9042 - val_loss: 0.2824\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7606 - binary_accuracy: 0.9069 - loss: 0.2714 - val_auc: 0.7393 - val_binary_accuracy: 0.9044 - val_loss: 0.2792\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9069 - loss: 0.2688 - val_auc: 0.7333 - val_binary_accuracy: 0.9044 - val_loss: 0.2777\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7395 - val_binary_accuracy: 0.9044 - val_loss: 0.2770\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9069 - loss: 0.2660 - val_auc: 0.7345 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9069 - loss: 0.2652 - val_auc: 0.7471 - val_binary_accuracy: 0.9041 - val_loss: 0.2758\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9069 - loss: 0.2645 - val_auc: 0.7442 - val_binary_accuracy: 0.9041 - val_loss: 0.2753\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9069 - loss: 0.2639 - val_auc: 0.7444 - val_binary_accuracy: 0.9041 - val_loss: 0.2749\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7428 - binary_accuracy: 0.9081 - loss: 0.2662\n",
      "Fold 1 Metrics: Loss = 0.2749, Accuracy = 0.9041, AUC = 0.7444\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5584 - binary_accuracy: 0.7373 - loss: 0.5031 - val_auc: 0.7282 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7379 - binary_accuracy: 0.9029 - loss: 0.2878 - val_auc: 0.7527 - val_binary_accuracy: 0.9042 - val_loss: 0.2819\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7542 - binary_accuracy: 0.9029 - loss: 0.2822 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7659 - binary_accuracy: 0.9029 - loss: 0.2775 - val_auc: 0.7833 - val_binary_accuracy: 0.9042 - val_loss: 0.2716\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2734 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7802 - binary_accuracy: 0.9029 - loss: 0.2704 - val_auc: 0.7926 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2685 - val_auc: 0.7953 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7872 - binary_accuracy: 0.9043 - loss: 0.2676 - val_auc: 0.7943 - val_binary_accuracy: 0.9053 - val_loss: 0.2657\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9072 - loss: 0.2666 - val_auc: 0.7934 - val_binary_accuracy: 0.9065 - val_loss: 0.2658\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7911 - val_binary_accuracy: 0.9076 - val_loss: 0.2662\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9112 - loss: 0.2568\n",
      "Fold 2 Metrics: Loss = 0.2662, Accuracy = 0.9076, AUC = 0.7911\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5662 - binary_accuracy: 0.8890 - loss: 0.3588 - val_auc: 0.7475 - val_binary_accuracy: 0.9042 - val_loss: 0.2856\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7347 - binary_accuracy: 0.9051 - loss: 0.2849 - val_auc: 0.7552 - val_binary_accuracy: 0.9042 - val_loss: 0.2783\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7453 - binary_accuracy: 0.9051 - loss: 0.2784 - val_auc: 0.7623 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7551 - binary_accuracy: 0.9051 - loss: 0.2734 - val_auc: 0.7645 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7613 - binary_accuracy: 0.9051 - loss: 0.2702 - val_auc: 0.7666 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7656 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7695 - val_binary_accuracy: 0.9042 - val_loss: 0.2701\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2667 - val_auc: 0.7708 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9051 - loss: 0.2656 - val_auc: 0.7716 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9051 - loss: 0.2645 - val_auc: 0.7711 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9051 - loss: 0.2637 - val_auc: 0.7710 - val_binary_accuracy: 0.9042 - val_loss: 0.2683\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7722 - binary_accuracy: 0.9046 - loss: 0.2666\n",
      "Fold 3 Metrics: Loss = 0.2683, Accuracy = 0.9042, AUC = 0.7710\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6024 - binary_accuracy: 0.9021 - loss: 0.3401 - val_auc: 0.7602 - val_binary_accuracy: 0.9044 - val_loss: 0.2823\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7582 - binary_accuracy: 0.9047 - loss: 0.2790 - val_auc: 0.7630 - val_binary_accuracy: 0.9044 - val_loss: 0.2767\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9047 - loss: 0.2731 - val_auc: 0.7760 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9047 - loss: 0.2720 - val_auc: 0.7770 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7708 - binary_accuracy: 0.9047 - loss: 0.2704 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7707 - binary_accuracy: 0.9047 - loss: 0.2693 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9047 - loss: 0.2689 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2709\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9047 - loss: 0.2682 - val_auc: 0.7795 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9048 - loss: 0.2670 - val_auc: 0.7808 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9074 - loss: 0.2667 - val_auc: 0.7824 - val_binary_accuracy: 0.9048 - val_loss: 0.2698\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7642 - binary_accuracy: 0.9049 - loss: 0.2719\n",
      "Fold 4 Metrics: Loss = 0.2698, Accuracy = 0.9048, AUC = 0.7824\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5597 - binary_accuracy: 0.8180 - loss: 0.4326 - val_auc: 0.7197 - val_binary_accuracy: 0.9044 - val_loss: 0.2887\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7302 - binary_accuracy: 0.9040 - loss: 0.2872 - val_auc: 0.7675 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9040 - loss: 0.2770 - val_auc: 0.7802 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9040 - loss: 0.2736 - val_auc: 0.7830 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9049 - loss: 0.2708 - val_auc: 0.7877 - val_binary_accuracy: 0.9060 - val_loss: 0.2647\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9062 - loss: 0.2690 - val_auc: 0.7919 - val_binary_accuracy: 0.9075 - val_loss: 0.2610\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9074 - loss: 0.2680 - val_auc: 0.7888 - val_binary_accuracy: 0.9078 - val_loss: 0.2629\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9072 - loss: 0.2666 - val_auc: 0.7949 - val_binary_accuracy: 0.9094 - val_loss: 0.2591\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9082 - loss: 0.2663 - val_auc: 0.7945 - val_binary_accuracy: 0.9097 - val_loss: 0.2593\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9084 - loss: 0.2655 - val_auc: 0.7912 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8006 - binary_accuracy: 0.9073 - loss: 0.2610\n",
      "Fold 5 Metrics: Loss = 0.2611, Accuracy = 0.9094, AUC = 0.7912\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2680\n",
      "Average Accuracy: 0.9060\n",
      "Average AUC: 0.7760\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 1, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6618 - binary_accuracy: 0.7700 - loss: 0.4375 - val_auc: 0.7479 - val_binary_accuracy: 0.9044 - val_loss: 0.2784\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9069 - loss: 0.2648 - val_auc: 0.7617 - val_binary_accuracy: 0.9068 - val_loss: 0.2727\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9091 - loss: 0.2596 - val_auc: 0.7696 - val_binary_accuracy: 0.9079 - val_loss: 0.2694\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9095 - loss: 0.2574 - val_auc: 0.7734 - val_binary_accuracy: 0.9081 - val_loss: 0.2678\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9104 - loss: 0.2564 - val_auc: 0.7732 - val_binary_accuracy: 0.9087 - val_loss: 0.2672\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9107 - loss: 0.2558 - val_auc: 0.7736 - val_binary_accuracy: 0.9090 - val_loss: 0.2666\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9107 - loss: 0.2551 - val_auc: 0.7745 - val_binary_accuracy: 0.9088 - val_loss: 0.2660\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7958 - binary_accuracy: 0.9107 - loss: 0.2548 - val_auc: 0.7762 - val_binary_accuracy: 0.9091 - val_loss: 0.2655\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9113 - loss: 0.2546 - val_auc: 0.7766 - val_binary_accuracy: 0.9091 - val_loss: 0.2650\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9121 - loss: 0.2540 - val_auc: 0.7768 - val_binary_accuracy: 0.9093 - val_loss: 0.2646\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7754 - binary_accuracy: 0.9131 - loss: 0.2572\n",
      "Fold 1 Metrics: Loss = 0.2646, Accuracy = 0.9093, AUC = 0.7768\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6894 - binary_accuracy: 0.9016 - loss: 0.3190 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7709 - binary_accuracy: 0.9029 - loss: 0.2740 - val_auc: 0.7883 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9037 - loss: 0.2711 - val_auc: 0.7929 - val_binary_accuracy: 0.9042 - val_loss: 0.2669\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9057 - loss: 0.2695 - val_auc: 0.7960 - val_binary_accuracy: 0.9050 - val_loss: 0.2655\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9069 - loss: 0.2677 - val_auc: 0.7993 - val_binary_accuracy: 0.9056 - val_loss: 0.2648\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9070 - loss: 0.2667 - val_auc: 0.8006 - val_binary_accuracy: 0.9065 - val_loss: 0.2644\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9062 - loss: 0.2661 - val_auc: 0.8025 - val_binary_accuracy: 0.9065 - val_loss: 0.2614\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9066 - loss: 0.2653 - val_auc: 0.8017 - val_binary_accuracy: 0.9071 - val_loss: 0.2617\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9068 - loss: 0.2647 - val_auc: 0.8018 - val_binary_accuracy: 0.9078 - val_loss: 0.2604\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9070 - loss: 0.2630 - val_auc: 0.8031 - val_binary_accuracy: 0.9078 - val_loss: 0.2610\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8067 - binary_accuracy: 0.9119 - loss: 0.2508\n",
      "Fold 2 Metrics: Loss = 0.2610, Accuracy = 0.9078, AUC = 0.8031\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6874 - binary_accuracy: 0.8978 - loss: 0.3120 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2732\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7691 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7731 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7778 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9051 - loss: 0.2667 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7767 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7801 - val_binary_accuracy: 0.9047 - val_loss: 0.2676\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7792 - binary_accuracy: 0.9063 - loss: 0.2644 - val_auc: 0.7807 - val_binary_accuracy: 0.9069 - val_loss: 0.2670\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7811 - binary_accuracy: 0.9069 - loss: 0.2635 - val_auc: 0.7826 - val_binary_accuracy: 0.9075 - val_loss: 0.2663\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9071 - loss: 0.2626 - val_auc: 0.7835 - val_binary_accuracy: 0.9081 - val_loss: 0.2658\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7845 - binary_accuracy: 0.9075 - loss: 0.2619 - val_auc: 0.7850 - val_binary_accuracy: 0.9087 - val_loss: 0.2658\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7841 - binary_accuracy: 0.9077 - loss: 0.2616 - val_auc: 0.7867 - val_binary_accuracy: 0.9087 - val_loss: 0.2646\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7809 - binary_accuracy: 0.9096 - loss: 0.2653\n",
      "Fold 3 Metrics: Loss = 0.2646, Accuracy = 0.9087, AUC = 0.7867\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6057 - binary_accuracy: 0.6792 - loss: 0.5916 - val_auc: 0.7379 - val_binary_accuracy: 0.9044 - val_loss: 0.2846\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7347 - binary_accuracy: 0.9047 - loss: 0.2840 - val_auc: 0.7619 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7603 - binary_accuracy: 0.9048 - loss: 0.2746 - val_auc: 0.7738 - val_binary_accuracy: 0.9053 - val_loss: 0.2711\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7704 - binary_accuracy: 0.9059 - loss: 0.2706 - val_auc: 0.7752 - val_binary_accuracy: 0.9050 - val_loss: 0.2708\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7742 - binary_accuracy: 0.9068 - loss: 0.2688 - val_auc: 0.7797 - val_binary_accuracy: 0.9059 - val_loss: 0.2690\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7792 - binary_accuracy: 0.9080 - loss: 0.2661 - val_auc: 0.7833 - val_binary_accuracy: 0.9072 - val_loss: 0.2668\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9075 - loss: 0.2648 - val_auc: 0.7847 - val_binary_accuracy: 0.9085 - val_loss: 0.2656\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.7862 - val_binary_accuracy: 0.9081 - val_loss: 0.2653\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9091 - loss: 0.2630 - val_auc: 0.7871 - val_binary_accuracy: 0.9082 - val_loss: 0.2657\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9091 - loss: 0.2625 - val_auc: 0.7867 - val_binary_accuracy: 0.9082 - val_loss: 0.2664\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7648 - binary_accuracy: 0.9080 - loss: 0.2720\n",
      "Fold 4 Metrics: Loss = 0.2664, Accuracy = 0.9082, AUC = 0.7867\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6366 - binary_accuracy: 0.8897 - loss: 0.3399 - val_auc: 0.7799 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7812 - val_binary_accuracy: 0.9044 - val_loss: 0.2659\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7665 - binary_accuracy: 0.9043 - loss: 0.2737 - val_auc: 0.7878 - val_binary_accuracy: 0.9048 - val_loss: 0.2625\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7714 - binary_accuracy: 0.9061 - loss: 0.2713 - val_auc: 0.7884 - val_binary_accuracy: 0.9054 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7717 - binary_accuracy: 0.9065 - loss: 0.2710 - val_auc: 0.7891 - val_binary_accuracy: 0.9057 - val_loss: 0.2612\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2707 - val_auc: 0.7896 - val_binary_accuracy: 0.9066 - val_loss: 0.2603\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9072 - loss: 0.2694 - val_auc: 0.7900 - val_binary_accuracy: 0.9067 - val_loss: 0.2599\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9074 - loss: 0.2688 - val_auc: 0.7916 - val_binary_accuracy: 0.9084 - val_loss: 0.2593\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9073 - loss: 0.2686 - val_auc: 0.7900 - val_binary_accuracy: 0.9088 - val_loss: 0.2590\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9075 - loss: 0.2680 - val_auc: 0.7930 - val_binary_accuracy: 0.9084 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8015 - binary_accuracy: 0.9076 - loss: 0.2594\n",
      "Fold 5 Metrics: Loss = 0.2586, Accuracy = 0.9084, AUC = 0.7930\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2630\n",
      "Average Accuracy: 0.9085\n",
      "Average AUC: 0.7892\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 1, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7272 - binary_accuracy: 0.9069 - loss: 0.2821 - val_auc: 0.7683 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9069 - loss: 0.2599 - val_auc: 0.7758 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9073 - loss: 0.2565 - val_auc: 0.7821 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9078 - loss: 0.2540 - val_auc: 0.7857 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9090 - loss: 0.2519 - val_auc: 0.7861 - val_binary_accuracy: 0.9072 - val_loss: 0.2627\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9106 - loss: 0.2507 - val_auc: 0.7890 - val_binary_accuracy: 0.9079 - val_loss: 0.2617\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8086 - binary_accuracy: 0.9114 - loss: 0.2500 - val_auc: 0.7901 - val_binary_accuracy: 0.9088 - val_loss: 0.2606\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8097 - binary_accuracy: 0.9125 - loss: 0.2490 - val_auc: 0.7901 - val_binary_accuracy: 0.9103 - val_loss: 0.2601\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9131 - loss: 0.2481 - val_auc: 0.7910 - val_binary_accuracy: 0.9100 - val_loss: 0.2597\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9127 - loss: 0.2478 - val_auc: 0.7913 - val_binary_accuracy: 0.9104 - val_loss: 0.2595\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7898 - binary_accuracy: 0.9133 - loss: 0.2522\n",
      "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9104, AUC = 0.7913\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6781 - binary_accuracy: 0.9029 - loss: 0.3073 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2719 - val_auc: 0.7997 - val_binary_accuracy: 0.9042 - val_loss: 0.2645\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9035 - loss: 0.2684 - val_auc: 0.8021 - val_binary_accuracy: 0.9045 - val_loss: 0.2634\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9052 - loss: 0.2665 - val_auc: 0.8043 - val_binary_accuracy: 0.9057 - val_loss: 0.2623\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9057 - loss: 0.2656 - val_auc: 0.8046 - val_binary_accuracy: 0.9069 - val_loss: 0.2592\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7906 - binary_accuracy: 0.9071 - loss: 0.2644 - val_auc: 0.8049 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9077 - loss: 0.2635 - val_auc: 0.8068 - val_binary_accuracy: 0.9081 - val_loss: 0.2588\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7944 - binary_accuracy: 0.9078 - loss: 0.2625 - val_auc: 0.8068 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7956 - binary_accuracy: 0.9087 - loss: 0.2621 - val_auc: 0.8081 - val_binary_accuracy: 0.9088 - val_loss: 0.2593\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9082 - loss: 0.2617 - val_auc: 0.8089 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8161 - binary_accuracy: 0.9124 - loss: 0.2463\n",
      "Fold 2 Metrics: Loss = 0.2576, Accuracy = 0.9094, AUC = 0.8089\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7279 - binary_accuracy: 0.9051 - loss: 0.2831 - val_auc: 0.7758 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9055 - loss: 0.2684 - val_auc: 0.7836 - val_binary_accuracy: 0.9063 - val_loss: 0.2677\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9068 - loss: 0.2654 - val_auc: 0.7907 - val_binary_accuracy: 0.9088 - val_loss: 0.2641\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9079 - loss: 0.2637 - val_auc: 0.7966 - val_binary_accuracy: 0.9096 - val_loss: 0.2616\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9080 - loss: 0.2620 - val_auc: 0.8013 - val_binary_accuracy: 0.9102 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9091 - loss: 0.2613 - val_auc: 0.8036 - val_binary_accuracy: 0.9100 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9089 - loss: 0.2605 - val_auc: 0.8052 - val_binary_accuracy: 0.9109 - val_loss: 0.2573\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7884 - binary_accuracy: 0.9092 - loss: 0.2602 - val_auc: 0.8060 - val_binary_accuracy: 0.9112 - val_loss: 0.2567\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9095 - loss: 0.2596 - val_auc: 0.8072 - val_binary_accuracy: 0.9112 - val_loss: 0.2562\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9095 - loss: 0.2590 - val_auc: 0.8076 - val_binary_accuracy: 0.9113 - val_loss: 0.2559\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8000 - binary_accuracy: 0.9124 - loss: 0.2562\n",
      "Fold 3 Metrics: Loss = 0.2559, Accuracy = 0.9113, AUC = 0.8076\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6208 - binary_accuracy: 0.7267 - loss: 0.6144 - val_auc: 0.7587 - val_binary_accuracy: 0.9044 - val_loss: 0.2768\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7610 - binary_accuracy: 0.9047 - loss: 0.2750 - val_auc: 0.7804 - val_binary_accuracy: 0.9045 - val_loss: 0.2693\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9057 - loss: 0.2667 - val_auc: 0.7873 - val_binary_accuracy: 0.9050 - val_loss: 0.2670\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9066 - loss: 0.2642 - val_auc: 0.7935 - val_binary_accuracy: 0.9057 - val_loss: 0.2660\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7865 - binary_accuracy: 0.9071 - loss: 0.2629 - val_auc: 0.7933 - val_binary_accuracy: 0.9079 - val_loss: 0.2636\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9075 - loss: 0.2619 - val_auc: 0.7934 - val_binary_accuracy: 0.9069 - val_loss: 0.2662\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9088 - loss: 0.2614 - val_auc: 0.7942 - val_binary_accuracy: 0.9078 - val_loss: 0.2659\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9093 - loss: 0.2606 - val_auc: 0.7964 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9094 - loss: 0.2599 - val_auc: 0.7970 - val_binary_accuracy: 0.9085 - val_loss: 0.2636\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7927 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.7980 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7776 - binary_accuracy: 0.9085 - loss: 0.2684\n",
      "Fold 4 Metrics: Loss = 0.2631, Accuracy = 0.9082, AUC = 0.7980\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7277 - binary_accuracy: 0.9040 - loss: 0.2875 - val_auc: 0.7910 - val_binary_accuracy: 0.9057 - val_loss: 0.2616\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9043 - loss: 0.2694 - val_auc: 0.7962 - val_binary_accuracy: 0.9054 - val_loss: 0.2582\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9063 - loss: 0.2659 - val_auc: 0.7976 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9069 - loss: 0.2637 - val_auc: 0.8015 - val_binary_accuracy: 0.9081 - val_loss: 0.2557\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9072 - loss: 0.2636 - val_auc: 0.8047 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8041 - val_binary_accuracy: 0.9094 - val_loss: 0.2534\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9085 - loss: 0.2607 - val_auc: 0.8050 - val_binary_accuracy: 0.9097 - val_loss: 0.2531\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7957 - binary_accuracy: 0.9087 - loss: 0.2601 - val_auc: 0.8056 - val_binary_accuracy: 0.9103 - val_loss: 0.2528\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7969 - binary_accuracy: 0.9093 - loss: 0.2594 - val_auc: 0.8049 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7966 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.8069 - val_binary_accuracy: 0.9110 - val_loss: 0.2523\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9089 - loss: 0.2508\n",
      "Fold 5 Metrics: Loss = 0.2523, Accuracy = 0.9110, AUC = 0.8069\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2577\n",
      "Average Accuracy: 0.9101\n",
      "Average AUC: 0.8025\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 1, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7450 - binary_accuracy: 0.9069 - loss: 0.2758 - val_auc: 0.7784 - val_binary_accuracy: 0.9056 - val_loss: 0.2687\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7951 - binary_accuracy: 0.9083 - loss: 0.2566 - val_auc: 0.7872 - val_binary_accuracy: 0.9053 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9087 - loss: 0.2532 - val_auc: 0.7890 - val_binary_accuracy: 0.9069 - val_loss: 0.2620\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8047 - binary_accuracy: 0.9116 - loss: 0.2515 - val_auc: 0.7903 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9125 - loss: 0.2502 - val_auc: 0.7907 - val_binary_accuracy: 0.9084 - val_loss: 0.2609\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8094 - binary_accuracy: 0.9126 - loss: 0.2490 - val_auc: 0.7918 - val_binary_accuracy: 0.9096 - val_loss: 0.2603\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8102 - binary_accuracy: 0.9125 - loss: 0.2482 - val_auc: 0.7943 - val_binary_accuracy: 0.9094 - val_loss: 0.2590\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8120 - binary_accuracy: 0.9126 - loss: 0.2471 - val_auc: 0.7947 - val_binary_accuracy: 0.9097 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8136 - binary_accuracy: 0.9134 - loss: 0.2463 - val_auc: 0.7955 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8152 - binary_accuracy: 0.9136 - loss: 0.2457 - val_auc: 0.7972 - val_binary_accuracy: 0.9094 - val_loss: 0.2584\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9130 - loss: 0.2519\n",
      "Fold 1 Metrics: Loss = 0.2584, Accuracy = 0.9094, AUC = 0.7972\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6504 - binary_accuracy: 0.7876 - loss: 0.4939 - val_auc: 0.7916 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7828 - binary_accuracy: 0.9029 - loss: 0.2700 - val_auc: 0.8022 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7915 - binary_accuracy: 0.9042 - loss: 0.2653 - val_auc: 0.8065 - val_binary_accuracy: 0.9045 - val_loss: 0.2610\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9061 - loss: 0.2631 - val_auc: 0.8095 - val_binary_accuracy: 0.9056 - val_loss: 0.2591\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9067 - loss: 0.2620 - val_auc: 0.8092 - val_binary_accuracy: 0.9063 - val_loss: 0.2585\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9075 - loss: 0.2608 - val_auc: 0.8089 - val_binary_accuracy: 0.9069 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7989 - binary_accuracy: 0.9084 - loss: 0.2606 - val_auc: 0.8106 - val_binary_accuracy: 0.9073 - val_loss: 0.2573\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8010 - binary_accuracy: 0.9082 - loss: 0.2597 - val_auc: 0.8104 - val_binary_accuracy: 0.9078 - val_loss: 0.2573\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9086 - loss: 0.2596 - val_auc: 0.8090 - val_binary_accuracy: 0.9075 - val_loss: 0.2577\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8022 - binary_accuracy: 0.9076 - loss: 0.2593 - val_auc: 0.8099 - val_binary_accuracy: 0.9081 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8163 - binary_accuracy: 0.9121 - loss: 0.2474\n",
      "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9081, AUC = 0.8099\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6593 - binary_accuracy: 0.8358 - loss: 0.3686 - val_auc: 0.7730 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9056 - loss: 0.2678 - val_auc: 0.7836 - val_binary_accuracy: 0.9072 - val_loss: 0.2660\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9079 - loss: 0.2644 - val_auc: 0.7903 - val_binary_accuracy: 0.9090 - val_loss: 0.2631\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9084 - loss: 0.2629 - val_auc: 0.7951 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9092 - loss: 0.2618 - val_auc: 0.7962 - val_binary_accuracy: 0.9097 - val_loss: 0.2599\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9095 - loss: 0.2610 - val_auc: 0.7950 - val_binary_accuracy: 0.9096 - val_loss: 0.2597\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9091 - loss: 0.2602 - val_auc: 0.7995 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9096 - loss: 0.2593 - val_auc: 0.8022 - val_binary_accuracy: 0.9106 - val_loss: 0.2576\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7903 - binary_accuracy: 0.9098 - loss: 0.2591 - val_auc: 0.8015 - val_binary_accuracy: 0.9109 - val_loss: 0.2574\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7908 - binary_accuracy: 0.9093 - loss: 0.2590 - val_auc: 0.8032 - val_binary_accuracy: 0.9113 - val_loss: 0.2575\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7936 - binary_accuracy: 0.9123 - loss: 0.2592\n",
      "Fold 3 Metrics: Loss = 0.2575, Accuracy = 0.9113, AUC = 0.8032\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7258 - binary_accuracy: 0.9049 - loss: 0.2833 - val_auc: 0.7871 - val_binary_accuracy: 0.9054 - val_loss: 0.2654\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9080 - loss: 0.2650 - val_auc: 0.7945 - val_binary_accuracy: 0.9079 - val_loss: 0.2623\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7878 - binary_accuracy: 0.9099 - loss: 0.2616 - val_auc: 0.7993 - val_binary_accuracy: 0.9078 - val_loss: 0.2598\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9104 - loss: 0.2595 - val_auc: 0.7999 - val_binary_accuracy: 0.9079 - val_loss: 0.2598\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7929 - binary_accuracy: 0.9102 - loss: 0.2587 - val_auc: 0.8000 - val_binary_accuracy: 0.9090 - val_loss: 0.2591\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9101 - loss: 0.2590 - val_auc: 0.8015 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9104 - loss: 0.2579 - val_auc: 0.8010 - val_binary_accuracy: 0.9091 - val_loss: 0.2589\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9102 - loss: 0.2578 - val_auc: 0.8010 - val_binary_accuracy: 0.9091 - val_loss: 0.2586\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7952 - binary_accuracy: 0.9102 - loss: 0.2577 - val_auc: 0.8026 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7966 - binary_accuracy: 0.9102 - loss: 0.2569 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2589\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7858 - binary_accuracy: 0.9084 - loss: 0.2648\n",
      "Fold 4 Metrics: Loss = 0.2589, Accuracy = 0.9087, AUC = 0.8037\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7170 - binary_accuracy: 0.9007 - loss: 0.2948 - val_auc: 0.7877 - val_binary_accuracy: 0.9045 - val_loss: 0.2642\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7721 - binary_accuracy: 0.9062 - loss: 0.2709 - val_auc: 0.7960 - val_binary_accuracy: 0.9063 - val_loss: 0.2594\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9072 - loss: 0.2680 - val_auc: 0.7969 - val_binary_accuracy: 0.9082 - val_loss: 0.2571\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9080 - loss: 0.2658 - val_auc: 0.8007 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9079 - loss: 0.2643 - val_auc: 0.8047 - val_binary_accuracy: 0.9095 - val_loss: 0.2544\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9085 - loss: 0.2628 - val_auc: 0.8059 - val_binary_accuracy: 0.9100 - val_loss: 0.2533\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9089 - loss: 0.2621 - val_auc: 0.8063 - val_binary_accuracy: 0.9106 - val_loss: 0.2530\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9094 - loss: 0.2615 - val_auc: 0.8069 - val_binary_accuracy: 0.9106 - val_loss: 0.2523\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9098 - loss: 0.2609 - val_auc: 0.8058 - val_binary_accuracy: 0.9100 - val_loss: 0.2532\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8063 - val_binary_accuracy: 0.9098 - val_loss: 0.2536\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8166 - binary_accuracy: 0.9075 - loss: 0.2519\n",
      "Fold 5 Metrics: Loss = 0.2536, Accuracy = 0.9098, AUC = 0.8063\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2574\n",
      "Average Accuracy: 0.9095\n",
      "Average AUC: 0.8041\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 1, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7411 - binary_accuracy: 0.9076 - loss: 0.2779 - val_auc: 0.7812 - val_binary_accuracy: 0.9053 - val_loss: 0.2688\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9103 - loss: 0.2552 - val_auc: 0.7894 - val_binary_accuracy: 0.9066 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9114 - loss: 0.2526 - val_auc: 0.7911 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8064 - binary_accuracy: 0.9118 - loss: 0.2506 - val_auc: 0.7926 - val_binary_accuracy: 0.9079 - val_loss: 0.2629\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9121 - loss: 0.2496 - val_auc: 0.7926 - val_binary_accuracy: 0.9076 - val_loss: 0.2626\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9125 - loss: 0.2487 - val_auc: 0.7943 - val_binary_accuracy: 0.9078 - val_loss: 0.2618\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9130 - loss: 0.2482 - val_auc: 0.7932 - val_binary_accuracy: 0.9082 - val_loss: 0.2620\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8119 - binary_accuracy: 0.9131 - loss: 0.2475 - val_auc: 0.7942 - val_binary_accuracy: 0.9084 - val_loss: 0.2607\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8129 - binary_accuracy: 0.9130 - loss: 0.2470 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9132 - loss: 0.2463 - val_auc: 0.7956 - val_binary_accuracy: 0.9081 - val_loss: 0.2602\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9114 - loss: 0.2519\n",
      "Fold 1 Metrics: Loss = 0.2602, Accuracy = 0.9081, AUC = 0.7956\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6722 - binary_accuracy: 0.8454 - loss: 0.3876 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9038 - loss: 0.2691 - val_auc: 0.8036 - val_binary_accuracy: 0.9060 - val_loss: 0.2605\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9059 - loss: 0.2651 - val_auc: 0.8067 - val_binary_accuracy: 0.9065 - val_loss: 0.2591\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9063 - loss: 0.2635 - val_auc: 0.8077 - val_binary_accuracy: 0.9068 - val_loss: 0.2582\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7963 - binary_accuracy: 0.9077 - loss: 0.2620 - val_auc: 0.8086 - val_binary_accuracy: 0.9071 - val_loss: 0.2570\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7978 - binary_accuracy: 0.9075 - loss: 0.2610 - val_auc: 0.8077 - val_binary_accuracy: 0.9075 - val_loss: 0.2579\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7976 - binary_accuracy: 0.9081 - loss: 0.2607 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2573\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9084 - loss: 0.2602 - val_auc: 0.8079 - val_binary_accuracy: 0.9079 - val_loss: 0.2567\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8006 - binary_accuracy: 0.9082 - loss: 0.2595 - val_auc: 0.8077 - val_binary_accuracy: 0.9079 - val_loss: 0.2573\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9081 - loss: 0.2593 - val_auc: 0.8085 - val_binary_accuracy: 0.9082 - val_loss: 0.2571\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8184 - binary_accuracy: 0.9118 - loss: 0.2458\n",
      "Fold 2 Metrics: Loss = 0.2571, Accuracy = 0.9082, AUC = 0.8085\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7200 - binary_accuracy: 0.9013 - loss: 0.2934 - val_auc: 0.7870 - val_binary_accuracy: 0.9059 - val_loss: 0.2656\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9067 - loss: 0.2680 - val_auc: 0.7945 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9078 - loss: 0.2657 - val_auc: 0.7981 - val_binary_accuracy: 0.9090 - val_loss: 0.2602\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9078 - loss: 0.2643 - val_auc: 0.7971 - val_binary_accuracy: 0.9099 - val_loss: 0.2597\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8005 - val_binary_accuracy: 0.9100 - val_loss: 0.2582\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9090 - loss: 0.2627 - val_auc: 0.8011 - val_binary_accuracy: 0.9102 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9092 - loss: 0.2621 - val_auc: 0.8014 - val_binary_accuracy: 0.9106 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9098 - loss: 0.2614 - val_auc: 0.8027 - val_binary_accuracy: 0.9107 - val_loss: 0.2570\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9100 - loss: 0.2608 - val_auc: 0.8022 - val_binary_accuracy: 0.9102 - val_loss: 0.2578\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9096 - loss: 0.2605 - val_auc: 0.8036 - val_binary_accuracy: 0.9106 - val_loss: 0.2570\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9112 - loss: 0.2577\n",
      "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9106, AUC = 0.8036\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7369 - binary_accuracy: 0.9059 - loss: 0.2818 - val_auc: 0.7948 - val_binary_accuracy: 0.9082 - val_loss: 0.2608\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9097 - loss: 0.2631 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2580\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9110 - loss: 0.2609 - val_auc: 0.8008 - val_binary_accuracy: 0.9082 - val_loss: 0.2578\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9107 - loss: 0.2596 - val_auc: 0.8025 - val_binary_accuracy: 0.9085 - val_loss: 0.2570\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9107 - loss: 0.2587 - val_auc: 0.8047 - val_binary_accuracy: 0.9093 - val_loss: 0.2564\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9109 - loss: 0.2581 - val_auc: 0.8047 - val_binary_accuracy: 0.9091 - val_loss: 0.2562\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9107 - loss: 0.2573 - val_auc: 0.8056 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9110 - loss: 0.2574 - val_auc: 0.8054 - val_binary_accuracy: 0.9090 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7958 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2552\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9110 - loss: 0.2564 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7874 - binary_accuracy: 0.9081 - loss: 0.2626\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9081, AUC = 0.8072\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7378 - binary_accuracy: 0.9045 - loss: 0.2839 - val_auc: 0.7956 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9069 - loss: 0.2696 - val_auc: 0.8026 - val_binary_accuracy: 0.9088 - val_loss: 0.2601\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9073 - loss: 0.2684 - val_auc: 0.8037 - val_binary_accuracy: 0.9088 - val_loss: 0.2564\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9081 - loss: 0.2660 - val_auc: 0.8060 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.8079 - val_binary_accuracy: 0.9093 - val_loss: 0.2534\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8073 - val_binary_accuracy: 0.9098 - val_loss: 0.2531\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9087 - loss: 0.2626 - val_auc: 0.8084 - val_binary_accuracy: 0.9095 - val_loss: 0.2527\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9087 - loss: 0.2621 - val_auc: 0.8082 - val_binary_accuracy: 0.9093 - val_loss: 0.2522\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9084 - loss: 0.2617 - val_auc: 0.8076 - val_binary_accuracy: 0.9098 - val_loss: 0.2519\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9090 - loss: 0.2609 - val_auc: 0.8089 - val_binary_accuracy: 0.9101 - val_loss: 0.2515\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9084 - loss: 0.2504\n",
      "Fold 5 Metrics: Loss = 0.2515, Accuracy = 0.9101, AUC = 0.8089\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2562\n",
      "Average Accuracy: 0.9090\n",
      "Average AUC: 0.8047\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 2, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6182 - binary_accuracy: 0.7984 - loss: 0.4154 - val_auc: 0.7467 - val_binary_accuracy: 0.9044 - val_loss: 0.2788\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9069 - loss: 0.2674 - val_auc: 0.7560 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9069 - loss: 0.2627 - val_auc: 0.7626 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9092 - loss: 0.2606 - val_auc: 0.7673 - val_binary_accuracy: 0.9059 - val_loss: 0.2701\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.7688 - val_binary_accuracy: 0.9059 - val_loss: 0.2698\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9106 - loss: 0.2581 - val_auc: 0.7702 - val_binary_accuracy: 0.9069 - val_loss: 0.2683\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9111 - loss: 0.2574 - val_auc: 0.7720 - val_binary_accuracy: 0.9072 - val_loss: 0.2674\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.7714 - val_binary_accuracy: 0.9073 - val_loss: 0.2673\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9111 - loss: 0.2571 - val_auc: 0.7740 - val_binary_accuracy: 0.9076 - val_loss: 0.2669\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9122 - loss: 0.2564 - val_auc: 0.7748 - val_binary_accuracy: 0.9078 - val_loss: 0.2669\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7723 - binary_accuracy: 0.9104 - loss: 0.2597\n",
      "Fold 1 Metrics: Loss = 0.2669, Accuracy = 0.9078, AUC = 0.7748\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5405 - binary_accuracy: 0.9022 - loss: 0.3564 - val_auc: 0.7345 - val_binary_accuracy: 0.9042 - val_loss: 0.2920\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7368 - binary_accuracy: 0.9029 - loss: 0.2893 - val_auc: 0.7651 - val_binary_accuracy: 0.9042 - val_loss: 0.2800\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7604 - binary_accuracy: 0.9029 - loss: 0.2777 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2739\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7654 - binary_accuracy: 0.9029 - loss: 0.2757 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9029 - loss: 0.2744 - val_auc: 0.7915 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9029 - loss: 0.2738 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2696\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9029 - loss: 0.2735 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2732 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9029 - loss: 0.2729 - val_auc: 0.7914 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.7974 - val_binary_accuracy: 0.9042 - val_loss: 0.2669\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7991 - binary_accuracy: 0.9092 - loss: 0.2580\n",
      "Fold 2 Metrics: Loss = 0.2669, Accuracy = 0.9042, AUC = 0.7974\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6537 - binary_accuracy: 0.8582 - loss: 0.3662 - val_auc: 0.7539 - val_binary_accuracy: 0.9042 - val_loss: 0.2782\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9051 - loss: 0.2736 - val_auc: 0.7799 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7812 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9051 - loss: 0.2656 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9051 - loss: 0.2652 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9051 - loss: 0.2646 - val_auc: 0.7864 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2642 - val_auc: 0.7865 - val_binary_accuracy: 0.9042 - val_loss: 0.2679\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9051 - loss: 0.2638 - val_auc: 0.7863 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7823 - binary_accuracy: 0.9046 - loss: 0.2684\n",
      "Fold 3 Metrics: Loss = 0.2677, Accuracy = 0.9042, AUC = 0.7863\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6045 - binary_accuracy: 0.8124 - loss: 0.4151 - val_auc: 0.7433 - val_binary_accuracy: 0.9044 - val_loss: 0.2850\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7468 - binary_accuracy: 0.9047 - loss: 0.2800 - val_auc: 0.7575 - val_binary_accuracy: 0.9044 - val_loss: 0.2764\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9047 - loss: 0.2709 - val_auc: 0.7677 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9050 - loss: 0.2684 - val_auc: 0.7764 - val_binary_accuracy: 0.9050 - val_loss: 0.2710\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9058 - loss: 0.2669 - val_auc: 0.7786 - val_binary_accuracy: 0.9056 - val_loss: 0.2689\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9064 - loss: 0.2661 - val_auc: 0.7781 - val_binary_accuracy: 0.9059 - val_loss: 0.2681\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7784 - binary_accuracy: 0.9072 - loss: 0.2651 - val_auc: 0.7782 - val_binary_accuracy: 0.9064 - val_loss: 0.2687\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.7836 - val_binary_accuracy: 0.9072 - val_loss: 0.2689\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9085 - loss: 0.2639 - val_auc: 0.7846 - val_binary_accuracy: 0.9079 - val_loss: 0.2688\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9081 - loss: 0.2634 - val_auc: 0.7845 - val_binary_accuracy: 0.9081 - val_loss: 0.2687\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7650 - binary_accuracy: 0.9084 - loss: 0.2739\n",
      "Fold 4 Metrics: Loss = 0.2687, Accuracy = 0.9081, AUC = 0.7845\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5155 - binary_accuracy: 0.7282 - loss: 0.5179 - val_auc: 0.6883 - val_binary_accuracy: 0.9044 - val_loss: 0.3035\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6826 - binary_accuracy: 0.9039 - loss: 0.3017 - val_auc: 0.7339 - val_binary_accuracy: 0.9044 - val_loss: 0.2869\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7254 - binary_accuracy: 0.9039 - loss: 0.2886 - val_auc: 0.7520 - val_binary_accuracy: 0.9044 - val_loss: 0.2769\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7356 - binary_accuracy: 0.9039 - loss: 0.2813 - val_auc: 0.7600 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7478 - binary_accuracy: 0.9039 - loss: 0.2801 - val_auc: 0.7637 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7571 - binary_accuracy: 0.9039 - loss: 0.2771 - val_auc: 0.7667 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9039 - loss: 0.2764 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7566 - binary_accuracy: 0.9039 - loss: 0.2760 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7574 - binary_accuracy: 0.9039 - loss: 0.2757 - val_auc: 0.7691 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9039 - loss: 0.2754 - val_auc: 0.7700 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7850 - binary_accuracy: 0.9013 - loss: 0.2659\n",
      "Fold 5 Metrics: Loss = 0.2671, Accuracy = 0.9044, AUC = 0.7700\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2675\n",
      "Average Accuracy: 0.9057\n",
      "Average AUC: 0.7826\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 2, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6210 - binary_accuracy: 0.8316 - loss: 0.3766 - val_auc: 0.7564 - val_binary_accuracy: 0.9044 - val_loss: 0.2802\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9069 - loss: 0.2693 - val_auc: 0.7684 - val_binary_accuracy: 0.9044 - val_loss: 0.2736\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9069 - loss: 0.2634 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9069 - loss: 0.2588 - val_auc: 0.7793 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9069 - loss: 0.2574 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9069 - loss: 0.2565 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9069 - loss: 0.2559 - val_auc: 0.7813 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9069 - loss: 0.2552 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9069 - loss: 0.2545 - val_auc: 0.7845 - val_binary_accuracy: 0.9044 - val_loss: 0.2672\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7878 - binary_accuracy: 0.9084 - loss: 0.2590\n",
      "Fold 1 Metrics: Loss = 0.2672, Accuracy = 0.9044, AUC = 0.7845\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6579 - binary_accuracy: 0.8703 - loss: 0.3423 - val_auc: 0.7854 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9029 - loss: 0.2735 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9034 - loss: 0.2714 - val_auc: 0.7927 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9034 - loss: 0.2691 - val_auc: 0.7955 - val_binary_accuracy: 0.9048 - val_loss: 0.2655\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9051 - loss: 0.2676 - val_auc: 0.7972 - val_binary_accuracy: 0.9051 - val_loss: 0.2669\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9049 - loss: 0.2666 - val_auc: 0.8002 - val_binary_accuracy: 0.9062 - val_loss: 0.2674\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9057 - loss: 0.2654 - val_auc: 0.7997 - val_binary_accuracy: 0.9063 - val_loss: 0.2652\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9066 - loss: 0.2645 - val_auc: 0.8026 - val_binary_accuracy: 0.9059 - val_loss: 0.2649\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9064 - loss: 0.2640 - val_auc: 0.8047 - val_binary_accuracy: 0.9066 - val_loss: 0.2629\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9071 - loss: 0.2631 - val_auc: 0.8060 - val_binary_accuracy: 0.9071 - val_loss: 0.2616\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8109 - binary_accuracy: 0.9111 - loss: 0.2509\n",
      "Fold 2 Metrics: Loss = 0.2616, Accuracy = 0.9071, AUC = 0.8060\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5777 - binary_accuracy: 0.8146 - loss: 0.4277 - val_auc: 0.7277 - val_binary_accuracy: 0.9042 - val_loss: 0.2887\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7181 - binary_accuracy: 0.9051 - loss: 0.2872 - val_auc: 0.7590 - val_binary_accuracy: 0.9042 - val_loss: 0.2760\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7548 - binary_accuracy: 0.9051 - loss: 0.2739 - val_auc: 0.7703 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2695 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2721\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9051 - loss: 0.2681 - val_auc: 0.7765 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7710 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7782 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7795 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7723 - binary_accuracy: 0.9051 - loss: 0.2679 - val_auc: 0.7821 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7848 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7783 - binary_accuracy: 0.9046 - loss: 0.2700\n",
      "Fold 3 Metrics: Loss = 0.2694, Accuracy = 0.9042, AUC = 0.7848\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6428 - binary_accuracy: 0.8646 - loss: 0.3499 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9048 - loss: 0.2689 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9049 - loss: 0.2668 - val_auc: 0.7831 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9062 - loss: 0.2653 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9060 - loss: 0.2640 - val_auc: 0.7878 - val_binary_accuracy: 0.9064 - val_loss: 0.2660\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9068 - loss: 0.2631 - val_auc: 0.7898 - val_binary_accuracy: 0.9070 - val_loss: 0.2658\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9081 - loss: 0.2624 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2640\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9081 - loss: 0.2617 - val_auc: 0.7935 - val_binary_accuracy: 0.9081 - val_loss: 0.2637\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9084 - loss: 0.2609 - val_auc: 0.7947 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9085 - loss: 0.2604 - val_auc: 0.7917 - val_binary_accuracy: 0.9084 - val_loss: 0.2649\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7694 - binary_accuracy: 0.9074 - loss: 0.2708\n",
      "Fold 4 Metrics: Loss = 0.2649, Accuracy = 0.9084, AUC = 0.7917\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6287 - binary_accuracy: 0.8434 - loss: 0.3650 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7647 - binary_accuracy: 0.9040 - loss: 0.2751 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2643\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9040 - loss: 0.2722 - val_auc: 0.7903 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.7912 - val_binary_accuracy: 0.9044 - val_loss: 0.2613\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9040 - loss: 0.2701 - val_auc: 0.7929 - val_binary_accuracy: 0.9044 - val_loss: 0.2607\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2610\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9041 - loss: 0.2688 - val_auc: 0.7926 - val_binary_accuracy: 0.9044 - val_loss: 0.2596\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9046 - loss: 0.2674 - val_auc: 0.7946 - val_binary_accuracy: 0.9054 - val_loss: 0.2588\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9053 - loss: 0.2668 - val_auc: 0.7965 - val_binary_accuracy: 0.9044 - val_loss: 0.2580\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9042 - loss: 0.2663 - val_auc: 0.7954 - val_binary_accuracy: 0.9078 - val_loss: 0.2580\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8084 - binary_accuracy: 0.9055 - loss: 0.2550\n",
      "Fold 5 Metrics: Loss = 0.2580, Accuracy = 0.9078, AUC = 0.7954\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2642\n",
      "Average Accuracy: 0.9064\n",
      "Average AUC: 0.7925\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 2, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7302 - binary_accuracy: 0.9069 - loss: 0.2803 - val_auc: 0.7687 - val_binary_accuracy: 0.9044 - val_loss: 0.2716\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9079 - loss: 0.2593 - val_auc: 0.7789 - val_binary_accuracy: 0.9069 - val_loss: 0.2654\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9100 - loss: 0.2550 - val_auc: 0.7823 - val_binary_accuracy: 0.9068 - val_loss: 0.2640\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9106 - loss: 0.2526 - val_auc: 0.7833 - val_binary_accuracy: 0.9073 - val_loss: 0.2637\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8049 - binary_accuracy: 0.9118 - loss: 0.2509 - val_auc: 0.7853 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8066 - binary_accuracy: 0.9122 - loss: 0.2496 - val_auc: 0.7853 - val_binary_accuracy: 0.9084 - val_loss: 0.2628\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8084 - binary_accuracy: 0.9125 - loss: 0.2487 - val_auc: 0.7856 - val_binary_accuracy: 0.9091 - val_loss: 0.2626\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9130 - loss: 0.2485 - val_auc: 0.7869 - val_binary_accuracy: 0.9096 - val_loss: 0.2618\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8111 - binary_accuracy: 0.9126 - loss: 0.2473 - val_auc: 0.7876 - val_binary_accuracy: 0.9094 - val_loss: 0.2616\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8124 - binary_accuracy: 0.9130 - loss: 0.2466 - val_auc: 0.7878 - val_binary_accuracy: 0.9094 - val_loss: 0.2616\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7879 - binary_accuracy: 0.9129 - loss: 0.2539\n",
      "Fold 1 Metrics: Loss = 0.2616, Accuracy = 0.9094, AUC = 0.7878\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.7044 - binary_accuracy: 0.8960 - loss: 0.3059 - val_auc: 0.7818 - val_binary_accuracy: 0.9051 - val_loss: 0.2685\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9045 - loss: 0.2723 - val_auc: 0.7957 - val_binary_accuracy: 0.9057 - val_loss: 0.2623\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9050 - loss: 0.2676 - val_auc: 0.8027 - val_binary_accuracy: 0.9054 - val_loss: 0.2587\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9061 - loss: 0.2645 - val_auc: 0.8040 - val_binary_accuracy: 0.9059 - val_loss: 0.2576\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9062 - loss: 0.2628 - val_auc: 0.8042 - val_binary_accuracy: 0.9062 - val_loss: 0.2574\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9073 - loss: 0.2617 - val_auc: 0.8032 - val_binary_accuracy: 0.9065 - val_loss: 0.2574\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9070 - loss: 0.2612 - val_auc: 0.8021 - val_binary_accuracy: 0.9069 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9074 - loss: 0.2604 - val_auc: 0.8037 - val_binary_accuracy: 0.9068 - val_loss: 0.2576\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9072 - loss: 0.2599 - val_auc: 0.8041 - val_binary_accuracy: 0.9066 - val_loss: 0.2578\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8020 - binary_accuracy: 0.9071 - loss: 0.2595 - val_auc: 0.8032 - val_binary_accuracy: 0.9066 - val_loss: 0.2582\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8091 - binary_accuracy: 0.9102 - loss: 0.2482\n",
      "Fold 2 Metrics: Loss = 0.2582, Accuracy = 0.9066, AUC = 0.8032\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7223 - binary_accuracy: 0.9053 - loss: 0.2857 - val_auc: 0.7872 - val_binary_accuracy: 0.9051 - val_loss: 0.2662\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9063 - loss: 0.2711 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2626\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.7959 - val_binary_accuracy: 0.9065 - val_loss: 0.2615\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9081 - loss: 0.2654 - val_auc: 0.7966 - val_binary_accuracy: 0.9088 - val_loss: 0.2607\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9086 - loss: 0.2641 - val_auc: 0.7980 - val_binary_accuracy: 0.9096 - val_loss: 0.2597\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9089 - loss: 0.2630 - val_auc: 0.7982 - val_binary_accuracy: 0.9100 - val_loss: 0.2590\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8013 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9090 - loss: 0.2614 - val_auc: 0.8016 - val_binary_accuracy: 0.9107 - val_loss: 0.2584\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9096 - loss: 0.2612 - val_auc: 0.8015 - val_binary_accuracy: 0.9110 - val_loss: 0.2577\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2574\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7950 - binary_accuracy: 0.9123 - loss: 0.2580\n",
      "Fold 3 Metrics: Loss = 0.2574, Accuracy = 0.9107, AUC = 0.8029\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6472 - binary_accuracy: 0.8780 - loss: 0.3309 - val_auc: 0.7821 - val_binary_accuracy: 0.9048 - val_loss: 0.2671\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9063 - loss: 0.2671 - val_auc: 0.7907 - val_binary_accuracy: 0.9073 - val_loss: 0.2628\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9084 - loss: 0.2652 - val_auc: 0.7940 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9089 - loss: 0.2633 - val_auc: 0.7953 - val_binary_accuracy: 0.9082 - val_loss: 0.2607\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9099 - loss: 0.2627 - val_auc: 0.7957 - val_binary_accuracy: 0.9093 - val_loss: 0.2595\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.7978 - val_binary_accuracy: 0.9097 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9104 - loss: 0.2598 - val_auc: 0.8003 - val_binary_accuracy: 0.9100 - val_loss: 0.2579\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9102 - loss: 0.2595 - val_auc: 0.8008 - val_binary_accuracy: 0.9109 - val_loss: 0.2585\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9106 - loss: 0.2586 - val_auc: 0.8022 - val_binary_accuracy: 0.9104 - val_loss: 0.2578\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9103 - loss: 0.2583 - val_auc: 0.8015 - val_binary_accuracy: 0.9101 - val_loss: 0.2577\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7813 - binary_accuracy: 0.9099 - loss: 0.2636\n",
      "Fold 4 Metrics: Loss = 0.2577, Accuracy = 0.9101, AUC = 0.8015\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6722 - binary_accuracy: 0.9038 - loss: 0.3049 - val_auc: 0.7820 - val_binary_accuracy: 0.9050 - val_loss: 0.2658\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9042 - loss: 0.2749 - val_auc: 0.7932 - val_binary_accuracy: 0.9045 - val_loss: 0.2604\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2704 - val_auc: 0.7930 - val_binary_accuracy: 0.9059 - val_loss: 0.2605\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9070 - loss: 0.2689 - val_auc: 0.7959 - val_binary_accuracy: 0.9097 - val_loss: 0.2572\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9082 - loss: 0.2667 - val_auc: 0.7991 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9083 - loss: 0.2654 - val_auc: 0.8011 - val_binary_accuracy: 0.9107 - val_loss: 0.2552\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9086 - loss: 0.2640 - val_auc: 0.8025 - val_binary_accuracy: 0.9113 - val_loss: 0.2546\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9093 - loss: 0.2632 - val_auc: 0.8036 - val_binary_accuracy: 0.9113 - val_loss: 0.2538\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8044 - val_binary_accuracy: 0.9113 - val_loss: 0.2534\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9096 - loss: 0.2624 - val_auc: 0.8062 - val_binary_accuracy: 0.9118 - val_loss: 0.2528\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9100 - loss: 0.2509\n",
      "Fold 5 Metrics: Loss = 0.2528, Accuracy = 0.9118, AUC = 0.8062\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2576\n",
      "Average Accuracy: 0.9097\n",
      "Average AUC: 0.8003\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 2, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.7228 - binary_accuracy: 0.9067 - loss: 0.2842 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9083 - loss: 0.2595 - val_auc: 0.7859 - val_binary_accuracy: 0.9069 - val_loss: 0.2660\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9104 - loss: 0.2555 - val_auc: 0.7893 - val_binary_accuracy: 0.9062 - val_loss: 0.2652\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8012 - binary_accuracy: 0.9113 - loss: 0.2529 - val_auc: 0.7898 - val_binary_accuracy: 0.9072 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9122 - loss: 0.2506 - val_auc: 0.7907 - val_binary_accuracy: 0.9082 - val_loss: 0.2632\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9121 - loss: 0.2489 - val_auc: 0.7918 - val_binary_accuracy: 0.9081 - val_loss: 0.2616\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8102 - binary_accuracy: 0.9129 - loss: 0.2478 - val_auc: 0.7920 - val_binary_accuracy: 0.9079 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9126 - loss: 0.2468 - val_auc: 0.7926 - val_binary_accuracy: 0.9081 - val_loss: 0.2603\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8135 - binary_accuracy: 0.9131 - loss: 0.2461 - val_auc: 0.7921 - val_binary_accuracy: 0.9091 - val_loss: 0.2598\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8144 - binary_accuracy: 0.9131 - loss: 0.2455 - val_auc: 0.7924 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7912 - binary_accuracy: 0.9129 - loss: 0.2519\n",
      "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9094, AUC = 0.7924\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6794 - binary_accuracy: 0.8797 - loss: 0.3308 - val_auc: 0.8003 - val_binary_accuracy: 0.9057 - val_loss: 0.2620\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9054 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9065 - val_loss: 0.2609\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.8038 - val_binary_accuracy: 0.9075 - val_loss: 0.2594\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9075 - loss: 0.2639 - val_auc: 0.8055 - val_binary_accuracy: 0.9082 - val_loss: 0.2584\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9080 - loss: 0.2621 - val_auc: 0.8062 - val_binary_accuracy: 0.9068 - val_loss: 0.2581\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9085 - loss: 0.2610 - val_auc: 0.8077 - val_binary_accuracy: 0.9081 - val_loss: 0.2569\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.8082 - val_binary_accuracy: 0.9082 - val_loss: 0.2564\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9083 - loss: 0.2594 - val_auc: 0.8093 - val_binary_accuracy: 0.9081 - val_loss: 0.2555\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9081 - loss: 0.2591 - val_auc: 0.8086 - val_binary_accuracy: 0.9085 - val_loss: 0.2558\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9081 - loss: 0.2588 - val_auc: 0.8088 - val_binary_accuracy: 0.9079 - val_loss: 0.2557\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9115 - loss: 0.2464\n",
      "Fold 2 Metrics: Loss = 0.2557, Accuracy = 0.9079, AUC = 0.8088\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7255 - binary_accuracy: 0.8980 - loss: 0.2938 - val_auc: 0.7890 - val_binary_accuracy: 0.9068 - val_loss: 0.2669\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9067 - loss: 0.2703 - val_auc: 0.7921 - val_binary_accuracy: 0.9068 - val_loss: 0.2653\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.7951 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9080 - loss: 0.2667 - val_auc: 0.7981 - val_binary_accuracy: 0.9090 - val_loss: 0.2613\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9082 - loss: 0.2653 - val_auc: 0.7986 - val_binary_accuracy: 0.9091 - val_loss: 0.2612\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8002 - val_binary_accuracy: 0.9093 - val_loss: 0.2607\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2593\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9087 - loss: 0.2630 - val_auc: 0.8005 - val_binary_accuracy: 0.9096 - val_loss: 0.2589\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8017 - val_binary_accuracy: 0.9099 - val_loss: 0.2582\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2572\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7949 - binary_accuracy: 0.9116 - loss: 0.2581\n",
      "Fold 3 Metrics: Loss = 0.2572, Accuracy = 0.9107, AUC = 0.8029\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6892 - binary_accuracy: 0.8896 - loss: 0.3105 - val_auc: 0.7928 - val_binary_accuracy: 0.9087 - val_loss: 0.2617\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9066 - loss: 0.2673 - val_auc: 0.7984 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9078 - loss: 0.2639 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2586\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9083 - loss: 0.2625 - val_auc: 0.8014 - val_binary_accuracy: 0.9091 - val_loss: 0.2569\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9088 - loss: 0.2611 - val_auc: 0.8038 - val_binary_accuracy: 0.9098 - val_loss: 0.2565\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9087 - loss: 0.2606 - val_auc: 0.8011 - val_binary_accuracy: 0.9088 - val_loss: 0.2571\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9090 - loss: 0.2596 - val_auc: 0.8024 - val_binary_accuracy: 0.9094 - val_loss: 0.2563\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.8035 - val_binary_accuracy: 0.9094 - val_loss: 0.2559\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9098 - loss: 0.2588 - val_auc: 0.8040 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9097 - loss: 0.2584 - val_auc: 0.8060 - val_binary_accuracy: 0.9097 - val_loss: 0.2550\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7860 - binary_accuracy: 0.9088 - loss: 0.2620\n",
      "Fold 4 Metrics: Loss = 0.2550, Accuracy = 0.9097, AUC = 0.8060\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6383 - binary_accuracy: 0.8697 - loss: 0.3769 - val_auc: 0.7925 - val_binary_accuracy: 0.9090 - val_loss: 0.2635\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9050 - loss: 0.2729 - val_auc: 0.7996 - val_binary_accuracy: 0.9085 - val_loss: 0.2635\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9046 - loss: 0.2706 - val_auc: 0.8026 - val_binary_accuracy: 0.9103 - val_loss: 0.2606\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9076 - loss: 0.2680 - val_auc: 0.8032 - val_binary_accuracy: 0.9101 - val_loss: 0.2565\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9089 - loss: 0.2664 - val_auc: 0.8036 - val_binary_accuracy: 0.9109 - val_loss: 0.2557\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9091 - loss: 0.2654 - val_auc: 0.8045 - val_binary_accuracy: 0.9107 - val_loss: 0.2539\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9094 - loss: 0.2643 - val_auc: 0.8040 - val_binary_accuracy: 0.9104 - val_loss: 0.2533\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9103 - loss: 0.2633 - val_auc: 0.8042 - val_binary_accuracy: 0.9110 - val_loss: 0.2530\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9106 - loss: 0.2627 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2526\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9101 - loss: 0.2621 - val_auc: 0.8061 - val_binary_accuracy: 0.9113 - val_loss: 0.2527\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9094 - loss: 0.2504\n",
      "Fold 5 Metrics: Loss = 0.2527, Accuracy = 0.9113, AUC = 0.8061\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2560\n",
      "Average Accuracy: 0.9098\n",
      "Average AUC: 0.8032\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 2, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7019 - binary_accuracy: 0.8908 - loss: 0.3147 - val_auc: 0.7819 - val_binary_accuracy: 0.9054 - val_loss: 0.2656\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9098 - loss: 0.2581 - val_auc: 0.7872 - val_binary_accuracy: 0.9078 - val_loss: 0.2634\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9109 - loss: 0.2548 - val_auc: 0.7884 - val_binary_accuracy: 0.9078 - val_loss: 0.2646\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9115 - loss: 0.2530 - val_auc: 0.7906 - val_binary_accuracy: 0.9079 - val_loss: 0.2642\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9119 - loss: 0.2513 - val_auc: 0.7908 - val_binary_accuracy: 0.9078 - val_loss: 0.2635\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9120 - loss: 0.2501 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2625\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9122 - loss: 0.2493 - val_auc: 0.7936 - val_binary_accuracy: 0.9087 - val_loss: 0.2618\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9124 - loss: 0.2486 - val_auc: 0.7933 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8096 - binary_accuracy: 0.9129 - loss: 0.2479 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2607\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8105 - binary_accuracy: 0.9131 - loss: 0.2475 - val_auc: 0.7947 - val_binary_accuracy: 0.9084 - val_loss: 0.2606\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9108 - loss: 0.2526\n",
      "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9084, AUC = 0.7947\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7231 - binary_accuracy: 0.9035 - loss: 0.2977 - val_auc: 0.7994 - val_binary_accuracy: 0.9056 - val_loss: 0.2685\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9050 - loss: 0.2684 - val_auc: 0.8049 - val_binary_accuracy: 0.9065 - val_loss: 0.2631\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9059 - loss: 0.2655 - val_auc: 0.8050 - val_binary_accuracy: 0.9072 - val_loss: 0.2612\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9073 - loss: 0.2636 - val_auc: 0.8075 - val_binary_accuracy: 0.9081 - val_loss: 0.2599\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9071 - loss: 0.2624 - val_auc: 0.8096 - val_binary_accuracy: 0.9082 - val_loss: 0.2594\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9081 - loss: 0.2612 - val_auc: 0.8101 - val_binary_accuracy: 0.9079 - val_loss: 0.2591\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9087 - loss: 0.2605 - val_auc: 0.8096 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9084 - loss: 0.2598 - val_auc: 0.8099 - val_binary_accuracy: 0.9084 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9092 - loss: 0.2593 - val_auc: 0.8106 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9092 - loss: 0.2592 - val_auc: 0.8111 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8190 - binary_accuracy: 0.9134 - loss: 0.2492\n",
      "Fold 2 Metrics: Loss = 0.2587, Accuracy = 0.9091, AUC = 0.8111\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7099 - binary_accuracy: 0.9052 - loss: 0.2995 - val_auc: 0.7868 - val_binary_accuracy: 0.9085 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7685 - binary_accuracy: 0.9083 - loss: 0.2690 - val_auc: 0.7927 - val_binary_accuracy: 0.9104 - val_loss: 0.2645\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9086 - loss: 0.2666 - val_auc: 0.7960 - val_binary_accuracy: 0.9106 - val_loss: 0.2623\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9080 - loss: 0.2658 - val_auc: 0.7983 - val_binary_accuracy: 0.9107 - val_loss: 0.2614\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.8003 - val_binary_accuracy: 0.9107 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8008 - val_binary_accuracy: 0.9112 - val_loss: 0.2601\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7775 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8021 - val_binary_accuracy: 0.9110 - val_loss: 0.2592\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7786 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8037 - val_binary_accuracy: 0.9112 - val_loss: 0.2590\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9087 - loss: 0.2631 - val_auc: 0.8038 - val_binary_accuracy: 0.9112 - val_loss: 0.2590\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9094 - loss: 0.2631 - val_auc: 0.8050 - val_binary_accuracy: 0.9110 - val_loss: 0.2576\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7977 - binary_accuracy: 0.9121 - loss: 0.2584\n",
      "Fold 3 Metrics: Loss = 0.2576, Accuracy = 0.9110, AUC = 0.8050\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6967 - binary_accuracy: 0.8868 - loss: 0.3252 - val_auc: 0.7942 - val_binary_accuracy: 0.9087 - val_loss: 0.2616\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9065 - loss: 0.2666 - val_auc: 0.7995 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9084 - loss: 0.2642 - val_auc: 0.8013 - val_binary_accuracy: 0.9067 - val_loss: 0.2587\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9085 - loss: 0.2625 - val_auc: 0.8037 - val_binary_accuracy: 0.9066 - val_loss: 0.2576\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8041 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8054 - val_binary_accuracy: 0.9094 - val_loss: 0.2558\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9104 - loss: 0.2599 - val_auc: 0.8067 - val_binary_accuracy: 0.9094 - val_loss: 0.2551\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9105 - loss: 0.2594 - val_auc: 0.8090 - val_binary_accuracy: 0.9093 - val_loss: 0.2540\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9105 - loss: 0.2590 - val_auc: 0.8088 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9107 - loss: 0.2586 - val_auc: 0.8094 - val_binary_accuracy: 0.9093 - val_loss: 0.2539\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7899 - binary_accuracy: 0.9091 - loss: 0.2620\n",
      "Fold 4 Metrics: Loss = 0.2539, Accuracy = 0.9093, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6883 - binary_accuracy: 0.8934 - loss: 0.3195 - val_auc: 0.7951 - val_binary_accuracy: 0.9087 - val_loss: 0.2591\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9060 - loss: 0.2712 - val_auc: 0.8000 - val_binary_accuracy: 0.9057 - val_loss: 0.2620\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.8027 - val_binary_accuracy: 0.9088 - val_loss: 0.2615\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9079 - loss: 0.2657 - val_auc: 0.8038 - val_binary_accuracy: 0.9094 - val_loss: 0.2619\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9081 - loss: 0.2650 - val_auc: 0.8050 - val_binary_accuracy: 0.9095 - val_loss: 0.2609\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9082 - loss: 0.2643 - val_auc: 0.8055 - val_binary_accuracy: 0.9091 - val_loss: 0.2598\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2635 - val_auc: 0.8056 - val_binary_accuracy: 0.9091 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8069 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.8066 - val_binary_accuracy: 0.9095 - val_loss: 0.2588\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9086 - loss: 0.2624 - val_auc: 0.8070 - val_binary_accuracy: 0.9079 - val_loss: 0.2591\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9088 - loss: 0.2563\n",
      "Fold 5 Metrics: Loss = 0.2591, Accuracy = 0.9079, AUC = 0.8070\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2580\n",
      "Average Accuracy: 0.9091\n",
      "Average AUC: 0.8054\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 3, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6231 - binary_accuracy: 0.9069 - loss: 0.3285 - val_auc: 0.7382 - val_binary_accuracy: 0.9044 - val_loss: 0.2813\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9069 - loss: 0.2674 - val_auc: 0.7482 - val_binary_accuracy: 0.9044 - val_loss: 0.2780\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9070 - loss: 0.2644 - val_auc: 0.7539 - val_binary_accuracy: 0.9044 - val_loss: 0.2757\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9070 - loss: 0.2631 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2730\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9070 - loss: 0.2620 - val_auc: 0.7639 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9070 - loss: 0.2618 - val_auc: 0.7644 - val_binary_accuracy: 0.9044 - val_loss: 0.2721\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.7645 - val_binary_accuracy: 0.9044 - val_loss: 0.2715\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9070 - loss: 0.2613 - val_auc: 0.7656 - val_binary_accuracy: 0.9044 - val_loss: 0.2715\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9069 - loss: 0.2610 - val_auc: 0.7660 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9069 - loss: 0.2608 - val_auc: 0.7669 - val_binary_accuracy: 0.9042 - val_loss: 0.2712\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7601 - binary_accuracy: 0.9082 - loss: 0.2640\n",
      "Fold 1 Metrics: Loss = 0.2712, Accuracy = 0.9042, AUC = 0.7669\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6295 - binary_accuracy: 0.8972 - loss: 0.3282 - val_auc: 0.7588 - val_binary_accuracy: 0.9042 - val_loss: 0.2822\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7492 - binary_accuracy: 0.9029 - loss: 0.2815 - val_auc: 0.7734 - val_binary_accuracy: 0.9042 - val_loss: 0.2742\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9029 - loss: 0.2763 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7646 - binary_accuracy: 0.9029 - loss: 0.2744 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2704\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9029 - loss: 0.2728 - val_auc: 0.7898 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9029 - loss: 0.2707 - val_auc: 0.7922 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.7952 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9029 - loss: 0.2695 - val_auc: 0.7962 - val_binary_accuracy: 0.9042 - val_loss: 0.2647\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9029 - loss: 0.2691 - val_auc: 0.7973 - val_binary_accuracy: 0.9042 - val_loss: 0.2643\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2689 - val_auc: 0.7991 - val_binary_accuracy: 0.9042 - val_loss: 0.2642\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7969 - binary_accuracy: 0.9092 - loss: 0.2540\n",
      "Fold 2 Metrics: Loss = 0.2642, Accuracy = 0.9042, AUC = 0.7991\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5201 - binary_accuracy: 0.9051 - loss: 0.3335 - val_auc: 0.7416 - val_binary_accuracy: 0.9042 - val_loss: 0.2879\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7409 - binary_accuracy: 0.9051 - loss: 0.2804 - val_auc: 0.7647 - val_binary_accuracy: 0.9042 - val_loss: 0.2747\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9051 - loss: 0.2696 - val_auc: 0.7767 - val_binary_accuracy: 0.9042 - val_loss: 0.2728\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9061 - loss: 0.2685 - val_auc: 0.7792 - val_binary_accuracy: 0.9066 - val_loss: 0.2711\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9066 - loss: 0.2674 - val_auc: 0.7848 - val_binary_accuracy: 0.9075 - val_loss: 0.2694\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9075 - loss: 0.2666 - val_auc: 0.7859 - val_binary_accuracy: 0.9076 - val_loss: 0.2671\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7886 - val_binary_accuracy: 0.9087 - val_loss: 0.2653\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9083 - loss: 0.2654 - val_auc: 0.7886 - val_binary_accuracy: 0.9099 - val_loss: 0.2642\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9089 - loss: 0.2650 - val_auc: 0.7896 - val_binary_accuracy: 0.9104 - val_loss: 0.2635\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9085 - loss: 0.2645 - val_auc: 0.7904 - val_binary_accuracy: 0.9100 - val_loss: 0.2631\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7841 - binary_accuracy: 0.9098 - loss: 0.2643\n",
      "Fold 3 Metrics: Loss = 0.2631, Accuracy = 0.9100, AUC = 0.7904\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5469 - binary_accuracy: 0.9047 - loss: 0.3493 - val_auc: 0.7014 - val_binary_accuracy: 0.9044 - val_loss: 0.2931\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7048 - binary_accuracy: 0.9047 - loss: 0.2899 - val_auc: 0.7433 - val_binary_accuracy: 0.9044 - val_loss: 0.2826\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7378 - binary_accuracy: 0.9047 - loss: 0.2812 - val_auc: 0.7586 - val_binary_accuracy: 0.9044 - val_loss: 0.2754\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7527 - binary_accuracy: 0.9047 - loss: 0.2763 - val_auc: 0.7696 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9047 - loss: 0.2738 - val_auc: 0.7721 - val_binary_accuracy: 0.9044 - val_loss: 0.2711\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9047 - loss: 0.2711 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9047 - loss: 0.2684 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9047 - loss: 0.2656 - val_auc: 0.7881 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9047 - loss: 0.2644 - val_auc: 0.7869 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9047 - loss: 0.2640 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7729 - binary_accuracy: 0.9049 - loss: 0.2698\n",
      "Fold 4 Metrics: Loss = 0.2675, Accuracy = 0.9044, AUC = 0.7872\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5982 - binary_accuracy: 0.9036 - loss: 0.3237 - val_auc: 0.7556 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7469 - binary_accuracy: 0.9037 - loss: 0.2794 - val_auc: 0.7687 - val_binary_accuracy: 0.9044 - val_loss: 0.2672\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7578 - binary_accuracy: 0.9039 - loss: 0.2767 - val_auc: 0.7793 - val_binary_accuracy: 0.9044 - val_loss: 0.2652\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7633 - binary_accuracy: 0.9039 - loss: 0.2742 - val_auc: 0.7822 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9040 - loss: 0.2730 - val_auc: 0.7838 - val_binary_accuracy: 0.9044 - val_loss: 0.2631\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9040 - loss: 0.2721 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2627\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9040 - loss: 0.2715 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2623\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.7875 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9040 - loss: 0.2698 - val_auc: 0.7885 - val_binary_accuracy: 0.9044 - val_loss: 0.2615\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8049 - binary_accuracy: 0.9013 - loss: 0.2585\n",
      "Fold 5 Metrics: Loss = 0.2615, Accuracy = 0.9044, AUC = 0.7885\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2655\n",
      "Average Accuracy: 0.9055\n",
      "Average AUC: 0.7864\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 3, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5706 - binary_accuracy: 0.9066 - loss: 0.3155 - val_auc: 0.7594 - val_binary_accuracy: 0.9044 - val_loss: 0.2817\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7713 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9069 - loss: 0.2621 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9071 - loss: 0.2591 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9083 - loss: 0.2572 - val_auc: 0.7832 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9089 - loss: 0.2557 - val_auc: 0.7820 - val_binary_accuracy: 0.9088 - val_loss: 0.2669\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9096 - loss: 0.2547 - val_auc: 0.7833 - val_binary_accuracy: 0.9082 - val_loss: 0.2650\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9111 - loss: 0.2537 - val_auc: 0.7852 - val_binary_accuracy: 0.9099 - val_loss: 0.2645\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9124 - loss: 0.2530 - val_auc: 0.7863 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9119 - loss: 0.2516 - val_auc: 0.7849 - val_binary_accuracy: 0.9090 - val_loss: 0.2644\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7846 - binary_accuracy: 0.9112 - loss: 0.2573\n",
      "Fold 1 Metrics: Loss = 0.2644, Accuracy = 0.9090, AUC = 0.7849\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6661 - binary_accuracy: 0.8577 - loss: 0.3449 - val_auc: 0.7872 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9043 - loss: 0.2716 - val_auc: 0.7932 - val_binary_accuracy: 0.9053 - val_loss: 0.2657\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9052 - loss: 0.2673 - val_auc: 0.7994 - val_binary_accuracy: 0.9065 - val_loss: 0.2612\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9059 - loss: 0.2646 - val_auc: 0.8019 - val_binary_accuracy: 0.9084 - val_loss: 0.2586\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9071 - loss: 0.2633 - val_auc: 0.8000 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9072 - loss: 0.2620 - val_auc: 0.7998 - val_binary_accuracy: 0.9093 - val_loss: 0.2592\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9082 - loss: 0.2609 - val_auc: 0.7977 - val_binary_accuracy: 0.9079 - val_loss: 0.2615\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9081 - loss: 0.2608 - val_auc: 0.7983 - val_binary_accuracy: 0.9078 - val_loss: 0.2618\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9087 - loss: 0.2607 - val_auc: 0.7985 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9098 - loss: 0.2605 - val_auc: 0.7985 - val_binary_accuracy: 0.9078 - val_loss: 0.2620\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8050 - binary_accuracy: 0.9118 - loss: 0.2514\n",
      "Fold 2 Metrics: Loss = 0.2620, Accuracy = 0.9078, AUC = 0.7985\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6525 - binary_accuracy: 0.8428 - loss: 0.3592 - val_auc: 0.7640 - val_binary_accuracy: 0.9048 - val_loss: 0.2753\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9058 - loss: 0.2722 - val_auc: 0.7723 - val_binary_accuracy: 0.9053 - val_loss: 0.2711\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7656 - binary_accuracy: 0.9063 - loss: 0.2700 - val_auc: 0.7733 - val_binary_accuracy: 0.9065 - val_loss: 0.2698\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9078 - loss: 0.2686 - val_auc: 0.7787 - val_binary_accuracy: 0.9082 - val_loss: 0.2690\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9086 - loss: 0.2673 - val_auc: 0.7782 - val_binary_accuracy: 0.9084 - val_loss: 0.2691\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9087 - loss: 0.2662 - val_auc: 0.7768 - val_binary_accuracy: 0.9084 - val_loss: 0.2689\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9085 - loss: 0.2655 - val_auc: 0.7776 - val_binary_accuracy: 0.9087 - val_loss: 0.2687\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9092 - loss: 0.2650 - val_auc: 0.7792 - val_binary_accuracy: 0.9088 - val_loss: 0.2685\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9094 - loss: 0.2646 - val_auc: 0.7790 - val_binary_accuracy: 0.9097 - val_loss: 0.2682\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9096 - loss: 0.2641 - val_auc: 0.7801 - val_binary_accuracy: 0.9093 - val_loss: 0.2679\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7731 - binary_accuracy: 0.9104 - loss: 0.2692\n",
      "Fold 3 Metrics: Loss = 0.2679, Accuracy = 0.9093, AUC = 0.7801\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6619 - binary_accuracy: 0.8546 - loss: 0.3482 - val_auc: 0.7817 - val_binary_accuracy: 0.9044 - val_loss: 0.2696\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9051 - loss: 0.2686 - val_auc: 0.7863 - val_binary_accuracy: 0.9047 - val_loss: 0.2671\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9069 - loss: 0.2656 - val_auc: 0.7906 - val_binary_accuracy: 0.9066 - val_loss: 0.2644\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.7924 - val_binary_accuracy: 0.9078 - val_loss: 0.2624\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9085 - loss: 0.2618 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2613\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2610 - val_auc: 0.7961 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9095 - loss: 0.2603 - val_auc: 0.7966 - val_binary_accuracy: 0.9087 - val_loss: 0.2610\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.7969 - val_binary_accuracy: 0.9087 - val_loss: 0.2609\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9100 - loss: 0.2595 - val_auc: 0.7972 - val_binary_accuracy: 0.9085 - val_loss: 0.2611\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9095 - loss: 0.2592 - val_auc: 0.7974 - val_binary_accuracy: 0.9084 - val_loss: 0.2613\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7778 - binary_accuracy: 0.9078 - loss: 0.2679\n",
      "Fold 4 Metrics: Loss = 0.2613, Accuracy = 0.9084, AUC = 0.7974\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7020 - binary_accuracy: 0.9041 - loss: 0.3018 - val_auc: 0.7885 - val_binary_accuracy: 0.9056 - val_loss: 0.2620\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9056 - loss: 0.2711 - val_auc: 0.7952 - val_binary_accuracy: 0.9063 - val_loss: 0.2594\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9071 - loss: 0.2690 - val_auc: 0.7975 - val_binary_accuracy: 0.9075 - val_loss: 0.2583\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9078 - loss: 0.2681 - val_auc: 0.7964 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9080 - loss: 0.2668 - val_auc: 0.7975 - val_binary_accuracy: 0.9097 - val_loss: 0.2574\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9080 - loss: 0.2657 - val_auc: 0.7985 - val_binary_accuracy: 0.9101 - val_loss: 0.2568\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8006 - val_binary_accuracy: 0.9091 - val_loss: 0.2561\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9075 - loss: 0.2642 - val_auc: 0.8026 - val_binary_accuracy: 0.9093 - val_loss: 0.2557\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.8023 - val_binary_accuracy: 0.9085 - val_loss: 0.2554\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9088 - loss: 0.2629 - val_auc: 0.8029 - val_binary_accuracy: 0.9085 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8135 - binary_accuracy: 0.9076 - loss: 0.2521\n",
      "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9085, AUC = 0.8029\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2621\n",
      "Average Accuracy: 0.9086\n",
      "Average AUC: 0.7928\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 3, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7186 - binary_accuracy: 0.9060 - loss: 0.2886 - val_auc: 0.7727 - val_binary_accuracy: 0.9044 - val_loss: 0.2707\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9082 - loss: 0.2591 - val_auc: 0.7799 - val_binary_accuracy: 0.9047 - val_loss: 0.2673\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9102 - loss: 0.2556 - val_auc: 0.7833 - val_binary_accuracy: 0.9054 - val_loss: 0.2650\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9120 - loss: 0.2533 - val_auc: 0.7855 - val_binary_accuracy: 0.9069 - val_loss: 0.2636\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9124 - loss: 0.2516 - val_auc: 0.7865 - val_binary_accuracy: 0.9072 - val_loss: 0.2628\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9124 - loss: 0.2504 - val_auc: 0.7874 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9127 - loss: 0.2496 - val_auc: 0.7857 - val_binary_accuracy: 0.9075 - val_loss: 0.2630\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9125 - loss: 0.2492 - val_auc: 0.7863 - val_binary_accuracy: 0.9078 - val_loss: 0.2631\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9126 - loss: 0.2493 - val_auc: 0.7871 - val_binary_accuracy: 0.9078 - val_loss: 0.2629\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9128 - loss: 0.2487 - val_auc: 0.7882 - val_binary_accuracy: 0.9082 - val_loss: 0.2622\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7870 - binary_accuracy: 0.9111 - loss: 0.2548\n",
      "Fold 1 Metrics: Loss = 0.2622, Accuracy = 0.9082, AUC = 0.7882\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6992 - binary_accuracy: 0.8989 - loss: 0.3037 - val_auc: 0.7879 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9037 - loss: 0.2709 - val_auc: 0.7982 - val_binary_accuracy: 0.9057 - val_loss: 0.2619\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9041 - loss: 0.2673 - val_auc: 0.7975 - val_binary_accuracy: 0.9063 - val_loss: 0.2609\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9058 - loss: 0.2652 - val_auc: 0.7974 - val_binary_accuracy: 0.9059 - val_loss: 0.2613\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9051 - loss: 0.2639 - val_auc: 0.7987 - val_binary_accuracy: 0.9069 - val_loss: 0.2601\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9059 - loss: 0.2635 - val_auc: 0.8015 - val_binary_accuracy: 0.9071 - val_loss: 0.2588\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9074 - loss: 0.2622 - val_auc: 0.8029 - val_binary_accuracy: 0.9072 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9077 - loss: 0.2613 - val_auc: 0.8046 - val_binary_accuracy: 0.9072 - val_loss: 0.2578\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9077 - loss: 0.2605 - val_auc: 0.8030 - val_binary_accuracy: 0.9069 - val_loss: 0.2586\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9077 - loss: 0.2605 - val_auc: 0.8030 - val_binary_accuracy: 0.9076 - val_loss: 0.2573\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8101 - binary_accuracy: 0.9118 - loss: 0.2467\n",
      "Fold 2 Metrics: Loss = 0.2573, Accuracy = 0.9076, AUC = 0.8030\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6749 - binary_accuracy: 0.8913 - loss: 0.3076 - val_auc: 0.7857 - val_binary_accuracy: 0.9053 - val_loss: 0.2664\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9064 - loss: 0.2713 - val_auc: 0.7879 - val_binary_accuracy: 0.9060 - val_loss: 0.2645\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9080 - loss: 0.2680 - val_auc: 0.7892 - val_binary_accuracy: 0.9099 - val_loss: 0.2658\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9080 - loss: 0.2651 - val_auc: 0.7945 - val_binary_accuracy: 0.9066 - val_loss: 0.2623\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9088 - loss: 0.2652 - val_auc: 0.7955 - val_binary_accuracy: 0.9069 - val_loss: 0.2615\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9088 - loss: 0.2644 - val_auc: 0.7971 - val_binary_accuracy: 0.9079 - val_loss: 0.2607\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9085 - loss: 0.2638 - val_auc: 0.7976 - val_binary_accuracy: 0.9091 - val_loss: 0.2596\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9085 - loss: 0.2631 - val_auc: 0.7983 - val_binary_accuracy: 0.9103 - val_loss: 0.2587\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9083 - loss: 0.2626 - val_auc: 0.7992 - val_binary_accuracy: 0.9106 - val_loss: 0.2583\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9082 - loss: 0.2622 - val_auc: 0.7996 - val_binary_accuracy: 0.9110 - val_loss: 0.2576\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9120 - loss: 0.2585\n",
      "Fold 3 Metrics: Loss = 0.2576, Accuracy = 0.9110, AUC = 0.7996\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6600 - binary_accuracy: 0.8742 - loss: 0.3284 - val_auc: 0.7844 - val_binary_accuracy: 0.9087 - val_loss: 0.2645\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9076 - loss: 0.2683 - val_auc: 0.7922 - val_binary_accuracy: 0.9084 - val_loss: 0.2601\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9092 - loss: 0.2638 - val_auc: 0.7939 - val_binary_accuracy: 0.9088 - val_loss: 0.2591\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9100 - loss: 0.2618 - val_auc: 0.7971 - val_binary_accuracy: 0.9087 - val_loss: 0.2583\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9105 - loss: 0.2604 - val_auc: 0.7999 - val_binary_accuracy: 0.9084 - val_loss: 0.2574\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9109 - loss: 0.2595 - val_auc: 0.8009 - val_binary_accuracy: 0.9085 - val_loss: 0.2572\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9112 - loss: 0.2591 - val_auc: 0.8001 - val_binary_accuracy: 0.9082 - val_loss: 0.2573\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9112 - loss: 0.2586 - val_auc: 0.8033 - val_binary_accuracy: 0.9082 - val_loss: 0.2569\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2583 - val_auc: 0.8029 - val_binary_accuracy: 0.9082 - val_loss: 0.2562\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9112 - loss: 0.2580 - val_auc: 0.8042 - val_binary_accuracy: 0.9091 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9085 - loss: 0.2616\n",
      "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9091, AUC = 0.8042\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6394 - binary_accuracy: 0.8589 - loss: 0.3551 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2648\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9040 - loss: 0.2752 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2607\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9045 - loss: 0.2725 - val_auc: 0.7961 - val_binary_accuracy: 0.9084 - val_loss: 0.2589\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9039 - loss: 0.2714 - val_auc: 0.8021 - val_binary_accuracy: 0.9098 - val_loss: 0.2562\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9056 - loss: 0.2692 - val_auc: 0.8040 - val_binary_accuracy: 0.9085 - val_loss: 0.2552\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.8037 - val_binary_accuracy: 0.9088 - val_loss: 0.2547\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9079 - loss: 0.2659 - val_auc: 0.8036 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2648 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2551\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9087 - loss: 0.2639 - val_auc: 0.8045 - val_binary_accuracy: 0.9093 - val_loss: 0.2549\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9088 - loss: 0.2632 - val_auc: 0.8044 - val_binary_accuracy: 0.9093 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8142 - binary_accuracy: 0.9077 - loss: 0.2534\n",
      "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9093, AUC = 0.8044\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2577\n",
      "Average Accuracy: 0.9091\n",
      "Average AUC: 0.7999\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 3, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6982 - binary_accuracy: 0.8899 - loss: 0.3054 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2685\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9073 - loss: 0.2610 - val_auc: 0.7826 - val_binary_accuracy: 0.9054 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9083 - loss: 0.2567 - val_auc: 0.7850 - val_binary_accuracy: 0.9056 - val_loss: 0.2643\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9093 - loss: 0.2549 - val_auc: 0.7874 - val_binary_accuracy: 0.9075 - val_loss: 0.2633\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8008 - binary_accuracy: 0.9098 - loss: 0.2530 - val_auc: 0.7896 - val_binary_accuracy: 0.9093 - val_loss: 0.2622\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9109 - loss: 0.2515 - val_auc: 0.7911 - val_binary_accuracy: 0.9090 - val_loss: 0.2611\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9120 - loss: 0.2505 - val_auc: 0.7922 - val_binary_accuracy: 0.9088 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9127 - loss: 0.2495 - val_auc: 0.7918 - val_binary_accuracy: 0.9087 - val_loss: 0.2602\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9130 - loss: 0.2491 - val_auc: 0.7932 - val_binary_accuracy: 0.9084 - val_loss: 0.2602\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9129 - loss: 0.2483 - val_auc: 0.7927 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9126 - loss: 0.2516\n",
      "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9087, AUC = 0.7927\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7276 - binary_accuracy: 0.9039 - loss: 0.2906 - val_auc: 0.8012 - val_binary_accuracy: 0.9068 - val_loss: 0.2673\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9055 - loss: 0.2699 - val_auc: 0.8019 - val_binary_accuracy: 0.9073 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9065 - loss: 0.2660 - val_auc: 0.8020 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9066 - loss: 0.2647 - val_auc: 0.8039 - val_binary_accuracy: 0.9069 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9074 - loss: 0.2629 - val_auc: 0.8043 - val_binary_accuracy: 0.9082 - val_loss: 0.2611\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9077 - loss: 0.2627 - val_auc: 0.8082 - val_binary_accuracy: 0.9071 - val_loss: 0.2602\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9082 - loss: 0.2618 - val_auc: 0.8084 - val_binary_accuracy: 0.9068 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9073 - loss: 0.2622 - val_auc: 0.8097 - val_binary_accuracy: 0.9053 - val_loss: 0.2602\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9077 - loss: 0.2618 - val_auc: 0.8109 - val_binary_accuracy: 0.9068 - val_loss: 0.2596\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9070 - loss: 0.2611 - val_auc: 0.8111 - val_binary_accuracy: 0.9069 - val_loss: 0.2596\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8178 - binary_accuracy: 0.9106 - loss: 0.2501\n",
      "Fold 2 Metrics: Loss = 0.2596, Accuracy = 0.9069, AUC = 0.8111\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7209 - binary_accuracy: 0.9055 - loss: 0.2889 - val_auc: 0.7895 - val_binary_accuracy: 0.9068 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9072 - loss: 0.2686 - val_auc: 0.7918 - val_binary_accuracy: 0.9051 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9074 - loss: 0.2679 - val_auc: 0.7945 - val_binary_accuracy: 0.9066 - val_loss: 0.2654\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9076 - loss: 0.2671 - val_auc: 0.7964 - val_binary_accuracy: 0.9056 - val_loss: 0.2639\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9072 - loss: 0.2664 - val_auc: 0.7968 - val_binary_accuracy: 0.9071 - val_loss: 0.2637\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9086 - loss: 0.2653 - val_auc: 0.7985 - val_binary_accuracy: 0.9056 - val_loss: 0.2619\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9083 - loss: 0.2647 - val_auc: 0.7982 - val_binary_accuracy: 0.9066 - val_loss: 0.2624\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.7989 - val_binary_accuracy: 0.9072 - val_loss: 0.2618\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8003 - val_binary_accuracy: 0.9084 - val_loss: 0.2605\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8008 - val_binary_accuracy: 0.9088 - val_loss: 0.2600\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7933 - binary_accuracy: 0.9100 - loss: 0.2607\n",
      "Fold 3 Metrics: Loss = 0.2600, Accuracy = 0.9088, AUC = 0.8008\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7056 - binary_accuracy: 0.8967 - loss: 0.2995 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2625\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9074 - loss: 0.2666 - val_auc: 0.7962 - val_binary_accuracy: 0.9075 - val_loss: 0.2614\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9079 - loss: 0.2637 - val_auc: 0.7978 - val_binary_accuracy: 0.9084 - val_loss: 0.2601\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9084 - loss: 0.2616 - val_auc: 0.7988 - val_binary_accuracy: 0.9087 - val_loss: 0.2592\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2605 - val_auc: 0.8013 - val_binary_accuracy: 0.9087 - val_loss: 0.2575\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9102 - loss: 0.2595 - val_auc: 0.8031 - val_binary_accuracy: 0.9093 - val_loss: 0.2571\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.8035 - val_binary_accuracy: 0.9097 - val_loss: 0.2568\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2582 - val_auc: 0.8035 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9106 - loss: 0.2583 - val_auc: 0.8044 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9112 - loss: 0.2577 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7875 - binary_accuracy: 0.9083 - loss: 0.2636\n",
      "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9094, AUC = 0.8062\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7007 - binary_accuracy: 0.9041 - loss: 0.2985 - val_auc: 0.7899 - val_binary_accuracy: 0.9066 - val_loss: 0.2644\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9056 - loss: 0.2744 - val_auc: 0.7980 - val_binary_accuracy: 0.9072 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9069 - loss: 0.2705 - val_auc: 0.8010 - val_binary_accuracy: 0.9084 - val_loss: 0.2629\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9073 - loss: 0.2680 - val_auc: 0.8044 - val_binary_accuracy: 0.9085 - val_loss: 0.2612\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9076 - loss: 0.2666 - val_auc: 0.8042 - val_binary_accuracy: 0.9090 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9070 - loss: 0.2655 - val_auc: 0.8077 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9084 - loss: 0.2638 - val_auc: 0.8081 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8086 - val_binary_accuracy: 0.9090 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8089 - val_binary_accuracy: 0.9109 - val_loss: 0.2550\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9094 - loss: 0.2618 - val_auc: 0.8090 - val_binary_accuracy: 0.9115 - val_loss: 0.2543\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9097 - loss: 0.2522\n",
      "Fold 5 Metrics: Loss = 0.2543, Accuracy = 0.9115, AUC = 0.8090\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2579\n",
      "Average Accuracy: 0.9091\n",
      "Average AUC: 0.8040\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 3, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7155 - binary_accuracy: 0.9054 - loss: 0.2915 - val_auc: 0.7776 - val_binary_accuracy: 0.9045 - val_loss: 0.2668\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9086 - loss: 0.2600 - val_auc: 0.7844 - val_binary_accuracy: 0.9081 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9106 - loss: 0.2559 - val_auc: 0.7884 - val_binary_accuracy: 0.9093 - val_loss: 0.2613\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9111 - loss: 0.2545 - val_auc: 0.7904 - val_binary_accuracy: 0.9094 - val_loss: 0.2608\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9118 - loss: 0.2529 - val_auc: 0.7904 - val_binary_accuracy: 0.9088 - val_loss: 0.2622\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9111 - loss: 0.2521 - val_auc: 0.7908 - val_binary_accuracy: 0.9093 - val_loss: 0.2624\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9120 - loss: 0.2511 - val_auc: 0.7907 - val_binary_accuracy: 0.9096 - val_loss: 0.2622\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9122 - loss: 0.2503 - val_auc: 0.7912 - val_binary_accuracy: 0.9097 - val_loss: 0.2623\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9126 - loss: 0.2501 - val_auc: 0.7921 - val_binary_accuracy: 0.9093 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8058 - binary_accuracy: 0.9130 - loss: 0.2500 - val_auc: 0.7916 - val_binary_accuracy: 0.9090 - val_loss: 0.2615\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7895 - binary_accuracy: 0.9121 - loss: 0.2539\n",
      "Fold 1 Metrics: Loss = 0.2615, Accuracy = 0.9090, AUC = 0.7916\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - auc: 0.7058 - binary_accuracy: 0.9016 - loss: 0.3067 - val_auc: 0.8011 - val_binary_accuracy: 0.9045 - val_loss: 0.2670\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9034 - loss: 0.2702 - val_auc: 0.8061 - val_binary_accuracy: 0.9072 - val_loss: 0.2626\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9061 - loss: 0.2669 - val_auc: 0.8086 - val_binary_accuracy: 0.9082 - val_loss: 0.2598\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9063 - loss: 0.2648 - val_auc: 0.8084 - val_binary_accuracy: 0.9081 - val_loss: 0.2599\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9070 - loss: 0.2638 - val_auc: 0.8094 - val_binary_accuracy: 0.9075 - val_loss: 0.2613\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9074 - loss: 0.2635 - val_auc: 0.8095 - val_binary_accuracy: 0.9071 - val_loss: 0.2621\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9071 - loss: 0.2628 - val_auc: 0.8095 - val_binary_accuracy: 0.9071 - val_loss: 0.2615\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9080 - loss: 0.2623 - val_auc: 0.8093 - val_binary_accuracy: 0.9069 - val_loss: 0.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9079 - loss: 0.2618 - val_auc: 0.8097 - val_binary_accuracy: 0.9065 - val_loss: 0.2633\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8111 - val_binary_accuracy: 0.9066 - val_loss: 0.2624\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9101 - loss: 0.2539\n",
      "Fold 2 Metrics: Loss = 0.2624, Accuracy = 0.9066, AUC = 0.8111\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7028 - binary_accuracy: 0.8871 - loss: 0.3199 - val_auc: 0.7849 - val_binary_accuracy: 0.9075 - val_loss: 0.2674\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9070 - loss: 0.2691 - val_auc: 0.7910 - val_binary_accuracy: 0.9088 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9075 - loss: 0.2676 - val_auc: 0.7931 - val_binary_accuracy: 0.9102 - val_loss: 0.2620\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9066 - loss: 0.2686 - val_auc: 0.7954 - val_binary_accuracy: 0.9100 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9067 - loss: 0.2673 - val_auc: 0.7965 - val_binary_accuracy: 0.9094 - val_loss: 0.2618\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9077 - loss: 0.2670 - val_auc: 0.7979 - val_binary_accuracy: 0.9107 - val_loss: 0.2617\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9079 - loss: 0.2662 - val_auc: 0.7992 - val_binary_accuracy: 0.9107 - val_loss: 0.2616\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9077 - loss: 0.2661 - val_auc: 0.7977 - val_binary_accuracy: 0.9106 - val_loss: 0.2624\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9072 - loss: 0.2659 - val_auc: 0.8003 - val_binary_accuracy: 0.9103 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9084 - loss: 0.2648 - val_auc: 0.7996 - val_binary_accuracy: 0.9103 - val_loss: 0.2625\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7917 - binary_accuracy: 0.9101 - loss: 0.2635\n",
      "Fold 3 Metrics: Loss = 0.2625, Accuracy = 0.9103, AUC = 0.7996\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6977 - binary_accuracy: 0.9047 - loss: 0.3033 - val_auc: 0.7941 - val_binary_accuracy: 0.9062 - val_loss: 0.2647\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9066 - loss: 0.2681 - val_auc: 0.7963 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9071 - loss: 0.2652 - val_auc: 0.7989 - val_binary_accuracy: 0.9087 - val_loss: 0.2612\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9079 - loss: 0.2638 - val_auc: 0.8008 - val_binary_accuracy: 0.9047 - val_loss: 0.2661\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8018 - val_binary_accuracy: 0.9098 - val_loss: 0.2606\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9094 - loss: 0.2620 - val_auc: 0.8039 - val_binary_accuracy: 0.9088 - val_loss: 0.2584\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9102 - loss: 0.2611 - val_auc: 0.8054 - val_binary_accuracy: 0.9094 - val_loss: 0.2575\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9106 - loss: 0.2604 - val_auc: 0.8066 - val_binary_accuracy: 0.9098 - val_loss: 0.2569\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9107 - loss: 0.2600 - val_auc: 0.8066 - val_binary_accuracy: 0.9098 - val_loss: 0.2569\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9106 - loss: 0.2593 - val_auc: 0.8087 - val_binary_accuracy: 0.9095 - val_loss: 0.2565\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7896 - binary_accuracy: 0.9087 - loss: 0.2656\n",
      "Fold 4 Metrics: Loss = 0.2565, Accuracy = 0.9095, AUC = 0.8087\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6900 - binary_accuracy: 0.9031 - loss: 0.3169 - val_auc: 0.7962 - val_binary_accuracy: 0.9093 - val_loss: 0.2583\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7672 - binary_accuracy: 0.9044 - loss: 0.2726 - val_auc: 0.8012 - val_binary_accuracy: 0.9093 - val_loss: 0.2577\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9064 - loss: 0.2681 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2581\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9072 - loss: 0.2658 - val_auc: 0.8042 - val_binary_accuracy: 0.9090 - val_loss: 0.2584\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9078 - loss: 0.2646 - val_auc: 0.8042 - val_binary_accuracy: 0.9087 - val_loss: 0.2575\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9084 - loss: 0.2640 - val_auc: 0.8046 - val_binary_accuracy: 0.9095 - val_loss: 0.2588\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9085 - loss: 0.2638 - val_auc: 0.8046 - val_binary_accuracy: 0.9100 - val_loss: 0.2587\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8055 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9083 - loss: 0.2629 - val_auc: 0.8066 - val_binary_accuracy: 0.9107 - val_loss: 0.2576\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9089 - loss: 0.2626 - val_auc: 0.8068 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8149 - binary_accuracy: 0.9102 - loss: 0.2535\n",
      "Fold 5 Metrics: Loss = 0.2573, Accuracy = 0.9091, AUC = 0.8068\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2600\n",
      "Average Accuracy: 0.9089\n",
      "Average AUC: 0.8036\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 4, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6476 - binary_accuracy: 0.8983 - loss: 0.3192 - val_auc: 0.7569 - val_binary_accuracy: 0.9040 - val_loss: 0.2772\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7598 - val_binary_accuracy: 0.9040 - val_loss: 0.2751\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9068 - loss: 0.2630 - val_auc: 0.7618 - val_binary_accuracy: 0.9040 - val_loss: 0.2753\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9068 - loss: 0.2627 - val_auc: 0.7640 - val_binary_accuracy: 0.9038 - val_loss: 0.2747\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9068 - loss: 0.2619 - val_auc: 0.7646 - val_binary_accuracy: 0.9038 - val_loss: 0.2740\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9068 - loss: 0.2614 - val_auc: 0.7650 - val_binary_accuracy: 0.9038 - val_loss: 0.2738\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9069 - loss: 0.2610 - val_auc: 0.7653 - val_binary_accuracy: 0.9038 - val_loss: 0.2738\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7663 - val_binary_accuracy: 0.9038 - val_loss: 0.2735\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9069 - loss: 0.2603 - val_auc: 0.7658 - val_binary_accuracy: 0.9038 - val_loss: 0.2730\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2601 - val_auc: 0.7674 - val_binary_accuracy: 0.9038 - val_loss: 0.2727\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7665 - binary_accuracy: 0.9078 - loss: 0.2653\n",
      "Fold 1 Metrics: Loss = 0.2727, Accuracy = 0.9038, AUC = 0.7674\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5976 - binary_accuracy: 0.8574 - loss: 0.3663 - val_auc: 0.7235 - val_binary_accuracy: 0.9042 - val_loss: 0.2919\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7143 - binary_accuracy: 0.9029 - loss: 0.2893 - val_auc: 0.7334 - val_binary_accuracy: 0.9042 - val_loss: 0.2892\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7256 - binary_accuracy: 0.9029 - loss: 0.2847 - val_auc: 0.7427 - val_binary_accuracy: 0.9042 - val_loss: 0.2839\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7418 - binary_accuracy: 0.9029 - loss: 0.2799 - val_auc: 0.7575 - val_binary_accuracy: 0.9042 - val_loss: 0.2784\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7509 - binary_accuracy: 0.9029 - loss: 0.2768 - val_auc: 0.7835 - val_binary_accuracy: 0.9042 - val_loss: 0.2731\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7626 - binary_accuracy: 0.9029 - loss: 0.2743 - val_auc: 0.7865 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9029 - loss: 0.2726 - val_auc: 0.7858 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9029 - loss: 0.2719 - val_auc: 0.7888 - val_binary_accuracy: 0.9042 - val_loss: 0.2709\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2707 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2713\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9029 - loss: 0.2709 - val_auc: 0.7875 - val_binary_accuracy: 0.9042 - val_loss: 0.2717\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7795 - binary_accuracy: 0.9092 - loss: 0.2621\n",
      "Fold 2 Metrics: Loss = 0.2717, Accuracy = 0.9042, AUC = 0.7875\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6142 - binary_accuracy: 0.9045 - loss: 0.3365 - val_auc: 0.7581 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7563 - binary_accuracy: 0.9048 - loss: 0.2747 - val_auc: 0.7709 - val_binary_accuracy: 0.9042 - val_loss: 0.2748\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9051 - loss: 0.2687 - val_auc: 0.7749 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7773 - val_binary_accuracy: 0.9041 - val_loss: 0.2727\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7809 - val_binary_accuracy: 0.9041 - val_loss: 0.2716\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7819 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9052 - loss: 0.2641 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9052 - loss: 0.2634 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9051 - loss: 0.2630 - val_auc: 0.7866 - val_binary_accuracy: 0.9042 - val_loss: 0.2672\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9051 - loss: 0.2627 - val_auc: 0.7878 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7824 - binary_accuracy: 0.9046 - loss: 0.2674\n",
      "Fold 3 Metrics: Loss = 0.2668, Accuracy = 0.9042, AUC = 0.7878\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4936 - binary_accuracy: 0.8270 - loss: 0.4017 - val_auc: 0.4962 - val_binary_accuracy: 0.9044 - val_loss: 0.3157\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5056 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4973 - val_binary_accuracy: 0.9044 - val_loss: 0.3157\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5047 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4976 - val_binary_accuracy: 0.9044 - val_loss: 0.3158\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5095 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4977 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5098 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4978 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5085 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4982 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5084 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4982 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5086 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5007 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5086 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5009 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5093 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5037 - val_binary_accuracy: 0.9044 - val_loss: 0.3158\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.5056 - binary_accuracy: 0.9049 - loss: 0.3146\n",
      "Fold 4 Metrics: Loss = 0.3158, Accuracy = 0.9044, AUC = 0.5037\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6141 - binary_accuracy: 0.8867 - loss: 0.3614 - val_auc: 0.7363 - val_binary_accuracy: 0.9044 - val_loss: 0.2835\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7209 - binary_accuracy: 0.9040 - loss: 0.2870 - val_auc: 0.7400 - val_binary_accuracy: 0.9044 - val_loss: 0.2800\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7253 - binary_accuracy: 0.9040 - loss: 0.2848 - val_auc: 0.7499 - val_binary_accuracy: 0.9045 - val_loss: 0.2768\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7319 - binary_accuracy: 0.9039 - loss: 0.2826 - val_auc: 0.7638 - val_binary_accuracy: 0.9045 - val_loss: 0.2738\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7450 - binary_accuracy: 0.9039 - loss: 0.2790 - val_auc: 0.7665 - val_binary_accuracy: 0.9044 - val_loss: 0.2721\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7503 - binary_accuracy: 0.9038 - loss: 0.2774 - val_auc: 0.7707 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7519 - binary_accuracy: 0.9039 - loss: 0.2781 - val_auc: 0.7705 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7553 - binary_accuracy: 0.9039 - loss: 0.2771 - val_auc: 0.7736 - val_binary_accuracy: 0.9044 - val_loss: 0.2678\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7564 - binary_accuracy: 0.9039 - loss: 0.2753 - val_auc: 0.7763 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9039 - loss: 0.2752 - val_auc: 0.7754 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9013 - loss: 0.2665\n",
      "Fold 5 Metrics: Loss = 0.2664, Accuracy = 0.9044, AUC = 0.7754\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2787\n",
      "Average Accuracy: 0.9042\n",
      "Average AUC: 0.7244\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 4, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6469 - binary_accuracy: 0.9069 - loss: 0.3076 - val_auc: 0.7691 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9068 - loss: 0.2585 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9070 - loss: 0.2564 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9072 - loss: 0.2549 - val_auc: 0.7883 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9075 - loss: 0.2535 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2655\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9085 - loss: 0.2521 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2642\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9085 - loss: 0.2515 - val_auc: 0.7904 - val_binary_accuracy: 0.9051 - val_loss: 0.2641\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8073 - binary_accuracy: 0.9104 - loss: 0.2506 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2622\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9105 - loss: 0.2500 - val_auc: 0.7925 - val_binary_accuracy: 0.9063 - val_loss: 0.2620\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7918 - binary_accuracy: 0.9094 - loss: 0.2548\n",
      "Fold 1 Metrics: Loss = 0.2620, Accuracy = 0.9063, AUC = 0.7925\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6112 - binary_accuracy: 0.8474 - loss: 0.3625 - val_auc: 0.7593 - val_binary_accuracy: 0.9042 - val_loss: 0.2813\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7562 - binary_accuracy: 0.9028 - loss: 0.2805 - val_auc: 0.7715 - val_binary_accuracy: 0.9041 - val_loss: 0.2794\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9040 - loss: 0.2762 - val_auc: 0.7959 - val_binary_accuracy: 0.9053 - val_loss: 0.2630\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2688 - val_auc: 0.7993 - val_binary_accuracy: 0.9056 - val_loss: 0.2637\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9052 - loss: 0.2676 - val_auc: 0.7997 - val_binary_accuracy: 0.9053 - val_loss: 0.2632\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9052 - loss: 0.2667 - val_auc: 0.8000 - val_binary_accuracy: 0.9063 - val_loss: 0.2607\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9066 - loss: 0.2654 - val_auc: 0.8003 - val_binary_accuracy: 0.9066 - val_loss: 0.2605\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9064 - loss: 0.2647 - val_auc: 0.8012 - val_binary_accuracy: 0.9063 - val_loss: 0.2603\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9067 - loss: 0.2631 - val_auc: 0.8048 - val_binary_accuracy: 0.9066 - val_loss: 0.2595\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9071 - loss: 0.2634 - val_auc: 0.8021 - val_binary_accuracy: 0.9072 - val_loss: 0.2603\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8054 - binary_accuracy: 0.9113 - loss: 0.2502\n",
      "Fold 2 Metrics: Loss = 0.2603, Accuracy = 0.9072, AUC = 0.8021\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6254 - binary_accuracy: 0.8785 - loss: 0.3328 - val_auc: 0.7636 - val_binary_accuracy: 0.9042 - val_loss: 0.2742\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9057 - loss: 0.2729 - val_auc: 0.7714 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9057 - loss: 0.2714 - val_auc: 0.7759 - val_binary_accuracy: 0.9047 - val_loss: 0.2708\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9063 - loss: 0.2688 - val_auc: 0.7749 - val_binary_accuracy: 0.9059 - val_loss: 0.2697\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7704 - binary_accuracy: 0.9064 - loss: 0.2677 - val_auc: 0.7763 - val_binary_accuracy: 0.9084 - val_loss: 0.2684\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9073 - loss: 0.2669 - val_auc: 0.7775 - val_binary_accuracy: 0.9073 - val_loss: 0.2684\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9065 - loss: 0.2664 - val_auc: 0.7790 - val_binary_accuracy: 0.9073 - val_loss: 0.2673\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9072 - loss: 0.2657 - val_auc: 0.7827 - val_binary_accuracy: 0.9076 - val_loss: 0.2661\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9081 - loss: 0.2653 - val_auc: 0.7839 - val_binary_accuracy: 0.9072 - val_loss: 0.2658\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9082 - loss: 0.2649 - val_auc: 0.7824 - val_binary_accuracy: 0.9075 - val_loss: 0.2657\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7762 - binary_accuracy: 0.9084 - loss: 0.2651\n",
      "Fold 3 Metrics: Loss = 0.2657, Accuracy = 0.9075, AUC = 0.7824\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6732 - binary_accuracy: 0.9052 - loss: 0.3074 - val_auc: 0.7863 - val_binary_accuracy: 0.9063 - val_loss: 0.2671\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9079 - loss: 0.2681 - val_auc: 0.7978 - val_binary_accuracy: 0.9075 - val_loss: 0.2623\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9087 - loss: 0.2650 - val_auc: 0.8024 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2632 - val_auc: 0.8036 - val_binary_accuracy: 0.9081 - val_loss: 0.2594\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9094 - loss: 0.2618 - val_auc: 0.8049 - val_binary_accuracy: 0.9082 - val_loss: 0.2586\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8057 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8049 - val_binary_accuracy: 0.9088 - val_loss: 0.2588\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9099 - loss: 0.2601 - val_auc: 0.8061 - val_binary_accuracy: 0.9090 - val_loss: 0.2587\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9097 - loss: 0.2598 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2586\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9097 - loss: 0.2596 - val_auc: 0.8076 - val_binary_accuracy: 0.9091 - val_loss: 0.2584\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7949 - binary_accuracy: 0.9090 - loss: 0.2623\n",
      "Fold 4 Metrics: Loss = 0.2584, Accuracy = 0.9091, AUC = 0.8076\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6298 - binary_accuracy: 0.9040 - loss: 0.3124 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9039 - loss: 0.2767 - val_auc: 0.7848 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9038 - loss: 0.2732 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2633\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9036 - loss: 0.2715 - val_auc: 0.7863 - val_binary_accuracy: 0.9044 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9042 - loss: 0.2696 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2610\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9038 - loss: 0.2686 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2602\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9053 - loss: 0.2677 - val_auc: 0.7962 - val_binary_accuracy: 0.9101 - val_loss: 0.2589\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9060 - loss: 0.2670 - val_auc: 0.7951 - val_binary_accuracy: 0.9106 - val_loss: 0.2581\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9070 - loss: 0.2659 - val_auc: 0.7973 - val_binary_accuracy: 0.9112 - val_loss: 0.2576\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2656 - val_auc: 0.7970 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8080 - binary_accuracy: 0.9111 - loss: 0.2538\n",
      "Fold 5 Metrics: Loss = 0.2571, Accuracy = 0.9112, AUC = 0.7970\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2607\n",
      "Average Accuracy: 0.9083\n",
      "Average AUC: 0.7963\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 4, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7309 - binary_accuracy: 0.9069 - loss: 0.2815 - val_auc: 0.7759 - val_binary_accuracy: 0.9048 - val_loss: 0.2681\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9086 - loss: 0.2589 - val_auc: 0.7823 - val_binary_accuracy: 0.9056 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9091 - loss: 0.2556 - val_auc: 0.7835 - val_binary_accuracy: 0.9054 - val_loss: 0.2649\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9088 - loss: 0.2539 - val_auc: 0.7848 - val_binary_accuracy: 0.9069 - val_loss: 0.2629\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9099 - loss: 0.2526 - val_auc: 0.7862 - val_binary_accuracy: 0.9100 - val_loss: 0.2617\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9102 - loss: 0.2520 - val_auc: 0.7867 - val_binary_accuracy: 0.9099 - val_loss: 0.2616\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9113 - loss: 0.2511 - val_auc: 0.7886 - val_binary_accuracy: 0.9096 - val_loss: 0.2612\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9114 - loss: 0.2505 - val_auc: 0.7881 - val_binary_accuracy: 0.9099 - val_loss: 0.2608\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9117 - loss: 0.2498 - val_auc: 0.7888 - val_binary_accuracy: 0.9099 - val_loss: 0.2605\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9120 - loss: 0.2491 - val_auc: 0.7889 - val_binary_accuracy: 0.9096 - val_loss: 0.2603\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7861 - binary_accuracy: 0.9128 - loss: 0.2534\n",
      "Fold 1 Metrics: Loss = 0.2603, Accuracy = 0.9096, AUC = 0.7889\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6884 - binary_accuracy: 0.8922 - loss: 0.3070 - val_auc: 0.7908 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9029 - loss: 0.2733 - val_auc: 0.8033 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9038 - loss: 0.2673 - val_auc: 0.8096 - val_binary_accuracy: 0.9042 - val_loss: 0.2601\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9056 - loss: 0.2648 - val_auc: 0.8118 - val_binary_accuracy: 0.9042 - val_loss: 0.2590\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9060 - loss: 0.2634 - val_auc: 0.8124 - val_binary_accuracy: 0.9042 - val_loss: 0.2589\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9056 - loss: 0.2627 - val_auc: 0.8121 - val_binary_accuracy: 0.9042 - val_loss: 0.2596\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9050 - loss: 0.2618 - val_auc: 0.8112 - val_binary_accuracy: 0.9047 - val_loss: 0.2597\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9061 - loss: 0.2609 - val_auc: 0.8109 - val_binary_accuracy: 0.9047 - val_loss: 0.2595\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9069 - loss: 0.2601 - val_auc: 0.8107 - val_binary_accuracy: 0.9051 - val_loss: 0.2585\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9079 - loss: 0.2598 - val_auc: 0.8099 - val_binary_accuracy: 0.9051 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9100 - loss: 0.2487\n",
      "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9051, AUC = 0.8099\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6706 - binary_accuracy: 0.8878 - loss: 0.3112 - val_auc: 0.7894 - val_binary_accuracy: 0.9065 - val_loss: 0.2684\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9063 - loss: 0.2710 - val_auc: 0.7957 - val_binary_accuracy: 0.9084 - val_loss: 0.2655\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9074 - loss: 0.2681 - val_auc: 0.7979 - val_binary_accuracy: 0.9099 - val_loss: 0.2635\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9089 - loss: 0.2666 - val_auc: 0.7986 - val_binary_accuracy: 0.9079 - val_loss: 0.2644\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9090 - loss: 0.2659 - val_auc: 0.7970 - val_binary_accuracy: 0.9066 - val_loss: 0.2641\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9084 - loss: 0.2657 - val_auc: 0.7996 - val_binary_accuracy: 0.9053 - val_loss: 0.2624\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9080 - loss: 0.2651 - val_auc: 0.7999 - val_binary_accuracy: 0.9053 - val_loss: 0.2614\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9087 - loss: 0.2644 - val_auc: 0.8002 - val_binary_accuracy: 0.9054 - val_loss: 0.2611\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8011 - val_binary_accuracy: 0.9054 - val_loss: 0.2609\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9086 - loss: 0.2632 - val_auc: 0.8008 - val_binary_accuracy: 0.9054 - val_loss: 0.2608\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9058 - loss: 0.2620\n",
      "Fold 3 Metrics: Loss = 0.2608, Accuracy = 0.9054, AUC = 0.8008\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7012 - binary_accuracy: 0.9004 - loss: 0.2989 - val_auc: 0.7891 - val_binary_accuracy: 0.9072 - val_loss: 0.2649\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9075 - loss: 0.2686 - val_auc: 0.7877 - val_binary_accuracy: 0.9079 - val_loss: 0.2645\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9086 - loss: 0.2659 - val_auc: 0.7927 - val_binary_accuracy: 0.9090 - val_loss: 0.2622\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9096 - loss: 0.2634 - val_auc: 0.7951 - val_binary_accuracy: 0.9095 - val_loss: 0.2610\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9096 - loss: 0.2622 - val_auc: 0.7975 - val_binary_accuracy: 0.9097 - val_loss: 0.2594\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9099 - loss: 0.2613 - val_auc: 0.7966 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.7971 - val_binary_accuracy: 0.9082 - val_loss: 0.2596\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9101 - loss: 0.2600 - val_auc: 0.7978 - val_binary_accuracy: 0.9082 - val_loss: 0.2595\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9103 - loss: 0.2594 - val_auc: 0.7976 - val_binary_accuracy: 0.9081 - val_loss: 0.2598\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9109 - loss: 0.2592 - val_auc: 0.7963 - val_binary_accuracy: 0.9085 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7777 - binary_accuracy: 0.9082 - loss: 0.2666\n",
      "Fold 4 Metrics: Loss = 0.2599, Accuracy = 0.9085, AUC = 0.7963\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6674 - binary_accuracy: 0.9039 - loss: 0.3090 - val_auc: 0.7882 - val_binary_accuracy: 0.9036 - val_loss: 0.2714\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9042 - loss: 0.2758 - val_auc: 0.7931 - val_binary_accuracy: 0.9038 - val_loss: 0.2647\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9045 - loss: 0.2723 - val_auc: 0.7967 - val_binary_accuracy: 0.9047 - val_loss: 0.2590\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9059 - loss: 0.2694 - val_auc: 0.7981 - val_binary_accuracy: 0.9060 - val_loss: 0.2573\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9066 - loss: 0.2671 - val_auc: 0.8001 - val_binary_accuracy: 0.9078 - val_loss: 0.2562\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9074 - loss: 0.2658 - val_auc: 0.8005 - val_binary_accuracy: 0.9073 - val_loss: 0.2559\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8017 - val_binary_accuracy: 0.9088 - val_loss: 0.2557\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8021 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9094 - loss: 0.2630 - val_auc: 0.8023 - val_binary_accuracy: 0.9088 - val_loss: 0.2553\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8027 - val_binary_accuracy: 0.9093 - val_loss: 0.2553\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.9075 - loss: 0.2533\n",
      "Fold 5 Metrics: Loss = 0.2553, Accuracy = 0.9093, AUC = 0.8027\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2590\n",
      "Average Accuracy: 0.9076\n",
      "Average AUC: 0.7998\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 4, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7170 - binary_accuracy: 0.9062 - loss: 0.2874 - val_auc: 0.7769 - val_binary_accuracy: 0.9045 - val_loss: 0.2674\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9063 - loss: 0.2616 - val_auc: 0.7833 - val_binary_accuracy: 0.9062 - val_loss: 0.2640\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9076 - loss: 0.2578 - val_auc: 0.7875 - val_binary_accuracy: 0.9076 - val_loss: 0.2623\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9091 - loss: 0.2555 - val_auc: 0.7903 - val_binary_accuracy: 0.9079 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9098 - loss: 0.2537 - val_auc: 0.7909 - val_binary_accuracy: 0.9079 - val_loss: 0.2608\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9104 - loss: 0.2525 - val_auc: 0.7931 - val_binary_accuracy: 0.9076 - val_loss: 0.2604\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9111 - loss: 0.2514 - val_auc: 0.7918 - val_binary_accuracy: 0.9088 - val_loss: 0.2602\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9123 - loss: 0.2508 - val_auc: 0.7924 - val_binary_accuracy: 0.9082 - val_loss: 0.2606\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9120 - loss: 0.2495 - val_auc: 0.7917 - val_binary_accuracy: 0.9084 - val_loss: 0.2609\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9126 - loss: 0.2489 - val_auc: 0.7926 - val_binary_accuracy: 0.9073 - val_loss: 0.2619\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7877 - binary_accuracy: 0.9115 - loss: 0.2551\n",
      "Fold 1 Metrics: Loss = 0.2619, Accuracy = 0.9073, AUC = 0.7926\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7122 - binary_accuracy: 0.8908 - loss: 0.3019 - val_auc: 0.7951 - val_binary_accuracy: 0.9042 - val_loss: 0.2736\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9029 - loss: 0.2708 - val_auc: 0.8036 - val_binary_accuracy: 0.9059 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9052 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9085 - val_loss: 0.2620\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9065 - loss: 0.2649 - val_auc: 0.8022 - val_binary_accuracy: 0.9060 - val_loss: 0.2644\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9062 - loss: 0.2635 - val_auc: 0.8047 - val_binary_accuracy: 0.9073 - val_loss: 0.2643\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9079 - loss: 0.2625 - val_auc: 0.8024 - val_binary_accuracy: 0.9072 - val_loss: 0.2644\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9084 - loss: 0.2621 - val_auc: 0.8017 - val_binary_accuracy: 0.9062 - val_loss: 0.2645\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9082 - loss: 0.2619 - val_auc: 0.8079 - val_binary_accuracy: 0.9060 - val_loss: 0.2634\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9081 - loss: 0.2612 - val_auc: 0.8081 - val_binary_accuracy: 0.9057 - val_loss: 0.2628\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9081 - loss: 0.2608 - val_auc: 0.8064 - val_binary_accuracy: 0.9053 - val_loss: 0.2640\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8128 - binary_accuracy: 0.9099 - loss: 0.2548\n",
      "Fold 2 Metrics: Loss = 0.2640, Accuracy = 0.9053, AUC = 0.8064\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7225 - binary_accuracy: 0.8978 - loss: 0.2938 - val_auc: 0.7896 - val_binary_accuracy: 0.9048 - val_loss: 0.2683\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9068 - loss: 0.2687 - val_auc: 0.7924 - val_binary_accuracy: 0.9054 - val_loss: 0.2647\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9062 - loss: 0.2689 - val_auc: 0.7954 - val_binary_accuracy: 0.9073 - val_loss: 0.2624\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9070 - loss: 0.2683 - val_auc: 0.7969 - val_binary_accuracy: 0.9054 - val_loss: 0.2632\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9073 - loss: 0.2669 - val_auc: 0.7973 - val_binary_accuracy: 0.9075 - val_loss: 0.2621\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9088 - loss: 0.2654 - val_auc: 0.7995 - val_binary_accuracy: 0.9059 - val_loss: 0.2623\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9088 - loss: 0.2655 - val_auc: 0.7997 - val_binary_accuracy: 0.9059 - val_loss: 0.2628\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8017 - val_binary_accuracy: 0.9054 - val_loss: 0.2628\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9090 - loss: 0.2648 - val_auc: 0.8025 - val_binary_accuracy: 0.9047 - val_loss: 0.2630\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9084 - loss: 0.2647 - val_auc: 0.8046 - val_binary_accuracy: 0.9056 - val_loss: 0.2620\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7969 - binary_accuracy: 0.9058 - loss: 0.2628\n",
      "Fold 3 Metrics: Loss = 0.2620, Accuracy = 0.9056, AUC = 0.8046\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7177 - binary_accuracy: 0.9056 - loss: 0.2889 - val_auc: 0.7918 - val_binary_accuracy: 0.9056 - val_loss: 0.2641\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9074 - loss: 0.2679 - val_auc: 0.7957 - val_binary_accuracy: 0.9059 - val_loss: 0.2622\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9083 - loss: 0.2656 - val_auc: 0.7999 - val_binary_accuracy: 0.9067 - val_loss: 0.2603\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9071 - loss: 0.2633 - val_auc: 0.8017 - val_binary_accuracy: 0.9075 - val_loss: 0.2592\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9084 - loss: 0.2619 - val_auc: 0.8021 - val_binary_accuracy: 0.9094 - val_loss: 0.2588\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9090 - loss: 0.2612 - val_auc: 0.8021 - val_binary_accuracy: 0.9098 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9091 - loss: 0.2607 - val_auc: 0.8014 - val_binary_accuracy: 0.9093 - val_loss: 0.2591\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8013 - val_binary_accuracy: 0.9095 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8017 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9099 - loss: 0.2593 - val_auc: 0.8041 - val_binary_accuracy: 0.9084 - val_loss: 0.2591\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7847 - binary_accuracy: 0.9082 - loss: 0.2677\n",
      "Fold 4 Metrics: Loss = 0.2591, Accuracy = 0.9084, AUC = 0.8041\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7079 - binary_accuracy: 0.8894 - loss: 0.3020 - val_auc: 0.7946 - val_binary_accuracy: 0.9076 - val_loss: 0.2590\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9049 - loss: 0.2734 - val_auc: 0.8002 - val_binary_accuracy: 0.9079 - val_loss: 0.2577\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9064 - loss: 0.2691 - val_auc: 0.8024 - val_binary_accuracy: 0.9091 - val_loss: 0.2584\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9070 - loss: 0.2669 - val_auc: 0.8034 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9073 - loss: 0.2655 - val_auc: 0.8040 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9074 - loss: 0.2642 - val_auc: 0.8039 - val_binary_accuracy: 0.9093 - val_loss: 0.2561\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9084 - loss: 0.2635 - val_auc: 0.8043 - val_binary_accuracy: 0.9095 - val_loss: 0.2557\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9086 - loss: 0.2628 - val_auc: 0.8045 - val_binary_accuracy: 0.9097 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9084 - loss: 0.2623 - val_auc: 0.8047 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9084 - loss: 0.2618 - val_auc: 0.8069 - val_binary_accuracy: 0.9095 - val_loss: 0.2548\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9101 - loss: 0.2511\n",
      "Fold 5 Metrics: Loss = 0.2548, Accuracy = 0.9095, AUC = 0.8069\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2603\n",
      "Average Accuracy: 0.9072\n",
      "Average AUC: 0.8029\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 4, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6985 - binary_accuracy: 0.8899 - loss: 0.3071 - val_auc: 0.7799 - val_binary_accuracy: 0.9081 - val_loss: 0.2732\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9073 - loss: 0.2623 - val_auc: 0.7851 - val_binary_accuracy: 0.9048 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9086 - loss: 0.2582 - val_auc: 0.7885 - val_binary_accuracy: 0.9119 - val_loss: 0.2609\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9098 - loss: 0.2551 - val_auc: 0.7872 - val_binary_accuracy: 0.9103 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9114 - loss: 0.2539 - val_auc: 0.7890 - val_binary_accuracy: 0.9081 - val_loss: 0.2647\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9111 - loss: 0.2529 - val_auc: 0.7882 - val_binary_accuracy: 0.9099 - val_loss: 0.2660\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9120 - loss: 0.2523 - val_auc: 0.7898 - val_binary_accuracy: 0.9097 - val_loss: 0.2645\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8033 - binary_accuracy: 0.9124 - loss: 0.2512 - val_auc: 0.7897 - val_binary_accuracy: 0.9088 - val_loss: 0.2643\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9127 - loss: 0.2508 - val_auc: 0.7917 - val_binary_accuracy: 0.9088 - val_loss: 0.2646\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9111 - loss: 0.2524 - val_auc: 0.7914 - val_binary_accuracy: 0.9091 - val_loss: 0.2643\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7888 - binary_accuracy: 0.9119 - loss: 0.2559\n",
      "Fold 1 Metrics: Loss = 0.2643, Accuracy = 0.9091, AUC = 0.7914\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6840 - binary_accuracy: 0.8860 - loss: 0.3194 - val_auc: 0.8017 - val_binary_accuracy: 0.9060 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9037 - loss: 0.2699 - val_auc: 0.7980 - val_binary_accuracy: 0.9082 - val_loss: 0.2638\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9052 - loss: 0.2691 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2651\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9069 - loss: 0.2680 - val_auc: 0.8022 - val_binary_accuracy: 0.9091 - val_loss: 0.2636\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9070 - loss: 0.2654 - val_auc: 0.8038 - val_binary_accuracy: 0.9090 - val_loss: 0.2672\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9073 - loss: 0.2652 - val_auc: 0.8056 - val_binary_accuracy: 0.9090 - val_loss: 0.2673\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9080 - loss: 0.2652 - val_auc: 0.8075 - val_binary_accuracy: 0.9094 - val_loss: 0.2707\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9082 - loss: 0.2635 - val_auc: 0.8056 - val_binary_accuracy: 0.9088 - val_loss: 0.2662\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9075 - loss: 0.2638 - val_auc: 0.8079 - val_binary_accuracy: 0.9094 - val_loss: 0.2690\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9090 - loss: 0.2643 - val_auc: 0.8094 - val_binary_accuracy: 0.9076 - val_loss: 0.2668\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9113 - loss: 0.2576\n",
      "Fold 2 Metrics: Loss = 0.2668, Accuracy = 0.9076, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6674 - binary_accuracy: 0.8867 - loss: 0.3288 - val_auc: 0.7851 - val_binary_accuracy: 0.9050 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7624 - binary_accuracy: 0.9048 - loss: 0.2717 - val_auc: 0.7902 - val_binary_accuracy: 0.9078 - val_loss: 0.2668\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9075 - loss: 0.2677 - val_auc: 0.7931 - val_binary_accuracy: 0.9096 - val_loss: 0.2634\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9065 - loss: 0.2688 - val_auc: 0.7939 - val_binary_accuracy: 0.9112 - val_loss: 0.2629\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9069 - loss: 0.2684 - val_auc: 0.7966 - val_binary_accuracy: 0.9109 - val_loss: 0.2616\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9063 - loss: 0.2695 - val_auc: 0.7955 - val_binary_accuracy: 0.9096 - val_loss: 0.2618\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9069 - loss: 0.2699 - val_auc: 0.7983 - val_binary_accuracy: 0.9109 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9067 - loss: 0.2675 - val_auc: 0.7994 - val_binary_accuracy: 0.9073 - val_loss: 0.2658\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9078 - loss: 0.2660 - val_auc: 0.7987 - val_binary_accuracy: 0.9112 - val_loss: 0.2624\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9082 - loss: 0.2661 - val_auc: 0.8020 - val_binary_accuracy: 0.9054 - val_loss: 0.2645\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7948 - binary_accuracy: 0.9059 - loss: 0.2651\n",
      "Fold 3 Metrics: Loss = 0.2645, Accuracy = 0.9054, AUC = 0.8020\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6779 - binary_accuracy: 0.8991 - loss: 0.3164 - val_auc: 0.7880 - val_binary_accuracy: 0.9038 - val_loss: 0.2694\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9054 - loss: 0.2715 - val_auc: 0.7949 - val_binary_accuracy: 0.9025 - val_loss: 0.2700\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9072 - loss: 0.2675 - val_auc: 0.7984 - val_binary_accuracy: 0.9041 - val_loss: 0.2680\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9076 - loss: 0.2666 - val_auc: 0.7982 - val_binary_accuracy: 0.9035 - val_loss: 0.2690\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9083 - loss: 0.2660 - val_auc: 0.8014 - val_binary_accuracy: 0.9017 - val_loss: 0.2681\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9082 - loss: 0.2641 - val_auc: 0.8040 - val_binary_accuracy: 0.9087 - val_loss: 0.2621\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.8042 - val_binary_accuracy: 0.9084 - val_loss: 0.2615\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8039 - val_binary_accuracy: 0.9095 - val_loss: 0.2602\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9095 - loss: 0.2614 - val_auc: 0.8040 - val_binary_accuracy: 0.9078 - val_loss: 0.2628\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2611 - val_auc: 0.8068 - val_binary_accuracy: 0.9082 - val_loss: 0.2565\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7854 - binary_accuracy: 0.9079 - loss: 0.2659\n",
      "Fold 4 Metrics: Loss = 0.2565, Accuracy = 0.9082, AUC = 0.8068\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6716 - binary_accuracy: 0.8855 - loss: 0.3284 - val_auc: 0.7931 - val_binary_accuracy: 0.9020 - val_loss: 0.2629\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7566 - binary_accuracy: 0.9030 - loss: 0.2780 - val_auc: 0.8001 - val_binary_accuracy: 0.9087 - val_loss: 0.2571\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9055 - loss: 0.2716 - val_auc: 0.8025 - val_binary_accuracy: 0.9085 - val_loss: 0.2571\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9064 - loss: 0.2688 - val_auc: 0.8052 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9067 - loss: 0.2671 - val_auc: 0.8062 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9074 - loss: 0.2661 - val_auc: 0.8079 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9074 - loss: 0.2657 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8077 - val_binary_accuracy: 0.9101 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8059 - val_binary_accuracy: 0.9104 - val_loss: 0.2555\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9097 - loss: 0.2629 - val_auc: 0.8078 - val_binary_accuracy: 0.9104 - val_loss: 0.2560\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9086 - loss: 0.2534\n",
      "Fold 5 Metrics: Loss = 0.2560, Accuracy = 0.9104, AUC = 0.8078\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2616\n",
      "Average Accuracy: 0.9082\n",
      "Average AUC: 0.8035\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 5, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6146 - binary_accuracy: 0.9011 - loss: 0.3375 - val_auc: 0.7421 - val_binary_accuracy: 0.9038 - val_loss: 0.2842\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7610 - binary_accuracy: 0.9069 - loss: 0.2687 - val_auc: 0.7503 - val_binary_accuracy: 0.9041 - val_loss: 0.2796\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9069 - loss: 0.2657 - val_auc: 0.7475 - val_binary_accuracy: 0.9040 - val_loss: 0.2767\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9069 - loss: 0.2636 - val_auc: 0.7646 - val_binary_accuracy: 0.9040 - val_loss: 0.2741\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7649 - val_binary_accuracy: 0.9040 - val_loss: 0.2732\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9069 - loss: 0.2622 - val_auc: 0.7666 - val_binary_accuracy: 0.9040 - val_loss: 0.2727\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9069 - loss: 0.2620 - val_auc: 0.7651 - val_binary_accuracy: 0.9040 - val_loss: 0.2725\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7659 - val_binary_accuracy: 0.9040 - val_loss: 0.2723\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9069 - loss: 0.2616 - val_auc: 0.7654 - val_binary_accuracy: 0.9040 - val_loss: 0.2721\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9069 - loss: 0.2614 - val_auc: 0.7652 - val_binary_accuracy: 0.9040 - val_loss: 0.2719\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7591 - binary_accuracy: 0.9079 - loss: 0.2648\n",
      "Fold 1 Metrics: Loss = 0.2719, Accuracy = 0.9040, AUC = 0.7652\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5868 - binary_accuracy: 0.8233 - loss: 0.3924 - val_auc: 0.6861 - val_binary_accuracy: 0.9042 - val_loss: 0.2951\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6966 - binary_accuracy: 0.9029 - loss: 0.2874 - val_auc: 0.7223 - val_binary_accuracy: 0.9042 - val_loss: 0.2889\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7317 - binary_accuracy: 0.9029 - loss: 0.2829 - val_auc: 0.7781 - val_binary_accuracy: 0.9042 - val_loss: 0.2733\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9029 - loss: 0.2762 - val_auc: 0.7869 - val_binary_accuracy: 0.9042 - val_loss: 0.2711\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7629 - binary_accuracy: 0.9029 - loss: 0.2747 - val_auc: 0.7901 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9029 - loss: 0.2733 - val_auc: 0.7924 - val_binary_accuracy: 0.9042 - val_loss: 0.2672\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.7894 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9032 - loss: 0.2728 - val_auc: 0.7895 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9029 - loss: 0.2718 - val_auc: 0.7921 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9038 - loss: 0.2710 - val_auc: 0.7937 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7886 - binary_accuracy: 0.9092 - loss: 0.2573\n",
      "Fold 2 Metrics: Loss = 0.2659, Accuracy = 0.9042, AUC = 0.7937\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5018 - binary_accuracy: 0.8569 - loss: 0.3752 - val_auc: 0.4997 - val_binary_accuracy: 0.9042 - val_loss: 0.3157\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5982 - binary_accuracy: 0.9051 - loss: 0.3065 - val_auc: 0.7714 - val_binary_accuracy: 0.9042 - val_loss: 0.2797\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7594 - binary_accuracy: 0.9051 - loss: 0.2745 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9051 - loss: 0.2699 - val_auc: 0.7779 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9051 - loss: 0.2687 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7796 - val_binary_accuracy: 0.9042 - val_loss: 0.2719\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9051 - loss: 0.2672 - val_auc: 0.7815 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9051 - loss: 0.2669 - val_auc: 0.7784 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7802 - val_binary_accuracy: 0.9042 - val_loss: 0.2696\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9051 - loss: 0.2643 - val_auc: 0.7816 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7779 - binary_accuracy: 0.9046 - loss: 0.2690\n",
      "Fold 3 Metrics: Loss = 0.2693, Accuracy = 0.9042, AUC = 0.7816\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5972 - binary_accuracy: 0.8563 - loss: 0.3674 - val_auc: 0.7605 - val_binary_accuracy: 0.9048 - val_loss: 0.2780\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7537 - binary_accuracy: 0.9066 - loss: 0.2746 - val_auc: 0.7719 - val_binary_accuracy: 0.9069 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9076 - loss: 0.2687 - val_auc: 0.7793 - val_binary_accuracy: 0.9079 - val_loss: 0.2671\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9080 - loss: 0.2668 - val_auc: 0.7884 - val_binary_accuracy: 0.9081 - val_loss: 0.2649\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9077 - loss: 0.2653 - val_auc: 0.7904 - val_binary_accuracy: 0.9081 - val_loss: 0.2648\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.7916 - val_binary_accuracy: 0.9076 - val_loss: 0.2650\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9088 - loss: 0.2633 - val_auc: 0.7922 - val_binary_accuracy: 0.9082 - val_loss: 0.2649\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.7924 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.7927 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9094 - loss: 0.2619 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2647\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7690 - binary_accuracy: 0.9086 - loss: 0.2704\n",
      "Fold 4 Metrics: Loss = 0.2647, Accuracy = 0.9085, AUC = 0.7923\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5539 - binary_accuracy: 0.9038 - loss: 0.3430 - val_auc: 0.7328 - val_binary_accuracy: 0.9044 - val_loss: 0.2860\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7154 - binary_accuracy: 0.9040 - loss: 0.2896 - val_auc: 0.7559 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7375 - binary_accuracy: 0.9040 - loss: 0.2833 - val_auc: 0.7601 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7402 - binary_accuracy: 0.9040 - loss: 0.2814 - val_auc: 0.7622 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7418 - binary_accuracy: 0.9040 - loss: 0.2806 - val_auc: 0.7629 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7433 - binary_accuracy: 0.9040 - loss: 0.2801 - val_auc: 0.7624 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7432 - binary_accuracy: 0.9040 - loss: 0.2796 - val_auc: 0.7623 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7446 - binary_accuracy: 0.9040 - loss: 0.2793 - val_auc: 0.7618 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7443 - binary_accuracy: 0.9040 - loss: 0.2790 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7459 - binary_accuracy: 0.9040 - loss: 0.2787 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7784 - binary_accuracy: 0.9013 - loss: 0.2666\n",
      "Fold 5 Metrics: Loss = 0.2681, Accuracy = 0.9044, AUC = 0.7615\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2680\n",
      "Average Accuracy: 0.9051\n",
      "Average AUC: 0.7788\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 5, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7006 - binary_accuracy: 0.9069 - loss: 0.2901 - val_auc: 0.7626 - val_binary_accuracy: 0.9044 - val_loss: 0.2774\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9069 - loss: 0.2667 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9069 - loss: 0.2631 - val_auc: 0.7772 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2752\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9069 - loss: 0.2609 - val_auc: 0.7797 - val_binary_accuracy: 0.9044 - val_loss: 0.2744\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9069 - loss: 0.2604 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9069 - loss: 0.2597 - val_auc: 0.7809 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9069 - loss: 0.2593 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9069 - loss: 0.2588 - val_auc: 0.7823 - val_binary_accuracy: 0.9044 - val_loss: 0.2702\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7835 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7794 - binary_accuracy: 0.9084 - loss: 0.2645\n",
      "Fold 1 Metrics: Loss = 0.2700, Accuracy = 0.9044, AUC = 0.7835\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6584 - binary_accuracy: 0.8835 - loss: 0.3277 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9037 - loss: 0.2734 - val_auc: 0.7959 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9029 - loss: 0.2712 - val_auc: 0.7965 - val_binary_accuracy: 0.9054 - val_loss: 0.2647\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9029 - loss: 0.2694 - val_auc: 0.8010 - val_binary_accuracy: 0.9042 - val_loss: 0.2626\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9039 - loss: 0.2668 - val_auc: 0.8040 - val_binary_accuracy: 0.9044 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9048 - loss: 0.2661 - val_auc: 0.8045 - val_binary_accuracy: 0.9056 - val_loss: 0.2601\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9058 - loss: 0.2650 - val_auc: 0.8053 - val_binary_accuracy: 0.9054 - val_loss: 0.2596\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9056 - loss: 0.2646 - val_auc: 0.8052 - val_binary_accuracy: 0.9054 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9064 - loss: 0.2643 - val_auc: 0.8047 - val_binary_accuracy: 0.9053 - val_loss: 0.2598\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9056 - loss: 0.2631 - val_auc: 0.8056 - val_binary_accuracy: 0.9051 - val_loss: 0.2600\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8100 - binary_accuracy: 0.9096 - loss: 0.2494\n",
      "Fold 2 Metrics: Loss = 0.2600, Accuracy = 0.9051, AUC = 0.8056\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5811 - binary_accuracy: 0.8507 - loss: 0.3665 - val_auc: 0.7571 - val_binary_accuracy: 0.9042 - val_loss: 0.2802\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9051 - loss: 0.2753 - val_auc: 0.7719 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7639 - binary_accuracy: 0.9051 - loss: 0.2722 - val_auc: 0.7703 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9051 - loss: 0.2710 - val_auc: 0.7728 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9051 - loss: 0.2694 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9051 - loss: 0.2688 - val_auc: 0.7819 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9051 - loss: 0.2689 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9051 - loss: 0.2668 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7826 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7771 - binary_accuracy: 0.9046 - loss: 0.2683\n",
      "Fold 3 Metrics: Loss = 0.2677, Accuracy = 0.9042, AUC = 0.7826\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6636 - binary_accuracy: 0.8729 - loss: 0.3319 - val_auc: 0.7745 - val_binary_accuracy: 0.9056 - val_loss: 0.2709\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9052 - loss: 0.2702 - val_auc: 0.7851 - val_binary_accuracy: 0.9073 - val_loss: 0.2644\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9067 - loss: 0.2659 - val_auc: 0.7946 - val_binary_accuracy: 0.9070 - val_loss: 0.2613\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2639 - val_auc: 0.7966 - val_binary_accuracy: 0.9081 - val_loss: 0.2593\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9081 - loss: 0.2626 - val_auc: 0.7977 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2615 - val_auc: 0.7975 - val_binary_accuracy: 0.9090 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9096 - loss: 0.2602 - val_auc: 0.7985 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9095 - loss: 0.2599 - val_auc: 0.7996 - val_binary_accuracy: 0.9079 - val_loss: 0.2582\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9101 - loss: 0.2590 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.8006 - val_binary_accuracy: 0.9075 - val_loss: 0.2589\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7793 - binary_accuracy: 0.9075 - loss: 0.2657\n",
      "Fold 4 Metrics: Loss = 0.2589, Accuracy = 0.9075, AUC = 0.8006\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6761 - binary_accuracy: 0.8716 - loss: 0.3302 - val_auc: 0.7795 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7591 - binary_accuracy: 0.9040 - loss: 0.2769 - val_auc: 0.7820 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7626 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7655 - binary_accuracy: 0.9040 - loss: 0.2747 - val_auc: 0.7855 - val_binary_accuracy: 0.9044 - val_loss: 0.2634\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7874 - val_binary_accuracy: 0.9044 - val_loss: 0.2628\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9040 - loss: 0.2734 - val_auc: 0.7876 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9040 - loss: 0.2730 - val_auc: 0.7910 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9040 - loss: 0.2724 - val_auc: 0.7899 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9040 - loss: 0.2716 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2613\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8038 - binary_accuracy: 0.9013 - loss: 0.2577\n",
      "Fold 5 Metrics: Loss = 0.2613, Accuracy = 0.9044, AUC = 0.7889\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2636\n",
      "Average Accuracy: 0.9051\n",
      "Average AUC: 0.7923\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 5, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7032 - binary_accuracy: 0.8961 - loss: 0.2951 - val_auc: 0.7677 - val_binary_accuracy: 0.9048 - val_loss: 0.2721\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9072 - loss: 0.2615 - val_auc: 0.7749 - val_binary_accuracy: 0.9060 - val_loss: 0.2691\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9086 - loss: 0.2590 - val_auc: 0.7809 - val_binary_accuracy: 0.9081 - val_loss: 0.2654\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9092 - loss: 0.2572 - val_auc: 0.7846 - val_binary_accuracy: 0.9096 - val_loss: 0.2629\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9102 - loss: 0.2556 - val_auc: 0.7846 - val_binary_accuracy: 0.9090 - val_loss: 0.2627\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9115 - loss: 0.2539 - val_auc: 0.7869 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9123 - loss: 0.2530 - val_auc: 0.7871 - val_binary_accuracy: 0.9057 - val_loss: 0.2636\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9114 - loss: 0.2519 - val_auc: 0.7886 - val_binary_accuracy: 0.9068 - val_loss: 0.2628\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9111 - loss: 0.2516 - val_auc: 0.7897 - val_binary_accuracy: 0.9053 - val_loss: 0.2629\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9111 - loss: 0.2506 - val_auc: 0.7914 - val_binary_accuracy: 0.9054 - val_loss: 0.2625\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7902 - binary_accuracy: 0.9097 - loss: 0.2552\n",
      "Fold 1 Metrics: Loss = 0.2625, Accuracy = 0.9054, AUC = 0.7914\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6903 - binary_accuracy: 0.8854 - loss: 0.3112 - val_auc: 0.7976 - val_binary_accuracy: 0.9063 - val_loss: 0.2643\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.8024 - val_binary_accuracy: 0.9066 - val_loss: 0.2615\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9061 - loss: 0.2676 - val_auc: 0.8006 - val_binary_accuracy: 0.9069 - val_loss: 0.2632\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9064 - loss: 0.2669 - val_auc: 0.8002 - val_binary_accuracy: 0.9071 - val_loss: 0.2654\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9066 - loss: 0.2657 - val_auc: 0.8015 - val_binary_accuracy: 0.9072 - val_loss: 0.2643\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8034 - val_binary_accuracy: 0.9072 - val_loss: 0.2642\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9074 - loss: 0.2638 - val_auc: 0.8030 - val_binary_accuracy: 0.9073 - val_loss: 0.2629\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9070 - loss: 0.2635 - val_auc: 0.8028 - val_binary_accuracy: 0.9075 - val_loss: 0.2632\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9086 - loss: 0.2625 - val_auc: 0.8054 - val_binary_accuracy: 0.9071 - val_loss: 0.2627\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9079 - loss: 0.2617 - val_auc: 0.8055 - val_binary_accuracy: 0.9066 - val_loss: 0.2619\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9105 - loss: 0.2510\n",
      "Fold 2 Metrics: Loss = 0.2619, Accuracy = 0.9066, AUC = 0.8055\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7101 - binary_accuracy: 0.9050 - loss: 0.2927 - val_auc: 0.7822 - val_binary_accuracy: 0.9047 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9048 - loss: 0.2738 - val_auc: 0.7888 - val_binary_accuracy: 0.9054 - val_loss: 0.2690\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7666 - binary_accuracy: 0.9057 - loss: 0.2702 - val_auc: 0.7911 - val_binary_accuracy: 0.9053 - val_loss: 0.2658\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9062 - loss: 0.2679 - val_auc: 0.7912 - val_binary_accuracy: 0.9050 - val_loss: 0.2677\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9076 - loss: 0.2678 - val_auc: 0.7939 - val_binary_accuracy: 0.9051 - val_loss: 0.2667\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9077 - loss: 0.2673 - val_auc: 0.7965 - val_binary_accuracy: 0.9056 - val_loss: 0.2669\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9078 - loss: 0.2671 - val_auc: 0.7985 - val_binary_accuracy: 0.9050 - val_loss: 0.2650\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7982 - val_binary_accuracy: 0.9053 - val_loss: 0.2640\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7990 - val_binary_accuracy: 0.9060 - val_loss: 0.2628\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.7984 - val_binary_accuracy: 0.9068 - val_loss: 0.2609\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7910 - binary_accuracy: 0.9071 - loss: 0.2620\n",
      "Fold 3 Metrics: Loss = 0.2609, Accuracy = 0.9068, AUC = 0.7984\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6462 - binary_accuracy: 0.8846 - loss: 0.3234 - val_auc: 0.7892 - val_binary_accuracy: 0.9051 - val_loss: 0.2630\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9048 - loss: 0.2695 - val_auc: 0.7938 - val_binary_accuracy: 0.9063 - val_loss: 0.2610\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9071 - loss: 0.2671 - val_auc: 0.7968 - val_binary_accuracy: 0.9066 - val_loss: 0.2605\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9065 - loss: 0.2655 - val_auc: 0.7995 - val_binary_accuracy: 0.9081 - val_loss: 0.2593\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9082 - loss: 0.2636 - val_auc: 0.7995 - val_binary_accuracy: 0.9072 - val_loss: 0.2600\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9082 - loss: 0.2631 - val_auc: 0.8012 - val_binary_accuracy: 0.9075 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8026 - val_binary_accuracy: 0.9081 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9094 - loss: 0.2609 - val_auc: 0.8039 - val_binary_accuracy: 0.9078 - val_loss: 0.2571\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9095 - loss: 0.2605 - val_auc: 0.8058 - val_binary_accuracy: 0.9091 - val_loss: 0.2566\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9097 - loss: 0.2601 - val_auc: 0.8040 - val_binary_accuracy: 0.9087 - val_loss: 0.2566\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7852 - binary_accuracy: 0.9090 - loss: 0.2631\n",
      "Fold 4 Metrics: Loss = 0.2566, Accuracy = 0.9087, AUC = 0.8040\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6929 - binary_accuracy: 0.9040 - loss: 0.2997 - val_auc: 0.7949 - val_binary_accuracy: 0.9063 - val_loss: 0.2659\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9044 - loss: 0.2725 - val_auc: 0.7987 - val_binary_accuracy: 0.9079 - val_loss: 0.2643\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.8001 - val_binary_accuracy: 0.9070 - val_loss: 0.2618\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9055 - loss: 0.2680 - val_auc: 0.8014 - val_binary_accuracy: 0.9087 - val_loss: 0.2601\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9066 - loss: 0.2669 - val_auc: 0.8017 - val_binary_accuracy: 0.9091 - val_loss: 0.2588\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9079 - loss: 0.2657 - val_auc: 0.8008 - val_binary_accuracy: 0.9098 - val_loss: 0.2579\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9080 - loss: 0.2648 - val_auc: 0.8002 - val_binary_accuracy: 0.9100 - val_loss: 0.2567\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9092 - loss: 0.2636 - val_auc: 0.8027 - val_binary_accuracy: 0.9100 - val_loss: 0.2556\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9101 - loss: 0.2626 - val_auc: 0.8026 - val_binary_accuracy: 0.9098 - val_loss: 0.2551\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9101 - loss: 0.2623 - val_auc: 0.8028 - val_binary_accuracy: 0.9098 - val_loss: 0.2546\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8165 - binary_accuracy: 0.9080 - loss: 0.2513\n",
      "Fold 5 Metrics: Loss = 0.2546, Accuracy = 0.9098, AUC = 0.8028\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2593\n",
      "Average Accuracy: 0.9075\n",
      "Average AUC: 0.8004\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 5, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6891 - binary_accuracy: 0.8898 - loss: 0.2983 - val_auc: 0.7726 - val_binary_accuracy: 0.9072 - val_loss: 0.2803\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9075 - loss: 0.2651 - val_auc: 0.7823 - val_binary_accuracy: 0.9087 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9087 - loss: 0.2590 - val_auc: 0.7844 - val_binary_accuracy: 0.9091 - val_loss: 0.2642\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9106 - loss: 0.2564 - val_auc: 0.7864 - val_binary_accuracy: 0.9096 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9111 - loss: 0.2539 - val_auc: 0.7872 - val_binary_accuracy: 0.9090 - val_loss: 0.2619\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9119 - loss: 0.2524 - val_auc: 0.7862 - val_binary_accuracy: 0.9094 - val_loss: 0.2626\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9129 - loss: 0.2518 - val_auc: 0.7882 - val_binary_accuracy: 0.9045 - val_loss: 0.2642\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9125 - loss: 0.2509 - val_auc: 0.7905 - val_binary_accuracy: 0.9073 - val_loss: 0.2626\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9136 - loss: 0.2506 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2647\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9107 - loss: 0.2519 - val_auc: 0.7902 - val_binary_accuracy: 0.9075 - val_loss: 0.2624\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7858 - binary_accuracy: 0.9106 - loss: 0.2559\n",
      "Fold 1 Metrics: Loss = 0.2624, Accuracy = 0.9075, AUC = 0.7902\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7181 - binary_accuracy: 0.9023 - loss: 0.2955 - val_auc: 0.7961 - val_binary_accuracy: 0.9053 - val_loss: 0.2736\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9028 - loss: 0.2721 - val_auc: 0.8051 - val_binary_accuracy: 0.9068 - val_loss: 0.2648\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9057 - loss: 0.2683 - val_auc: 0.8043 - val_binary_accuracy: 0.9084 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9067 - loss: 0.2666 - val_auc: 0.8036 - val_binary_accuracy: 0.9079 - val_loss: 0.2644\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9073 - loss: 0.2655 - val_auc: 0.8086 - val_binary_accuracy: 0.9081 - val_loss: 0.2640\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9073 - loss: 0.2638 - val_auc: 0.8096 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9073 - loss: 0.2626 - val_auc: 0.8102 - val_binary_accuracy: 0.9088 - val_loss: 0.2659\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9079 - loss: 0.2626 - val_auc: 0.8104 - val_binary_accuracy: 0.9088 - val_loss: 0.2678\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9085 - loss: 0.2625 - val_auc: 0.8103 - val_binary_accuracy: 0.9081 - val_loss: 0.2677\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9080 - loss: 0.2617 - val_auc: 0.8116 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8177 - binary_accuracy: 0.9127 - loss: 0.2547\n",
      "Fold 2 Metrics: Loss = 0.2636, Accuracy = 0.9082, AUC = 0.8116\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7121 - binary_accuracy: 0.8868 - loss: 0.2975 - val_auc: 0.7902 - val_binary_accuracy: 0.9047 - val_loss: 0.2664\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7666 - binary_accuracy: 0.9064 - loss: 0.2697 - val_auc: 0.7958 - val_binary_accuracy: 0.9066 - val_loss: 0.2655\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9070 - loss: 0.2679 - val_auc: 0.7986 - val_binary_accuracy: 0.9063 - val_loss: 0.2666\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9073 - loss: 0.2676 - val_auc: 0.7986 - val_binary_accuracy: 0.9081 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9070 - loss: 0.2690 - val_auc: 0.8012 - val_binary_accuracy: 0.9103 - val_loss: 0.2637\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9081 - loss: 0.2668 - val_auc: 0.8016 - val_binary_accuracy: 0.9093 - val_loss: 0.2650\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9078 - loss: 0.2664 - val_auc: 0.8017 - val_binary_accuracy: 0.9096 - val_loss: 0.2656\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.8025 - val_binary_accuracy: 0.9071 - val_loss: 0.2665\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9085 - loss: 0.2641 - val_auc: 0.8029 - val_binary_accuracy: 0.9057 - val_loss: 0.2660\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8027 - val_binary_accuracy: 0.9079 - val_loss: 0.2643\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7951 - binary_accuracy: 0.9082 - loss: 0.2656\n",
      "Fold 3 Metrics: Loss = 0.2643, Accuracy = 0.9079, AUC = 0.8027\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7232 - binary_accuracy: 0.8964 - loss: 0.2925 - val_auc: 0.7937 - val_binary_accuracy: 0.9064 - val_loss: 0.2670\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.7957 - val_binary_accuracy: 0.9056 - val_loss: 0.2658\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.7972 - val_binary_accuracy: 0.9050 - val_loss: 0.2676\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9081 - loss: 0.2639 - val_auc: 0.7979 - val_binary_accuracy: 0.9075 - val_loss: 0.2663\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7977 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9093 - loss: 0.2621 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2655\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9095 - loss: 0.2618 - val_auc: 0.7987 - val_binary_accuracy: 0.9082 - val_loss: 0.2629\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9099 - loss: 0.2612 - val_auc: 0.8001 - val_binary_accuracy: 0.9100 - val_loss: 0.2613\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2607 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2627\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9094 - loss: 0.2601 - val_auc: 0.8002 - val_binary_accuracy: 0.9095 - val_loss: 0.2606\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7807 - binary_accuracy: 0.9091 - loss: 0.2699\n",
      "Fold 4 Metrics: Loss = 0.2606, Accuracy = 0.9095, AUC = 0.8002\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7040 - binary_accuracy: 0.9036 - loss: 0.2973 - val_auc: 0.7878 - val_binary_accuracy: 0.9067 - val_loss: 0.2627\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9041 - loss: 0.2760 - val_auc: 0.7976 - val_binary_accuracy: 0.9075 - val_loss: 0.2586\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9063 - loss: 0.2704 - val_auc: 0.8002 - val_binary_accuracy: 0.9095 - val_loss: 0.2600\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9072 - loss: 0.2676 - val_auc: 0.8030 - val_binary_accuracy: 0.9101 - val_loss: 0.2597\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9077 - loss: 0.2663 - val_auc: 0.8040 - val_binary_accuracy: 0.9088 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8047 - val_binary_accuracy: 0.9103 - val_loss: 0.2597\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9083 - loss: 0.2642 - val_auc: 0.8050 - val_binary_accuracy: 0.9104 - val_loss: 0.2570\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9092 - loss: 0.2633 - val_auc: 0.8059 - val_binary_accuracy: 0.9107 - val_loss: 0.2574\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9081 - loss: 0.2634 - val_auc: 0.8061 - val_binary_accuracy: 0.9107 - val_loss: 0.2583\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9080 - loss: 0.2637 - val_auc: 0.8035 - val_binary_accuracy: 0.9094 - val_loss: 0.2575\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9094 - loss: 0.2534\n",
      "Fold 5 Metrics: Loss = 0.2575, Accuracy = 0.9094, AUC = 0.8035\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2617\n",
      "Average Accuracy: 0.9085\n",
      "Average AUC: 0.8017\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 5, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6891 - binary_accuracy: 0.8859 - loss: 0.3075 - val_auc: 0.7797 - val_binary_accuracy: 0.9102 - val_loss: 0.2736\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9080 - loss: 0.2624 - val_auc: 0.7868 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9064 - loss: 0.2611 - val_auc: 0.7890 - val_binary_accuracy: 0.9103 - val_loss: 0.2617\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9092 - loss: 0.2579 - val_auc: 0.7894 - val_binary_accuracy: 0.9119 - val_loss: 0.2606\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9115 - loss: 0.2552 - val_auc: 0.7902 - val_binary_accuracy: 0.9103 - val_loss: 0.2633\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9114 - loss: 0.2541 - val_auc: 0.7910 - val_binary_accuracy: 0.9094 - val_loss: 0.2605\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9092 - loss: 0.2569 - val_auc: 0.7927 - val_binary_accuracy: 0.9118 - val_loss: 0.2637\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9124 - loss: 0.2555 - val_auc: 0.7904 - val_binary_accuracy: 0.9066 - val_loss: 0.2643\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9109 - loss: 0.2542 - val_auc: 0.7875 - val_binary_accuracy: 0.9088 - val_loss: 0.2627\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9115 - loss: 0.2561 - val_auc: 0.7898 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7844 - binary_accuracy: 0.9113 - loss: 0.2558\n",
      "Fold 1 Metrics: Loss = 0.2631, Accuracy = 0.9082, AUC = 0.7898\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6904 - binary_accuracy: 0.8845 - loss: 0.3209 - val_auc: 0.8003 - val_binary_accuracy: 0.9060 - val_loss: 0.2667\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9040 - loss: 0.2722 - val_auc: 0.8018 - val_binary_accuracy: 0.9081 - val_loss: 0.2638\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9057 - loss: 0.2689 - val_auc: 0.8025 - val_binary_accuracy: 0.9081 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9071 - loss: 0.2676 - val_auc: 0.8006 - val_binary_accuracy: 0.9078 - val_loss: 0.2662\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9071 - loss: 0.2675 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2649\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9057 - loss: 0.2692 - val_auc: 0.8060 - val_binary_accuracy: 0.9066 - val_loss: 0.2660\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9050 - loss: 0.2675 - val_auc: 0.7934 - val_binary_accuracy: 0.9088 - val_loss: 0.2690\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9057 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9096 - val_loss: 0.2650\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9070 - loss: 0.2656 - val_auc: 0.7989 - val_binary_accuracy: 0.9091 - val_loss: 0.2674\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9078 - loss: 0.2650 - val_auc: 0.8125 - val_binary_accuracy: 0.9094 - val_loss: 0.2620\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8172 - binary_accuracy: 0.9135 - loss: 0.2530\n",
      "Fold 2 Metrics: Loss = 0.2620, Accuracy = 0.9094, AUC = 0.8125\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6702 - binary_accuracy: 0.8862 - loss: 0.3217 - val_auc: 0.7878 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9043 - loss: 0.2728 - val_auc: 0.7924 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7658 - binary_accuracy: 0.9055 - loss: 0.2699 - val_auc: 0.7955 - val_binary_accuracy: 0.9078 - val_loss: 0.2668\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9063 - loss: 0.2700 - val_auc: 0.7952 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9053 - loss: 0.2719 - val_auc: 0.7937 - val_binary_accuracy: 0.9042 - val_loss: 0.2637\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9053 - loss: 0.2716 - val_auc: 0.7965 - val_binary_accuracy: 0.9093 - val_loss: 0.2663\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9075 - loss: 0.2690 - val_auc: 0.7963 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7640 - binary_accuracy: 0.9072 - loss: 0.2703 - val_auc: 0.7961 - val_binary_accuracy: 0.9090 - val_loss: 0.2607\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7630 - binary_accuracy: 0.9089 - loss: 0.2683 - val_auc: 0.7968 - val_binary_accuracy: 0.9066 - val_loss: 0.2639\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9077 - loss: 0.2685 - val_auc: 0.7962 - val_binary_accuracy: 0.9104 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7872 - binary_accuracy: 0.9115 - loss: 0.2634\n",
      "Fold 3 Metrics: Loss = 0.2635, Accuracy = 0.9104, AUC = 0.7962\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6836 - binary_accuracy: 0.9007 - loss: 0.3080 - val_auc: 0.7859 - val_binary_accuracy: 0.9056 - val_loss: 0.2716\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9044 - loss: 0.2734 - val_auc: 0.7899 - val_binary_accuracy: 0.9032 - val_loss: 0.2683\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9053 - loss: 0.2704 - val_auc: 0.7958 - val_binary_accuracy: 0.9087 - val_loss: 0.2708\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9059 - loss: 0.2687 - val_auc: 0.7993 - val_binary_accuracy: 0.8992 - val_loss: 0.2815\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9067 - loss: 0.2706 - val_auc: 0.7954 - val_binary_accuracy: 0.9085 - val_loss: 0.2641\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9078 - loss: 0.2652 - val_auc: 0.7958 - val_binary_accuracy: 0.9072 - val_loss: 0.2635\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9092 - loss: 0.2649 - val_auc: 0.7956 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9088 - loss: 0.2632 - val_auc: 0.7937 - val_binary_accuracy: 0.9051 - val_loss: 0.2675\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9092 - loss: 0.2638 - val_auc: 0.7939 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9088 - loss: 0.2671 - val_auc: 0.7916 - val_binary_accuracy: 0.9084 - val_loss: 0.2619\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7694 - binary_accuracy: 0.9085 - loss: 0.2711\n",
      "Fold 4 Metrics: Loss = 0.2619, Accuracy = 0.9084, AUC = 0.7916\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6762 - binary_accuracy: 0.8851 - loss: 0.3195 - val_auc: 0.7930 - val_binary_accuracy: 0.9084 - val_loss: 0.2611\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7539 - binary_accuracy: 0.9025 - loss: 0.2790 - val_auc: 0.7988 - val_binary_accuracy: 0.9075 - val_loss: 0.2572\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9053 - loss: 0.2720 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9058 - loss: 0.2698 - val_auc: 0.8034 - val_binary_accuracy: 0.9097 - val_loss: 0.2588\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9063 - loss: 0.2684 - val_auc: 0.8045 - val_binary_accuracy: 0.9104 - val_loss: 0.2573\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9067 - loss: 0.2668 - val_auc: 0.8047 - val_binary_accuracy: 0.9098 - val_loss: 0.2571\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9097 - loss: 0.2655 - val_auc: 0.8072 - val_binary_accuracy: 0.9044 - val_loss: 0.2556\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9072 - loss: 0.2654 - val_auc: 0.8057 - val_binary_accuracy: 0.9101 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9071 - loss: 0.2701 - val_auc: 0.8062 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9090 - loss: 0.2655 - val_auc: 0.8044 - val_binary_accuracy: 0.9098 - val_loss: 0.2548\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8136 - binary_accuracy: 0.9076 - loss: 0.2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [1:22:51<00:00, 1657.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Metrics: Loss = 0.2548, Accuracy = 0.9098, AUC = 0.8044\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2610\n",
      "Average Accuracy: 0.9093\n",
      "Average AUC: 0.7989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# setting a seed\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# defining options\n",
    "hidden_layer_configs = [1,2,3,4,5]\n",
    "activation_config = ['relu', 'sigmoid', 'tanh']\n",
    "node_configs = [16, 32, 64, 128, 256]\n",
    "\n",
    "comparison_list = []\n",
    "comparison_df_new = pd.DataFrame()\n",
    "\n",
    "# training models\n",
    "with tf.device('/GPU:0'):\n",
    "    for activation in tqdm.tqdm(activation_config):\n",
    "        for hl in hidden_layer_configs:\n",
    "            for nodes in node_configs:\n",
    "                print(\"-\"*40)\n",
    "                print(f\"Performing training for: {activation, hl, nodes}\")\n",
    "                print(\"-\"*40)\n",
    "                # train model\n",
    "                fold_loss, fold_accuracies, fold_aucs, _ = k_fold_cross_validation(hl=hl, nodes=nodes, activation=activation, epochs = 10)\n",
    "                # store output\n",
    "                comparison_list.append((activation, hl, nodes, fold_loss, fold_accuracies, fold_aucs))\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_list)\n",
    "comparison_df.to_csv(\"/content/drive/MyDrive/Data Analytics/Assignments/Group Project/model_comparison_five_fold_strat.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "anByv4R4hb0V",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1764608414251,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "anByv4R4hb0V"
   },
   "outputs": [],
   "source": [
    "comparison_df = pd.read_csv(\"/content/drive/MyDrive/Data Analytics/Assignments/Group Project/model_comparison_five_fold.csv\")\n",
    "comparison_df.columns = [\"act\", \"hl\", \"nodes\", \"loss\", \"acc\", \"auc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VmycvIWdhuWE",
   "metadata": {
    "executionInfo": {
     "elapsed": 42974,
     "status": "aborted",
     "timestamp": 1764598363404,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "VmycvIWdhuWE"
   },
   "outputs": [],
   "source": [
    "comparison_df[\"avg_loss\"] = comparison_df[\"loss\"].apply(lambda x: np.mean(ast.literal_eval(x)))\n",
    "comparison_df[\"avg_acc\"] = comparison_df[\"acc\"].apply(lambda x: np.mean(ast.literal_eval(x)))\n",
    "comparison_df[\"avg_auc\"] = comparison_df[\"auc\"].apply(lambda x: np.mean(ast.literal_eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "jVC4AixTiKlo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1764608414288,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "jVC4AixTiKlo",
    "outputId": "b8215659-5f4f-496f-88e6-4f14cf1413ab"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"act\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"relu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nodes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85,\n        \"min\": 64,\n        \"max\": 256,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0.31858211755752563, 0.36027613282203674, 0.25885921716690063, 0.25837039947509766, 0.2512544095516205]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0.9083800315856934, 0.8490705490112305, 0.9091177582740784, 0.9052678346633911, 0.9107274413108826]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0.7873588800430298, 0.81210857629776, 0.7963587045669556, 0.810806930065155, 0.8128728270530701]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007085299939217751,\n        \"min\": 0.2765244722366333,\n        \"max\": 0.29502456188201903,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2894684553146362\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0021013830792327172,\n        \"min\": 0.8942399024963379,\n        \"max\": 0.8998175263404846,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8965127229690552\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007605461845128445,\n        \"min\": 0.8024112820625305,\n        \"max\": 0.8039302110671998,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8039011836051941\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-93ee67a0-0bb2-4324-9dc7-4f540edec123\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>hl</th>\n",
       "      <th>nodes</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_acc</th>\n",
       "      <th>avg_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>[0.30871862173080444, 0.343106210231781, 0.261...</td>\n",
       "      <td>[0.9092652797698975, 0.8623487949371338, 0.909...</td>\n",
       "      <td>[0.7868945002555847, 0.8111099600791931, 0.796...</td>\n",
       "      <td>0.295025</td>\n",
       "      <td>0.894240</td>\n",
       "      <td>0.803930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>[0.31858211755752563, 0.36027613282203674, 0.2...</td>\n",
       "      <td>[0.9083800315856934, 0.8490705490112305, 0.909...</td>\n",
       "      <td>[0.7873588800430298, 0.81210857629776, 0.79635...</td>\n",
       "      <td>0.289468</td>\n",
       "      <td>0.896513</td>\n",
       "      <td>0.803901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.3157957196235657, 0.36118727922439575, 0.25...</td>\n",
       "      <td>[0.9079374670982361, 0.8591029644012451, 0.909...</td>\n",
       "      <td>[0.7880730032920837, 0.809856116771698, 0.7958...</td>\n",
       "      <td>0.292142</td>\n",
       "      <td>0.897191</td>\n",
       "      <td>0.802667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>[0.26953381299972534, 0.33885297179222107, 0.2...</td>\n",
       "      <td>[0.9117733836174011, 0.8619061708450317, 0.909...</td>\n",
       "      <td>[0.7870328426361084, 0.8068638443946838, 0.797...</td>\n",
       "      <td>0.276524</td>\n",
       "      <td>0.899818</td>\n",
       "      <td>0.802533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>[0.295051246881485, 0.37400567531585693, 0.262...</td>\n",
       "      <td>[0.9097079038619995, 0.8436116576194763, 0.908...</td>\n",
       "      <td>[0.7852222919464111, 0.811111330986023, 0.7942...</td>\n",
       "      <td>0.289289</td>\n",
       "      <td>0.895421</td>\n",
       "      <td>0.802411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93ee67a0-0bb2-4324-9dc7-4f540edec123')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-93ee67a0-0bb2-4324-9dc7-4f540edec123 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-93ee67a0-0bb2-4324-9dc7-4f540edec123');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-c1d25a33-d43d-4bbd-899d-0cce84d6c59f\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1d25a33-d43d-4bbd-899d-0cce84d6c59f')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-c1d25a33-d43d-4bbd-899d-0cce84d6c59f button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    act  hl  nodes                                               loss  \\\n",
       "3  relu   1    128  [0.30871862173080444, 0.343106210231781, 0.261...   \n",
       "4  relu   1    256  [0.31858211755752563, 0.36027613282203674, 0.2...   \n",
       "2  relu   1     64  [0.3157957196235657, 0.36118727922439575, 0.25...   \n",
       "9  relu   2    256  [0.26953381299972534, 0.33885297179222107, 0.2...   \n",
       "8  relu   2    128  [0.295051246881485, 0.37400567531585693, 0.262...   \n",
       "\n",
       "                                                 acc  \\\n",
       "3  [0.9092652797698975, 0.8623487949371338, 0.909...   \n",
       "4  [0.9083800315856934, 0.8490705490112305, 0.909...   \n",
       "2  [0.9079374670982361, 0.8591029644012451, 0.909...   \n",
       "9  [0.9117733836174011, 0.8619061708450317, 0.909...   \n",
       "8  [0.9097079038619995, 0.8436116576194763, 0.908...   \n",
       "\n",
       "                                                 auc  avg_loss   avg_acc  \\\n",
       "3  [0.7868945002555847, 0.8111099600791931, 0.796...  0.295025  0.894240   \n",
       "4  [0.7873588800430298, 0.81210857629776, 0.79635...  0.289468  0.896513   \n",
       "2  [0.7880730032920837, 0.809856116771698, 0.7958...  0.292142  0.897191   \n",
       "9  [0.7870328426361084, 0.8068638443946838, 0.797...  0.276524  0.899818   \n",
       "8  [0.7852222919464111, 0.811111330986023, 0.7942...  0.289289  0.895421   \n",
       "\n",
       "    avg_auc  \n",
       "3  0.803930  \n",
       "4  0.803901  \n",
       "2  0.802667  \n",
       "9  0.802533  \n",
       "8  0.802411  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.sort_values(by = [\"avg_auc\", \"avg_acc\"], ascending = [False, False]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8djlZJci05oD",
   "metadata": {
    "id": "8djlZJci05oD"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "099hWGV8z_NF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6296,
     "status": "ok",
     "timestamp": 1764608420597,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "099hWGV8z_NF",
    "outputId": "456d3d88-1527-4f5e-e3c4-b190d3571e18"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# setting a seed\u001b[39;00m\n\u001b[32m      2\u001b[39m seed = \u001b[32m123\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mrandom\u001b[49m.seed(seed)\n\u001b[32m      5\u001b[39m np.random.seed(seed)\n\u001b[32m      6\u001b[39m tf.random.set_seed(seed)\n",
      "\u001b[31mNameError\u001b[39m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "# setting a seed\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# confusion matrix\n",
    "best_model, _, _ = train_and_evaluate_model(hl = 1, nodes = 128, activation = \"relu\", epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C8eXy1kl1JHA",
   "metadata": {
    "executionInfo": {
     "elapsed": 42970,
     "status": "aborted",
     "timestamp": 1764598363406,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "C8eXy1kl1JHA"
   },
   "outputs": [],
   "source": [
    "pred_probs = best_model.predict(test_x)\n",
    "y_pred = (pred_probs > 0.2).astype(int)   # convert probabilities to 0/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KJlC_Hkyc6z7",
   "metadata": {
    "id": "KJlC_Hkyc6z7"
   },
   "source": [
    "### **Confusion matrix**\n",
    "\n",
    "*I am not sure, if that is the right way to evaluate it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YsY-yaAP1ZY4",
   "metadata": {
    "executionInfo": {
     "elapsed": 42967,
     "status": "aborted",
     "timestamp": 1764598363407,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "YsY-yaAP1ZY4"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_y, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qDmVlbUk55H8",
   "metadata": {
    "id": "qDmVlbUk55H8"
   },
   "source": [
    "# Evaluating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PU1dLc8tOpDv",
   "metadata": {
    "executionInfo": {
     "elapsed": 42964,
     "status": "aborted",
     "timestamp": 1764598363407,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "PU1dLc8tOpDv"
   },
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame(pred_probs, test_y).reset_index()\n",
    "evaluation.columns = [\"outcome\", \"pred_prob\"]\n",
    "\n",
    "model_probs = np.linspace(0.025, 0.975, num = 20)\n",
    "true_probs = []\n",
    "\n",
    "for prob in model_probs:\n",
    "    true_probs.append(evaluation[(evaluation[\"pred_prob\"] >= prob -0.025) & (evaluation[\"pred_prob\"] <= prob + 0.025)][\"outcome\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79YcRuXWCxu",
   "metadata": {
    "id": "b79YcRuXWCxu"
   },
   "source": [
    "There is no predicted probs above 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "AbkHeuuDVlB9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 111,
     "status": "ok",
     "timestamp": 1764608421711,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "AbkHeuuDVlB9",
    "outputId": "ec039f13-50e9-4bd1-daf0-1ee31a81c790"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_probs = np.linspace(0,1.01, num = 10)\n",
    "\n",
    "plt.plot(model_probs, true_probs, color = \"red\", marker='.', label = \"Model line\")\n",
    "plt.plot(plot_probs, plot_probs, alpha = 0.5, color = \"blue\", label = \"Ideal line\")\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "#plt.axvspan(0.9, 1, alpha=0.1, label = \"No shots with prob > 0.9\", color = \"red\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Model Probability\")\n",
    "plt.ylabel(\"True Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OAKQKJOWcV4E",
   "metadata": {
    "id": "OAKQKJOWcV4E"
   },
   "source": [
    "## Isometric regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "if5vt00o6GhD",
   "metadata": {
    "executionInfo": {
     "elapsed": 42960,
     "status": "aborted",
     "timestamp": 1764598363408,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "if5vt00o6GhD"
   },
   "outputs": [],
   "source": [
    "f_X = football_df.drop(\"shot_outcome_encoded\", axis = 1)\n",
    "f_y = football_df[\"shot_outcome_encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "iGAzQ_k86GhD",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1764608421823,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "iGAzQ_k86GhD"
   },
   "outputs": [],
   "source": [
    "# setting a seed\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# splitting the data\n",
    "f_train_x, f_test_x , f_train_y, f_test_y = train_test_split(\n",
    "    f_X, f_y,\n",
    "    test_size = 0.25,\n",
    "    random_state= 123,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WeezwtfN5_n-",
   "metadata": {
    "executionInfo": {
     "elapsed": 42990,
     "status": "aborted",
     "timestamp": 1764598363442,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "WeezwtfN5_n-"
   },
   "outputs": [],
   "source": [
    "# checking that both are the same\n",
    "sum(f_test_y == test_y.numpy()) == len(test_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2lURL85k6aQj",
   "metadata": {
    "executionInfo": {
     "elapsed": 42989,
     "status": "aborted",
     "timestamp": 1764598363443,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "2lURL85k6aQj"
   },
   "outputs": [],
   "source": [
    "# comparing statsbomb and our expected goal probabilities\n",
    "test = pd.concat([f_test_x[\"shot_statsbomb_xg\"].reset_index(), pd.DataFrame(pred_probs).reset_index()], axis = 1, ignore_index=True).drop([0,2], axis = 1)\n",
    "test.columns = [\"shot_statsbomb_xg\", \"pred_prob\"]\n",
    "test[\"diff\"] = test[\"shot_statsbomb_xg\"] - test[\"pred_prob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "Ie9x1trc7NDN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1764608421952,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "Ie9x1trc7NDN",
    "outputId": "217473aa-fc44-46fb-90d5-d3ab8d08eb5c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_i_r = sk_i.IsotonicRegression().fit(test[\"shot_statsbomb_xg\"], evaluation[\"outcome\"])\n",
    "i_r = sk_i.IsotonicRegression().fit(evaluation[\"pred_prob\"], evaluation[\"outcome\"])\n",
    "\n",
    "model_probs = np.linspace(0, 1, num=100)\n",
    "\n",
    "calibrated_probs = i_r.predict(model_probs)\n",
    "f_calibrated_probs = f_i_r.predict(model_probs)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot([0, 1], [0, 1])\n",
    "\n",
    "plt.plot(model_probs, f_calibrated_probs, color='black', alpha = 0.3, label = \"Statsb. perf.\")\n",
    "plt.plot(model_probs, calibrated_probs, color='red', label = \"Model perf.\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Model probability')\n",
    "plt.ylabel('Calibrated probability')\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fXcppND6-BxP",
   "metadata": {
    "id": "fXcppND6-BxP"
   },
   "source": [
    "## AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eqGunzpG7hI2",
   "metadata": {
    "executionInfo": {
     "elapsed": 42987,
     "status": "aborted",
     "timestamp": 1764598363446,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "eqGunzpG7hI2"
   },
   "outputs": [],
   "source": [
    "# Calculate AUC\n",
    "auc = roc_auc_score(test_y, pred_probs)\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_y, pred_probs)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ct1Lf38D-HWy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1764608422772,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "ct1Lf38D-HWy",
    "outputId": "e6c00892-7581-4f77-c1c0-27a1ea147d72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.4956\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate AUC\n",
    "auc = roc_auc_score(test_y, test[\"shot_statsbomb_xg\"])\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_y, test[\"shot_statsbomb_xg\"])\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr, tpr, color='black', label=f'SB ROC Curve (AUC = {auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
