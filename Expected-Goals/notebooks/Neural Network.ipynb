{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba190db",
   "metadata": {
    "id": "4ba190db"
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133e8d59",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1764598320594,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "133e8d59"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import ast\n",
    "import math\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import sklearn.isotonic as sk_i\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea16aa4",
   "metadata": {
    "id": "2ea16aa4"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6SMrbzowm2VT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31226,
     "status": "ok",
     "timestamp": 1764598351832,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "6SMrbzowm2VT",
    "outputId": "e9044ba9-076a-40d7-b567-d1f2514dc59f"
   },
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "RAW_DIR = DATA_DIR / \"raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df62e30",
   "metadata": {
    "executionInfo": {
     "elapsed": 8693,
     "status": "ok",
     "timestamp": 1764598360528,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "4df62e30"
   },
   "outputs": [],
   "source": [
    "football_df = pd.read_pickle(PROCESSED_DIR / \"football_processed.pickle\")\n",
    "football_model_df = pd.read_pickle(PROCESSED_DIR / \"football_model_processed.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985d459",
   "metadata": {
    "id": "0985d459"
   },
   "source": [
    "# Looking at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a635472",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1764598360544,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "8a635472",
    "outputId": "411cfd5f-d9e1-41ee-f4e8-c0420e758dc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['under_pressure', 'shot_open_goal', 'shot_first_time',\n",
       "       'shot_one_on_one', 'shot_outcome_encoded', 'player_x', 'player_y',\n",
       "       'distance_from_goal_center', 'distance_from_goal_left_post',\n",
       "       'distance_from_goal_right_post', 'body_part_head', 'body_part_other',\n",
       "       'body_part_foot', 'shot_technique_backheel',\n",
       "       'shot_technique_diving_header', 'shot_technique_half_volley',\n",
       "       'shot_technique_lob', 'shot_technique_normal',\n",
       "       'shot_technique_overhead_kick', 'shot_technique_volley',\n",
       "       'play_pattern_from_corner', 'play_pattern_from_counter',\n",
       "       'play_pattern_from_free_kick', 'play_pattern_from_goal_kick',\n",
       "       'play_pattern_from_keeper', 'play_pattern_from_kick_off',\n",
       "       'play_pattern_from_throw_in', 'play_pattern_other',\n",
       "       'play_pattern_regular_play', 'shot_type_free_kick',\n",
       "       'shot_type_open_play', 'goalkeeper_x', 'goalkeeper_y',\n",
       "       'gk_distance_from_goal_center', 'gk_distance_from_goal_left_post',\n",
       "       'gk_distance_from_goal_right_post', 'shot_angle', 'distance_player_gk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "football_model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8178d6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2769,
     "status": "ok",
     "timestamp": 1764598363314,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "c8178d6f",
    "outputId": "e51b6636-08dc-43cd-fafa-5c0f85b02580"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 12))  # increase figure size\n",
    "sns.heatmap(football_model_df.corr(), annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d05b33",
   "metadata": {
    "id": "82d05b33"
   },
   "source": [
    "# Preparing Data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125e8733",
   "metadata": {
    "id": "125e8733"
   },
   "source": [
    "Splitting train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df5f83e",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1764598363330,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "9df5f83e"
   },
   "outputs": [],
   "source": [
    "X = football_model_df.drop(\"shot_outcome_encoded\", axis = 1)\n",
    "y = football_model_df[\"shot_outcome_encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1751dd9",
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1764598384210,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "b1751dd9"
   },
   "outputs": [],
   "source": [
    "# setting a seed\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# splitting the data\n",
    "train_x, test_x , train_y, test_y = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.25,\n",
    "    random_state= 123,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Mtm5jifSmwde",
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1764598388320,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "Mtm5jifSmwde"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = tf.convert_to_tensor(train_x, dtype=tf.float32), tf.convert_to_tensor(train_y, dtype=tf.float32)\n",
    "test_x, test_y = tf.convert_to_tensor(test_x, dtype=tf.float32), tf.convert_to_tensor(test_y, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aa2fa6",
   "metadata": {
    "id": "91aa2fa6"
   },
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-87hAuFrDlr8",
   "metadata": {
    "id": "-87hAuFrDlr8"
   },
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d253ea",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1764598388322,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "56d253ea"
   },
   "outputs": [],
   "source": [
    "def build_model(hl: int = 1, nodes: int = 32, activation: str = 'relu', epochs: int = 5, batches: int = 100):\n",
    "\n",
    "    # initiating model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # adding input layer\n",
    "    model.add(Input(shape=(37,), name = \"Input_Layer\")) # 37 input columns\n",
    "\n",
    "    # adding hidden layers\n",
    "    for i in range(hl):\n",
    "        model.add(Dense(units = nodes, activation = activation, name = f\"HL_{i+1}\"))\n",
    "\n",
    "    # add output layer\n",
    "    model.add(Dense(units = 1, activation = \"sigmoid\", name = \"Output_Layer\"))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"binary_accuracy\", tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "189d9dad",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1764598390008,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "189d9dad"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(hl: int = 1,\n",
    "                             nodes: int = 32,\n",
    "                             activation: str = 'relu',\n",
    "                             epochs: int = 5,\n",
    "                             batches: int = 100,\n",
    "                             train_x = train_x,\n",
    "                             train_y = train_y,\n",
    "                             test_x = test_x,\n",
    "                             test_y = test_y\n",
    "                             ):\n",
    "\n",
    "    model = build_model(hl, nodes, activation, epochs, batches)\n",
    "\n",
    "    # training the model\n",
    "    history = model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        epochs = epochs,\n",
    "        batch_size = batches,\n",
    "        validation_data = (test_x, test_y),\n",
    "        verbose = 1\n",
    "    )\n",
    "\n",
    "    # getting accuracies\n",
    "    eval_accuracies = model.evaluate(test_x, test_y)\n",
    "\n",
    "    return model, history, eval_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "XvGeXqOLDr-k",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1764598391336,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "XvGeXqOLDr-k"
   },
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(hl: int = 1,\n",
    "                            nodes: int = 32,\n",
    "                            activation: str = 'relu',\n",
    "                            epochs: int = 5,\n",
    "                            batches: int = 100,\n",
    "                            k: int = 5,\n",
    "                            train_x = train_x,\n",
    "                            train_y = train_y\n",
    "                            ):\n",
    "\n",
    "    # set seed\n",
    "    seed = 123\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # Initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Create empty lists to store metrics from each fold\n",
    "    fold_losses = []\n",
    "    fold_accuracies = []\n",
    "    fold_aucs = []\n",
    "\n",
    "    # Convert train_x and train_y to numpy for StratifiedKFold\n",
    "    train_x_np = train_x.numpy()\n",
    "    train_y_np = train_y.numpy()\n",
    "\n",
    "    # Loop through the splits\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(train_x_np, train_y_np)):\n",
    "        print(f\"\\n--- Starting Fold {fold+1}/{k} ---\")\n",
    "\n",
    "        # Create training and validation datasets for the current fold\n",
    "        fold_train_x = train_x_np[train_index]\n",
    "        fold_train_y = train_y_np[train_index]\n",
    "        fold_val_x = train_x_np[val_index]\n",
    "        fold_val_y = train_y_np[val_index]\n",
    "\n",
    "        # Convert to TensorFlow tensors\n",
    "        fold_train_x = tf.convert_to_tensor(fold_train_x, dtype=tf.float32)\n",
    "        fold_train_y = tf.convert_to_tensor(fold_train_y, dtype=tf.float32)\n",
    "        fold_val_x = tf.convert_to_tensor(fold_val_x, dtype=tf.float32)\n",
    "        fold_val_y = tf.convert_to_tensor(fold_val_y, dtype=tf.float32)\n",
    "\n",
    "        # Train and evaluate the model for the current fold\n",
    "        model, history, eval_accuracies = train_and_evaluate_model(\n",
    "            hl=hl,\n",
    "            nodes=nodes,\n",
    "            activation=activation,\n",
    "            epochs=epochs,\n",
    "            batches=batches,\n",
    "            train_x=fold_train_x,\n",
    "            train_y=fold_train_y,\n",
    "            test_x=fold_val_x,\n",
    "            test_y=fold_val_y\n",
    "        )\n",
    "\n",
    "        # eval_accuracies contains [loss, binary_accuracy, auc]\n",
    "        fold_losses.append(eval_accuracies[0])\n",
    "        fold_accuracies.append(eval_accuracies[1])\n",
    "        fold_aucs.append(eval_accuracies[2])\n",
    "\n",
    "        print(f\"Fold {fold+1} Metrics: Loss = {eval_accuracies[0]:.4f}, Accuracy = {eval_accuracies[1]:.4f}, AUC = {eval_accuracies[2]:.4f}\")\n",
    "\n",
    "    print(\"\\n--- K-Fold Cross-Validation Complete ---\")\n",
    "    print(f\"Average Loss: {np.mean(fold_losses):.4f}\")\n",
    "    print(f\"Average Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
    "    print(f\"Average AUC: {np.mean(fold_aucs):.4f}\")\n",
    "\n",
    "    return fold_losses, fold_accuracies, fold_aucs, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4BBxgx0XgUrf",
   "metadata": {
    "id": "4BBxgx0XgUrf"
   },
   "source": [
    "# Looking at Training results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XIXijxpkDoEN",
   "metadata": {
    "id": "XIXijxpkDoEN"
   },
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "FD-pBaOOGhGY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1785957,
     "status": "ok",
     "timestamp": 1764608414036,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "FD-pBaOOGhGY",
    "outputId": "263c70df-0c15-4a58-f2f4-190631a56439"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Performing training for: ('relu', 1, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6250 - binary_accuracy: 0.7419 - loss: 2.9174 - val_auc: 0.7233 - val_binary_accuracy: 0.9023 - val_loss: 0.2893\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7684 - binary_accuracy: 0.8985 - loss: 0.2768 - val_auc: 0.7710 - val_binary_accuracy: 0.9034 - val_loss: 0.2737\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7898 - binary_accuracy: 0.9029 - loss: 0.2642 - val_auc: 0.7802 - val_binary_accuracy: 0.9062 - val_loss: 0.2763\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7945 - binary_accuracy: 0.9060 - loss: 0.2605 - val_auc: 0.7825 - val_binary_accuracy: 0.9068 - val_loss: 0.2724\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7973 - binary_accuracy: 0.9079 - loss: 0.2581 - val_auc: 0.7835 - val_binary_accuracy: 0.9072 - val_loss: 0.2663\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7994 - binary_accuracy: 0.9098 - loss: 0.2565 - val_auc: 0.7842 - val_binary_accuracy: 0.9066 - val_loss: 0.2645\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9096 - loss: 0.2557 - val_auc: 0.7851 - val_binary_accuracy: 0.9069 - val_loss: 0.2665\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9101 - loss: 0.2554 - val_auc: 0.7856 - val_binary_accuracy: 0.9054 - val_loss: 0.2695\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9103 - loss: 0.2554 - val_auc: 0.7869 - val_binary_accuracy: 0.9056 - val_loss: 0.2700\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7983 - binary_accuracy: 0.9108 - loss: 0.2551 - val_auc: 0.7872 - val_binary_accuracy: 0.9059 - val_loss: 0.2692\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7845 - binary_accuracy: 0.9087 - loss: 0.2646\n",
      "Fold 1 Metrics: Loss = 0.2692, Accuracy = 0.9059, AUC = 0.7872\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6458 - binary_accuracy: 0.7401 - loss: 1.6699 - val_auc: 0.7206 - val_binary_accuracy: 0.9065 - val_loss: 0.2979\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7412 - binary_accuracy: 0.9039 - loss: 0.2875 - val_auc: 0.7840 - val_binary_accuracy: 0.9081 - val_loss: 0.2675\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7819 - binary_accuracy: 0.9047 - loss: 0.2712 - val_auc: 0.7983 - val_binary_accuracy: 0.9096 - val_loss: 0.2613\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9052 - loss: 0.2674 - val_auc: 0.8031 - val_binary_accuracy: 0.9100 - val_loss: 0.2587\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7932 - binary_accuracy: 0.9062 - loss: 0.2653 - val_auc: 0.8059 - val_binary_accuracy: 0.9102 - val_loss: 0.2570\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7953 - binary_accuracy: 0.9070 - loss: 0.2639 - val_auc: 0.8074 - val_binary_accuracy: 0.9099 - val_loss: 0.2561\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7970 - binary_accuracy: 0.9073 - loss: 0.2630 - val_auc: 0.8096 - val_binary_accuracy: 0.9099 - val_loss: 0.2554\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9079 - loss: 0.2624 - val_auc: 0.8112 - val_binary_accuracy: 0.9099 - val_loss: 0.2546\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9081 - loss: 0.2619 - val_auc: 0.8117 - val_binary_accuracy: 0.9104 - val_loss: 0.2538\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8123 - val_binary_accuracy: 0.9104 - val_loss: 0.2533\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8149 - binary_accuracy: 0.9138 - loss: 0.2448\n",
      "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9104, AUC = 0.8123\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6087 - binary_accuracy: 0.8443 - loss: 0.4981 - val_auc: 0.7668 - val_binary_accuracy: 0.9063 - val_loss: 0.2722\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7682 - binary_accuracy: 0.9075 - loss: 0.2699 - val_auc: 0.7957 - val_binary_accuracy: 0.9071 - val_loss: 0.2641\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9079 - loss: 0.2636 - val_auc: 0.7999 - val_binary_accuracy: 0.9081 - val_loss: 0.2622\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9076 - loss: 0.2630 - val_auc: 0.8021 - val_binary_accuracy: 0.9093 - val_loss: 0.2608\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9084 - loss: 0.2627 - val_auc: 0.8034 - val_binary_accuracy: 0.9103 - val_loss: 0.2592\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7858 - binary_accuracy: 0.9091 - loss: 0.2625 - val_auc: 0.8041 - val_binary_accuracy: 0.9109 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9094 - loss: 0.2622 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2577\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9096 - loss: 0.2619 - val_auc: 0.8062 - val_binary_accuracy: 0.9110 - val_loss: 0.2572\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8057 - val_binary_accuracy: 0.9110 - val_loss: 0.2570\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9097 - loss: 0.2615 - val_auc: 0.8063 - val_binary_accuracy: 0.9110 - val_loss: 0.2568\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7996 - binary_accuracy: 0.9131 - loss: 0.2566\n",
      "Fold 3 Metrics: Loss = 0.2568, Accuracy = 0.9110, AUC = 0.8063\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6235 - binary_accuracy: 0.8994 - loss: 0.3500 - val_auc: 0.7747 - val_binary_accuracy: 0.9039 - val_loss: 0.2720\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7676 - binary_accuracy: 0.9040 - loss: 0.2741 - val_auc: 0.7865 - val_binary_accuracy: 0.9050 - val_loss: 0.2661\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7771 - binary_accuracy: 0.9056 - loss: 0.2696 - val_auc: 0.7906 - val_binary_accuracy: 0.9060 - val_loss: 0.2636\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7811 - binary_accuracy: 0.9065 - loss: 0.2672 - val_auc: 0.7939 - val_binary_accuracy: 0.9084 - val_loss: 0.2617\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7829 - binary_accuracy: 0.9073 - loss: 0.2656 - val_auc: 0.7964 - val_binary_accuracy: 0.9097 - val_loss: 0.2603\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7848 - binary_accuracy: 0.9078 - loss: 0.2644 - val_auc: 0.7986 - val_binary_accuracy: 0.9097 - val_loss: 0.2593\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2636 - val_auc: 0.8002 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7873 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8024 - val_binary_accuracy: 0.9100 - val_loss: 0.2572\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9090 - loss: 0.2625 - val_auc: 0.8033 - val_binary_accuracy: 0.9101 - val_loss: 0.2567\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9092 - loss: 0.2620 - val_auc: 0.8044 - val_binary_accuracy: 0.9103 - val_loss: 0.2563\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7873 - binary_accuracy: 0.9101 - loss: 0.2631\n",
      "Fold 4 Metrics: Loss = 0.2563, Accuracy = 0.9103, AUC = 0.8044\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6808 - binary_accuracy: 0.9036 - loss: 0.3078 - val_auc: 0.7917 - val_binary_accuracy: 0.8995 - val_loss: 0.2775\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7666 - binary_accuracy: 0.9011 - loss: 0.2789 - val_auc: 0.8004 - val_binary_accuracy: 0.8998 - val_loss: 0.2746\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7763 - binary_accuracy: 0.9021 - loss: 0.2731 - val_auc: 0.8049 - val_binary_accuracy: 0.9028 - val_loss: 0.2718\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7813 - binary_accuracy: 0.9043 - loss: 0.2693 - val_auc: 0.8059 - val_binary_accuracy: 0.9026 - val_loss: 0.2720\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9044 - loss: 0.2677 - val_auc: 0.8072 - val_binary_accuracy: 0.9032 - val_loss: 0.2711\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9052 - loss: 0.2666 - val_auc: 0.8078 - val_binary_accuracy: 0.9041 - val_loss: 0.2714\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9064 - loss: 0.2657 - val_auc: 0.8079 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9066 - loss: 0.2651 - val_auc: 0.8082 - val_binary_accuracy: 0.9054 - val_loss: 0.2698\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9070 - loss: 0.2646 - val_auc: 0.8076 - val_binary_accuracy: 0.9032 - val_loss: 0.2711\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9072 - loss: 0.2644 - val_auc: 0.8082 - val_binary_accuracy: 0.9036 - val_loss: 0.2706\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8170 - binary_accuracy: 0.9056 - loss: 0.2685\n",
      "Fold 5 Metrics: Loss = 0.2706, Accuracy = 0.9036, AUC = 0.8082\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2612\n",
      "Average Accuracy: 0.9083\n",
      "Average AUC: 0.8037\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 1, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6862 - binary_accuracy: 0.8592 - loss: 0.5908 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2762\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9071 - loss: 0.2693 - val_auc: 0.7723 - val_binary_accuracy: 0.9017 - val_loss: 0.2800\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.7786 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9106 - loss: 0.2594 - val_auc: 0.7839 - val_binary_accuracy: 0.9076 - val_loss: 0.2692\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7911 - binary_accuracy: 0.9115 - loss: 0.2565 - val_auc: 0.7872 - val_binary_accuracy: 0.9084 - val_loss: 0.2660\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9117 - loss: 0.2548 - val_auc: 0.7893 - val_binary_accuracy: 0.9085 - val_loss: 0.2638\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7968 - binary_accuracy: 0.9120 - loss: 0.2536 - val_auc: 0.7911 - val_binary_accuracy: 0.9090 - val_loss: 0.2623\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7984 - binary_accuracy: 0.9120 - loss: 0.2528 - val_auc: 0.7923 - val_binary_accuracy: 0.9090 - val_loss: 0.2615\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7932 - val_binary_accuracy: 0.9088 - val_loss: 0.2610\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9126 - loss: 0.2519 - val_auc: 0.7936 - val_binary_accuracy: 0.9088 - val_loss: 0.2605\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7857 - binary_accuracy: 0.9111 - loss: 0.2563\n",
      "Fold 1 Metrics: Loss = 0.2605, Accuracy = 0.9088, AUC = 0.7936\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6825 - binary_accuracy: 0.8857 - loss: 0.3480 - val_auc: 0.7850 - val_binary_accuracy: 0.9081 - val_loss: 0.2691\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7647 - binary_accuracy: 0.9056 - loss: 0.2777 - val_auc: 0.8016 - val_binary_accuracy: 0.9096 - val_loss: 0.2620\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7806 - binary_accuracy: 0.9065 - loss: 0.2707 - val_auc: 0.8064 - val_binary_accuracy: 0.9100 - val_loss: 0.2589\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7863 - binary_accuracy: 0.9068 - loss: 0.2678 - val_auc: 0.8093 - val_binary_accuracy: 0.9091 - val_loss: 0.2574\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9071 - loss: 0.2658 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2560\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7921 - binary_accuracy: 0.9075 - loss: 0.2644 - val_auc: 0.8114 - val_binary_accuracy: 0.9099 - val_loss: 0.2562\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7935 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8138 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9083 - loss: 0.2625 - val_auc: 0.8145 - val_binary_accuracy: 0.9099 - val_loss: 0.2559\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7972 - binary_accuracy: 0.9083 - loss: 0.2618 - val_auc: 0.8161 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9082 - loss: 0.2612 - val_auc: 0.8158 - val_binary_accuracy: 0.9090 - val_loss: 0.2553\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8227 - binary_accuracy: 0.9125 - loss: 0.2459\n",
      "Fold 2 Metrics: Loss = 0.2553, Accuracy = 0.9090, AUC = 0.8158\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7163 - binary_accuracy: 0.8859 - loss: 0.3651 - val_auc: 0.7699 - val_binary_accuracy: 0.8982 - val_loss: 0.2847\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7610 - binary_accuracy: 0.9030 - loss: 0.2754 - val_auc: 0.7911 - val_binary_accuracy: 0.9032 - val_loss: 0.2727\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7758 - binary_accuracy: 0.9063 - loss: 0.2673 - val_auc: 0.7974 - val_binary_accuracy: 0.9048 - val_loss: 0.2686\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7810 - binary_accuracy: 0.9072 - loss: 0.2647 - val_auc: 0.8013 - val_binary_accuracy: 0.9054 - val_loss: 0.2672\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7837 - binary_accuracy: 0.9080 - loss: 0.2631 - val_auc: 0.8034 - val_binary_accuracy: 0.9059 - val_loss: 0.2669\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2622 - val_auc: 0.8041 - val_binary_accuracy: 0.9057 - val_loss: 0.2666\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7869 - binary_accuracy: 0.9083 - loss: 0.2617 - val_auc: 0.8053 - val_binary_accuracy: 0.9056 - val_loss: 0.2675\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7876 - binary_accuracy: 0.9083 - loss: 0.2613 - val_auc: 0.8061 - val_binary_accuracy: 0.9057 - val_loss: 0.2676\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7886 - binary_accuracy: 0.9085 - loss: 0.2610 - val_auc: 0.8064 - val_binary_accuracy: 0.9056 - val_loss: 0.2677\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7890 - binary_accuracy: 0.9088 - loss: 0.2608 - val_auc: 0.8070 - val_binary_accuracy: 0.9056 - val_loss: 0.2678\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8043 - binary_accuracy: 0.9058 - loss: 0.2677\n",
      "Fold 3 Metrics: Loss = 0.2678, Accuracy = 0.9056, AUC = 0.8070\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6602 - binary_accuracy: 0.8776 - loss: 0.3897 - val_auc: 0.7762 - val_binary_accuracy: 0.9062 - val_loss: 0.2726\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7629 - binary_accuracy: 0.9050 - loss: 0.2777 - val_auc: 0.7908 - val_binary_accuracy: 0.9060 - val_loss: 0.2644\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7732 - binary_accuracy: 0.9068 - loss: 0.2709 - val_auc: 0.7972 - val_binary_accuracy: 0.9076 - val_loss: 0.2611\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7797 - binary_accuracy: 0.9078 - loss: 0.2675 - val_auc: 0.8001 - val_binary_accuracy: 0.9081 - val_loss: 0.2601\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7836 - binary_accuracy: 0.9080 - loss: 0.2655 - val_auc: 0.8028 - val_binary_accuracy: 0.9081 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7862 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8046 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7881 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2583\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7889 - binary_accuracy: 0.9082 - loss: 0.2621 - val_auc: 0.8077 - val_binary_accuracy: 0.9091 - val_loss: 0.2578\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7897 - binary_accuracy: 0.9083 - loss: 0.2617 - val_auc: 0.8084 - val_binary_accuracy: 0.9091 - val_loss: 0.2574\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7907 - binary_accuracy: 0.9090 - loss: 0.2613 - val_auc: 0.8090 - val_binary_accuracy: 0.9087 - val_loss: 0.2571\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9066 - loss: 0.2637\n",
      "Fold 4 Metrics: Loss = 0.2571, Accuracy = 0.9087, AUC = 0.8090\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6565 - binary_accuracy: 0.8934 - loss: 0.3689 - val_auc: 0.7838 - val_binary_accuracy: 0.9048 - val_loss: 0.2664\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7613 - binary_accuracy: 0.9052 - loss: 0.2762 - val_auc: 0.7952 - val_binary_accuracy: 0.9078 - val_loss: 0.2599\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7696 - binary_accuracy: 0.9075 - loss: 0.2717 - val_auc: 0.7998 - val_binary_accuracy: 0.9091 - val_loss: 0.2568\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9078 - loss: 0.2691 - val_auc: 0.8030 - val_binary_accuracy: 0.9106 - val_loss: 0.2558\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7778 - binary_accuracy: 0.9085 - loss: 0.2677 - val_auc: 0.8046 - val_binary_accuracy: 0.9104 - val_loss: 0.2548\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9087 - loss: 0.2668 - val_auc: 0.8068 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7806 - binary_accuracy: 0.9088 - loss: 0.2663 - val_auc: 0.8078 - val_binary_accuracy: 0.9101 - val_loss: 0.2534\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9077 - loss: 0.2656 - val_auc: 0.8072 - val_binary_accuracy: 0.9087 - val_loss: 0.2536\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7821 - binary_accuracy: 0.9082 - loss: 0.2655 - val_auc: 0.8076 - val_binary_accuracy: 0.9079 - val_loss: 0.2537\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7832 - binary_accuracy: 0.9089 - loss: 0.2651 - val_auc: 0.8080 - val_binary_accuracy: 0.9082 - val_loss: 0.2537\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9069 - loss: 0.2532\n",
      "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9082, AUC = 0.8080\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2589\n",
      "Average Accuracy: 0.9081\n",
      "Average AUC: 0.8067\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 1, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7034 - binary_accuracy: 0.8996 - loss: 0.3101 - val_auc: 0.7697 - val_binary_accuracy: 0.9081 - val_loss: 0.2725\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9089 - loss: 0.2643 - val_auc: 0.7847 - val_binary_accuracy: 0.9103 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9109 - loss: 0.2571 - val_auc: 0.7876 - val_binary_accuracy: 0.9099 - val_loss: 0.2676\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7957 - binary_accuracy: 0.9117 - loss: 0.2555 - val_auc: 0.7925 - val_binary_accuracy: 0.9097 - val_loss: 0.2603\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9120 - loss: 0.2532 - val_auc: 0.7931 - val_binary_accuracy: 0.9097 - val_loss: 0.2600\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9119 - loss: 0.2528 - val_auc: 0.7942 - val_binary_accuracy: 0.9097 - val_loss: 0.2597\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9122 - loss: 0.2521 - val_auc: 0.7947 - val_binary_accuracy: 0.9096 - val_loss: 0.2594\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9125 - loss: 0.2515 - val_auc: 0.7953 - val_binary_accuracy: 0.9099 - val_loss: 0.2593\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8048 - binary_accuracy: 0.9125 - loss: 0.2513 - val_auc: 0.7956 - val_binary_accuracy: 0.9093 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9127 - loss: 0.2508 - val_auc: 0.7962 - val_binary_accuracy: 0.9093 - val_loss: 0.2593\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7917 - binary_accuracy: 0.9135 - loss: 0.2520\n",
      "Fold 1 Metrics: Loss = 0.2593, Accuracy = 0.9093, AUC = 0.7962\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5927 - binary_accuracy: 0.8873 - loss: 0.7866 - val_auc: 0.7893 - val_binary_accuracy: 0.9068 - val_loss: 0.2654\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9050 - loss: 0.2744 - val_auc: 0.8040 - val_binary_accuracy: 0.9079 - val_loss: 0.2582\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7799 - binary_accuracy: 0.9065 - loss: 0.2693 - val_auc: 0.8073 - val_binary_accuracy: 0.9088 - val_loss: 0.2563\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7863 - binary_accuracy: 0.9064 - loss: 0.2670 - val_auc: 0.8056 - val_binary_accuracy: 0.9104 - val_loss: 0.2571\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9065 - loss: 0.2658 - val_auc: 0.8097 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7927 - binary_accuracy: 0.9067 - loss: 0.2643 - val_auc: 0.8107 - val_binary_accuracy: 0.9082 - val_loss: 0.2552\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7934 - binary_accuracy: 0.9068 - loss: 0.2639 - val_auc: 0.8125 - val_binary_accuracy: 0.9090 - val_loss: 0.2537\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7962 - binary_accuracy: 0.9070 - loss: 0.2629 - val_auc: 0.8124 - val_binary_accuracy: 0.9088 - val_loss: 0.2539\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9070 - loss: 0.2630 - val_auc: 0.8131 - val_binary_accuracy: 0.9085 - val_loss: 0.2533\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9075 - loss: 0.2623 - val_auc: 0.8130 - val_binary_accuracy: 0.9087 - val_loss: 0.2533\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8199 - binary_accuracy: 0.9122 - loss: 0.2438\n",
      "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9087, AUC = 0.8130\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6633 - binary_accuracy: 0.8966 - loss: 0.4320 - val_auc: 0.7971 - val_binary_accuracy: 0.9096 - val_loss: 0.2604\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7724 - binary_accuracy: 0.9059 - loss: 0.2692 - val_auc: 0.8024 - val_binary_accuracy: 0.9106 - val_loss: 0.2572\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7767 - binary_accuracy: 0.9061 - loss: 0.2674 - val_auc: 0.8041 - val_binary_accuracy: 0.9107 - val_loss: 0.2562\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7777 - binary_accuracy: 0.9063 - loss: 0.2667 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7786 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.8062 - val_binary_accuracy: 0.9107 - val_loss: 0.2557\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7803 - binary_accuracy: 0.9066 - loss: 0.2658 - val_auc: 0.8074 - val_binary_accuracy: 0.9116 - val_loss: 0.2554\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7817 - binary_accuracy: 0.9069 - loss: 0.2652 - val_auc: 0.8072 - val_binary_accuracy: 0.9112 - val_loss: 0.2555\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7825 - binary_accuracy: 0.9072 - loss: 0.2648 - val_auc: 0.8082 - val_binary_accuracy: 0.9122 - val_loss: 0.2550\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7831 - binary_accuracy: 0.9076 - loss: 0.2643 - val_auc: 0.8072 - val_binary_accuracy: 0.9121 - val_loss: 0.2556\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9075 - loss: 0.2640 - val_auc: 0.8074 - val_binary_accuracy: 0.9124 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8025 - binary_accuracy: 0.9128 - loss: 0.2555\n",
      "Fold 3 Metrics: Loss = 0.2552, Accuracy = 0.9124, AUC = 0.8074\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5709 - binary_accuracy: 0.7201 - loss: 4.4762 - val_auc: 0.7878 - val_binary_accuracy: 0.9041 - val_loss: 0.2668\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7690 - binary_accuracy: 0.9050 - loss: 0.2725 - val_auc: 0.8000 - val_binary_accuracy: 0.9081 - val_loss: 0.2606\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7791 - binary_accuracy: 0.9080 - loss: 0.2666 - val_auc: 0.8041 - val_binary_accuracy: 0.9078 - val_loss: 0.2594\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7819 - binary_accuracy: 0.9085 - loss: 0.2651 - val_auc: 0.8063 - val_binary_accuracy: 0.9064 - val_loss: 0.2598\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7838 - binary_accuracy: 0.9089 - loss: 0.2641 - val_auc: 0.8078 - val_binary_accuracy: 0.9072 - val_loss: 0.2585\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7865 - binary_accuracy: 0.9090 - loss: 0.2629 - val_auc: 0.8090 - val_binary_accuracy: 0.9088 - val_loss: 0.2567\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7886 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8087 - val_binary_accuracy: 0.9104 - val_loss: 0.2558\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9094 - loss: 0.2620 - val_auc: 0.8094 - val_binary_accuracy: 0.9104 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7879 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8103 - val_binary_accuracy: 0.9104 - val_loss: 0.2550\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7879 - binary_accuracy: 0.9089 - loss: 0.2620 - val_auc: 0.8102 - val_binary_accuracy: 0.9103 - val_loss: 0.2550\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7952 - binary_accuracy: 0.9090 - loss: 0.2614\n",
      "Fold 4 Metrics: Loss = 0.2550, Accuracy = 0.9103, AUC = 0.8102\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6283 - binary_accuracy: 0.8896 - loss: 0.8065 - val_auc: 0.7923 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9053 - loss: 0.2773 - val_auc: 0.7995 - val_binary_accuracy: 0.9097 - val_loss: 0.2592\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7657 - binary_accuracy: 0.9060 - loss: 0.2736 - val_auc: 0.8023 - val_binary_accuracy: 0.9073 - val_loss: 0.2591\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7692 - binary_accuracy: 0.9066 - loss: 0.2720 - val_auc: 0.8053 - val_binary_accuracy: 0.9073 - val_loss: 0.2592\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7710 - binary_accuracy: 0.9063 - loss: 0.2711 - val_auc: 0.8066 - val_binary_accuracy: 0.9067 - val_loss: 0.2597\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7718 - binary_accuracy: 0.9065 - loss: 0.2709 - val_auc: 0.8074 - val_binary_accuracy: 0.9066 - val_loss: 0.2588\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7732 - binary_accuracy: 0.9073 - loss: 0.2704 - val_auc: 0.8080 - val_binary_accuracy: 0.9064 - val_loss: 0.2585\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9070 - loss: 0.2697 - val_auc: 0.8082 - val_binary_accuracy: 0.9062 - val_loss: 0.2578\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7762 - binary_accuracy: 0.9072 - loss: 0.2693 - val_auc: 0.8085 - val_binary_accuracy: 0.9067 - val_loss: 0.2573\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7768 - binary_accuracy: 0.9072 - loss: 0.2691 - val_auc: 0.8083 - val_binary_accuracy: 0.9059 - val_loss: 0.2567\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8140 - binary_accuracy: 0.9062 - loss: 0.2557\n",
      "Fold 5 Metrics: Loss = 0.2567, Accuracy = 0.9059, AUC = 0.8083\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2559\n",
      "Average Accuracy: 0.9093\n",
      "Average AUC: 0.8070\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 1, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6756 - binary_accuracy: 0.8977 - loss: 0.4019 - val_auc: 0.7866 - val_binary_accuracy: 0.9085 - val_loss: 0.2622\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7899 - binary_accuracy: 0.9116 - loss: 0.2575 - val_auc: 0.7926 - val_binary_accuracy: 0.9100 - val_loss: 0.2600\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7940 - binary_accuracy: 0.9120 - loss: 0.2555 - val_auc: 0.7960 - val_binary_accuracy: 0.9104 - val_loss: 0.2591\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7984 - binary_accuracy: 0.9123 - loss: 0.2535 - val_auc: 0.7967 - val_binary_accuracy: 0.9100 - val_loss: 0.2590\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7998 - binary_accuracy: 0.9126 - loss: 0.2527 - val_auc: 0.7972 - val_binary_accuracy: 0.9096 - val_loss: 0.2587\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8011 - binary_accuracy: 0.9127 - loss: 0.2522 - val_auc: 0.7987 - val_binary_accuracy: 0.9094 - val_loss: 0.2582\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8031 - binary_accuracy: 0.9129 - loss: 0.2515 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8033 - binary_accuracy: 0.9130 - loss: 0.2514 - val_auc: 0.7990 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9132 - loss: 0.2509 - val_auc: 0.7989 - val_binary_accuracy: 0.9097 - val_loss: 0.2574\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8052 - binary_accuracy: 0.9132 - loss: 0.2507 - val_auc: 0.7983 - val_binary_accuracy: 0.9099 - val_loss: 0.2576\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7944 - binary_accuracy: 0.9140 - loss: 0.2500\n",
      "Fold 1 Metrics: Loss = 0.2576, Accuracy = 0.9099, AUC = 0.7983\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5951 - binary_accuracy: 0.8489 - loss: 0.9462 - val_auc: 0.8019 - val_binary_accuracy: 0.9059 - val_loss: 0.2635\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9057 - loss: 0.2711 - val_auc: 0.8111 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9069 - loss: 0.2685 - val_auc: 0.8111 - val_binary_accuracy: 0.9099 - val_loss: 0.2563\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7852 - binary_accuracy: 0.9067 - loss: 0.2683 - val_auc: 0.8115 - val_binary_accuracy: 0.9099 - val_loss: 0.2557\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9063 - loss: 0.2683 - val_auc: 0.8118 - val_binary_accuracy: 0.9104 - val_loss: 0.2554\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7856 - binary_accuracy: 0.9066 - loss: 0.2683 - val_auc: 0.8115 - val_binary_accuracy: 0.9104 - val_loss: 0.2557\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7856 - binary_accuracy: 0.9063 - loss: 0.2681 - val_auc: 0.8113 - val_binary_accuracy: 0.9100 - val_loss: 0.2559\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9065 - loss: 0.2679 - val_auc: 0.8113 - val_binary_accuracy: 0.9100 - val_loss: 0.2558\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7875 - binary_accuracy: 0.9067 - loss: 0.2673 - val_auc: 0.8120 - val_binary_accuracy: 0.9097 - val_loss: 0.2559\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9069 - loss: 0.2665 - val_auc: 0.8124 - val_binary_accuracy: 0.9099 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8201 - binary_accuracy: 0.9141 - loss: 0.2456\n",
      "Fold 2 Metrics: Loss = 0.2552, Accuracy = 0.9099, AUC = 0.8124\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6426 - binary_accuracy: 0.8351 - loss: 1.1844 - val_auc: 0.7773 - val_binary_accuracy: 0.9087 - val_loss: 0.2691\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7591 - binary_accuracy: 0.9047 - loss: 0.2747 - val_auc: 0.7910 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7657 - binary_accuracy: 0.9053 - loss: 0.2727 - val_auc: 0.7981 - val_binary_accuracy: 0.9038 - val_loss: 0.2686\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7738 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.8018 - val_binary_accuracy: 0.9004 - val_loss: 0.2724\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7756 - binary_accuracy: 0.9069 - loss: 0.2682 - val_auc: 0.8036 - val_binary_accuracy: 0.8972 - val_loss: 0.2742\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7772 - binary_accuracy: 0.9066 - loss: 0.2682 - val_auc: 0.8053 - val_binary_accuracy: 0.8969 - val_loss: 0.2742\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7776 - binary_accuracy: 0.9060 - loss: 0.2677 - val_auc: 0.8064 - val_binary_accuracy: 0.8969 - val_loss: 0.2747\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9065 - loss: 0.2677 - val_auc: 0.8074 - val_binary_accuracy: 0.8948 - val_loss: 0.2769\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7789 - binary_accuracy: 0.9064 - loss: 0.2673 - val_auc: 0.8078 - val_binary_accuracy: 0.8942 - val_loss: 0.2772\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7800 - binary_accuracy: 0.9066 - loss: 0.2670 - val_auc: 0.8081 - val_binary_accuracy: 0.8952 - val_loss: 0.2765\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8043 - binary_accuracy: 0.8954 - loss: 0.2766\n",
      "Fold 3 Metrics: Loss = 0.2765, Accuracy = 0.8952, AUC = 0.8081\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6570 - binary_accuracy: 0.8842 - loss: 0.5254 - val_auc: 0.7953 - val_binary_accuracy: 0.9085 - val_loss: 0.2630\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9084 - loss: 0.2721 - val_auc: 0.8073 - val_binary_accuracy: 0.9091 - val_loss: 0.2611\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9088 - loss: 0.2692 - val_auc: 0.8104 - val_binary_accuracy: 0.9090 - val_loss: 0.2599\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7772 - binary_accuracy: 0.9090 - loss: 0.2674 - val_auc: 0.8116 - val_binary_accuracy: 0.9090 - val_loss: 0.2589\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7794 - binary_accuracy: 0.9094 - loss: 0.2663 - val_auc: 0.8130 - val_binary_accuracy: 0.9097 - val_loss: 0.2582\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7804 - binary_accuracy: 0.9089 - loss: 0.2658 - val_auc: 0.8144 - val_binary_accuracy: 0.9097 - val_loss: 0.2564\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7822 - binary_accuracy: 0.9093 - loss: 0.2649 - val_auc: 0.8145 - val_binary_accuracy: 0.9097 - val_loss: 0.2562\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7826 - binary_accuracy: 0.9095 - loss: 0.2649 - val_auc: 0.8143 - val_binary_accuracy: 0.9095 - val_loss: 0.2561\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2644 - val_auc: 0.8142 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7843 - binary_accuracy: 0.9096 - loss: 0.2643 - val_auc: 0.8145 - val_binary_accuracy: 0.9098 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7978 - binary_accuracy: 0.9082 - loss: 0.2625\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9098, AUC = 0.8145\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5360 - binary_accuracy: 0.8048 - loss: 1.9087 - val_auc: 0.7869 - val_binary_accuracy: 0.9063 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7625 - binary_accuracy: 0.9056 - loss: 0.2748 - val_auc: 0.8003 - val_binary_accuracy: 0.9090 - val_loss: 0.2569\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9065 - loss: 0.2711 - val_auc: 0.8047 - val_binary_accuracy: 0.9051 - val_loss: 0.2613\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7709 - binary_accuracy: 0.9061 - loss: 0.2709 - val_auc: 0.8069 - val_binary_accuracy: 0.9019 - val_loss: 0.2670\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9063 - loss: 0.2703 - val_auc: 0.8073 - val_binary_accuracy: 0.9014 - val_loss: 0.2696\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7751 - binary_accuracy: 0.9061 - loss: 0.2699 - val_auc: 0.8077 - val_binary_accuracy: 0.9005 - val_loss: 0.2702\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7751 - binary_accuracy: 0.9064 - loss: 0.2701 - val_auc: 0.8078 - val_binary_accuracy: 0.8997 - val_loss: 0.2712\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7752 - binary_accuracy: 0.9063 - loss: 0.2702 - val_auc: 0.8079 - val_binary_accuracy: 0.8988 - val_loss: 0.2723\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7752 - binary_accuracy: 0.9065 - loss: 0.2706 - val_auc: 0.8079 - val_binary_accuracy: 0.8991 - val_loss: 0.2726\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7747 - binary_accuracy: 0.9063 - loss: 0.2707 - val_auc: 0.8083 - val_binary_accuracy: 0.8995 - val_loss: 0.2723\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9035 - loss: 0.2698\n",
      "Fold 5 Metrics: Loss = 0.2723, Accuracy = 0.8995, AUC = 0.8083\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2633\n",
      "Average Accuracy: 0.9049\n",
      "Average AUC: 0.8083\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 1, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7102 - binary_accuracy: 0.9002 - loss: 0.3113 - val_auc: 0.7878 - val_binary_accuracy: 0.9062 - val_loss: 0.2950\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9093 - loss: 0.2649 - val_auc: 0.7940 - val_binary_accuracy: 0.9072 - val_loss: 0.3029\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9096 - loss: 0.2626 - val_auc: 0.7944 - val_binary_accuracy: 0.9079 - val_loss: 0.3055\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9106 - loss: 0.2611 - val_auc: 0.7986 - val_binary_accuracy: 0.9078 - val_loss: 0.3028\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7866 - binary_accuracy: 0.9106 - loss: 0.2602 - val_auc: 0.7988 - val_binary_accuracy: 0.9081 - val_loss: 0.3022\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7889 - binary_accuracy: 0.9111 - loss: 0.2591 - val_auc: 0.8007 - val_binary_accuracy: 0.9081 - val_loss: 0.3000\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7902 - binary_accuracy: 0.9110 - loss: 0.2587 - val_auc: 0.7994 - val_binary_accuracy: 0.9081 - val_loss: 0.2919\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7928 - binary_accuracy: 0.9108 - loss: 0.2572 - val_auc: 0.7990 - val_binary_accuracy: 0.9081 - val_loss: 0.2882\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9112 - loss: 0.2564 - val_auc: 0.7994 - val_binary_accuracy: 0.9088 - val_loss: 0.2844\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7958 - binary_accuracy: 0.9111 - loss: 0.2556 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2794\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7957 - binary_accuracy: 0.9128 - loss: 0.2695\n",
      "Fold 1 Metrics: Loss = 0.2794, Accuracy = 0.9088, AUC = 0.7997\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6661 - binary_accuracy: 0.8791 - loss: 0.4294 - val_auc: 0.8100 - val_binary_accuracy: 0.8960 - val_loss: 0.2967\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7596 - binary_accuracy: 0.9035 - loss: 0.2802 - val_auc: 0.8109 - val_binary_accuracy: 0.8964 - val_loss: 0.2970\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9048 - loss: 0.2791 - val_auc: 0.8142 - val_binary_accuracy: 0.8979 - val_loss: 0.2922\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9052 - loss: 0.2777 - val_auc: 0.8110 - val_binary_accuracy: 0.8991 - val_loss: 0.2890\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7701 - binary_accuracy: 0.9056 - loss: 0.2762 - val_auc: 0.8113 - val_binary_accuracy: 0.8991 - val_loss: 0.2898\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7716 - binary_accuracy: 0.9055 - loss: 0.2758 - val_auc: 0.8125 - val_binary_accuracy: 0.8986 - val_loss: 0.2876\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9055 - loss: 0.2743 - val_auc: 0.8114 - val_binary_accuracy: 0.8986 - val_loss: 0.2883\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7757 - binary_accuracy: 0.9058 - loss: 0.2740 - val_auc: 0.8065 - val_binary_accuracy: 0.9007 - val_loss: 0.2841\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7784 - binary_accuracy: 0.9059 - loss: 0.2727 - val_auc: 0.8114 - val_binary_accuracy: 0.9023 - val_loss: 0.2745\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7812 - binary_accuracy: 0.9059 - loss: 0.2707 - val_auc: 0.8090 - val_binary_accuracy: 0.9054 - val_loss: 0.2709\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9082 - loss: 0.2627\n",
      "Fold 2 Metrics: Loss = 0.2709, Accuracy = 0.9054, AUC = 0.8090\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6325 - binary_accuracy: 0.8668 - loss: 0.6690 - val_auc: 0.7893 - val_binary_accuracy: 0.9063 - val_loss: 0.2674\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7722 - binary_accuracy: 0.9058 - loss: 0.2699 - val_auc: 0.7994 - val_binary_accuracy: 0.9017 - val_loss: 0.2711\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7725 - binary_accuracy: 0.9071 - loss: 0.2699 - val_auc: 0.8024 - val_binary_accuracy: 0.9023 - val_loss: 0.2673\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9061 - loss: 0.2710 - val_auc: 0.8041 - val_binary_accuracy: 0.9038 - val_loss: 0.2652\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9066 - loss: 0.2706 - val_auc: 0.8042 - val_binary_accuracy: 0.9026 - val_loss: 0.2683\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7737 - binary_accuracy: 0.9067 - loss: 0.2698 - val_auc: 0.8055 - val_binary_accuracy: 0.9013 - val_loss: 0.2680\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9070 - loss: 0.2690 - val_auc: 0.8053 - val_binary_accuracy: 0.9006 - val_loss: 0.2705\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7766 - binary_accuracy: 0.9071 - loss: 0.2684 - val_auc: 0.8061 - val_binary_accuracy: 0.9003 - val_loss: 0.2717\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.8058 - val_binary_accuracy: 0.9014 - val_loss: 0.2721\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7788 - binary_accuracy: 0.9072 - loss: 0.2672 - val_auc: 0.8059 - val_binary_accuracy: 0.8988 - val_loss: 0.2736\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8025 - binary_accuracy: 0.9010 - loss: 0.2736\n",
      "Fold 3 Metrics: Loss = 0.2736, Accuracy = 0.8988, AUC = 0.8059\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7025 - binary_accuracy: 0.8919 - loss: 0.3483 - val_auc: 0.8065 - val_binary_accuracy: 0.9081 - val_loss: 0.2577\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7717 - binary_accuracy: 0.9084 - loss: 0.2697 - val_auc: 0.8101 - val_binary_accuracy: 0.9026 - val_loss: 0.2593\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9081 - loss: 0.2691 - val_auc: 0.8120 - val_binary_accuracy: 0.9033 - val_loss: 0.2579\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9078 - loss: 0.2686 - val_auc: 0.8125 - val_binary_accuracy: 0.9069 - val_loss: 0.2551\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9088 - loss: 0.2676 - val_auc: 0.8118 - val_binary_accuracy: 0.9097 - val_loss: 0.2648\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9096 - loss: 0.2665 - val_auc: 0.8111 - val_binary_accuracy: 0.9100 - val_loss: 0.2961\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7777 - binary_accuracy: 0.9089 - loss: 0.2671 - val_auc: 0.8101 - val_binary_accuracy: 0.9090 - val_loss: 0.3140\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7748 - binary_accuracy: 0.9085 - loss: 0.2688 - val_auc: 0.8092 - val_binary_accuracy: 0.9091 - val_loss: 0.3189\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7715 - binary_accuracy: 0.9086 - loss: 0.2717 - val_auc: 0.8132 - val_binary_accuracy: 0.9095 - val_loss: 0.2976\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7718 - binary_accuracy: 0.9075 - loss: 0.2720 - val_auc: 0.8129 - val_binary_accuracy: 0.9098 - val_loss: 0.2836\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7967 - binary_accuracy: 0.9093 - loss: 0.2904\n",
      "Fold 4 Metrics: Loss = 0.2836, Accuracy = 0.9098, AUC = 0.8129\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6815 - binary_accuracy: 0.8778 - loss: 0.4993 - val_auc: 0.7960 - val_binary_accuracy: 0.8927 - val_loss: 0.2965\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7478 - binary_accuracy: 0.9037 - loss: 0.2840 - val_auc: 0.8031 - val_binary_accuracy: 0.8918 - val_loss: 0.2983\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7524 - binary_accuracy: 0.9039 - loss: 0.2828 - val_auc: 0.8050 - val_binary_accuracy: 0.8895 - val_loss: 0.2979\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7557 - binary_accuracy: 0.9038 - loss: 0.2810 - val_auc: 0.8066 - val_binary_accuracy: 0.8889 - val_loss: 0.2970\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7587 - binary_accuracy: 0.9036 - loss: 0.2797 - val_auc: 0.8074 - val_binary_accuracy: 0.8920 - val_loss: 0.2937\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7622 - binary_accuracy: 0.9041 - loss: 0.2781 - val_auc: 0.8080 - val_binary_accuracy: 0.8935 - val_loss: 0.2897\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7637 - binary_accuracy: 0.9046 - loss: 0.2772 - val_auc: 0.8079 - val_binary_accuracy: 0.8942 - val_loss: 0.2887\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9048 - loss: 0.2763 - val_auc: 0.8083 - val_binary_accuracy: 0.8941 - val_loss: 0.2876\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7663 - binary_accuracy: 0.9052 - loss: 0.2756 - val_auc: 0.8083 - val_binary_accuracy: 0.8939 - val_loss: 0.2867\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7681 - binary_accuracy: 0.9054 - loss: 0.2749 - val_auc: 0.8082 - val_binary_accuracy: 0.8954 - val_loss: 0.2848\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.8988 - loss: 0.2816\n",
      "Fold 5 Metrics: Loss = 0.2848, Accuracy = 0.8954, AUC = 0.8082\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2785\n",
      "Average Accuracy: 0.9037\n",
      "Average AUC: 0.8072\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 2, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6672 - binary_accuracy: 0.8183 - loss: 0.9800 - val_auc: 0.7084 - val_binary_accuracy: 0.9062 - val_loss: 0.2851\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7467 - binary_accuracy: 0.9104 - loss: 0.2730 - val_auc: 0.7630 - val_binary_accuracy: 0.9085 - val_loss: 0.2725\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9115 - loss: 0.2640 - val_auc: 0.7712 - val_binary_accuracy: 0.9078 - val_loss: 0.2701\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9116 - loss: 0.2609 - val_auc: 0.7749 - val_binary_accuracy: 0.9081 - val_loss: 0.2696\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9110 - loss: 0.2592 - val_auc: 0.7790 - val_binary_accuracy: 0.9088 - val_loss: 0.2691\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9110 - loss: 0.2577 - val_auc: 0.7828 - val_binary_accuracy: 0.9082 - val_loss: 0.2687\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9112 - loss: 0.2566 - val_auc: 0.7846 - val_binary_accuracy: 0.9088 - val_loss: 0.2677\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9117 - loss: 0.2557 - val_auc: 0.7861 - val_binary_accuracy: 0.9091 - val_loss: 0.2670\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9118 - loss: 0.2546 - val_auc: 0.7875 - val_binary_accuracy: 0.9091 - val_loss: 0.2667\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9122 - loss: 0.2539 - val_auc: 0.7892 - val_binary_accuracy: 0.9093 - val_loss: 0.2660\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7822 - binary_accuracy: 0.9124 - loss: 0.2588\n",
      "Fold 1 Metrics: Loss = 0.2660, Accuracy = 0.9093, AUC = 0.7892\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6465 - binary_accuracy: 0.8995 - loss: 0.4357 - val_auc: 0.7847 - val_binary_accuracy: 0.9057 - val_loss: 0.2662\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9039 - loss: 0.2732 - val_auc: 0.7982 - val_binary_accuracy: 0.9069 - val_loss: 0.2611\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9050 - loss: 0.2692 - val_auc: 0.8029 - val_binary_accuracy: 0.9078 - val_loss: 0.2584\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9053 - loss: 0.2669 - val_auc: 0.8064 - val_binary_accuracy: 0.9091 - val_loss: 0.2565\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9062 - loss: 0.2651 - val_auc: 0.8092 - val_binary_accuracy: 0.9097 - val_loss: 0.2555\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9067 - loss: 0.2640 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2546\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9072 - loss: 0.2629 - val_auc: 0.8124 - val_binary_accuracy: 0.9097 - val_loss: 0.2535\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9074 - loss: 0.2617 - val_auc: 0.8130 - val_binary_accuracy: 0.9099 - val_loss: 0.2538\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9083 - loss: 0.2610 - val_auc: 0.8145 - val_binary_accuracy: 0.9102 - val_loss: 0.2532\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9082 - loss: 0.2601 - val_auc: 0.8131 - val_binary_accuracy: 0.9100 - val_loss: 0.2538\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9138 - loss: 0.2447\n",
      "Fold 2 Metrics: Loss = 0.2538, Accuracy = 0.9100, AUC = 0.8131\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - auc: 0.6251 - binary_accuracy: 0.6070 - loss: 7.7190 - val_auc: 0.7514 - val_binary_accuracy: 0.8979 - val_loss: 0.3540\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7481 - binary_accuracy: 0.9018 - loss: 0.3162 - val_auc: 0.7567 - val_binary_accuracy: 0.9062 - val_loss: 0.2830\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7510 - binary_accuracy: 0.9061 - loss: 0.2809 - val_auc: 0.7641 - val_binary_accuracy: 0.9073 - val_loss: 0.2780\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7572 - binary_accuracy: 0.9071 - loss: 0.2766 - val_auc: 0.7705 - val_binary_accuracy: 0.9084 - val_loss: 0.2747\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7611 - binary_accuracy: 0.9078 - loss: 0.2740 - val_auc: 0.7745 - val_binary_accuracy: 0.9088 - val_loss: 0.2721\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9084 - loss: 0.2722 - val_auc: 0.7785 - val_binary_accuracy: 0.9099 - val_loss: 0.2698\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9087 - loss: 0.2710 - val_auc: 0.7810 - val_binary_accuracy: 0.9099 - val_loss: 0.2681\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9083 - loss: 0.2700 - val_auc: 0.7833 - val_binary_accuracy: 0.9102 - val_loss: 0.2663\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9085 - loss: 0.2693 - val_auc: 0.7858 - val_binary_accuracy: 0.9107 - val_loss: 0.2647\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9084 - loss: 0.2688 - val_auc: 0.7874 - val_binary_accuracy: 0.9106 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7845 - binary_accuracy: 0.9120 - loss: 0.2628\n",
      "Fold 3 Metrics: Loss = 0.2635, Accuracy = 0.9106, AUC = 0.7874\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6090 - binary_accuracy: 0.7314 - loss: 1.4009 - val_auc: 0.7550 - val_binary_accuracy: 0.9044 - val_loss: 0.2814\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7491 - binary_accuracy: 0.9039 - loss: 0.2804 - val_auc: 0.7699 - val_binary_accuracy: 0.9044 - val_loss: 0.2756\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9047 - loss: 0.2751 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9051 - loss: 0.2718 - val_auc: 0.7811 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9062 - loss: 0.2696 - val_auc: 0.7847 - val_binary_accuracy: 0.9048 - val_loss: 0.2687\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9075 - loss: 0.2675 - val_auc: 0.7883 - val_binary_accuracy: 0.9051 - val_loss: 0.2663\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9082 - loss: 0.2657 - val_auc: 0.7931 - val_binary_accuracy: 0.9067 - val_loss: 0.2641\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9091 - loss: 0.2642 - val_auc: 0.7973 - val_binary_accuracy: 0.9075 - val_loss: 0.2617\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9091 - loss: 0.2629 - val_auc: 0.8005 - val_binary_accuracy: 0.9075 - val_loss: 0.2599\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9097 - loss: 0.2620 - val_auc: 0.8028 - val_binary_accuracy: 0.9064 - val_loss: 0.2588\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7843 - binary_accuracy: 0.9057 - loss: 0.2647\n",
      "Fold 4 Metrics: Loss = 0.2588, Accuracy = 0.9064, AUC = 0.8028\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.3823 - binary_accuracy: 0.6444 - loss: 2.6988 - val_auc: 0.7613 - val_binary_accuracy: 0.9044 - val_loss: 0.2801\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7563 - binary_accuracy: 0.9041 - loss: 0.2800 - val_auc: 0.7886 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9042 - loss: 0.2727 - val_auc: 0.7919 - val_binary_accuracy: 0.9057 - val_loss: 0.2651\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9053 - loss: 0.2699 - val_auc: 0.7942 - val_binary_accuracy: 0.9066 - val_loss: 0.2634\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9067 - loss: 0.2681 - val_auc: 0.7959 - val_binary_accuracy: 0.9079 - val_loss: 0.2619\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.7979 - val_binary_accuracy: 0.9088 - val_loss: 0.2607\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9086 - loss: 0.2658 - val_auc: 0.7985 - val_binary_accuracy: 0.9088 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9088 - loss: 0.2649 - val_auc: 0.7996 - val_binary_accuracy: 0.9098 - val_loss: 0.2583\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9089 - loss: 0.2642 - val_auc: 0.8003 - val_binary_accuracy: 0.9106 - val_loss: 0.2573\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9089 - loss: 0.2636 - val_auc: 0.8013 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8121 - binary_accuracy: 0.9093 - loss: 0.2559\n",
      "Fold 5 Metrics: Loss = 0.2564, Accuracy = 0.9107, AUC = 0.8013\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2597\n",
      "Average Accuracy: 0.9094\n",
      "Average AUC: 0.7988\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 2, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5850 - binary_accuracy: 0.7056 - loss: 3.5820 - val_auc: 0.7506 - val_binary_accuracy: 0.9032 - val_loss: 0.2870\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9062 - loss: 0.2728 - val_auc: 0.7654 - val_binary_accuracy: 0.9012 - val_loss: 0.2774\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9059 - loss: 0.2640 - val_auc: 0.7735 - val_binary_accuracy: 0.9051 - val_loss: 0.2695\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9073 - loss: 0.2599 - val_auc: 0.7791 - val_binary_accuracy: 0.9065 - val_loss: 0.2673\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9091 - loss: 0.2576 - val_auc: 0.7819 - val_binary_accuracy: 0.9076 - val_loss: 0.2669\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9104 - loss: 0.2560 - val_auc: 0.7850 - val_binary_accuracy: 0.9082 - val_loss: 0.2670\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9110 - loss: 0.2544 - val_auc: 0.7886 - val_binary_accuracy: 0.9081 - val_loss: 0.2660\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9113 - loss: 0.2538 - val_auc: 0.7912 - val_binary_accuracy: 0.9081 - val_loss: 0.2651\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8023 - binary_accuracy: 0.9117 - loss: 0.2529 - val_auc: 0.7917 - val_binary_accuracy: 0.9094 - val_loss: 0.2645\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8033 - binary_accuracy: 0.9117 - loss: 0.2523 - val_auc: 0.7925 - val_binary_accuracy: 0.9097 - val_loss: 0.2641\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7866 - binary_accuracy: 0.9138 - loss: 0.2563\n",
      "Fold 1 Metrics: Loss = 0.2641, Accuracy = 0.9097, AUC = 0.7925\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6988 - binary_accuracy: 0.8928 - loss: 0.3315 - val_auc: 0.8039 - val_binary_accuracy: 0.9093 - val_loss: 0.2594\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9051 - loss: 0.2747 - val_auc: 0.8084 - val_binary_accuracy: 0.9090 - val_loss: 0.2561\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9049 - loss: 0.2702 - val_auc: 0.8109 - val_binary_accuracy: 0.9088 - val_loss: 0.2545\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9062 - loss: 0.2671 - val_auc: 0.8095 - val_binary_accuracy: 0.9097 - val_loss: 0.2549\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9058 - loss: 0.2657 - val_auc: 0.8088 - val_binary_accuracy: 0.9102 - val_loss: 0.2549\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9070 - loss: 0.2641 - val_auc: 0.8103 - val_binary_accuracy: 0.9106 - val_loss: 0.2543\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9065 - loss: 0.2636 - val_auc: 0.8100 - val_binary_accuracy: 0.9096 - val_loss: 0.2549\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9065 - loss: 0.2628 - val_auc: 0.8152 - val_binary_accuracy: 0.9096 - val_loss: 0.2527\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9064 - loss: 0.2621 - val_auc: 0.8099 - val_binary_accuracy: 0.9088 - val_loss: 0.2554\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9065 - loss: 0.2616 - val_auc: 0.8157 - val_binary_accuracy: 0.9097 - val_loss: 0.2523\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8194 - binary_accuracy: 0.9133 - loss: 0.2432\n",
      "Fold 2 Metrics: Loss = 0.2523, Accuracy = 0.9097, AUC = 0.8157\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5993 - binary_accuracy: 0.6960 - loss: 4.3704 - val_auc: 0.7570 - val_binary_accuracy: 0.9032 - val_loss: 0.2827\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7523 - binary_accuracy: 0.9015 - loss: 0.2811 - val_auc: 0.7754 - val_binary_accuracy: 0.9037 - val_loss: 0.2753\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7638 - binary_accuracy: 0.9037 - loss: 0.2751 - val_auc: 0.7816 - val_binary_accuracy: 0.9062 - val_loss: 0.2684\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9043 - loss: 0.2722 - val_auc: 0.7873 - val_binary_accuracy: 0.9073 - val_loss: 0.2650\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9061 - loss: 0.2696 - val_auc: 0.7918 - val_binary_accuracy: 0.9081 - val_loss: 0.2634\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9074 - loss: 0.2678 - val_auc: 0.7946 - val_binary_accuracy: 0.9072 - val_loss: 0.2637\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9081 - loss: 0.2660 - val_auc: 0.7969 - val_binary_accuracy: 0.9079 - val_loss: 0.2639\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9087 - loss: 0.2645 - val_auc: 0.7983 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9084 - loss: 0.2638 - val_auc: 0.8001 - val_binary_accuracy: 0.9065 - val_loss: 0.2652\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8013 - val_binary_accuracy: 0.9071 - val_loss: 0.2658\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7952 - binary_accuracy: 0.9058 - loss: 0.2666\n",
      "Fold 3 Metrics: Loss = 0.2658, Accuracy = 0.9071, AUC = 0.8013\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6354 - binary_accuracy: 0.8301 - loss: 0.6190 - val_auc: 0.7861 - val_binary_accuracy: 0.9060 - val_loss: 0.2670\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9055 - loss: 0.2697 - val_auc: 0.7922 - val_binary_accuracy: 0.9066 - val_loss: 0.2635\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9058 - loss: 0.2663 - val_auc: 0.7966 - val_binary_accuracy: 0.9072 - val_loss: 0.2611\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9073 - loss: 0.2643 - val_auc: 0.8001 - val_binary_accuracy: 0.9072 - val_loss: 0.2598\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9078 - loss: 0.2634 - val_auc: 0.8021 - val_binary_accuracy: 0.9085 - val_loss: 0.2589\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9080 - loss: 0.2620 - val_auc: 0.8040 - val_binary_accuracy: 0.9064 - val_loss: 0.2586\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9085 - loss: 0.2612 - val_auc: 0.8061 - val_binary_accuracy: 0.9085 - val_loss: 0.2573\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9087 - loss: 0.2607 - val_auc: 0.8071 - val_binary_accuracy: 0.9081 - val_loss: 0.2568\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9095 - loss: 0.2599 - val_auc: 0.8083 - val_binary_accuracy: 0.9079 - val_loss: 0.2561\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9095 - loss: 0.2597 - val_auc: 0.8095 - val_binary_accuracy: 0.9084 - val_loss: 0.2556\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9072 - loss: 0.2619\n",
      "Fold 4 Metrics: Loss = 0.2556, Accuracy = 0.9084, AUC = 0.8095\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5681 - binary_accuracy: 0.8017 - loss: 1.5777 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7602 - binary_accuracy: 0.9040 - loss: 0.2780 - val_auc: 0.7966 - val_binary_accuracy: 0.9060 - val_loss: 0.2675\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9051 - loss: 0.2728 - val_auc: 0.8024 - val_binary_accuracy: 0.9063 - val_loss: 0.2599\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9068 - loss: 0.2695 - val_auc: 0.8041 - val_binary_accuracy: 0.9062 - val_loss: 0.2572\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.8061 - val_binary_accuracy: 0.9060 - val_loss: 0.2557\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9073 - loss: 0.2677 - val_auc: 0.8068 - val_binary_accuracy: 0.9057 - val_loss: 0.2553\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9074 - loss: 0.2674 - val_auc: 0.8077 - val_binary_accuracy: 0.9050 - val_loss: 0.2549\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9074 - loss: 0.2671 - val_auc: 0.8084 - val_binary_accuracy: 0.9076 - val_loss: 0.2534\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9075 - loss: 0.2661 - val_auc: 0.8089 - val_binary_accuracy: 0.9085 - val_loss: 0.2527\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7823 - binary_accuracy: 0.9077 - loss: 0.2656 - val_auc: 0.8085 - val_binary_accuracy: 0.9062 - val_loss: 0.2537\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8185 - binary_accuracy: 0.9057 - loss: 0.2510\n",
      "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9062, AUC = 0.8085\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2583\n",
      "Average Accuracy: 0.9082\n",
      "Average AUC: 0.8055\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 2, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7206 - binary_accuracy: 0.9015 - loss: 0.2951 - val_auc: 0.7831 - val_binary_accuracy: 0.9057 - val_loss: 0.2774\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9075 - loss: 0.2660 - val_auc: 0.7913 - val_binary_accuracy: 0.9082 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9103 - loss: 0.2602 - val_auc: 0.7923 - val_binary_accuracy: 0.9100 - val_loss: 0.2604\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9117 - loss: 0.2571 - val_auc: 0.7938 - val_binary_accuracy: 0.9093 - val_loss: 0.2603\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9121 - loss: 0.2553 - val_auc: 0.7942 - val_binary_accuracy: 0.9097 - val_loss: 0.2599\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9120 - loss: 0.2541 - val_auc: 0.7920 - val_binary_accuracy: 0.9090 - val_loss: 0.2725\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9104 - loss: 0.2563 - val_auc: 0.7953 - val_binary_accuracy: 0.9113 - val_loss: 0.2587\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9130 - loss: 0.2515 - val_auc: 0.7960 - val_binary_accuracy: 0.9113 - val_loss: 0.2612\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9125 - loss: 0.2512 - val_auc: 0.7964 - val_binary_accuracy: 0.9093 - val_loss: 0.2646\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9130 - loss: 0.2505 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2682\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9115 - loss: 0.2636\n",
      "Fold 1 Metrics: Loss = 0.2682, Accuracy = 0.9084, AUC = 0.7962\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6507 - binary_accuracy: 0.8843 - loss: 0.4740 - val_auc: 0.7976 - val_binary_accuracy: 0.8947 - val_loss: 0.3016\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7485 - binary_accuracy: 0.9023 - loss: 0.2852 - val_auc: 0.8083 - val_binary_accuracy: 0.9025 - val_loss: 0.2893\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9043 - loss: 0.2794 - val_auc: 0.8127 - val_binary_accuracy: 0.8916 - val_loss: 0.2959\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9051 - loss: 0.2766 - val_auc: 0.8112 - val_binary_accuracy: 0.8998 - val_loss: 0.2769\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9057 - loss: 0.2730 - val_auc: 0.8106 - val_binary_accuracy: 0.9073 - val_loss: 0.2647\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9065 - loss: 0.2696 - val_auc: 0.8122 - val_binary_accuracy: 0.9090 - val_loss: 0.2586\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9060 - loss: 0.2673 - val_auc: 0.8116 - val_binary_accuracy: 0.9078 - val_loss: 0.2565\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9058 - loss: 0.2656 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9065 - loss: 0.2643 - val_auc: 0.8129 - val_binary_accuracy: 0.9087 - val_loss: 0.2559\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9058 - loss: 0.2639 - val_auc: 0.8117 - val_binary_accuracy: 0.9084 - val_loss: 0.2563\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9129 - loss: 0.2466\n",
      "Fold 2 Metrics: Loss = 0.2563, Accuracy = 0.9084, AUC = 0.8117\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6639 - binary_accuracy: 0.8643 - loss: 0.6035 - val_auc: 0.7813 - val_binary_accuracy: 0.9066 - val_loss: 0.2673\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9042 - loss: 0.2733 - val_auc: 0.7930 - val_binary_accuracy: 0.9078 - val_loss: 0.2642\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9054 - loss: 0.2707 - val_auc: 0.7990 - val_binary_accuracy: 0.9073 - val_loss: 0.2617\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7723 - binary_accuracy: 0.9055 - loss: 0.2689 - val_auc: 0.8002 - val_binary_accuracy: 0.9088 - val_loss: 0.2587\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9066 - loss: 0.2686 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2568\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2682 - val_auc: 0.8021 - val_binary_accuracy: 0.9103 - val_loss: 0.2572\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9059 - loss: 0.2670 - val_auc: 0.8038 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9064 - loss: 0.2652 - val_auc: 0.8028 - val_binary_accuracy: 0.9102 - val_loss: 0.2566\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9071 - loss: 0.2647 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2565\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9075 - loss: 0.2614 - val_auc: 0.8046 - val_binary_accuracy: 0.9091 - val_loss: 0.2583\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7994 - binary_accuracy: 0.9108 - loss: 0.2583\n",
      "Fold 3 Metrics: Loss = 0.2583, Accuracy = 0.9091, AUC = 0.8046\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5694 - binary_accuracy: 0.8304 - loss: 1.5457 - val_auc: 0.7800 - val_binary_accuracy: 0.9056 - val_loss: 0.2700\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7628 - binary_accuracy: 0.9050 - loss: 0.2748 - val_auc: 0.7886 - val_binary_accuracy: 0.9076 - val_loss: 0.2643\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9077 - loss: 0.2698 - val_auc: 0.7945 - val_binary_accuracy: 0.9100 - val_loss: 0.2620\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9082 - loss: 0.2678 - val_auc: 0.7987 - val_binary_accuracy: 0.9101 - val_loss: 0.2602\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9079 - loss: 0.2668 - val_auc: 0.8028 - val_binary_accuracy: 0.9095 - val_loss: 0.2585\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9085 - loss: 0.2658 - val_auc: 0.8057 - val_binary_accuracy: 0.9093 - val_loss: 0.2578\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9085 - loss: 0.2653 - val_auc: 0.8074 - val_binary_accuracy: 0.9095 - val_loss: 0.2566\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.8083 - val_binary_accuracy: 0.9097 - val_loss: 0.2561\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9086 - loss: 0.2635 - val_auc: 0.8092 - val_binary_accuracy: 0.9098 - val_loss: 0.2557\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9086 - loss: 0.2629 - val_auc: 0.8098 - val_binary_accuracy: 0.9093 - val_loss: 0.2554\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7923 - binary_accuracy: 0.9090 - loss: 0.2623\n",
      "Fold 4 Metrics: Loss = 0.2554, Accuracy = 0.9093, AUC = 0.8098\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6531 - binary_accuracy: 0.8927 - loss: 0.4317 - val_auc: 0.7936 - val_binary_accuracy: 0.8969 - val_loss: 0.2813\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7395 - binary_accuracy: 0.9018 - loss: 0.2877 - val_auc: 0.8023 - val_binary_accuracy: 0.8939 - val_loss: 0.2877\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7499 - binary_accuracy: 0.9029 - loss: 0.2835 - val_auc: 0.8056 - val_binary_accuracy: 0.8904 - val_loss: 0.2915\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7577 - binary_accuracy: 0.9043 - loss: 0.2793 - val_auc: 0.8084 - val_binary_accuracy: 0.8942 - val_loss: 0.2893\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9052 - loss: 0.2770 - val_auc: 0.8088 - val_binary_accuracy: 0.8972 - val_loss: 0.2828\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9055 - loss: 0.2751 - val_auc: 0.8097 - val_binary_accuracy: 0.8977 - val_loss: 0.2783\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9063 - loss: 0.2732 - val_auc: 0.8101 - val_binary_accuracy: 0.8997 - val_loss: 0.2738\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9056 - loss: 0.2718 - val_auc: 0.8100 - val_binary_accuracy: 0.9005 - val_loss: 0.2708\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9055 - loss: 0.2708 - val_auc: 0.8100 - val_binary_accuracy: 0.9016 - val_loss: 0.2697\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.8098 - val_binary_accuracy: 0.9017 - val_loss: 0.2687\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8171 - binary_accuracy: 0.9044 - loss: 0.2660\n",
      "Fold 5 Metrics: Loss = 0.2687, Accuracy = 0.9017, AUC = 0.8098\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2614\n",
      "Average Accuracy: 0.9074\n",
      "Average AUC: 0.8064\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 2, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6751 - binary_accuracy: 0.8891 - loss: 0.4576 - val_auc: 0.7801 - val_binary_accuracy: 0.9048 - val_loss: 0.2903\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9071 - loss: 0.2705 - val_auc: 0.7893 - val_binary_accuracy: 0.9072 - val_loss: 0.2758\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9083 - loss: 0.2653 - val_auc: 0.7927 - val_binary_accuracy: 0.9068 - val_loss: 0.2953\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7971 - val_binary_accuracy: 0.9072 - val_loss: 0.2744\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9099 - loss: 0.2589 - val_auc: 0.7995 - val_binary_accuracy: 0.9100 - val_loss: 0.2568\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9128 - loss: 0.2536 - val_auc: 0.7993 - val_binary_accuracy: 0.9085 - val_loss: 0.2695\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9110 - loss: 0.2546 - val_auc: 0.7992 - val_binary_accuracy: 0.9104 - val_loss: 0.2565\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9133 - loss: 0.2506 - val_auc: 0.7986 - val_binary_accuracy: 0.9100 - val_loss: 0.2572\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9129 - loss: 0.2498 - val_auc: 0.7979 - val_binary_accuracy: 0.9109 - val_loss: 0.2608\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9135 - loss: 0.2497 - val_auc: 0.7989 - val_binary_accuracy: 0.9110 - val_loss: 0.2685\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7940 - binary_accuracy: 0.9147 - loss: 0.2639\n",
      "Fold 1 Metrics: Loss = 0.2685, Accuracy = 0.9110, AUC = 0.7989\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6523 - binary_accuracy: 0.8804 - loss: 0.4424 - val_auc: 0.8101 - val_binary_accuracy: 0.9072 - val_loss: 0.2617\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9016 - loss: 0.2777 - val_auc: 0.8124 - val_binary_accuracy: 0.9082 - val_loss: 0.2594\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7771 - binary_accuracy: 0.9039 - loss: 0.2722 - val_auc: 0.8119 - val_binary_accuracy: 0.9069 - val_loss: 0.2695\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7794 - binary_accuracy: 0.9050 - loss: 0.2712 - val_auc: 0.8135 - val_binary_accuracy: 0.9075 - val_loss: 0.2694\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9047 - loss: 0.2728 - val_auc: 0.8077 - val_binary_accuracy: 0.9032 - val_loss: 0.2869\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7746 - binary_accuracy: 0.9046 - loss: 0.2735 - val_auc: 0.8085 - val_binary_accuracy: 0.9062 - val_loss: 0.2697\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7793 - binary_accuracy: 0.9053 - loss: 0.2711 - val_auc: 0.8074 - val_binary_accuracy: 0.9085 - val_loss: 0.2583\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9061 - loss: 0.2668 - val_auc: 0.8010 - val_binary_accuracy: 0.9081 - val_loss: 0.2615\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9065 - loss: 0.2658 - val_auc: 0.8077 - val_binary_accuracy: 0.9097 - val_loss: 0.2575\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7954 - binary_accuracy: 0.9076 - loss: 0.2630 - val_auc: 0.8098 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8171 - binary_accuracy: 0.9121 - loss: 0.2472\n",
      "Fold 2 Metrics: Loss = 0.2560, Accuracy = 0.9090, AUC = 0.8098\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6354 - binary_accuracy: 0.8592 - loss: 1.1882 - val_auc: 0.7836 - val_binary_accuracy: 0.9063 - val_loss: 0.2833\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7343 - binary_accuracy: 0.9017 - loss: 0.2911 - val_auc: 0.7957 - val_binary_accuracy: 0.9054 - val_loss: 0.3158\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7497 - binary_accuracy: 0.9062 - loss: 0.2802 - val_auc: 0.7990 - val_binary_accuracy: 0.9063 - val_loss: 0.3010\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7469 - binary_accuracy: 0.9048 - loss: 0.2840 - val_auc: 0.8028 - val_binary_accuracy: 0.9103 - val_loss: 0.2643\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7557 - binary_accuracy: 0.9056 - loss: 0.2795 - val_auc: 0.8042 - val_binary_accuracy: 0.9079 - val_loss: 0.2603\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9059 - loss: 0.2735 - val_auc: 0.8053 - val_binary_accuracy: 0.9019 - val_loss: 0.2697\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9073 - loss: 0.2696 - val_auc: 0.8050 - val_binary_accuracy: 0.8979 - val_loss: 0.2764\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9063 - loss: 0.2675 - val_auc: 0.8050 - val_binary_accuracy: 0.9032 - val_loss: 0.2713\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9069 - loss: 0.2662 - val_auc: 0.8055 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9075 - loss: 0.2672 - val_auc: 0.8045 - val_binary_accuracy: 0.9106 - val_loss: 0.2564\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9113 - loss: 0.2574\n",
      "Fold 3 Metrics: Loss = 0.2564, Accuracy = 0.9106, AUC = 0.8045\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6163 - binary_accuracy: 0.8575 - loss: 1.0092 - val_auc: 0.7969 - val_binary_accuracy: 0.9069 - val_loss: 0.2687\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9063 - loss: 0.2717 - val_auc: 0.7996 - val_binary_accuracy: 0.9072 - val_loss: 0.2764\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9062 - loss: 0.2717 - val_auc: 0.8056 - val_binary_accuracy: 0.9084 - val_loss: 0.2722\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9072 - loss: 0.2693 - val_auc: 0.8056 - val_binary_accuracy: 0.9093 - val_loss: 0.2649\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9081 - loss: 0.2673 - val_auc: 0.8103 - val_binary_accuracy: 0.9088 - val_loss: 0.2744\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9080 - loss: 0.2664 - val_auc: 0.8102 - val_binary_accuracy: 0.9095 - val_loss: 0.2560\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9096 - loss: 0.2632 - val_auc: 0.8079 - val_binary_accuracy: 0.9090 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9099 - loss: 0.2632 - val_auc: 0.8097 - val_binary_accuracy: 0.9098 - val_loss: 0.2559\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2621 - val_auc: 0.8114 - val_binary_accuracy: 0.9091 - val_loss: 0.2548\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8106 - val_binary_accuracy: 0.9091 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9082 - loss: 0.2627\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9091, AUC = 0.8106\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6018 - binary_accuracy: 0.8659 - loss: 0.8248 - val_auc: 0.7914 - val_binary_accuracy: 0.8991 - val_loss: 0.2734\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7383 - binary_accuracy: 0.9010 - loss: 0.2886 - val_auc: 0.8022 - val_binary_accuracy: 0.8964 - val_loss: 0.2739\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7462 - binary_accuracy: 0.9019 - loss: 0.2855 - val_auc: 0.8053 - val_binary_accuracy: 0.8974 - val_loss: 0.2661\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7504 - binary_accuracy: 0.9025 - loss: 0.2836 - val_auc: 0.8068 - val_binary_accuracy: 0.8948 - val_loss: 0.2792\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7560 - binary_accuracy: 0.9043 - loss: 0.2796 - val_auc: 0.8080 - val_binary_accuracy: 0.8963 - val_loss: 0.2804\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9047 - loss: 0.2770 - val_auc: 0.8085 - val_binary_accuracy: 0.8954 - val_loss: 0.2792\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9050 - loss: 0.2745 - val_auc: 0.8091 - val_binary_accuracy: 0.8986 - val_loss: 0.2732\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9049 - loss: 0.2723 - val_auc: 0.8096 - val_binary_accuracy: 0.9004 - val_loss: 0.2684\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9050 - loss: 0.2709 - val_auc: 0.8097 - val_binary_accuracy: 0.9047 - val_loss: 0.2630\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9055 - loss: 0.2689 - val_auc: 0.8094 - val_binary_accuracy: 0.9036 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9055 - loss: 0.2615\n",
      "Fold 5 Metrics: Loss = 0.2635, Accuracy = 0.9036, AUC = 0.8094\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2599\n",
      "Average Accuracy: 0.9087\n",
      "Average AUC: 0.8066\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 2, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6504 - binary_accuracy: 0.8786 - loss: 0.5864 - val_auc: 0.7817 - val_binary_accuracy: 0.9090 - val_loss: 0.2642\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7497 - binary_accuracy: 0.9061 - loss: 0.2797 - val_auc: 0.7915 - val_binary_accuracy: 0.9097 - val_loss: 0.2596\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9094 - loss: 0.2658 - val_auc: 0.7916 - val_binary_accuracy: 0.9096 - val_loss: 0.2672\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9096 - loss: 0.2645 - val_auc: 0.7939 - val_binary_accuracy: 0.9072 - val_loss: 0.2882\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9106 - loss: 0.2604 - val_auc: 0.7954 - val_binary_accuracy: 0.9075 - val_loss: 0.2800\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9101 - loss: 0.2594 - val_auc: 0.7972 - val_binary_accuracy: 0.9106 - val_loss: 0.2575\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9119 - loss: 0.2534 - val_auc: 0.7982 - val_binary_accuracy: 0.9110 - val_loss: 0.2569\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9129 - loss: 0.2515 - val_auc: 0.7977 - val_binary_accuracy: 0.9118 - val_loss: 0.2590\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9126 - loss: 0.2512 - val_auc: 0.7983 - val_binary_accuracy: 0.9115 - val_loss: 0.2604\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9129 - loss: 0.2498 - val_auc: 0.7975 - val_binary_accuracy: 0.9100 - val_loss: 0.2641\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7943 - binary_accuracy: 0.9126 - loss: 0.2593\n",
      "Fold 1 Metrics: Loss = 0.2641, Accuracy = 0.9100, AUC = 0.7975\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6451 - binary_accuracy: 0.8699 - loss: 0.7414 - val_auc: 0.8049 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9026 - loss: 0.2829 - val_auc: 0.8066 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9054 - loss: 0.2741 - val_auc: 0.8084 - val_binary_accuracy: 0.9090 - val_loss: 0.2603\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9047 - loss: 0.2715 - val_auc: 0.8099 - val_binary_accuracy: 0.9093 - val_loss: 0.2710\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9046 - loss: 0.2708 - val_auc: 0.8078 - val_binary_accuracy: 0.9068 - val_loss: 0.2784\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.8036 - val_binary_accuracy: 0.9097 - val_loss: 0.2598\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9065 - loss: 0.2692 - val_auc: 0.8046 - val_binary_accuracy: 0.9094 - val_loss: 0.2610\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9070 - loss: 0.2643 - val_auc: 0.8036 - val_binary_accuracy: 0.9099 - val_loss: 0.2586\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9073 - loss: 0.2626 - val_auc: 0.8043 - val_binary_accuracy: 0.9099 - val_loss: 0.2599\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9074 - loss: 0.2612 - val_auc: 0.7874 - val_binary_accuracy: 0.9091 - val_loss: 0.2646\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7999 - binary_accuracy: 0.9126 - loss: 0.2546\n",
      "Fold 2 Metrics: Loss = 0.2646, Accuracy = 0.9091, AUC = 0.7874\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6312 - binary_accuracy: 0.8660 - loss: 1.1762 - val_auc: 0.7974 - val_binary_accuracy: 0.9044 - val_loss: 0.2904\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7125 - binary_accuracy: 0.8964 - loss: 0.3124 - val_auc: 0.8023 - val_binary_accuracy: 0.9088 - val_loss: 0.2753\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7300 - binary_accuracy: 0.9011 - loss: 0.2977 - val_auc: 0.8039 - val_binary_accuracy: 0.9102 - val_loss: 0.2717\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7544 - binary_accuracy: 0.9030 - loss: 0.2803 - val_auc: 0.8034 - val_binary_accuracy: 0.9109 - val_loss: 0.2582\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7682 - binary_accuracy: 0.9053 - loss: 0.2721 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2785\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9056 - loss: 0.2778 - val_auc: 0.8070 - val_binary_accuracy: 0.9029 - val_loss: 0.2728\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9071 - loss: 0.2688 - val_auc: 0.8083 - val_binary_accuracy: 0.9048 - val_loss: 0.2672\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9059 - loss: 0.2665 - val_auc: 0.8085 - val_binary_accuracy: 0.9102 - val_loss: 0.2558\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9066 - loss: 0.2673 - val_auc: 0.8046 - val_binary_accuracy: 0.9115 - val_loss: 0.2581\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9060 - loss: 0.2694 - val_auc: 0.8055 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7987 - binary_accuracy: 0.9127 - loss: 0.2570\n",
      "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9109, AUC = 0.8055\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6304 - binary_accuracy: 0.8679 - loss: 0.8913 - val_auc: 0.7991 - val_binary_accuracy: 0.9059 - val_loss: 0.2620\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7455 - binary_accuracy: 0.9030 - loss: 0.2861 - val_auc: 0.8030 - val_binary_accuracy: 0.8994 - val_loss: 0.2697\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7504 - binary_accuracy: 0.9039 - loss: 0.2830 - val_auc: 0.8068 - val_binary_accuracy: 0.9036 - val_loss: 0.2613\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7532 - binary_accuracy: 0.9046 - loss: 0.2829 - val_auc: 0.8096 - val_binary_accuracy: 0.9062 - val_loss: 0.2562\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9077 - loss: 0.2700 - val_auc: 0.8097 - val_binary_accuracy: 0.9097 - val_loss: 0.2577\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9083 - loss: 0.2682 - val_auc: 0.8111 - val_binary_accuracy: 0.9087 - val_loss: 0.2879\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9082 - loss: 0.2706 - val_auc: 0.8127 - val_binary_accuracy: 0.9098 - val_loss: 0.2601\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9086 - loss: 0.2642 - val_auc: 0.8118 - val_binary_accuracy: 0.9097 - val_loss: 0.2550\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9096 - loss: 0.2642 - val_auc: 0.8109 - val_binary_accuracy: 0.9079 - val_loss: 0.2547\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9090 - loss: 0.2631 - val_auc: 0.8117 - val_binary_accuracy: 0.9097 - val_loss: 0.2546\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7939 - binary_accuracy: 0.9087 - loss: 0.2618\n",
      "Fold 4 Metrics: Loss = 0.2546, Accuracy = 0.9097, AUC = 0.8117\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6253 - binary_accuracy: 0.8703 - loss: 0.8894 - val_auc: 0.7991 - val_binary_accuracy: 0.9020 - val_loss: 0.2607\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7261 - binary_accuracy: 0.8994 - loss: 0.2994 - val_auc: 0.8043 - val_binary_accuracy: 0.8976 - val_loss: 0.2687\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7441 - binary_accuracy: 0.9007 - loss: 0.2874 - val_auc: 0.8064 - val_binary_accuracy: 0.8941 - val_loss: 0.2824\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7505 - binary_accuracy: 0.9025 - loss: 0.2835 - val_auc: 0.8074 - val_binary_accuracy: 0.8932 - val_loss: 0.2816\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9044 - loss: 0.2779 - val_auc: 0.8087 - val_binary_accuracy: 0.8955 - val_loss: 0.2819\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7670 - binary_accuracy: 0.9047 - loss: 0.2749 - val_auc: 0.8082 - val_binary_accuracy: 0.8997 - val_loss: 0.2742\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9046 - loss: 0.2726 - val_auc: 0.8087 - val_binary_accuracy: 0.8982 - val_loss: 0.2733\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9045 - loss: 0.2717 - val_auc: 0.8086 - val_binary_accuracy: 0.9028 - val_loss: 0.2651\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9049 - loss: 0.2713 - val_auc: 0.8088 - val_binary_accuracy: 0.9091 - val_loss: 0.2544\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9082 - loss: 0.2678 - val_auc: 0.8098 - val_binary_accuracy: 0.9103 - val_loss: 0.2518\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9092 - loss: 0.2512\n",
      "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9103, AUC = 0.8098\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2584\n",
      "Average Accuracy: 0.9100\n",
      "Average AUC: 0.8024\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 3, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6665 - binary_accuracy: 0.8809 - loss: 0.3548 - val_auc: 0.7707 - val_binary_accuracy: 0.9053 - val_loss: 0.2720\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9099 - loss: 0.2599 - val_auc: 0.7797 - val_binary_accuracy: 0.9054 - val_loss: 0.2697\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9112 - loss: 0.2573 - val_auc: 0.7813 - val_binary_accuracy: 0.9088 - val_loss: 0.2655\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9124 - loss: 0.2552 - val_auc: 0.7835 - val_binary_accuracy: 0.9094 - val_loss: 0.2650\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9120 - loss: 0.2541 - val_auc: 0.7842 - val_binary_accuracy: 0.9097 - val_loss: 0.2642\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9124 - loss: 0.2531 - val_auc: 0.7844 - val_binary_accuracy: 0.9082 - val_loss: 0.2656\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9124 - loss: 0.2528 - val_auc: 0.7838 - val_binary_accuracy: 0.9084 - val_loss: 0.2655\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9131 - loss: 0.2516 - val_auc: 0.7850 - val_binary_accuracy: 0.9087 - val_loss: 0.2645\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9131 - loss: 0.2506 - val_auc: 0.7873 - val_binary_accuracy: 0.9084 - val_loss: 0.2631\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9137 - loss: 0.2498 - val_auc: 0.7884 - val_binary_accuracy: 0.9090 - val_loss: 0.2616\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7839 - binary_accuracy: 0.9112 - loss: 0.2553\n",
      "Fold 1 Metrics: Loss = 0.2616, Accuracy = 0.9090, AUC = 0.7884\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6155 - binary_accuracy: 0.6510 - loss: 4.1405 - val_auc: 0.7794 - val_binary_accuracy: 0.9062 - val_loss: 0.2693\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9053 - loss: 0.2719 - val_auc: 0.7858 - val_binary_accuracy: 0.9066 - val_loss: 0.2671\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9056 - loss: 0.2693 - val_auc: 0.7872 - val_binary_accuracy: 0.9069 - val_loss: 0.2670\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9059 - loss: 0.2673 - val_auc: 0.7906 - val_binary_accuracy: 0.9073 - val_loss: 0.2652\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9057 - loss: 0.2665 - val_auc: 0.7928 - val_binary_accuracy: 0.9071 - val_loss: 0.2647\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9060 - loss: 0.2655 - val_auc: 0.7938 - val_binary_accuracy: 0.9075 - val_loss: 0.2648\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9067 - loss: 0.2648 - val_auc: 0.7987 - val_binary_accuracy: 0.9082 - val_loss: 0.2628\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9065 - loss: 0.2640 - val_auc: 0.7981 - val_binary_accuracy: 0.9081 - val_loss: 0.2629\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9069 - loss: 0.2633 - val_auc: 0.7996 - val_binary_accuracy: 0.9082 - val_loss: 0.2611\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9071 - loss: 0.2624 - val_auc: 0.8021 - val_binary_accuracy: 0.9084 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8058 - binary_accuracy: 0.9120 - loss: 0.2503\n",
      "Fold 2 Metrics: Loss = 0.2599, Accuracy = 0.9084, AUC = 0.8021\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5921 - binary_accuracy: 0.8004 - loss: 0.7227 - val_auc: 0.7783 - val_binary_accuracy: 0.9045 - val_loss: 0.2729\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9058 - loss: 0.2708 - val_auc: 0.7856 - val_binary_accuracy: 0.9045 - val_loss: 0.2701\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.7903 - val_binary_accuracy: 0.9056 - val_loss: 0.2687\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9070 - loss: 0.2667 - val_auc: 0.7940 - val_binary_accuracy: 0.9059 - val_loss: 0.2657\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9072 - loss: 0.2661 - val_auc: 0.7964 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9076 - loss: 0.2651 - val_auc: 0.7981 - val_binary_accuracy: 0.9097 - val_loss: 0.2615\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9085 - loss: 0.2648 - val_auc: 0.7985 - val_binary_accuracy: 0.9104 - val_loss: 0.2605\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9091 - loss: 0.2640 - val_auc: 0.7985 - val_binary_accuracy: 0.9107 - val_loss: 0.2604\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.7994 - val_binary_accuracy: 0.9112 - val_loss: 0.2601\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9092 - loss: 0.2630 - val_auc: 0.7999 - val_binary_accuracy: 0.9118 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9134 - loss: 0.2596\n",
      "Fold 3 Metrics: Loss = 0.2599, Accuracy = 0.9118, AUC = 0.7999\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5840 - binary_accuracy: 0.9036 - loss: 0.6592 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2716\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9041 - loss: 0.2733 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9053 - loss: 0.2686 - val_auc: 0.7917 - val_binary_accuracy: 0.9047 - val_loss: 0.2635\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9066 - loss: 0.2660 - val_auc: 0.7953 - val_binary_accuracy: 0.9069 - val_loss: 0.2616\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.7974 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9084 - loss: 0.2631 - val_auc: 0.7989 - val_binary_accuracy: 0.9087 - val_loss: 0.2593\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9092 - loss: 0.2622 - val_auc: 0.8015 - val_binary_accuracy: 0.9098 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9099 - loss: 0.2614 - val_auc: 0.8030 - val_binary_accuracy: 0.9100 - val_loss: 0.2574\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.8052 - val_binary_accuracy: 0.9106 - val_loss: 0.2567\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9099 - loss: 0.2600 - val_auc: 0.8075 - val_binary_accuracy: 0.9101 - val_loss: 0.2560\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7887 - binary_accuracy: 0.9099 - loss: 0.2617\n",
      "Fold 4 Metrics: Loss = 0.2560, Accuracy = 0.9101, AUC = 0.8075\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6327 - binary_accuracy: 0.9013 - loss: 0.3295 - val_auc: 0.7975 - val_binary_accuracy: 0.9050 - val_loss: 0.2635\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9047 - loss: 0.2742 - val_auc: 0.8009 - val_binary_accuracy: 0.9054 - val_loss: 0.2606\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9044 - loss: 0.2713 - val_auc: 0.8029 - val_binary_accuracy: 0.9048 - val_loss: 0.2600\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9054 - loss: 0.2696 - val_auc: 0.8037 - val_binary_accuracy: 0.9060 - val_loss: 0.2603\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9063 - loss: 0.2679 - val_auc: 0.8051 - val_binary_accuracy: 0.9064 - val_loss: 0.2612\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9065 - loss: 0.2664 - val_auc: 0.8060 - val_binary_accuracy: 0.9070 - val_loss: 0.2612\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9067 - loss: 0.2652 - val_auc: 0.8068 - val_binary_accuracy: 0.9073 - val_loss: 0.2614\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9071 - loss: 0.2646 - val_auc: 0.8073 - val_binary_accuracy: 0.9060 - val_loss: 0.2625\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9074 - loss: 0.2641 - val_auc: 0.8077 - val_binary_accuracy: 0.9062 - val_loss: 0.2635\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8081 - val_binary_accuracy: 0.9056 - val_loss: 0.2646\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8173 - binary_accuracy: 0.9061 - loss: 0.2620\n",
      "Fold 5 Metrics: Loss = 0.2646, Accuracy = 0.9056, AUC = 0.8081\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2604\n",
      "Average Accuracy: 0.9090\n",
      "Average AUC: 0.8012\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 3, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - auc: 0.5937 - binary_accuracy: 0.8173 - loss: 0.9928 - val_auc: 0.7537 - val_binary_accuracy: 0.9044 - val_loss: 0.2783\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9072 - loss: 0.2688 - val_auc: 0.7666 - val_binary_accuracy: 0.9051 - val_loss: 0.2734\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9082 - loss: 0.2637 - val_auc: 0.7752 - val_binary_accuracy: 0.9060 - val_loss: 0.2701\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9094 - loss: 0.2592 - val_auc: 0.7817 - val_binary_accuracy: 0.9075 - val_loss: 0.2679\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9099 - loss: 0.2582 - val_auc: 0.7860 - val_binary_accuracy: 0.9063 - val_loss: 0.2665\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9105 - loss: 0.2556 - val_auc: 0.7906 - val_binary_accuracy: 0.9078 - val_loss: 0.2641\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9114 - loss: 0.2535 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2627\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9114 - loss: 0.2525 - val_auc: 0.7919 - val_binary_accuracy: 0.9099 - val_loss: 0.2621\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8050 - binary_accuracy: 0.9117 - loss: 0.2514 - val_auc: 0.7944 - val_binary_accuracy: 0.9096 - val_loss: 0.2622\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8067 - binary_accuracy: 0.9119 - loss: 0.2506 - val_auc: 0.7947 - val_binary_accuracy: 0.9096 - val_loss: 0.2614\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9130 - loss: 0.2529\n",
      "Fold 1 Metrics: Loss = 0.2614, Accuracy = 0.9096, AUC = 0.7947\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6341 - binary_accuracy: 0.8556 - loss: 0.5990 - val_auc: 0.7921 - val_binary_accuracy: 0.9081 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9058 - loss: 0.2726 - val_auc: 0.8011 - val_binary_accuracy: 0.9071 - val_loss: 0.2636\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9061 - loss: 0.2684 - val_auc: 0.8076 - val_binary_accuracy: 0.9081 - val_loss: 0.2601\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9073 - loss: 0.2658 - val_auc: 0.8074 - val_binary_accuracy: 0.9088 - val_loss: 0.2601\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9070 - loss: 0.2646 - val_auc: 0.7926 - val_binary_accuracy: 0.9088 - val_loss: 0.2640\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9066 - loss: 0.2638 - val_auc: 0.8001 - val_binary_accuracy: 0.9097 - val_loss: 0.2617\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7975 - binary_accuracy: 0.9074 - loss: 0.2621 - val_auc: 0.8042 - val_binary_accuracy: 0.9097 - val_loss: 0.2602\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9077 - loss: 0.2613 - val_auc: 0.7962 - val_binary_accuracy: 0.9100 - val_loss: 0.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9077 - loss: 0.2617 - val_auc: 0.7965 - val_binary_accuracy: 0.9096 - val_loss: 0.2630\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9080 - loss: 0.2611 - val_auc: 0.8082 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8139 - binary_accuracy: 0.9123 - loss: 0.2519\n",
      "Fold 2 Metrics: Loss = 0.2608, Accuracy = 0.9078, AUC = 0.8082\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7358 - binary_accuracy: 0.9028 - loss: 0.2868 - val_auc: 0.7793 - val_binary_accuracy: 0.9050 - val_loss: 0.2715\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7651 - binary_accuracy: 0.9059 - loss: 0.2716 - val_auc: 0.7876 - val_binary_accuracy: 0.9065 - val_loss: 0.2706\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9080 - loss: 0.2672 - val_auc: 0.7938 - val_binary_accuracy: 0.9034 - val_loss: 0.2710\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9079 - loss: 0.2655 - val_auc: 0.7952 - val_binary_accuracy: 0.9066 - val_loss: 0.2670\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9085 - loss: 0.2657 - val_auc: 0.7968 - val_binary_accuracy: 0.9038 - val_loss: 0.2660\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9086 - loss: 0.2650 - val_auc: 0.7997 - val_binary_accuracy: 0.9056 - val_loss: 0.2631\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9088 - loss: 0.2656 - val_auc: 0.8009 - val_binary_accuracy: 0.9087 - val_loss: 0.2597\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9090 - loss: 0.2644 - val_auc: 0.8020 - val_binary_accuracy: 0.9047 - val_loss: 0.2618\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9090 - loss: 0.2648 - val_auc: 0.8026 - val_binary_accuracy: 0.9063 - val_loss: 0.2604\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9094 - loss: 0.2647 - val_auc: 0.8032 - val_binary_accuracy: 0.9094 - val_loss: 0.2573\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7966 - binary_accuracy: 0.9113 - loss: 0.2573\n",
      "Fold 3 Metrics: Loss = 0.2573, Accuracy = 0.9094, AUC = 0.8032\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6065 - binary_accuracy: 0.8294 - loss: 0.9768 - val_auc: 0.7830 - val_binary_accuracy: 0.9060 - val_loss: 0.2673\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9069 - loss: 0.2726 - val_auc: 0.7948 - val_binary_accuracy: 0.9094 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9085 - loss: 0.2673 - val_auc: 0.7999 - val_binary_accuracy: 0.9093 - val_loss: 0.2596\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9090 - loss: 0.2647 - val_auc: 0.8028 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9095 - loss: 0.2630 - val_auc: 0.8046 - val_binary_accuracy: 0.9091 - val_loss: 0.2571\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8064 - val_binary_accuracy: 0.9088 - val_loss: 0.2565\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9100 - loss: 0.2608 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2561\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9101 - loss: 0.2604 - val_auc: 0.8080 - val_binary_accuracy: 0.9078 - val_loss: 0.2560\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9098 - loss: 0.2601 - val_auc: 0.8078 - val_binary_accuracy: 0.9073 - val_loss: 0.2560\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9105 - loss: 0.2591 - val_auc: 0.8093 - val_binary_accuracy: 0.9067 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7920 - binary_accuracy: 0.9055 - loss: 0.2624\n",
      "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9067, AUC = 0.8093\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6545 - binary_accuracy: 0.8859 - loss: 0.3953 - val_auc: 0.7898 - val_binary_accuracy: 0.9073 - val_loss: 0.2651\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7587 - binary_accuracy: 0.9047 - loss: 0.2773 - val_auc: 0.7965 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7628 - binary_accuracy: 0.9048 - loss: 0.2751 - val_auc: 0.8017 - val_binary_accuracy: 0.9093 - val_loss: 0.2603\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7659 - binary_accuracy: 0.9043 - loss: 0.2730 - val_auc: 0.8038 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9056 - loss: 0.2703 - val_auc: 0.8052 - val_binary_accuracy: 0.9097 - val_loss: 0.2551\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9068 - loss: 0.2681 - val_auc: 0.8063 - val_binary_accuracy: 0.9094 - val_loss: 0.2535\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9077 - loss: 0.2662 - val_auc: 0.8072 - val_binary_accuracy: 0.9101 - val_loss: 0.2548\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9082 - loss: 0.2650 - val_auc: 0.8072 - val_binary_accuracy: 0.9066 - val_loss: 0.2581\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8079 - val_binary_accuracy: 0.9076 - val_loss: 0.2598\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.8072 - val_binary_accuracy: 0.9007 - val_loss: 0.2656\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8175 - binary_accuracy: 0.9040 - loss: 0.2620\n",
      "Fold 5 Metrics: Loss = 0.2656, Accuracy = 0.9007, AUC = 0.8072\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2602\n",
      "Average Accuracy: 0.9068\n",
      "Average AUC: 0.8045\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 3, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6956 - binary_accuracy: 0.8981 - loss: 0.3256 - val_auc: 0.7753 - val_binary_accuracy: 0.9066 - val_loss: 0.2714\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9109 - loss: 0.2643 - val_auc: 0.7793 - val_binary_accuracy: 0.9051 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9109 - loss: 0.2587 - val_auc: 0.7843 - val_binary_accuracy: 0.9053 - val_loss: 0.2744\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9102 - loss: 0.2562 - val_auc: 0.7861 - val_binary_accuracy: 0.9076 - val_loss: 0.2693\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9111 - loss: 0.2540 - val_auc: 0.7888 - val_binary_accuracy: 0.9091 - val_loss: 0.2610\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9134 - loss: 0.2522 - val_auc: 0.7873 - val_binary_accuracy: 0.9088 - val_loss: 0.2628\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9128 - loss: 0.2523 - val_auc: 0.7875 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9132 - loss: 0.2509 - val_auc: 0.7874 - val_binary_accuracy: 0.9081 - val_loss: 0.2658\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9125 - loss: 0.2510 - val_auc: 0.7905 - val_binary_accuracy: 0.9078 - val_loss: 0.2643\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9126 - loss: 0.2500 - val_auc: 0.7934 - val_binary_accuracy: 0.9087 - val_loss: 0.2630\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7922 - binary_accuracy: 0.9116 - loss: 0.2540\n",
      "Fold 1 Metrics: Loss = 0.2630, Accuracy = 0.9087, AUC = 0.7934\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6361 - binary_accuracy: 0.8670 - loss: 0.5392 - val_auc: 0.7902 - val_binary_accuracy: 0.9072 - val_loss: 0.2664\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9043 - loss: 0.2703 - val_auc: 0.7981 - val_binary_accuracy: 0.9079 - val_loss: 0.2626\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9057 - loss: 0.2677 - val_auc: 0.8008 - val_binary_accuracy: 0.9084 - val_loss: 0.2616\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9062 - loss: 0.2668 - val_auc: 0.7989 - val_binary_accuracy: 0.9099 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9065 - loss: 0.2667 - val_auc: 0.8062 - val_binary_accuracy: 0.9097 - val_loss: 0.2585\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9079 - loss: 0.2630 - val_auc: 0.8099 - val_binary_accuracy: 0.9097 - val_loss: 0.2600\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9078 - loss: 0.2615 - val_auc: 0.8086 - val_binary_accuracy: 0.9085 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9077 - loss: 0.2622 - val_auc: 0.8068 - val_binary_accuracy: 0.9099 - val_loss: 0.2579\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9086 - loss: 0.2605 - val_auc: 0.7886 - val_binary_accuracy: 0.9085 - val_loss: 0.2636\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9079 - loss: 0.2608 - val_auc: 0.8095 - val_binary_accuracy: 0.9084 - val_loss: 0.2578\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9133 - loss: 0.2487\n",
      "Fold 2 Metrics: Loss = 0.2578, Accuracy = 0.9084, AUC = 0.8095\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5923 - binary_accuracy: 0.8422 - loss: 1.5019 - val_auc: 0.7845 - val_binary_accuracy: 0.9094 - val_loss: 0.2713\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9060 - loss: 0.2708 - val_auc: 0.7917 - val_binary_accuracy: 0.9102 - val_loss: 0.2628\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9057 - loss: 0.2703 - val_auc: 0.7971 - val_binary_accuracy: 0.9103 - val_loss: 0.2601\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9060 - loss: 0.2695 - val_auc: 0.7996 - val_binary_accuracy: 0.9106 - val_loss: 0.2588\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9062 - loss: 0.2684 - val_auc: 0.8010 - val_binary_accuracy: 0.9107 - val_loss: 0.2581\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9062 - loss: 0.2660 - val_auc: 0.8041 - val_binary_accuracy: 0.9104 - val_loss: 0.2568\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9076 - loss: 0.2639 - val_auc: 0.8044 - val_binary_accuracy: 0.9107 - val_loss: 0.2583\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9084 - loss: 0.2621 - val_auc: 0.8048 - val_binary_accuracy: 0.9100 - val_loss: 0.2609\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.8040 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9087 - loss: 0.2611 - val_auc: 0.8040 - val_binary_accuracy: 0.9071 - val_loss: 0.2631\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7953 - binary_accuracy: 0.9070 - loss: 0.2647\n",
      "Fold 3 Metrics: Loss = 0.2631, Accuracy = 0.9071, AUC = 0.8040\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6367 - binary_accuracy: 0.8423 - loss: 0.8825 - val_auc: 0.7859 - val_binary_accuracy: 0.9056 - val_loss: 0.2670\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9066 - loss: 0.2724 - val_auc: 0.7916 - val_binary_accuracy: 0.9063 - val_loss: 0.2652\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9070 - loss: 0.2686 - val_auc: 0.7988 - val_binary_accuracy: 0.9063 - val_loss: 0.2617\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9069 - loss: 0.2664 - val_auc: 0.8009 - val_binary_accuracy: 0.9079 - val_loss: 0.2597\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9078 - loss: 0.2651 - val_auc: 0.8030 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9088 - loss: 0.2630 - val_auc: 0.8057 - val_binary_accuracy: 0.9067 - val_loss: 0.2583\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9096 - loss: 0.2612 - val_auc: 0.8065 - val_binary_accuracy: 0.9060 - val_loss: 0.2581\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9094 - loss: 0.2607 - val_auc: 0.8071 - val_binary_accuracy: 0.9054 - val_loss: 0.2576\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9095 - loss: 0.2596 - val_auc: 0.8063 - val_binary_accuracy: 0.9029 - val_loss: 0.2584\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9096 - loss: 0.2590 - val_auc: 0.8078 - val_binary_accuracy: 0.9045 - val_loss: 0.2571\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7888 - binary_accuracy: 0.9034 - loss: 0.2643\n",
      "Fold 4 Metrics: Loss = 0.2571, Accuracy = 0.9045, AUC = 0.8078\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6077 - binary_accuracy: 0.8418 - loss: 1.1925 - val_auc: 0.7915 - val_binary_accuracy: 0.9060 - val_loss: 0.2669\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9026 - loss: 0.2794 - val_auc: 0.7980 - val_binary_accuracy: 0.9013 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7592 - binary_accuracy: 0.9033 - loss: 0.2775 - val_auc: 0.8011 - val_binary_accuracy: 0.9022 - val_loss: 0.2667\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9039 - loss: 0.2756 - val_auc: 0.8030 - val_binary_accuracy: 0.9059 - val_loss: 0.2590\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9045 - loss: 0.2732 - val_auc: 0.8042 - val_binary_accuracy: 0.9073 - val_loss: 0.2569\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9055 - loss: 0.2711 - val_auc: 0.8046 - val_binary_accuracy: 0.9095 - val_loss: 0.2549\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9066 - loss: 0.2716 - val_auc: 0.8053 - val_binary_accuracy: 0.9082 - val_loss: 0.2546\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9071 - loss: 0.2672 - val_auc: 0.8060 - val_binary_accuracy: 0.9079 - val_loss: 0.2548\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9076 - loss: 0.2658 - val_auc: 0.8058 - val_binary_accuracy: 0.9101 - val_loss: 0.2537\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9083 - loss: 0.2641 - val_auc: 0.8068 - val_binary_accuracy: 0.9091 - val_loss: 0.2604\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9103 - loss: 0.2588\n",
      "Fold 5 Metrics: Loss = 0.2604, Accuracy = 0.9091, AUC = 0.8068\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2603\n",
      "Average Accuracy: 0.9075\n",
      "Average AUC: 0.8043\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 3, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6620 - binary_accuracy: 0.8833 - loss: 0.4496 - val_auc: 0.7799 - val_binary_accuracy: 0.9063 - val_loss: 0.2659\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9081 - loss: 0.2658 - val_auc: 0.7848 - val_binary_accuracy: 0.9094 - val_loss: 0.2648\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9113 - loss: 0.2585 - val_auc: 0.7904 - val_binary_accuracy: 0.9099 - val_loss: 0.2627\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9116 - loss: 0.2551 - val_auc: 0.7899 - val_binary_accuracy: 0.9099 - val_loss: 0.2674\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9122 - loss: 0.2547 - val_auc: 0.7905 - val_binary_accuracy: 0.9116 - val_loss: 0.2607\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9130 - loss: 0.2520 - val_auc: 0.7956 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9134 - loss: 0.2508 - val_auc: 0.7931 - val_binary_accuracy: 0.9091 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9132 - loss: 0.2502 - val_auc: 0.7965 - val_binary_accuracy: 0.9094 - val_loss: 0.2582\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9127 - loss: 0.2493 - val_auc: 0.7941 - val_binary_accuracy: 0.9084 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9126 - loss: 0.2507 - val_auc: 0.7925 - val_binary_accuracy: 0.9078 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2541\n",
      "Fold 1 Metrics: Loss = 0.2635, Accuracy = 0.9078, AUC = 0.7925\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6600 - binary_accuracy: 0.8773 - loss: 0.4980 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7620 - binary_accuracy: 0.9007 - loss: 0.2799 - val_auc: 0.8084 - val_binary_accuracy: 0.9075 - val_loss: 0.2741\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9035 - loss: 0.2776 - val_auc: 0.8099 - val_binary_accuracy: 0.9087 - val_loss: 0.2728\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9048 - loss: 0.2731 - val_auc: 0.8094 - val_binary_accuracy: 0.9090 - val_loss: 0.2603\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9072 - loss: 0.2662 - val_auc: 0.8081 - val_binary_accuracy: 0.9085 - val_loss: 0.2601\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9079 - loss: 0.2648 - val_auc: 0.8067 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9073 - loss: 0.2640 - val_auc: 0.8100 - val_binary_accuracy: 0.9093 - val_loss: 0.2604\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9082 - loss: 0.2621 - val_auc: 0.8084 - val_binary_accuracy: 0.9088 - val_loss: 0.2623\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9086 - loss: 0.2616 - val_auc: 0.8096 - val_binary_accuracy: 0.9091 - val_loss: 0.2619\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9087 - loss: 0.2606 - val_auc: 0.8117 - val_binary_accuracy: 0.9094 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9136 - loss: 0.2495\n",
      "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9094, AUC = 0.8117\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6791 - binary_accuracy: 0.8861 - loss: 0.3834 - val_auc: 0.7818 - val_binary_accuracy: 0.9048 - val_loss: 0.2699\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7358 - binary_accuracy: 0.9021 - loss: 0.2882 - val_auc: 0.7873 - val_binary_accuracy: 0.9094 - val_loss: 0.2638\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9046 - loss: 0.2724 - val_auc: 0.7951 - val_binary_accuracy: 0.9096 - val_loss: 0.2608\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9066 - loss: 0.2682 - val_auc: 0.7976 - val_binary_accuracy: 0.9082 - val_loss: 0.2660\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9086 - loss: 0.2634 - val_auc: 0.7979 - val_binary_accuracy: 0.9106 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9092 - loss: 0.2634 - val_auc: 0.7986 - val_binary_accuracy: 0.9090 - val_loss: 0.2644\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9092 - loss: 0.2627 - val_auc: 0.8002 - val_binary_accuracy: 0.9096 - val_loss: 0.2616\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8004 - val_binary_accuracy: 0.9109 - val_loss: 0.2614\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9106 - loss: 0.2622 - val_auc: 0.8011 - val_binary_accuracy: 0.9112 - val_loss: 0.2604\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9095 - loss: 0.2622 - val_auc: 0.8030 - val_binary_accuracy: 0.9112 - val_loss: 0.2607\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7959 - binary_accuracy: 0.9136 - loss: 0.2612\n",
      "Fold 3 Metrics: Loss = 0.2607, Accuracy = 0.9112, AUC = 0.8030\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6388 - binary_accuracy: 0.8631 - loss: 0.8942 - val_auc: 0.7867 - val_binary_accuracy: 0.9048 - val_loss: 0.2682\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9056 - loss: 0.2752 - val_auc: 0.7949 - val_binary_accuracy: 0.9082 - val_loss: 0.2619\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9076 - loss: 0.2698 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2594\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9079 - loss: 0.2675 - val_auc: 0.8062 - val_binary_accuracy: 0.9093 - val_loss: 0.2566\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9082 - loss: 0.2656 - val_auc: 0.8061 - val_binary_accuracy: 0.9094 - val_loss: 0.2567\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9089 - loss: 0.2627 - val_auc: 0.8084 - val_binary_accuracy: 0.9094 - val_loss: 0.2554\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9092 - loss: 0.2613 - val_auc: 0.8066 - val_binary_accuracy: 0.9081 - val_loss: 0.2564\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9097 - loss: 0.2597 - val_auc: 0.8074 - val_binary_accuracy: 0.9087 - val_loss: 0.2563\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9098 - loss: 0.2596 - val_auc: 0.8103 - val_binary_accuracy: 0.9082 - val_loss: 0.2549\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9098 - loss: 0.2587 - val_auc: 0.8091 - val_binary_accuracy: 0.9084 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7912 - binary_accuracy: 0.9070 - loss: 0.2622\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9084, AUC = 0.8091\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6449 - binary_accuracy: 0.8789 - loss: 0.6324 - val_auc: 0.7935 - val_binary_accuracy: 0.8997 - val_loss: 0.2774\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7408 - binary_accuracy: 0.9024 - loss: 0.2866 - val_auc: 0.7989 - val_binary_accuracy: 0.8995 - val_loss: 0.2754\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9037 - loss: 0.2780 - val_auc: 0.8015 - val_binary_accuracy: 0.8991 - val_loss: 0.2727\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9040 - loss: 0.2746 - val_auc: 0.8044 - val_binary_accuracy: 0.9035 - val_loss: 0.2653\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9039 - loss: 0.2743 - val_auc: 0.8053 - val_binary_accuracy: 0.9091 - val_loss: 0.2541\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9058 - loss: 0.2716 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2536\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9079 - loss: 0.2663 - val_auc: 0.8048 - val_binary_accuracy: 0.9078 - val_loss: 0.2582\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9072 - loss: 0.2669 - val_auc: 0.8068 - val_binary_accuracy: 0.9066 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9074 - loss: 0.2647 - val_auc: 0.8064 - val_binary_accuracy: 0.9059 - val_loss: 0.2610\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9076 - loss: 0.2646 - val_auc: 0.8082 - val_binary_accuracy: 0.9073 - val_loss: 0.2601\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8170 - binary_accuracy: 0.9088 - loss: 0.2586\n",
      "Fold 5 Metrics: Loss = 0.2601, Accuracy = 0.9073, AUC = 0.8082\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2596\n",
      "Average Accuracy: 0.9088\n",
      "Average AUC: 0.8049\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 3, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6388 - binary_accuracy: 0.8800 - loss: 0.6860 - val_auc: 0.7757 - val_binary_accuracy: 0.9048 - val_loss: 0.2865\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9083 - loss: 0.2669 - val_auc: 0.7827 - val_binary_accuracy: 0.9106 - val_loss: 0.2686\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9112 - loss: 0.2575 - val_auc: 0.7874 - val_binary_accuracy: 0.9103 - val_loss: 0.2672\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9115 - loss: 0.2548 - val_auc: 0.7905 - val_binary_accuracy: 0.9100 - val_loss: 0.2609\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9129 - loss: 0.2533 - val_auc: 0.7899 - val_binary_accuracy: 0.9112 - val_loss: 0.2639\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9118 - loss: 0.2521 - val_auc: 0.7929 - val_binary_accuracy: 0.9100 - val_loss: 0.2595\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9128 - loss: 0.2509 - val_auc: 0.7960 - val_binary_accuracy: 0.9084 - val_loss: 0.2597\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9123 - loss: 0.2501 - val_auc: 0.7964 - val_binary_accuracy: 0.9071 - val_loss: 0.2621\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9127 - loss: 0.2490 - val_auc: 0.7963 - val_binary_accuracy: 0.9072 - val_loss: 0.2632\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8086 - binary_accuracy: 0.9128 - loss: 0.2486 - val_auc: 0.7955 - val_binary_accuracy: 0.9076 - val_loss: 0.2637\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7939 - binary_accuracy: 0.9108 - loss: 0.2548\n",
      "Fold 1 Metrics: Loss = 0.2637, Accuracy = 0.9076, AUC = 0.7955\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6477 - binary_accuracy: 0.8743 - loss: 0.6347 - val_auc: 0.8025 - val_binary_accuracy: 0.9075 - val_loss: 0.2917\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9032 - loss: 0.2789 - val_auc: 0.8055 - val_binary_accuracy: 0.9063 - val_loss: 0.2628\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9052 - loss: 0.2677 - val_auc: 0.8072 - val_binary_accuracy: 0.9084 - val_loss: 0.2620\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9069 - loss: 0.2647 - val_auc: 0.7967 - val_binary_accuracy: 0.9073 - val_loss: 0.2640\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9070 - loss: 0.2656 - val_auc: 0.8046 - val_binary_accuracy: 0.9084 - val_loss: 0.2632\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.8033 - val_binary_accuracy: 0.9096 - val_loss: 0.2651\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8108 - val_binary_accuracy: 0.9093 - val_loss: 0.2593\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9081 - loss: 0.2610 - val_auc: 0.8091 - val_binary_accuracy: 0.9082 - val_loss: 0.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9084 - loss: 0.2606 - val_auc: 0.8068 - val_binary_accuracy: 0.9100 - val_loss: 0.2622\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9091 - loss: 0.2605 - val_auc: 0.8080 - val_binary_accuracy: 0.9094 - val_loss: 0.2625\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9132 - loss: 0.2537\n",
      "Fold 2 Metrics: Loss = 0.2625, Accuracy = 0.9094, AUC = 0.8080\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6304 - binary_accuracy: 0.8858 - loss: 0.5479 - val_auc: 0.7825 - val_binary_accuracy: 0.9045 - val_loss: 0.2745\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9056 - loss: 0.2742 - val_auc: 0.7914 - val_binary_accuracy: 0.9096 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9059 - loss: 0.2710 - val_auc: 0.7938 - val_binary_accuracy: 0.9094 - val_loss: 0.2681\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9089 - loss: 0.2652 - val_auc: 0.7984 - val_binary_accuracy: 0.9099 - val_loss: 0.2606\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9084 - loss: 0.2637 - val_auc: 0.8018 - val_binary_accuracy: 0.9106 - val_loss: 0.2602\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9081 - loss: 0.2631 - val_auc: 0.8028 - val_binary_accuracy: 0.9104 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9091 - loss: 0.2626 - val_auc: 0.8040 - val_binary_accuracy: 0.9115 - val_loss: 0.2586\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8036 - val_binary_accuracy: 0.9113 - val_loss: 0.2588\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9094 - loss: 0.2616 - val_auc: 0.8056 - val_binary_accuracy: 0.9112 - val_loss: 0.2570\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9092 - loss: 0.2620 - val_auc: 0.8072 - val_binary_accuracy: 0.9113 - val_loss: 0.2564\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7995 - binary_accuracy: 0.9131 - loss: 0.2569\n",
      "Fold 3 Metrics: Loss = 0.2564, Accuracy = 0.9113, AUC = 0.8072\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6582 - binary_accuracy: 0.8837 - loss: 0.4978 - val_auc: 0.7885 - val_binary_accuracy: 0.9063 - val_loss: 0.2651\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7616 - binary_accuracy: 0.9074 - loss: 0.2732 - val_auc: 0.7977 - val_binary_accuracy: 0.9084 - val_loss: 0.2606\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9080 - loss: 0.2676 - val_auc: 0.7999 - val_binary_accuracy: 0.9063 - val_loss: 0.2605\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.8037 - val_binary_accuracy: 0.9073 - val_loss: 0.2583\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9086 - loss: 0.2626 - val_auc: 0.8056 - val_binary_accuracy: 0.9053 - val_loss: 0.2606\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8077 - val_binary_accuracy: 0.9073 - val_loss: 0.2570\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9099 - loss: 0.2607 - val_auc: 0.8077 - val_binary_accuracy: 0.9072 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9097 - loss: 0.2600 - val_auc: 0.8090 - val_binary_accuracy: 0.9095 - val_loss: 0.2550\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9100 - loss: 0.2594 - val_auc: 0.8111 - val_binary_accuracy: 0.9066 - val_loss: 0.2576\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9105 - loss: 0.2590 - val_auc: 0.8121 - val_binary_accuracy: 0.9094 - val_loss: 0.2541\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9083 - loss: 0.2626\n",
      "Fold 4 Metrics: Loss = 0.2541, Accuracy = 0.9094, AUC = 0.8121\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6539 - binary_accuracy: 0.8786 - loss: 0.5847 - val_auc: 0.7943 - val_binary_accuracy: 0.8989 - val_loss: 0.2791\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7515 - binary_accuracy: 0.9014 - loss: 0.2809 - val_auc: 0.7996 - val_binary_accuracy: 0.9003 - val_loss: 0.2678\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7562 - binary_accuracy: 0.9038 - loss: 0.2776 - val_auc: 0.8028 - val_binary_accuracy: 0.9098 - val_loss: 0.2559\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9069 - loss: 0.2694 - val_auc: 0.8029 - val_binary_accuracy: 0.9072 - val_loss: 0.2561\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9055 - loss: 0.2693 - val_auc: 0.8059 - val_binary_accuracy: 0.9064 - val_loss: 0.2601\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.8060 - val_binary_accuracy: 0.9064 - val_loss: 0.2627\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9074 - loss: 0.2652 - val_auc: 0.8074 - val_binary_accuracy: 0.9098 - val_loss: 0.2635\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9087 - loss: 0.2641 - val_auc: 0.8080 - val_binary_accuracy: 0.9107 - val_loss: 0.2613\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9091 - loss: 0.2633 - val_auc: 0.8089 - val_binary_accuracy: 0.9107 - val_loss: 0.2611\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8096 - val_binary_accuracy: 0.9119 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8174 - binary_accuracy: 0.9104 - loss: 0.2589\n",
      "Fold 5 Metrics: Loss = 0.2599, Accuracy = 0.9119, AUC = 0.8096\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2593\n",
      "Average Accuracy: 0.9099\n",
      "Average AUC: 0.8065\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 4, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6384 - binary_accuracy: 0.7253 - loss: 0.6739 - val_auc: 0.7654 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9078 - loss: 0.2624 - val_auc: 0.7704 - val_binary_accuracy: 0.9071 - val_loss: 0.2705\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9102 - loss: 0.2583 - val_auc: 0.7766 - val_binary_accuracy: 0.9076 - val_loss: 0.2668\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9113 - loss: 0.2560 - val_auc: 0.7785 - val_binary_accuracy: 0.9082 - val_loss: 0.2660\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9109 - loss: 0.2554 - val_auc: 0.7813 - val_binary_accuracy: 0.9088 - val_loss: 0.2646\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9116 - loss: 0.2536 - val_auc: 0.7830 - val_binary_accuracy: 0.9084 - val_loss: 0.2646\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9120 - loss: 0.2528 - val_auc: 0.7833 - val_binary_accuracy: 0.9084 - val_loss: 0.2649\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9120 - loss: 0.2531 - val_auc: 0.7844 - val_binary_accuracy: 0.9088 - val_loss: 0.2636\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9117 - loss: 0.2523 - val_auc: 0.7862 - val_binary_accuracy: 0.9088 - val_loss: 0.2633\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8023 - binary_accuracy: 0.9122 - loss: 0.2519 - val_auc: 0.7858 - val_binary_accuracy: 0.9084 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7829 - binary_accuracy: 0.9113 - loss: 0.2570\n",
      "Fold 1 Metrics: Loss = 0.2635, Accuracy = 0.9084, AUC = 0.7858\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7086 - binary_accuracy: 0.9021 - loss: 0.2949 - val_auc: 0.7871 - val_binary_accuracy: 0.9037 - val_loss: 0.2693\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9035 - loss: 0.2758 - val_auc: 0.7947 - val_binary_accuracy: 0.9045 - val_loss: 0.2644\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9039 - loss: 0.2725 - val_auc: 0.7982 - val_binary_accuracy: 0.9071 - val_loss: 0.2615\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9041 - loss: 0.2703 - val_auc: 0.7994 - val_binary_accuracy: 0.9069 - val_loss: 0.2612\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9053 - loss: 0.2685 - val_auc: 0.8018 - val_binary_accuracy: 0.9068 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9066 - loss: 0.2672 - val_auc: 0.8031 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9077 - loss: 0.2657 - val_auc: 0.8058 - val_binary_accuracy: 0.9081 - val_loss: 0.2574\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9080 - loss: 0.2645 - val_auc: 0.8058 - val_binary_accuracy: 0.9072 - val_loss: 0.2594\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9084 - loss: 0.2639 - val_auc: 0.8076 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9077 - loss: 0.2627 - val_auc: 0.8092 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8094 - binary_accuracy: 0.9120 - loss: 0.2474\n",
      "Fold 2 Metrics: Loss = 0.2549, Accuracy = 0.9091, AUC = 0.8092\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5823 - binary_accuracy: 0.8480 - loss: 0.3761 - val_auc: 0.7783 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7558 - binary_accuracy: 0.9051 - loss: 0.2762 - val_auc: 0.7873 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9054 - loss: 0.2711 - val_auc: 0.7906 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9059 - loss: 0.2684 - val_auc: 0.7936 - val_binary_accuracy: 0.9048 - val_loss: 0.2640\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9069 - loss: 0.2670 - val_auc: 0.7955 - val_binary_accuracy: 0.9071 - val_loss: 0.2631\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9076 - loss: 0.2658 - val_auc: 0.7965 - val_binary_accuracy: 0.9090 - val_loss: 0.2616\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9077 - loss: 0.2651 - val_auc: 0.7986 - val_binary_accuracy: 0.9090 - val_loss: 0.2609\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.8005 - val_binary_accuracy: 0.9096 - val_loss: 0.2598\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9089 - loss: 0.2628 - val_auc: 0.8015 - val_binary_accuracy: 0.9093 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9090 - loss: 0.2623 - val_auc: 0.8019 - val_binary_accuracy: 0.9100 - val_loss: 0.2583\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7959 - binary_accuracy: 0.9112 - loss: 0.2586\n",
      "Fold 3 Metrics: Loss = 0.2583, Accuracy = 0.9100, AUC = 0.8019\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5424 - binary_accuracy: 0.7829 - loss: 2.5380 - val_auc: 0.7417 - val_binary_accuracy: 0.9042 - val_loss: 0.2835\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7403 - binary_accuracy: 0.9047 - loss: 0.2825 - val_auc: 0.7766 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7654 - binary_accuracy: 0.9051 - loss: 0.2741 - val_auc: 0.7845 - val_binary_accuracy: 0.9060 - val_loss: 0.2684\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9057 - loss: 0.2713 - val_auc: 0.7886 - val_binary_accuracy: 0.9057 - val_loss: 0.2669\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9066 - loss: 0.2691 - val_auc: 0.7914 - val_binary_accuracy: 0.9067 - val_loss: 0.2646\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9073 - loss: 0.2670 - val_auc: 0.7940 - val_binary_accuracy: 0.9072 - val_loss: 0.2627\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9083 - loss: 0.2652 - val_auc: 0.7963 - val_binary_accuracy: 0.9078 - val_loss: 0.2610\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9085 - loss: 0.2642 - val_auc: 0.7988 - val_binary_accuracy: 0.9079 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.7999 - val_binary_accuracy: 0.9078 - val_loss: 0.2587\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.8012 - val_binary_accuracy: 0.9084 - val_loss: 0.2582\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7816 - binary_accuracy: 0.9074 - loss: 0.2649\n",
      "Fold 4 Metrics: Loss = 0.2582, Accuracy = 0.9084, AUC = 0.8012\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6275 - binary_accuracy: 0.7391 - loss: 0.8155 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9040 - loss: 0.2751 - val_auc: 0.7884 - val_binary_accuracy: 0.9047 - val_loss: 0.2655\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9050 - loss: 0.2705 - val_auc: 0.7919 - val_binary_accuracy: 0.9054 - val_loss: 0.2642\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9060 - loss: 0.2683 - val_auc: 0.7948 - val_binary_accuracy: 0.9064 - val_loss: 0.2613\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9070 - loss: 0.2670 - val_auc: 0.7955 - val_binary_accuracy: 0.9059 - val_loss: 0.2607\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9073 - loss: 0.2658 - val_auc: 0.7986 - val_binary_accuracy: 0.9062 - val_loss: 0.2584\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9080 - loss: 0.2647 - val_auc: 0.8002 - val_binary_accuracy: 0.9082 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9081 - loss: 0.2642 - val_auc: 0.8006 - val_binary_accuracy: 0.9098 - val_loss: 0.2568\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9085 - loss: 0.2635 - val_auc: 0.8030 - val_binary_accuracy: 0.9095 - val_loss: 0.2563\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9092 - loss: 0.2628 - val_auc: 0.8030 - val_binary_accuracy: 0.9101 - val_loss: 0.2553\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9084 - loss: 0.2544\n",
      "Fold 5 Metrics: Loss = 0.2553, Accuracy = 0.9101, AUC = 0.8030\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2580\n",
      "Average Accuracy: 0.9092\n",
      "Average AUC: 0.8002\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 4, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6757 - binary_accuracy: 0.8468 - loss: 0.5495 - val_auc: 0.7643 - val_binary_accuracy: 0.9044 - val_loss: 0.2779\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9066 - loss: 0.2666 - val_auc: 0.7750 - val_binary_accuracy: 0.9047 - val_loss: 0.2712\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9079 - loss: 0.2623 - val_auc: 0.7807 - val_binary_accuracy: 0.9056 - val_loss: 0.2686\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9093 - loss: 0.2587 - val_auc: 0.7848 - val_binary_accuracy: 0.9059 - val_loss: 0.2674\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9096 - loss: 0.2566 - val_auc: 0.7860 - val_binary_accuracy: 0.9066 - val_loss: 0.2668\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9096 - loss: 0.2544 - val_auc: 0.7871 - val_binary_accuracy: 0.9069 - val_loss: 0.2668\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8017 - binary_accuracy: 0.9107 - loss: 0.2529 - val_auc: 0.7890 - val_binary_accuracy: 0.9068 - val_loss: 0.2661\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9107 - loss: 0.2526 - val_auc: 0.7918 - val_binary_accuracy: 0.9075 - val_loss: 0.2652\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9111 - loss: 0.2512 - val_auc: 0.7935 - val_binary_accuracy: 0.9079 - val_loss: 0.2638\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8081 - binary_accuracy: 0.9116 - loss: 0.2500 - val_auc: 0.7935 - val_binary_accuracy: 0.9085 - val_loss: 0.2631\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9120 - loss: 0.2536\n",
      "Fold 1 Metrics: Loss = 0.2631, Accuracy = 0.9085, AUC = 0.7935\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6902 - binary_accuracy: 0.8972 - loss: 0.3136 - val_auc: 0.7918 - val_binary_accuracy: 0.9079 - val_loss: 0.2654\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9049 - loss: 0.2730 - val_auc: 0.7993 - val_binary_accuracy: 0.9096 - val_loss: 0.2639\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9067 - loss: 0.2697 - val_auc: 0.8037 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9065 - loss: 0.2693 - val_auc: 0.8056 - val_binary_accuracy: 0.9106 - val_loss: 0.2598\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9073 - loss: 0.2667 - val_auc: 0.8046 - val_binary_accuracy: 0.9072 - val_loss: 0.2676\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9075 - loss: 0.2645 - val_auc: 0.8046 - val_binary_accuracy: 0.9073 - val_loss: 0.2627\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9075 - loss: 0.2636 - val_auc: 0.8023 - val_binary_accuracy: 0.9090 - val_loss: 0.2621\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9084 - loss: 0.2623 - val_auc: 0.8102 - val_binary_accuracy: 0.9102 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8023 - val_binary_accuracy: 0.9090 - val_loss: 0.2625\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9083 - loss: 0.2611 - val_auc: 0.8094 - val_binary_accuracy: 0.9087 - val_loss: 0.2577\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.9118 - loss: 0.2485\n",
      "Fold 2 Metrics: Loss = 0.2577, Accuracy = 0.9087, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6536 - binary_accuracy: 0.8522 - loss: 0.7490 - val_auc: 0.7771 - val_binary_accuracy: 0.9056 - val_loss: 0.2699\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7580 - binary_accuracy: 0.9071 - loss: 0.2740 - val_auc: 0.7829 - val_binary_accuracy: 0.9075 - val_loss: 0.2692\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7664 - binary_accuracy: 0.9071 - loss: 0.2707 - val_auc: 0.7879 - val_binary_accuracy: 0.9084 - val_loss: 0.2675\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9067 - loss: 0.2691 - val_auc: 0.7899 - val_binary_accuracy: 0.9087 - val_loss: 0.2670\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.7923 - val_binary_accuracy: 0.9059 - val_loss: 0.2672\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9075 - loss: 0.2664 - val_auc: 0.7951 - val_binary_accuracy: 0.9097 - val_loss: 0.2641\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9078 - loss: 0.2666 - val_auc: 0.7944 - val_binary_accuracy: 0.9103 - val_loss: 0.2628\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9081 - loss: 0.2658 - val_auc: 0.7962 - val_binary_accuracy: 0.9079 - val_loss: 0.2634\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9081 - loss: 0.2657 - val_auc: 0.7973 - val_binary_accuracy: 0.9099 - val_loss: 0.2622\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9082 - loss: 0.2648 - val_auc: 0.7984 - val_binary_accuracy: 0.9102 - val_loss: 0.2601\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7943 - binary_accuracy: 0.9107 - loss: 0.2599\n",
      "Fold 3 Metrics: Loss = 0.2601, Accuracy = 0.9102, AUC = 0.7984\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - auc: 0.6610 - binary_accuracy: 0.9044 - loss: 0.3356 - val_auc: 0.7807 - val_binary_accuracy: 0.9048 - val_loss: 0.2690\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9063 - loss: 0.2737 - val_auc: 0.7888 - val_binary_accuracy: 0.9070 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9070 - loss: 0.2696 - val_auc: 0.7962 - val_binary_accuracy: 0.9053 - val_loss: 0.2630\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9063 - loss: 0.2666 - val_auc: 0.7984 - val_binary_accuracy: 0.9023 - val_loss: 0.2622\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2643 - val_auc: 0.8011 - val_binary_accuracy: 0.9062 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9076 - loss: 0.2632 - val_auc: 0.8021 - val_binary_accuracy: 0.9035 - val_loss: 0.2602\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9086 - loss: 0.2624 - val_auc: 0.8032 - val_binary_accuracy: 0.9032 - val_loss: 0.2599\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.8072 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9094 - loss: 0.2603 - val_auc: 0.8086 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8094 - val_binary_accuracy: 0.9090 - val_loss: 0.2546\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7896 - binary_accuracy: 0.9082 - loss: 0.2620\n",
      "Fold 4 Metrics: Loss = 0.2546, Accuracy = 0.9090, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5903 - binary_accuracy: 0.8426 - loss: 0.8164 - val_auc: 0.7801 - val_binary_accuracy: 0.9066 - val_loss: 0.2782\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7524 - binary_accuracy: 0.9046 - loss: 0.2796 - val_auc: 0.7909 - val_binary_accuracy: 0.9069 - val_loss: 0.2708\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9046 - loss: 0.2746 - val_auc: 0.7965 - val_binary_accuracy: 0.9073 - val_loss: 0.2656\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9044 - loss: 0.2720 - val_auc: 0.8004 - val_binary_accuracy: 0.9069 - val_loss: 0.2650\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9039 - loss: 0.2702 - val_auc: 0.8023 - val_binary_accuracy: 0.9059 - val_loss: 0.2651\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9054 - loss: 0.2685 - val_auc: 0.8046 - val_binary_accuracy: 0.9066 - val_loss: 0.2666\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9065 - loss: 0.2671 - val_auc: 0.8059 - val_binary_accuracy: 0.9075 - val_loss: 0.2641\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9071 - loss: 0.2656 - val_auc: 0.8055 - val_binary_accuracy: 0.9053 - val_loss: 0.2659\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.8081 - val_binary_accuracy: 0.9063 - val_loss: 0.2657\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8076 - val_binary_accuracy: 0.9066 - val_loss: 0.2638\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9092 - loss: 0.2615\n",
      "Fold 5 Metrics: Loss = 0.2638, Accuracy = 0.9066, AUC = 0.8076\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2599\n",
      "Average Accuracy: 0.9086\n",
      "Average AUC: 0.8037\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 4, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6601 - binary_accuracy: 0.8901 - loss: 0.3777 - val_auc: 0.7766 - val_binary_accuracy: 0.9072 - val_loss: 0.2873\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9085 - loss: 0.2657 - val_auc: 0.7797 - val_binary_accuracy: 0.9054 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9094 - loss: 0.2584 - val_auc: 0.7858 - val_binary_accuracy: 0.9071 - val_loss: 0.2628\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9100 - loss: 0.2566 - val_auc: 0.7885 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9112 - loss: 0.2537 - val_auc: 0.7880 - val_binary_accuracy: 0.9073 - val_loss: 0.2634\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9117 - loss: 0.2526 - val_auc: 0.7910 - val_binary_accuracy: 0.9082 - val_loss: 0.2622\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9122 - loss: 0.2506 - val_auc: 0.7872 - val_binary_accuracy: 0.9066 - val_loss: 0.2642\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9123 - loss: 0.2502 - val_auc: 0.7878 - val_binary_accuracy: 0.9082 - val_loss: 0.2619\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9120 - loss: 0.2493 - val_auc: 0.7917 - val_binary_accuracy: 0.9076 - val_loss: 0.2609\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9129 - loss: 0.2482 - val_auc: 0.7920 - val_binary_accuracy: 0.9079 - val_loss: 0.2604\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7921 - binary_accuracy: 0.9108 - loss: 0.2517\n",
      "Fold 1 Metrics: Loss = 0.2604, Accuracy = 0.9079, AUC = 0.7920\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6860 - binary_accuracy: 0.8952 - loss: 0.3456 - val_auc: 0.7974 - val_binary_accuracy: 0.9045 - val_loss: 0.2650\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9038 - loss: 0.2723 - val_auc: 0.7958 - val_binary_accuracy: 0.9047 - val_loss: 0.2685\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9048 - loss: 0.2687 - val_auc: 0.8071 - val_binary_accuracy: 0.9065 - val_loss: 0.2631\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9066 - loss: 0.2662 - val_auc: 0.8038 - val_binary_accuracy: 0.9069 - val_loss: 0.2612\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9052 - loss: 0.2657 - val_auc: 0.8051 - val_binary_accuracy: 0.9087 - val_loss: 0.2634\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9080 - loss: 0.2622 - val_auc: 0.8095 - val_binary_accuracy: 0.9091 - val_loss: 0.2595\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9083 - loss: 0.2616 - val_auc: 0.8078 - val_binary_accuracy: 0.9085 - val_loss: 0.2598\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9082 - loss: 0.2610 - val_auc: 0.8081 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9082 - loss: 0.2608 - val_auc: 0.8132 - val_binary_accuracy: 0.9088 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9089 - loss: 0.2603 - val_auc: 0.8115 - val_binary_accuracy: 0.9093 - val_loss: 0.2583\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9126 - loss: 0.2503\n",
      "Fold 2 Metrics: Loss = 0.2583, Accuracy = 0.9093, AUC = 0.8115\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6137 - binary_accuracy: 0.8627 - loss: 0.8741 - val_auc: 0.7711 - val_binary_accuracy: 0.9042 - val_loss: 0.2741\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7423 - binary_accuracy: 0.9036 - loss: 0.2834 - val_auc: 0.7781 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9035 - loss: 0.2775 - val_auc: 0.7866 - val_binary_accuracy: 0.9069 - val_loss: 0.2650\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9054 - loss: 0.2721 - val_auc: 0.7931 - val_binary_accuracy: 0.9094 - val_loss: 0.2615\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.7949 - val_binary_accuracy: 0.9093 - val_loss: 0.2676\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9082 - loss: 0.2646 - val_auc: 0.7980 - val_binary_accuracy: 0.9094 - val_loss: 0.2644\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9094 - loss: 0.2627 - val_auc: 0.7995 - val_binary_accuracy: 0.9075 - val_loss: 0.2640\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9092 - loss: 0.2619 - val_auc: 0.8025 - val_binary_accuracy: 0.9112 - val_loss: 0.2585\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9097 - loss: 0.2623 - val_auc: 0.8021 - val_binary_accuracy: 0.9091 - val_loss: 0.2627\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9099 - loss: 0.2620 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2578\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9121 - loss: 0.2586\n",
      "Fold 3 Metrics: Loss = 0.2578, Accuracy = 0.9107, AUC = 0.8026\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6741 - binary_accuracy: 0.8865 - loss: 0.3803 - val_auc: 0.7838 - val_binary_accuracy: 0.9053 - val_loss: 0.2682\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9059 - loss: 0.2740 - val_auc: 0.7923 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9071 - loss: 0.2697 - val_auc: 0.7957 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9076 - loss: 0.2674 - val_auc: 0.7989 - val_binary_accuracy: 0.9062 - val_loss: 0.2605\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9080 - loss: 0.2638 - val_auc: 0.8016 - val_binary_accuracy: 0.9084 - val_loss: 0.2594\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9081 - loss: 0.2630 - val_auc: 0.8025 - val_binary_accuracy: 0.9084 - val_loss: 0.2579\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.8034 - val_binary_accuracy: 0.9062 - val_loss: 0.2580\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9098 - loss: 0.2608 - val_auc: 0.8053 - val_binary_accuracy: 0.9073 - val_loss: 0.2575\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.8054 - val_binary_accuracy: 0.9082 - val_loss: 0.2572\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9096 - loss: 0.2602 - val_auc: 0.8062 - val_binary_accuracy: 0.9088 - val_loss: 0.2559\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7868 - binary_accuracy: 0.9074 - loss: 0.2634\n",
      "Fold 4 Metrics: Loss = 0.2559, Accuracy = 0.9088, AUC = 0.8062\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7049 - binary_accuracy: 0.9019 - loss: 0.3049 - val_auc: 0.7936 - val_binary_accuracy: 0.8948 - val_loss: 0.2847\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7451 - binary_accuracy: 0.9022 - loss: 0.2836 - val_auc: 0.7960 - val_binary_accuracy: 0.9064 - val_loss: 0.2609\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7600 - binary_accuracy: 0.9063 - loss: 0.2748 - val_auc: 0.7998 - val_binary_accuracy: 0.9091 - val_loss: 0.2580\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9075 - loss: 0.2697 - val_auc: 0.8023 - val_binary_accuracy: 0.9014 - val_loss: 0.2655\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9061 - loss: 0.2675 - val_auc: 0.8047 - val_binary_accuracy: 0.9063 - val_loss: 0.2620\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9078 - loss: 0.2658 - val_auc: 0.8059 - val_binary_accuracy: 0.9045 - val_loss: 0.2639\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9081 - loss: 0.2652 - val_auc: 0.8069 - val_binary_accuracy: 0.9064 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9090 - loss: 0.2639 - val_auc: 0.8075 - val_binary_accuracy: 0.9075 - val_loss: 0.2598\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8081 - val_binary_accuracy: 0.9078 - val_loss: 0.2599\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9095 - loss: 0.2635 - val_auc: 0.8076 - val_binary_accuracy: 0.9094 - val_loss: 0.2566\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9087 - loss: 0.2541\n",
      "Fold 5 Metrics: Loss = 0.2566, Accuracy = 0.9094, AUC = 0.8076\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2578\n",
      "Average Accuracy: 0.9092\n",
      "Average AUC: 0.8040\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 4, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6876 - binary_accuracy: 0.8980 - loss: 0.3569 - val_auc: 0.7743 - val_binary_accuracy: 0.9050 - val_loss: 0.2731\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9083 - loss: 0.2651 - val_auc: 0.7793 - val_binary_accuracy: 0.9094 - val_loss: 0.2753\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9097 - loss: 0.2597 - val_auc: 0.7853 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9115 - loss: 0.2556 - val_auc: 0.7903 - val_binary_accuracy: 0.9069 - val_loss: 0.2635\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9118 - loss: 0.2535 - val_auc: 0.7921 - val_binary_accuracy: 0.9088 - val_loss: 0.2603\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8005 - binary_accuracy: 0.9122 - loss: 0.2525 - val_auc: 0.7940 - val_binary_accuracy: 0.9096 - val_loss: 0.2593\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9118 - loss: 0.2508 - val_auc: 0.7942 - val_binary_accuracy: 0.9094 - val_loss: 0.2607\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9121 - loss: 0.2510 - val_auc: 0.7926 - val_binary_accuracy: 0.9075 - val_loss: 0.2641\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8068 - binary_accuracy: 0.9132 - loss: 0.2497 - val_auc: 0.7980 - val_binary_accuracy: 0.9081 - val_loss: 0.2589\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8098 - binary_accuracy: 0.9131 - loss: 0.2479 - val_auc: 0.7973 - val_binary_accuracy: 0.9076 - val_loss: 0.2613\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7942 - binary_accuracy: 0.9109 - loss: 0.2531\n",
      "Fold 1 Metrics: Loss = 0.2613, Accuracy = 0.9076, AUC = 0.7973\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6711 - binary_accuracy: 0.8797 - loss: 0.5018 - val_auc: 0.8015 - val_binary_accuracy: 0.9056 - val_loss: 0.2718\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9027 - loss: 0.2744 - val_auc: 0.7999 - val_binary_accuracy: 0.9076 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9057 - loss: 0.2688 - val_auc: 0.8042 - val_binary_accuracy: 0.9076 - val_loss: 0.2603\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9064 - loss: 0.2659 - val_auc: 0.8051 - val_binary_accuracy: 0.9072 - val_loss: 0.2614\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9075 - loss: 0.2641 - val_auc: 0.8066 - val_binary_accuracy: 0.9091 - val_loss: 0.2605\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.8084 - val_binary_accuracy: 0.9091 - val_loss: 0.2640\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9075 - loss: 0.2617 - val_auc: 0.8021 - val_binary_accuracy: 0.9091 - val_loss: 0.2644\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8089 - val_binary_accuracy: 0.9099 - val_loss: 0.2613\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9089 - loss: 0.2604 - val_auc: 0.8110 - val_binary_accuracy: 0.9094 - val_loss: 0.2597\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8002 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.8073 - val_binary_accuracy: 0.9091 - val_loss: 0.2639\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8134 - binary_accuracy: 0.9130 - loss: 0.2549\n",
      "Fold 2 Metrics: Loss = 0.2639, Accuracy = 0.9091, AUC = 0.8073\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7087 - binary_accuracy: 0.8943 - loss: 0.3278 - val_auc: 0.7834 - val_binary_accuracy: 0.9068 - val_loss: 0.2663\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7614 - binary_accuracy: 0.9058 - loss: 0.2729 - val_auc: 0.7872 - val_binary_accuracy: 0.9088 - val_loss: 0.2684\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9084 - loss: 0.2662 - val_auc: 0.7947 - val_binary_accuracy: 0.9094 - val_loss: 0.2662\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9085 - loss: 0.2653 - val_auc: 0.7956 - val_binary_accuracy: 0.9097 - val_loss: 0.2623\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9079 - loss: 0.2651 - val_auc: 0.7958 - val_binary_accuracy: 0.9104 - val_loss: 0.2619\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9075 - loss: 0.2632 - val_auc: 0.8008 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9079 - loss: 0.2642 - val_auc: 0.7996 - val_binary_accuracy: 0.9106 - val_loss: 0.2593\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9090 - loss: 0.2615 - val_auc: 0.8014 - val_binary_accuracy: 0.9104 - val_loss: 0.2591\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9094 - loss: 0.2607 - val_auc: 0.8003 - val_binary_accuracy: 0.9110 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2612 - val_auc: 0.8013 - val_binary_accuracy: 0.9115 - val_loss: 0.2585\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7944 - binary_accuracy: 0.9129 - loss: 0.2589\n",
      "Fold 3 Metrics: Loss = 0.2585, Accuracy = 0.9115, AUC = 0.8013\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6414 - binary_accuracy: 0.8837 - loss: 0.4603 - val_auc: 0.7865 - val_binary_accuracy: 0.9048 - val_loss: 0.2691\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9071 - loss: 0.2743 - val_auc: 0.7921 - val_binary_accuracy: 0.9079 - val_loss: 0.2627\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9080 - loss: 0.2686 - val_auc: 0.7938 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9084 - loss: 0.2649 - val_auc: 0.7994 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.8044 - val_binary_accuracy: 0.9051 - val_loss: 0.2585\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9092 - loss: 0.2629 - val_auc: 0.8044 - val_binary_accuracy: 0.9075 - val_loss: 0.2573\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9098 - loss: 0.2614 - val_auc: 0.8047 - val_binary_accuracy: 0.9078 - val_loss: 0.2575\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.8072 - val_binary_accuracy: 0.9078 - val_loss: 0.2569\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9102 - loss: 0.2600 - val_auc: 0.8093 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8093 - val_binary_accuracy: 0.9079 - val_loss: 0.2554\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7897 - binary_accuracy: 0.9071 - loss: 0.2634\n",
      "Fold 4 Metrics: Loss = 0.2554, Accuracy = 0.9079, AUC = 0.8093\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6406 - binary_accuracy: 0.8849 - loss: 0.5232 - val_auc: 0.7915 - val_binary_accuracy: 0.9003 - val_loss: 0.2699\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7510 - binary_accuracy: 0.9013 - loss: 0.2806 - val_auc: 0.7973 - val_binary_accuracy: 0.9063 - val_loss: 0.2584\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7659 - binary_accuracy: 0.9040 - loss: 0.2732 - val_auc: 0.7997 - val_binary_accuracy: 0.9057 - val_loss: 0.2617\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9050 - loss: 0.2706 - val_auc: 0.8024 - val_binary_accuracy: 0.9075 - val_loss: 0.2551\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9059 - loss: 0.2685 - val_auc: 0.8049 - val_binary_accuracy: 0.9103 - val_loss: 0.2586\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9077 - loss: 0.2651 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2591\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9088 - loss: 0.2643 - val_auc: 0.8056 - val_binary_accuracy: 0.9110 - val_loss: 0.2556\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9072 - loss: 0.2652 - val_auc: 0.8070 - val_binary_accuracy: 0.9110 - val_loss: 0.2575\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8089 - val_binary_accuracy: 0.9112 - val_loss: 0.2575\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9096 - loss: 0.2636 - val_auc: 0.8088 - val_binary_accuracy: 0.9110 - val_loss: 0.2563\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9095 - loss: 0.2553\n",
      "Fold 5 Metrics: Loss = 0.2563, Accuracy = 0.9110, AUC = 0.8088\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2591\n",
      "Average Accuracy: 0.9094\n",
      "Average AUC: 0.8048\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 4, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6483 - binary_accuracy: 0.8755 - loss: 0.5879 - val_auc: 0.7742 - val_binary_accuracy: 0.9085 - val_loss: 0.2753\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.7806 - val_binary_accuracy: 0.9102 - val_loss: 0.2640\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9105 - loss: 0.2580 - val_auc: 0.7864 - val_binary_accuracy: 0.9104 - val_loss: 0.2625\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9110 - loss: 0.2549 - val_auc: 0.7909 - val_binary_accuracy: 0.9113 - val_loss: 0.2664\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9119 - loss: 0.2535 - val_auc: 0.7925 - val_binary_accuracy: 0.9100 - val_loss: 0.2614\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9126 - loss: 0.2514 - val_auc: 0.7936 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9129 - loss: 0.2511 - val_auc: 0.7957 - val_binary_accuracy: 0.9090 - val_loss: 0.2599\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8064 - binary_accuracy: 0.9132 - loss: 0.2499 - val_auc: 0.7953 - val_binary_accuracy: 0.9099 - val_loss: 0.2581\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9126 - loss: 0.2502 - val_auc: 0.7961 - val_binary_accuracy: 0.9082 - val_loss: 0.2605\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8092 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7959 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9107 - loss: 0.2537\n",
      "Fold 1 Metrics: Loss = 0.2621, Accuracy = 0.9078, AUC = 0.7959\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6642 - binary_accuracy: 0.8735 - loss: 0.5663 - val_auc: 0.7947 - val_binary_accuracy: 0.9085 - val_loss: 0.2929\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9033 - loss: 0.2770 - val_auc: 0.8037 - val_binary_accuracy: 0.9054 - val_loss: 0.2659\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.8057 - val_binary_accuracy: 0.9063 - val_loss: 0.2629\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9059 - loss: 0.2669 - val_auc: 0.7991 - val_binary_accuracy: 0.9079 - val_loss: 0.2624\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9068 - loss: 0.2656 - val_auc: 0.8044 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9083 - loss: 0.2644 - val_auc: 0.8036 - val_binary_accuracy: 0.9076 - val_loss: 0.2645\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9085 - loss: 0.2627 - val_auc: 0.8062 - val_binary_accuracy: 0.9088 - val_loss: 0.2634\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9090 - loss: 0.2620 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2604\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9091 - loss: 0.2608 - val_auc: 0.8073 - val_binary_accuracy: 0.9097 - val_loss: 0.2639\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9085 - loss: 0.2611 - val_auc: 0.8074 - val_binary_accuracy: 0.9087 - val_loss: 0.2623\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8090 - binary_accuracy: 0.9128 - loss: 0.2549\n",
      "Fold 2 Metrics: Loss = 0.2623, Accuracy = 0.9087, AUC = 0.8074\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6402 - binary_accuracy: 0.8750 - loss: 0.6017 - val_auc: 0.7788 - val_binary_accuracy: 0.9072 - val_loss: 0.2750\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9053 - loss: 0.2736 - val_auc: 0.7840 - val_binary_accuracy: 0.9087 - val_loss: 0.2655\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9067 - loss: 0.2696 - val_auc: 0.7891 - val_binary_accuracy: 0.9093 - val_loss: 0.2649\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9084 - loss: 0.2669 - val_auc: 0.7925 - val_binary_accuracy: 0.9096 - val_loss: 0.2627\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9084 - loss: 0.2645 - val_auc: 0.7955 - val_binary_accuracy: 0.9104 - val_loss: 0.2603\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.7969 - val_binary_accuracy: 0.9106 - val_loss: 0.2606\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9087 - loss: 0.2636 - val_auc: 0.8000 - val_binary_accuracy: 0.9110 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9090 - loss: 0.2628 - val_auc: 0.8008 - val_binary_accuracy: 0.9107 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.8026 - val_binary_accuracy: 0.9112 - val_loss: 0.2593\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2581\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9112 - loss: 0.2587\n",
      "Fold 3 Metrics: Loss = 0.2581, Accuracy = 0.9107, AUC = 0.8026\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6449 - binary_accuracy: 0.8701 - loss: 0.8217 - val_auc: 0.7858 - val_binary_accuracy: 0.9053 - val_loss: 0.2684\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7600 - binary_accuracy: 0.9066 - loss: 0.2741 - val_auc: 0.7921 - val_binary_accuracy: 0.9082 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9084 - loss: 0.2681 - val_auc: 0.7965 - val_binary_accuracy: 0.9069 - val_loss: 0.2615\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9081 - loss: 0.2654 - val_auc: 0.8006 - val_binary_accuracy: 0.9088 - val_loss: 0.2594\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8035 - val_binary_accuracy: 0.9095 - val_loss: 0.2571\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9103 - loss: 0.2614 - val_auc: 0.8059 - val_binary_accuracy: 0.9098 - val_loss: 0.2557\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9104 - loss: 0.2604 - val_auc: 0.8073 - val_binary_accuracy: 0.9097 - val_loss: 0.2552\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9107 - loss: 0.2595 - val_auc: 0.8074 - val_binary_accuracy: 0.9100 - val_loss: 0.2550\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9104 - loss: 0.2598 - val_auc: 0.8083 - val_binary_accuracy: 0.9094 - val_loss: 0.2547\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9109 - loss: 0.2590 - val_auc: 0.8102 - val_binary_accuracy: 0.9095 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9089 - loss: 0.2623\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9095, AUC = 0.8102\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6608 - binary_accuracy: 0.8902 - loss: 0.4149 - val_auc: 0.7908 - val_binary_accuracy: 0.8977 - val_loss: 0.2746\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7512 - binary_accuracy: 0.9027 - loss: 0.2799 - val_auc: 0.7955 - val_binary_accuracy: 0.9032 - val_loss: 0.2625\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9039 - loss: 0.2754 - val_auc: 0.7993 - val_binary_accuracy: 0.9107 - val_loss: 0.2599\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7739 - binary_accuracy: 0.9060 - loss: 0.2696 - val_auc: 0.8012 - val_binary_accuracy: 0.9098 - val_loss: 0.2597\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9080 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2635\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9084 - loss: 0.2662 - val_auc: 0.8046 - val_binary_accuracy: 0.9084 - val_loss: 0.2644\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9076 - loss: 0.2654 - val_auc: 0.8065 - val_binary_accuracy: 0.9121 - val_loss: 0.2636\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9084 - loss: 0.2641 - val_auc: 0.8061 - val_binary_accuracy: 0.9106 - val_loss: 0.2647\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9086 - loss: 0.2640 - val_auc: 0.8081 - val_binary_accuracy: 0.9112 - val_loss: 0.2596\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9091 - loss: 0.2622 - val_auc: 0.8080 - val_binary_accuracy: 0.9116 - val_loss: 0.2602\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9115 - loss: 0.2588\n",
      "Fold 5 Metrics: Loss = 0.2602, Accuracy = 0.9116, AUC = 0.8080\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2596\n",
      "Average Accuracy: 0.9097\n",
      "Average AUC: 0.8048\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 5, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7407 - binary_accuracy: 0.9073 - loss: 0.2764 - val_auc: 0.7709 - val_binary_accuracy: 0.9047 - val_loss: 0.2712\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9094 - loss: 0.2598 - val_auc: 0.7768 - val_binary_accuracy: 0.9069 - val_loss: 0.2681\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9099 - loss: 0.2563 - val_auc: 0.7825 - val_binary_accuracy: 0.9065 - val_loss: 0.2662\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9106 - loss: 0.2545 - val_auc: 0.7853 - val_binary_accuracy: 0.9078 - val_loss: 0.2640\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9117 - loss: 0.2531 - val_auc: 0.7872 - val_binary_accuracy: 0.9088 - val_loss: 0.2630\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9120 - loss: 0.2518 - val_auc: 0.7887 - val_binary_accuracy: 0.9090 - val_loss: 0.2622\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7905 - val_binary_accuracy: 0.9094 - val_loss: 0.2618\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8069 - binary_accuracy: 0.9127 - loss: 0.2499 - val_auc: 0.7915 - val_binary_accuracy: 0.9099 - val_loss: 0.2613\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8082 - binary_accuracy: 0.9133 - loss: 0.2488 - val_auc: 0.7916 - val_binary_accuracy: 0.9093 - val_loss: 0.2611\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8092 - binary_accuracy: 0.9135 - loss: 0.2479 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2607\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9125 - loss: 0.2542\n",
      "Fold 1 Metrics: Loss = 0.2607, Accuracy = 0.9093, AUC = 0.7919\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5360 - binary_accuracy: 0.6777 - loss: 2.9505 - val_auc: 0.7771 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9029 - loss: 0.2784 - val_auc: 0.7787 - val_binary_accuracy: 0.9047 - val_loss: 0.2716\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9032 - loss: 0.2736 - val_auc: 0.7911 - val_binary_accuracy: 0.9056 - val_loss: 0.2646\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9049 - loss: 0.2709 - val_auc: 0.7938 - val_binary_accuracy: 0.9072 - val_loss: 0.2632\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9066 - loss: 0.2694 - val_auc: 0.7963 - val_binary_accuracy: 0.9078 - val_loss: 0.2622\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9065 - loss: 0.2683 - val_auc: 0.7986 - val_binary_accuracy: 0.9079 - val_loss: 0.2607\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9072 - loss: 0.2669 - val_auc: 0.8014 - val_binary_accuracy: 0.9078 - val_loss: 0.2594\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9078 - loss: 0.2658 - val_auc: 0.8025 - val_binary_accuracy: 0.9075 - val_loss: 0.2588\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9080 - loss: 0.2650 - val_auc: 0.8050 - val_binary_accuracy: 0.9073 - val_loss: 0.2586\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9082 - loss: 0.2644 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2574\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8085 - binary_accuracy: 0.9125 - loss: 0.2485\n",
      "Fold 2 Metrics: Loss = 0.2574, Accuracy = 0.9078, AUC = 0.8073\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4992 - binary_accuracy: 0.8095 - loss: 0.6973 - val_auc: 0.7599 - val_binary_accuracy: 0.9042 - val_loss: 0.2772\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9051 - loss: 0.2758 - val_auc: 0.7685 - val_binary_accuracy: 0.9042 - val_loss: 0.2740\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9054 - loss: 0.2724 - val_auc: 0.7766 - val_binary_accuracy: 0.9041 - val_loss: 0.2729\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9060 - loss: 0.2703 - val_auc: 0.7790 - val_binary_accuracy: 0.9045 - val_loss: 0.2711\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9061 - loss: 0.2688 - val_auc: 0.7822 - val_binary_accuracy: 0.9054 - val_loss: 0.2697\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.7842 - val_binary_accuracy: 0.9072 - val_loss: 0.2678\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9071 - loss: 0.2675 - val_auc: 0.7862 - val_binary_accuracy: 0.9087 - val_loss: 0.2669\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9073 - loss: 0.2668 - val_auc: 0.7873 - val_binary_accuracy: 0.9094 - val_loss: 0.2664\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9078 - loss: 0.2661 - val_auc: 0.7886 - val_binary_accuracy: 0.9102 - val_loss: 0.2654\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9082 - loss: 0.2655 - val_auc: 0.7896 - val_binary_accuracy: 0.9103 - val_loss: 0.2650\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7849 - binary_accuracy: 0.9110 - loss: 0.2645\n",
      "Fold 3 Metrics: Loss = 0.2650, Accuracy = 0.9103, AUC = 0.7896\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6278 - binary_accuracy: 0.8020 - loss: 0.4701 - val_auc: 0.7498 - val_binary_accuracy: 0.9044 - val_loss: 0.2810\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7508 - binary_accuracy: 0.9047 - loss: 0.2777 - val_auc: 0.7720 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9057 - loss: 0.2705 - val_auc: 0.7820 - val_binary_accuracy: 0.9060 - val_loss: 0.2687\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9083 - loss: 0.2678 - val_auc: 0.7870 - val_binary_accuracy: 0.9069 - val_loss: 0.2682\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9088 - loss: 0.2652 - val_auc: 0.7895 - val_binary_accuracy: 0.9069 - val_loss: 0.2663\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9094 - loss: 0.2636 - val_auc: 0.7913 - val_binary_accuracy: 0.9078 - val_loss: 0.2656\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9093 - loss: 0.2625 - val_auc: 0.7928 - val_binary_accuracy: 0.9078 - val_loss: 0.2651\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9094 - loss: 0.2617 - val_auc: 0.7946 - val_binary_accuracy: 0.9081 - val_loss: 0.2644\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2610 - val_auc: 0.7955 - val_binary_accuracy: 0.9081 - val_loss: 0.2647\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9096 - loss: 0.2601 - val_auc: 0.7969 - val_binary_accuracy: 0.9081 - val_loss: 0.2640\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7745 - binary_accuracy: 0.9073 - loss: 0.2713\n",
      "Fold 4 Metrics: Loss = 0.2640, Accuracy = 0.9081, AUC = 0.7969\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7206 - binary_accuracy: 0.9042 - loss: 0.2886 - val_auc: 0.7822 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7582 - binary_accuracy: 0.9044 - loss: 0.2772 - val_auc: 0.7893 - val_binary_accuracy: 0.9057 - val_loss: 0.2700\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9049 - loss: 0.2742 - val_auc: 0.7929 - val_binary_accuracy: 0.9062 - val_loss: 0.2663\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9060 - loss: 0.2720 - val_auc: 0.7953 - val_binary_accuracy: 0.9072 - val_loss: 0.2619\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9071 - loss: 0.2701 - val_auc: 0.7964 - val_binary_accuracy: 0.9076 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9072 - loss: 0.2692 - val_auc: 0.7965 - val_binary_accuracy: 0.9078 - val_loss: 0.2588\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9075 - loss: 0.2673 - val_auc: 0.7999 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9075 - loss: 0.2661 - val_auc: 0.8008 - val_binary_accuracy: 0.9098 - val_loss: 0.2570\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9086 - loss: 0.2659 - val_auc: 0.8012 - val_binary_accuracy: 0.9100 - val_loss: 0.2566\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9082 - loss: 0.2651 - val_auc: 0.8018 - val_binary_accuracy: 0.9109 - val_loss: 0.2557\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8119 - binary_accuracy: 0.9096 - loss: 0.2539\n",
      "Fold 5 Metrics: Loss = 0.2557, Accuracy = 0.9109, AUC = 0.8018\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2606\n",
      "Average Accuracy: 0.9093\n",
      "Average AUC: 0.7975\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 5, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6768 - binary_accuracy: 0.9012 - loss: 0.3083 - val_auc: 0.7721 - val_binary_accuracy: 0.9045 - val_loss: 0.2709\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9083 - loss: 0.2637 - val_auc: 0.7824 - val_binary_accuracy: 0.9053 - val_loss: 0.2659\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2583 - val_auc: 0.7853 - val_binary_accuracy: 0.9078 - val_loss: 0.2627\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9106 - loss: 0.2559 - val_auc: 0.7875 - val_binary_accuracy: 0.9087 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9118 - loss: 0.2540 - val_auc: 0.7889 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9116 - loss: 0.2527 - val_auc: 0.7904 - val_binary_accuracy: 0.9069 - val_loss: 0.2629\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9119 - loss: 0.2515 - val_auc: 0.7939 - val_binary_accuracy: 0.9088 - val_loss: 0.2604\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9119 - loss: 0.2500 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9123 - loss: 0.2497 - val_auc: 0.7948 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8091 - binary_accuracy: 0.9122 - loss: 0.2490 - val_auc: 0.7953 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9118 - loss: 0.2518\n",
      "Fold 1 Metrics: Loss = 0.2594, Accuracy = 0.9085, AUC = 0.7953\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7273 - binary_accuracy: 0.9029 - loss: 0.2894 - val_auc: 0.7957 - val_binary_accuracy: 0.9044 - val_loss: 0.2647\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9034 - loss: 0.2712 - val_auc: 0.8002 - val_binary_accuracy: 0.9071 - val_loss: 0.2608\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9047 - loss: 0.2676 - val_auc: 0.8050 - val_binary_accuracy: 0.9066 - val_loss: 0.2592\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7906 - binary_accuracy: 0.9060 - loss: 0.2656 - val_auc: 0.8074 - val_binary_accuracy: 0.9081 - val_loss: 0.2573\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9077 - loss: 0.2643 - val_auc: 0.8084 - val_binary_accuracy: 0.9088 - val_loss: 0.2566\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9084 - loss: 0.2630 - val_auc: 0.8108 - val_binary_accuracy: 0.9090 - val_loss: 0.2543\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8112 - val_binary_accuracy: 0.9099 - val_loss: 0.2539\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9082 - loss: 0.2605 - val_auc: 0.8111 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8006 - binary_accuracy: 0.9083 - loss: 0.2604 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2532\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9086 - loss: 0.2593 - val_auc: 0.8105 - val_binary_accuracy: 0.9099 - val_loss: 0.2544\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9137 - loss: 0.2452\n",
      "Fold 2 Metrics: Loss = 0.2544, Accuracy = 0.9099, AUC = 0.8105\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6220 - binary_accuracy: 0.8580 - loss: 0.4961 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7602 - binary_accuracy: 0.9052 - loss: 0.2745 - val_auc: 0.7819 - val_binary_accuracy: 0.9048 - val_loss: 0.2688\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7672 - binary_accuracy: 0.9063 - loss: 0.2710 - val_auc: 0.7895 - val_binary_accuracy: 0.9091 - val_loss: 0.2644\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9057 - loss: 0.2686 - val_auc: 0.7913 - val_binary_accuracy: 0.9085 - val_loss: 0.2633\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9065 - loss: 0.2667 - val_auc: 0.7919 - val_binary_accuracy: 0.9096 - val_loss: 0.2624\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9067 - loss: 0.2656 - val_auc: 0.7946 - val_binary_accuracy: 0.9097 - val_loss: 0.2612\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9080 - loss: 0.2635 - val_auc: 0.7939 - val_binary_accuracy: 0.9102 - val_loss: 0.2604\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9080 - loss: 0.2637 - val_auc: 0.7963 - val_binary_accuracy: 0.9103 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9082 - loss: 0.2612 - val_auc: 0.7947 - val_binary_accuracy: 0.9082 - val_loss: 0.2605\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9081 - loss: 0.2621 - val_auc: 0.7952 - val_binary_accuracy: 0.9097 - val_loss: 0.2594\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7884 - binary_accuracy: 0.9120 - loss: 0.2604\n",
      "Fold 3 Metrics: Loss = 0.2594, Accuracy = 0.9097, AUC = 0.7952\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6633 - binary_accuracy: 0.9040 - loss: 0.3229 - val_auc: 0.7850 - val_binary_accuracy: 0.9048 - val_loss: 0.2676\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9048 - loss: 0.2722 - val_auc: 0.7925 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9057 - loss: 0.2683 - val_auc: 0.7943 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7988 - val_binary_accuracy: 0.9051 - val_loss: 0.2609\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9077 - loss: 0.2638 - val_auc: 0.8002 - val_binary_accuracy: 0.9057 - val_loss: 0.2599\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2619 - val_auc: 0.8020 - val_binary_accuracy: 0.9011 - val_loss: 0.2632\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9082 - loss: 0.2624 - val_auc: 0.8046 - val_binary_accuracy: 0.9022 - val_loss: 0.2611\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9090 - loss: 0.2608 - val_auc: 0.8046 - val_binary_accuracy: 0.9070 - val_loss: 0.2576\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9103 - loss: 0.2591 - val_auc: 0.8067 - val_binary_accuracy: 0.9059 - val_loss: 0.2580\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8067 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7872 - binary_accuracy: 0.9074 - loss: 0.2640\n",
      "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9087, AUC = 0.8067\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6249 - binary_accuracy: 0.8291 - loss: 0.4671 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9043 - loss: 0.2747 - val_auc: 0.7917 - val_binary_accuracy: 0.9003 - val_loss: 0.2738\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9041 - loss: 0.2734 - val_auc: 0.7943 - val_binary_accuracy: 0.8995 - val_loss: 0.2674\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7991 - val_binary_accuracy: 0.9067 - val_loss: 0.2655\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9060 - loss: 0.2693 - val_auc: 0.8004 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9080 - loss: 0.2660 - val_auc: 0.8007 - val_binary_accuracy: 0.9067 - val_loss: 0.2611\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9074 - loss: 0.2656 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2577\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9088 - loss: 0.2633 - val_auc: 0.8051 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8058 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9088 - loss: 0.2624 - val_auc: 0.8067 - val_binary_accuracy: 0.9103 - val_loss: 0.2563\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9101 - loss: 0.2536\n",
      "Fold 5 Metrics: Loss = 0.2563, Accuracy = 0.9103, AUC = 0.8067\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2571\n",
      "Average Accuracy: 0.9094\n",
      "Average AUC: 0.8029\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 5, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7065 - binary_accuracy: 0.9066 - loss: 0.2945 - val_auc: 0.7741 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9077 - loss: 0.2617 - val_auc: 0.7815 - val_binary_accuracy: 0.9050 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9095 - loss: 0.2581 - val_auc: 0.7843 - val_binary_accuracy: 0.9072 - val_loss: 0.2643\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9112 - loss: 0.2549 - val_auc: 0.7880 - val_binary_accuracy: 0.9072 - val_loss: 0.2635\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9112 - loss: 0.2535 - val_auc: 0.7885 - val_binary_accuracy: 0.9069 - val_loss: 0.2627\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9110 - loss: 0.2514 - val_auc: 0.7901 - val_binary_accuracy: 0.9094 - val_loss: 0.2613\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9117 - loss: 0.2508 - val_auc: 0.7918 - val_binary_accuracy: 0.9088 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9120 - loss: 0.2498 - val_auc: 0.7914 - val_binary_accuracy: 0.9081 - val_loss: 0.2612\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8099 - binary_accuracy: 0.9129 - loss: 0.2480 - val_auc: 0.7918 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8098 - binary_accuracy: 0.9131 - loss: 0.2480 - val_auc: 0.7914 - val_binary_accuracy: 0.9072 - val_loss: 0.2619\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7918 - binary_accuracy: 0.9114 - loss: 0.2528\n",
      "Fold 1 Metrics: Loss = 0.2619, Accuracy = 0.9072, AUC = 0.7914\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - auc: 0.6525 - binary_accuracy: 0.8688 - loss: 0.5184 - val_auc: 0.7926 - val_binary_accuracy: 0.9040 - val_loss: 0.2703\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9032 - loss: 0.2726 - val_auc: 0.7990 - val_binary_accuracy: 0.9047 - val_loss: 0.2685\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9047 - loss: 0.2679 - val_auc: 0.8014 - val_binary_accuracy: 0.9068 - val_loss: 0.2666\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9075 - loss: 0.2670 - val_auc: 0.8016 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9071 - loss: 0.2652 - val_auc: 0.8024 - val_binary_accuracy: 0.9069 - val_loss: 0.2633\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9076 - loss: 0.2636 - val_auc: 0.8017 - val_binary_accuracy: 0.9088 - val_loss: 0.2628\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9071 - loss: 0.2625 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2598\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9081 - loss: 0.2615 - val_auc: 0.8113 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9085 - loss: 0.2608 - val_auc: 0.8099 - val_binary_accuracy: 0.9093 - val_loss: 0.2587\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9091 - loss: 0.2603 - val_auc: 0.8159 - val_binary_accuracy: 0.9087 - val_loss: 0.2553\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8209 - binary_accuracy: 0.9127 - loss: 0.2465\n",
      "Fold 2 Metrics: Loss = 0.2553, Accuracy = 0.9087, AUC = 0.8159\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6395 - binary_accuracy: 0.8448 - loss: 0.8657 - val_auc: 0.7829 - val_binary_accuracy: 0.9059 - val_loss: 0.2744\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9073 - loss: 0.2715 - val_auc: 0.7891 - val_binary_accuracy: 0.9081 - val_loss: 0.2712\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9073 - loss: 0.2683 - val_auc: 0.7922 - val_binary_accuracy: 0.9050 - val_loss: 0.2667\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9076 - loss: 0.2681 - val_auc: 0.7940 - val_binary_accuracy: 0.9085 - val_loss: 0.2638\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9079 - loss: 0.2663 - val_auc: 0.7974 - val_binary_accuracy: 0.9084 - val_loss: 0.2618\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9078 - loss: 0.2643 - val_auc: 0.7991 - val_binary_accuracy: 0.9091 - val_loss: 0.2622\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9082 - loss: 0.2631 - val_auc: 0.8007 - val_binary_accuracy: 0.9090 - val_loss: 0.2607\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9089 - loss: 0.2625 - val_auc: 0.8027 - val_binary_accuracy: 0.9090 - val_loss: 0.2601\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9088 - loss: 0.2617 - val_auc: 0.8039 - val_binary_accuracy: 0.9073 - val_loss: 0.2604\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9095 - loss: 0.2615 - val_auc: 0.8035 - val_binary_accuracy: 0.9096 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7963 - binary_accuracy: 0.9118 - loss: 0.2593\n",
      "Fold 3 Metrics: Loss = 0.2587, Accuracy = 0.9096, AUC = 0.8035\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7178 - binary_accuracy: 0.9054 - loss: 0.2938 - val_auc: 0.7950 - val_binary_accuracy: 0.9076 - val_loss: 0.2615\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9079 - loss: 0.2668 - val_auc: 0.7960 - val_binary_accuracy: 0.9064 - val_loss: 0.2606\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9075 - loss: 0.2651 - val_auc: 0.7994 - val_binary_accuracy: 0.9053 - val_loss: 0.2609\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8033 - val_binary_accuracy: 0.9067 - val_loss: 0.2581\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9089 - loss: 0.2615 - val_auc: 0.8032 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9096 - loss: 0.2606 - val_auc: 0.7999 - val_binary_accuracy: 0.9088 - val_loss: 0.2583\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9105 - loss: 0.2601 - val_auc: 0.8074 - val_binary_accuracy: 0.9094 - val_loss: 0.2552\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8089 - val_binary_accuracy: 0.9087 - val_loss: 0.2560\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9107 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9107 - loss: 0.2571 - val_auc: 0.8107 - val_binary_accuracy: 0.9093 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7915 - binary_accuracy: 0.9094 - loss: 0.2624\n",
      "Fold 4 Metrics: Loss = 0.2551, Accuracy = 0.9093, AUC = 0.8107\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6953 - binary_accuracy: 0.9039 - loss: 0.2980 - val_auc: 0.7916 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9037 - loss: 0.2771 - val_auc: 0.7958 - val_binary_accuracy: 0.9053 - val_loss: 0.2638\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9051 - loss: 0.2717 - val_auc: 0.8012 - val_binary_accuracy: 0.9093 - val_loss: 0.2614\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.8033 - val_binary_accuracy: 0.9093 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9081 - loss: 0.2666 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2614\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9084 - loss: 0.2659 - val_auc: 0.8059 - val_binary_accuracy: 0.9093 - val_loss: 0.2613\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9076 - loss: 0.2644 - val_auc: 0.8071 - val_binary_accuracy: 0.9101 - val_loss: 0.2575\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.8085 - val_binary_accuracy: 0.9103 - val_loss: 0.2564\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9099 - loss: 0.2622 - val_auc: 0.8092 - val_binary_accuracy: 0.9107 - val_loss: 0.2549\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9100 - loss: 0.2624 - val_auc: 0.8099 - val_binary_accuracy: 0.9098 - val_loss: 0.2529\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9086 - loss: 0.2514\n",
      "Fold 5 Metrics: Loss = 0.2529, Accuracy = 0.9098, AUC = 0.8099\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2568\n",
      "Average Accuracy: 0.9089\n",
      "Average AUC: 0.8063\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 5, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6974 - binary_accuracy: 0.9006 - loss: 0.3307 - val_auc: 0.7742 - val_binary_accuracy: 0.9084 - val_loss: 0.2769\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.7827 - val_binary_accuracy: 0.9085 - val_loss: 0.2661\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9103 - loss: 0.2595 - val_auc: 0.7857 - val_binary_accuracy: 0.9091 - val_loss: 0.2629\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9110 - loss: 0.2545 - val_auc: 0.7854 - val_binary_accuracy: 0.9115 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9113 - loss: 0.2533 - val_auc: 0.7902 - val_binary_accuracy: 0.9088 - val_loss: 0.2597\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7908 - val_binary_accuracy: 0.9079 - val_loss: 0.2609\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9125 - loss: 0.2505 - val_auc: 0.7908 - val_binary_accuracy: 0.9084 - val_loss: 0.2633\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9130 - loss: 0.2494 - val_auc: 0.7945 - val_binary_accuracy: 0.9063 - val_loss: 0.2647\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9125 - loss: 0.2491 - val_auc: 0.7944 - val_binary_accuracy: 0.9072 - val_loss: 0.2648\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9126 - loss: 0.2485 - val_auc: 0.7941 - val_binary_accuracy: 0.9073 - val_loss: 0.2626\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7940 - binary_accuracy: 0.9106 - loss: 0.2539\n",
      "Fold 1 Metrics: Loss = 0.2626, Accuracy = 0.9073, AUC = 0.7941\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6998 - binary_accuracy: 0.8838 - loss: 0.3609 - val_auc: 0.7953 - val_binary_accuracy: 0.9045 - val_loss: 0.2826\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7627 - binary_accuracy: 0.9035 - loss: 0.2775 - val_auc: 0.7992 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9049 - loss: 0.2698 - val_auc: 0.8042 - val_binary_accuracy: 0.9066 - val_loss: 0.2631\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9058 - loss: 0.2670 - val_auc: 0.8063 - val_binary_accuracy: 0.9081 - val_loss: 0.2642\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9070 - loss: 0.2663 - val_auc: 0.8062 - val_binary_accuracy: 0.9073 - val_loss: 0.2653\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9077 - loss: 0.2641 - val_auc: 0.8034 - val_binary_accuracy: 0.9075 - val_loss: 0.2677\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8074 - val_binary_accuracy: 0.9093 - val_loss: 0.2652\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9081 - loss: 0.2617 - val_auc: 0.8063 - val_binary_accuracy: 0.9085 - val_loss: 0.2641\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9086 - loss: 0.2614 - val_auc: 0.8058 - val_binary_accuracy: 0.9091 - val_loss: 0.2637\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9082 - loss: 0.2606 - val_auc: 0.8082 - val_binary_accuracy: 0.9079 - val_loss: 0.2628\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8096 - binary_accuracy: 0.9121 - loss: 0.2547\n",
      "Fold 2 Metrics: Loss = 0.2628, Accuracy = 0.9079, AUC = 0.8082\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6591 - binary_accuracy: 0.8839 - loss: 0.5042 - val_auc: 0.7756 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7546 - binary_accuracy: 0.9049 - loss: 0.2768 - val_auc: 0.7852 - val_binary_accuracy: 0.9096 - val_loss: 0.2672\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9076 - loss: 0.2673 - val_auc: 0.7930 - val_binary_accuracy: 0.9103 - val_loss: 0.2622\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9080 - loss: 0.2657 - val_auc: 0.7946 - val_binary_accuracy: 0.9081 - val_loss: 0.2625\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9087 - loss: 0.2637 - val_auc: 0.7972 - val_binary_accuracy: 0.9102 - val_loss: 0.2609\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9084 - loss: 0.2633 - val_auc: 0.7994 - val_binary_accuracy: 0.9103 - val_loss: 0.2604\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9089 - loss: 0.2623 - val_auc: 0.8015 - val_binary_accuracy: 0.9110 - val_loss: 0.2616\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.8018 - val_binary_accuracy: 0.9107 - val_loss: 0.2612\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9088 - loss: 0.2616 - val_auc: 0.8027 - val_binary_accuracy: 0.9112 - val_loss: 0.2596\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8039 - val_binary_accuracy: 0.9109 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7971 - binary_accuracy: 0.9118 - loss: 0.2592\n",
      "Fold 3 Metrics: Loss = 0.2586, Accuracy = 0.9109, AUC = 0.8039\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6802 - binary_accuracy: 0.8869 - loss: 0.3484 - val_auc: 0.7851 - val_binary_accuracy: 0.9075 - val_loss: 0.2662\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9065 - loss: 0.2705 - val_auc: 0.7932 - val_binary_accuracy: 0.9038 - val_loss: 0.2647\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9072 - loss: 0.2670 - val_auc: 0.7967 - val_binary_accuracy: 0.9076 - val_loss: 0.2605\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.8005 - val_binary_accuracy: 0.9085 - val_loss: 0.2580\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9089 - loss: 0.2626 - val_auc: 0.8009 - val_binary_accuracy: 0.9098 - val_loss: 0.2574\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8040 - val_binary_accuracy: 0.9094 - val_loss: 0.2563\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9102 - loss: 0.2614 - val_auc: 0.8055 - val_binary_accuracy: 0.9097 - val_loss: 0.2563\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9101 - loss: 0.2600 - val_auc: 0.8064 - val_binary_accuracy: 0.9095 - val_loss: 0.2564\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9100 - loss: 0.2593 - val_auc: 0.8075 - val_binary_accuracy: 0.9098 - val_loss: 0.2562\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9106 - loss: 0.2585 - val_auc: 0.8080 - val_binary_accuracy: 0.9093 - val_loss: 0.2556\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9082 - loss: 0.2633\n",
      "Fold 4 Metrics: Loss = 0.2556, Accuracy = 0.9093, AUC = 0.8080\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6713 - binary_accuracy: 0.8885 - loss: 0.3562 - val_auc: 0.7881 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7560 - binary_accuracy: 0.9039 - loss: 0.2776 - val_auc: 0.7947 - val_binary_accuracy: 0.9079 - val_loss: 0.2627\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9065 - loss: 0.2729 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9060 - loss: 0.2705 - val_auc: 0.8007 - val_binary_accuracy: 0.9112 - val_loss: 0.2633\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9067 - loss: 0.2687 - val_auc: 0.8021 - val_binary_accuracy: 0.9104 - val_loss: 0.2590\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9071 - loss: 0.2674 - val_auc: 0.8048 - val_binary_accuracy: 0.9104 - val_loss: 0.2580\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.8060 - val_binary_accuracy: 0.9104 - val_loss: 0.2581\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2634 - val_auc: 0.8072 - val_binary_accuracy: 0.9113 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9094 - loss: 0.2623 - val_auc: 0.8063 - val_binary_accuracy: 0.9110 - val_loss: 0.2551\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9087 - loss: 0.2620 - val_auc: 0.8075 - val_binary_accuracy: 0.9113 - val_loss: 0.2542\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8159 - binary_accuracy: 0.9098 - loss: 0.2532\n",
      "Fold 5 Metrics: Loss = 0.2542, Accuracy = 0.9113, AUC = 0.8075\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2588\n",
      "Average Accuracy: 0.9093\n",
      "Average AUC: 0.8043\n",
      "----------------------------------------\n",
      "Performing training for: ('relu', 5, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6604 - binary_accuracy: 0.8799 - loss: 0.4752 - val_auc: 0.7722 - val_binary_accuracy: 0.9071 - val_loss: 0.2713\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9091 - loss: 0.2630 - val_auc: 0.7802 - val_binary_accuracy: 0.9078 - val_loss: 0.2715\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2572 - val_auc: 0.7870 - val_binary_accuracy: 0.9093 - val_loss: 0.2636\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9117 - loss: 0.2553 - val_auc: 0.7902 - val_binary_accuracy: 0.9099 - val_loss: 0.2630\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9121 - loss: 0.2537 - val_auc: 0.7928 - val_binary_accuracy: 0.9090 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9131 - loss: 0.2514 - val_auc: 0.7936 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9127 - loss: 0.2506 - val_auc: 0.7947 - val_binary_accuracy: 0.9088 - val_loss: 0.2592\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9133 - loss: 0.2493 - val_auc: 0.7947 - val_binary_accuracy: 0.9087 - val_loss: 0.2591\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8062 - binary_accuracy: 0.9130 - loss: 0.2492 - val_auc: 0.7944 - val_binary_accuracy: 0.9075 - val_loss: 0.2643\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9130 - loss: 0.2478 - val_auc: 0.7967 - val_binary_accuracy: 0.9075 - val_loss: 0.2624\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9105 - loss: 0.2539\n",
      "Fold 1 Metrics: Loss = 0.2624, Accuracy = 0.9075, AUC = 0.7967\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6583 - binary_accuracy: 0.8823 - loss: 0.5256 - val_auc: 0.7975 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9035 - loss: 0.2733 - val_auc: 0.8036 - val_binary_accuracy: 0.9063 - val_loss: 0.2675\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9057 - loss: 0.2684 - val_auc: 0.8062 - val_binary_accuracy: 0.9081 - val_loss: 0.2629\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9063 - loss: 0.2668 - val_auc: 0.8093 - val_binary_accuracy: 0.9062 - val_loss: 0.2619\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9068 - loss: 0.2650 - val_auc: 0.8026 - val_binary_accuracy: 0.9073 - val_loss: 0.2651\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9079 - loss: 0.2645 - val_auc: 0.8084 - val_binary_accuracy: 0.9071 - val_loss: 0.2659\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9067 - loss: 0.2632 - val_auc: 0.8118 - val_binary_accuracy: 0.9071 - val_loss: 0.2634\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9079 - loss: 0.2620 - val_auc: 0.8119 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9078 - loss: 0.2617 - val_auc: 0.8081 - val_binary_accuracy: 0.9082 - val_loss: 0.2628\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9088 - loss: 0.2612 - val_auc: 0.8066 - val_binary_accuracy: 0.9082 - val_loss: 0.2651\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8135 - binary_accuracy: 0.9126 - loss: 0.2562\n",
      "Fold 2 Metrics: Loss = 0.2651, Accuracy = 0.9082, AUC = 0.8066\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6539 - binary_accuracy: 0.8703 - loss: 0.4389 - val_auc: 0.7834 - val_binary_accuracy: 0.9063 - val_loss: 0.2737\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9068 - loss: 0.2708 - val_auc: 0.7899 - val_binary_accuracy: 0.9051 - val_loss: 0.2677\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9077 - loss: 0.2666 - val_auc: 0.7933 - val_binary_accuracy: 0.9053 - val_loss: 0.2636\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9085 - loss: 0.2650 - val_auc: 0.7966 - val_binary_accuracy: 0.9071 - val_loss: 0.2616\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9083 - loss: 0.2644 - val_auc: 0.7991 - val_binary_accuracy: 0.9054 - val_loss: 0.2626\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9095 - loss: 0.2624 - val_auc: 0.8015 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8019 - val_binary_accuracy: 0.9102 - val_loss: 0.2598\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8035 - val_binary_accuracy: 0.9109 - val_loss: 0.2575\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9096 - loss: 0.2620 - val_auc: 0.8041 - val_binary_accuracy: 0.9071 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9093 - loss: 0.2600 - val_auc: 0.8056 - val_binary_accuracy: 0.9097 - val_loss: 0.2588\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7988 - binary_accuracy: 0.9097 - loss: 0.2595\n",
      "Fold 3 Metrics: Loss = 0.2588, Accuracy = 0.9097, AUC = 0.8056\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6627 - binary_accuracy: 0.8852 - loss: 0.4744 - val_auc: 0.7887 - val_binary_accuracy: 0.9050 - val_loss: 0.2751\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9071 - loss: 0.2727 - val_auc: 0.7961 - val_binary_accuracy: 0.9069 - val_loss: 0.2627\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.8004 - val_binary_accuracy: 0.9081 - val_loss: 0.2597\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8025 - val_binary_accuracy: 0.9079 - val_loss: 0.2594\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9091 - loss: 0.2633 - val_auc: 0.8055 - val_binary_accuracy: 0.9093 - val_loss: 0.2563\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9095 - loss: 0.2620 - val_auc: 0.8067 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9103 - loss: 0.2612 - val_auc: 0.8094 - val_binary_accuracy: 0.9104 - val_loss: 0.2542\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9103 - loss: 0.2606 - val_auc: 0.8108 - val_binary_accuracy: 0.9097 - val_loss: 0.2539\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9103 - loss: 0.2600 - val_auc: 0.8101 - val_binary_accuracy: 0.9095 - val_loss: 0.2542\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9105 - loss: 0.2591 - val_auc: 0.8119 - val_binary_accuracy: 0.9097 - val_loss: 0.2532\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7929 - binary_accuracy: 0.9092 - loss: 0.2601\n",
      "Fold 4 Metrics: Loss = 0.2532, Accuracy = 0.9097, AUC = 0.8119\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6627 - binary_accuracy: 0.8900 - loss: 0.3801 - val_auc: 0.7908 - val_binary_accuracy: 0.9064 - val_loss: 0.2643\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9036 - loss: 0.2766 - val_auc: 0.7966 - val_binary_accuracy: 0.9022 - val_loss: 0.2604\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9040 - loss: 0.2731 - val_auc: 0.8000 - val_binary_accuracy: 0.9026 - val_loss: 0.2655\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9050 - loss: 0.2698 - val_auc: 0.8031 - val_binary_accuracy: 0.9098 - val_loss: 0.2657\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9076 - loss: 0.2673 - val_auc: 0.8038 - val_binary_accuracy: 0.9103 - val_loss: 0.2662\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9067 - loss: 0.2667 - val_auc: 0.8061 - val_binary_accuracy: 0.9101 - val_loss: 0.2626\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8078 - val_binary_accuracy: 0.9109 - val_loss: 0.2629\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9085 - loss: 0.2637 - val_auc: 0.8088 - val_binary_accuracy: 0.9113 - val_loss: 0.2612\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8093 - val_binary_accuracy: 0.9112 - val_loss: 0.2606\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9089 - loss: 0.2621 - val_auc: 0.8105 - val_binary_accuracy: 0.9110 - val_loss: 0.2592\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8180 - binary_accuracy: 0.9095 - loss: 0.2583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 33%|      | 1/3 [27:29<54:58, 1649.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Metrics: Loss = 0.2592, Accuracy = 0.9110, AUC = 0.8105\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2597\n",
      "Average Accuracy: 0.9092\n",
      "Average AUC: 0.8063\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 1, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5407 - binary_accuracy: 0.8881 - loss: 0.4453 - val_auc: 0.7252 - val_binary_accuracy: 0.9044 - val_loss: 0.2942\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7504 - binary_accuracy: 0.9069 - loss: 0.2838 - val_auc: 0.7611 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9069 - loss: 0.2731 - val_auc: 0.7639 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9069 - loss: 0.2694 - val_auc: 0.7680 - val_binary_accuracy: 0.9044 - val_loss: 0.2769\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.7680 - val_binary_accuracy: 0.9044 - val_loss: 0.2740\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9069 - loss: 0.2637 - val_auc: 0.7704 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7703 - val_binary_accuracy: 0.9044 - val_loss: 0.2711\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9069 - loss: 0.2606 - val_auc: 0.7728 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2597 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9069 - loss: 0.2591 - val_auc: 0.7754 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7695 - binary_accuracy: 0.9084 - loss: 0.2623\n",
      "Fold 1 Metrics: Loss = 0.2693, Accuracy = 0.9044, AUC = 0.7754\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5431 - binary_accuracy: 0.6690 - loss: 0.5823 - val_auc: 0.7283 - val_binary_accuracy: 0.9042 - val_loss: 0.2975\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7313 - binary_accuracy: 0.9029 - loss: 0.2964 - val_auc: 0.7698 - val_binary_accuracy: 0.9042 - val_loss: 0.2864\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7585 - binary_accuracy: 0.9029 - loss: 0.2881 - val_auc: 0.7775 - val_binary_accuracy: 0.9042 - val_loss: 0.2786\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9029 - loss: 0.2803 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2724\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2756 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9029 - loss: 0.2730 - val_auc: 0.7930 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9029 - loss: 0.2714 - val_auc: 0.7936 - val_binary_accuracy: 0.9042 - val_loss: 0.2647\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9029 - loss: 0.2702 - val_auc: 0.7938 - val_binary_accuracy: 0.9042 - val_loss: 0.2635\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9029 - loss: 0.2692 - val_auc: 0.7980 - val_binary_accuracy: 0.9042 - val_loss: 0.2621\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9029 - loss: 0.2683 - val_auc: 0.7988 - val_binary_accuracy: 0.9042 - val_loss: 0.2610\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7984 - binary_accuracy: 0.9092 - loss: 0.2522\n",
      "Fold 2 Metrics: Loss = 0.2610, Accuracy = 0.9042, AUC = 0.7988\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5566 - binary_accuracy: 0.8404 - loss: 0.4183 - val_auc: 0.7434 - val_binary_accuracy: 0.9042 - val_loss: 0.2893\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7448 - binary_accuracy: 0.9051 - loss: 0.2850 - val_auc: 0.7576 - val_binary_accuracy: 0.9042 - val_loss: 0.2785\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9051 - loss: 0.2765 - val_auc: 0.7733 - val_binary_accuracy: 0.9042 - val_loss: 0.2735\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9051 - loss: 0.2715 - val_auc: 0.7771 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9051 - loss: 0.2685 - val_auc: 0.7793 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7828 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9051 - loss: 0.2654 - val_auc: 0.7842 - val_binary_accuracy: 0.9042 - val_loss: 0.2678\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9051 - loss: 0.2646 - val_auc: 0.7856 - val_binary_accuracy: 0.9042 - val_loss: 0.2673\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9051 - loss: 0.2636 - val_auc: 0.7896 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7821 - binary_accuracy: 0.9046 - loss: 0.2672\n",
      "Fold 3 Metrics: Loss = 0.2663, Accuracy = 0.9042, AUC = 0.7896\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5240 - binary_accuracy: 0.7788 - loss: 0.5157 - val_auc: 0.7256 - val_binary_accuracy: 0.9044 - val_loss: 0.3122\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7287 - binary_accuracy: 0.9047 - loss: 0.3036 - val_auc: 0.7630 - val_binary_accuracy: 0.9044 - val_loss: 0.2779\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7619 - binary_accuracy: 0.9047 - loss: 0.2764 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9047 - loss: 0.2717 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7742 - binary_accuracy: 0.9047 - loss: 0.2695 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9047 - loss: 0.2683 - val_auc: 0.7825 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9047 - loss: 0.2676 - val_auc: 0.7815 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9047 - loss: 0.2670 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9047 - loss: 0.2665 - val_auc: 0.7827 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9047 - loss: 0.2660 - val_auc: 0.7825 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7576 - binary_accuracy: 0.9049 - loss: 0.2724\n",
      "Fold 4 Metrics: Loss = 0.2665, Accuracy = 0.9044, AUC = 0.7825\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5757 - binary_accuracy: 0.8772 - loss: 0.3729 - val_auc: 0.7388 - val_binary_accuracy: 0.9044 - val_loss: 0.2870\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7411 - binary_accuracy: 0.9040 - loss: 0.2862 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7650 - binary_accuracy: 0.9040 - loss: 0.2755 - val_auc: 0.7852 - val_binary_accuracy: 0.9044 - val_loss: 0.2646\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7720 - binary_accuracy: 0.9049 - loss: 0.2702 - val_auc: 0.7873 - val_binary_accuracy: 0.9067 - val_loss: 0.2615\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9062 - loss: 0.2676 - val_auc: 0.7915 - val_binary_accuracy: 0.9076 - val_loss: 0.2600\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9077 - loss: 0.2660 - val_auc: 0.7935 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7824 - binary_accuracy: 0.9084 - loss: 0.2650 - val_auc: 0.7944 - val_binary_accuracy: 0.9097 - val_loss: 0.2582\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9085 - loss: 0.2643 - val_auc: 0.7955 - val_binary_accuracy: 0.9100 - val_loss: 0.2578\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9086 - loss: 0.2637 - val_auc: 0.7962 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7852 - binary_accuracy: 0.9084 - loss: 0.2633 - val_auc: 0.7966 - val_binary_accuracy: 0.9100 - val_loss: 0.2568\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8049 - binary_accuracy: 0.9085 - loss: 0.2565\n",
      "Fold 5 Metrics: Loss = 0.2568, Accuracy = 0.9100, AUC = 0.7966\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2640\n",
      "Average Accuracy: 0.9055\n",
      "Average AUC: 0.7886\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 1, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5814 - binary_accuracy: 0.6433 - loss: 0.6112 - val_auc: 0.7338 - val_binary_accuracy: 0.9044 - val_loss: 0.2928\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7551 - binary_accuracy: 0.9069 - loss: 0.2785 - val_auc: 0.7602 - val_binary_accuracy: 0.9044 - val_loss: 0.2753\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9069 - loss: 0.2657 - val_auc: 0.7694 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7941 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7769 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7977 - binary_accuracy: 0.9069 - loss: 0.2567 - val_auc: 0.7788 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7992 - binary_accuracy: 0.9070 - loss: 0.2558 - val_auc: 0.7803 - val_binary_accuracy: 0.9060 - val_loss: 0.2648\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8003 - binary_accuracy: 0.9084 - loss: 0.2548 - val_auc: 0.7815 - val_binary_accuracy: 0.9071 - val_loss: 0.2641\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8019 - binary_accuracy: 0.9096 - loss: 0.2540 - val_auc: 0.7836 - val_binary_accuracy: 0.9076 - val_loss: 0.2635\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8027 - binary_accuracy: 0.9106 - loss: 0.2534 - val_auc: 0.7855 - val_binary_accuracy: 0.9088 - val_loss: 0.2629\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7808 - binary_accuracy: 0.9122 - loss: 0.2566\n",
      "Fold 1 Metrics: Loss = 0.2629, Accuracy = 0.9088, AUC = 0.7855\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5741 - binary_accuracy: 0.7016 - loss: 0.5321 - val_auc: 0.7599 - val_binary_accuracy: 0.9042 - val_loss: 0.2855\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7551 - binary_accuracy: 0.9029 - loss: 0.2834 - val_auc: 0.7829 - val_binary_accuracy: 0.9042 - val_loss: 0.2736\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9029 - loss: 0.2756 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7805 - binary_accuracy: 0.9029 - loss: 0.2717 - val_auc: 0.7976 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9029 - loss: 0.2694 - val_auc: 0.8017 - val_binary_accuracy: 0.9042 - val_loss: 0.2658\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9029 - loss: 0.2679 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2636\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9045 - loss: 0.2666 - val_auc: 0.8037 - val_binary_accuracy: 0.9048 - val_loss: 0.2610\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9054 - loss: 0.2651 - val_auc: 0.8046 - val_binary_accuracy: 0.9057 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9065 - loss: 0.2641 - val_auc: 0.8073 - val_binary_accuracy: 0.9066 - val_loss: 0.2590\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9070 - loss: 0.2632 - val_auc: 0.8092 - val_binary_accuracy: 0.9069 - val_loss: 0.2584\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8106 - binary_accuracy: 0.9109 - loss: 0.2493\n",
      "Fold 2 Metrics: Loss = 0.2584, Accuracy = 0.9069, AUC = 0.8092\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6599 - binary_accuracy: 0.9042 - loss: 0.3330 - val_auc: 0.7664 - val_binary_accuracy: 0.9042 - val_loss: 0.2731\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9051 - loss: 0.2704 - val_auc: 0.7746 - val_binary_accuracy: 0.9042 - val_loss: 0.2704\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9051 - loss: 0.2674 - val_auc: 0.7760 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9051 - loss: 0.2659 - val_auc: 0.7795 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7805 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2641 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2665\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9053 - loss: 0.2633 - val_auc: 0.7856 - val_binary_accuracy: 0.9057 - val_loss: 0.2654\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7857 - binary_accuracy: 0.9065 - loss: 0.2623 - val_auc: 0.7881 - val_binary_accuracy: 0.9069 - val_loss: 0.2643\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7871 - binary_accuracy: 0.9072 - loss: 0.2613 - val_auc: 0.7913 - val_binary_accuracy: 0.9090 - val_loss: 0.2630\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9075 - loss: 0.2604 - val_auc: 0.7932 - val_binary_accuracy: 0.9093 - val_loss: 0.2620\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7855 - binary_accuracy: 0.9099 - loss: 0.2633\n",
      "Fold 3 Metrics: Loss = 0.2620, Accuracy = 0.9093, AUC = 0.7932\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5827 - binary_accuracy: 0.6991 - loss: 0.5044 - val_auc: 0.7478 - val_binary_accuracy: 0.9044 - val_loss: 0.2858\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7446 - binary_accuracy: 0.9047 - loss: 0.2826 - val_auc: 0.7729 - val_binary_accuracy: 0.9044 - val_loss: 0.2749\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9047 - loss: 0.2730 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9047 - loss: 0.2686 - val_auc: 0.7858 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9047 - loss: 0.2663 - val_auc: 0.7884 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9048 - loss: 0.2643 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7868 - binary_accuracy: 0.9052 - loss: 0.2632 - val_auc: 0.7899 - val_binary_accuracy: 0.9047 - val_loss: 0.2660\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9070 - loss: 0.2623 - val_auc: 0.7910 - val_binary_accuracy: 0.9056 - val_loss: 0.2654\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9087 - loss: 0.2615 - val_auc: 0.7925 - val_binary_accuracy: 0.9070 - val_loss: 0.2648\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9089 - loss: 0.2606 - val_auc: 0.7934 - val_binary_accuracy: 0.9076 - val_loss: 0.2642\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7696 - binary_accuracy: 0.9062 - loss: 0.2695\n",
      "Fold 4 Metrics: Loss = 0.2642, Accuracy = 0.9076, AUC = 0.7934\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6358 - binary_accuracy: 0.9040 - loss: 0.3280 - val_auc: 0.7817 - val_binary_accuracy: 0.9044 - val_loss: 0.2685\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9040 - loss: 0.2742 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7746 - binary_accuracy: 0.9040 - loss: 0.2710 - val_auc: 0.7913 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.7956 - val_binary_accuracy: 0.9044 - val_loss: 0.2601\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7818 - binary_accuracy: 0.9040 - loss: 0.2679 - val_auc: 0.7975 - val_binary_accuracy: 0.9044 - val_loss: 0.2589\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9042 - loss: 0.2666 - val_auc: 0.7992 - val_binary_accuracy: 0.9048 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7997 - val_binary_accuracy: 0.9053 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9065 - loss: 0.2647 - val_auc: 0.8003 - val_binary_accuracy: 0.9073 - val_loss: 0.2565\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9070 - loss: 0.2638 - val_auc: 0.8006 - val_binary_accuracy: 0.9085 - val_loss: 0.2558\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9080 - loss: 0.2630 - val_auc: 0.8014 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8118 - binary_accuracy: 0.9068 - loss: 0.2537\n",
      "Fold 5 Metrics: Loss = 0.2550, Accuracy = 0.9090, AUC = 0.8014\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2605\n",
      "Average Accuracy: 0.9083\n",
      "Average AUC: 0.7965\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 1, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6186 - binary_accuracy: 0.8966 - loss: 0.3419 - val_auc: 0.7591 - val_binary_accuracy: 0.9044 - val_loss: 0.2778\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9069 - loss: 0.2665 - val_auc: 0.7716 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9070 - loss: 0.2587 - val_auc: 0.7766 - val_binary_accuracy: 0.9060 - val_loss: 0.2672\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9098 - loss: 0.2561 - val_auc: 0.7801 - val_binary_accuracy: 0.9073 - val_loss: 0.2654\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9113 - loss: 0.2543 - val_auc: 0.7829 - val_binary_accuracy: 0.9088 - val_loss: 0.2639\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9120 - loss: 0.2527 - val_auc: 0.7854 - val_binary_accuracy: 0.9099 - val_loss: 0.2624\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9123 - loss: 0.2513 - val_auc: 0.7874 - val_binary_accuracy: 0.9094 - val_loss: 0.2613\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9123 - loss: 0.2503 - val_auc: 0.7893 - val_binary_accuracy: 0.9093 - val_loss: 0.2608\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8094 - binary_accuracy: 0.9129 - loss: 0.2494 - val_auc: 0.7898 - val_binary_accuracy: 0.9091 - val_loss: 0.2603\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9128 - loss: 0.2486 - val_auc: 0.7912 - val_binary_accuracy: 0.9096 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7863 - binary_accuracy: 0.9139 - loss: 0.2541\n",
      "Fold 1 Metrics: Loss = 0.2599, Accuracy = 0.9096, AUC = 0.7912\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6473 - binary_accuracy: 0.9029 - loss: 0.3159 - val_auc: 0.7858 - val_binary_accuracy: 0.9042 - val_loss: 0.2720\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9029 - loss: 0.2745 - val_auc: 0.7967 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.7998 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9031 - loss: 0.2680 - val_auc: 0.8024 - val_binary_accuracy: 0.9044 - val_loss: 0.2627\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9045 - loss: 0.2662 - val_auc: 0.8050 - val_binary_accuracy: 0.9057 - val_loss: 0.2602\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9060 - loss: 0.2646 - val_auc: 0.8058 - val_binary_accuracy: 0.9060 - val_loss: 0.2592\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9070 - loss: 0.2627 - val_auc: 0.8070 - val_binary_accuracy: 0.9062 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9073 - loss: 0.2615 - val_auc: 0.8076 - val_binary_accuracy: 0.9071 - val_loss: 0.2590\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9080 - loss: 0.2604 - val_auc: 0.8090 - val_binary_accuracy: 0.9078 - val_loss: 0.2587\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8017 - binary_accuracy: 0.9078 - loss: 0.2596 - val_auc: 0.8100 - val_binary_accuracy: 0.9081 - val_loss: 0.2583\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8147 - binary_accuracy: 0.9118 - loss: 0.2477\n",
      "Fold 2 Metrics: Loss = 0.2583, Accuracy = 0.9081, AUC = 0.8100\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7156 - binary_accuracy: 0.9051 - loss: 0.2877 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7728 - binary_accuracy: 0.9051 - loss: 0.2691 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7798 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7847 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9053 - loss: 0.2639 - val_auc: 0.7893 - val_binary_accuracy: 0.9048 - val_loss: 0.2648\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7860 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.7926 - val_binary_accuracy: 0.9076 - val_loss: 0.2628\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9076 - loss: 0.2611 - val_auc: 0.7957 - val_binary_accuracy: 0.9094 - val_loss: 0.2615\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7907 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.7979 - val_binary_accuracy: 0.9100 - val_loss: 0.2604\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7916 - binary_accuracy: 0.9094 - loss: 0.2593 - val_auc: 0.7993 - val_binary_accuracy: 0.9102 - val_loss: 0.2594\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7931 - binary_accuracy: 0.9095 - loss: 0.2587 - val_auc: 0.8006 - val_binary_accuracy: 0.9103 - val_loss: 0.2587\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7939 - binary_accuracy: 0.9098 - loss: 0.2582 - val_auc: 0.8025 - val_binary_accuracy: 0.9104 - val_loss: 0.2580\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9120 - loss: 0.2587\n",
      "Fold 3 Metrics: Loss = 0.2580, Accuracy = 0.9104, AUC = 0.8025\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5983 - binary_accuracy: 0.7126 - loss: 0.5437 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2777\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7606 - binary_accuracy: 0.9047 - loss: 0.2754 - val_auc: 0.7823 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9047 - loss: 0.2678 - val_auc: 0.7875 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7826 - binary_accuracy: 0.9050 - loss: 0.2653 - val_auc: 0.7899 - val_binary_accuracy: 0.9045 - val_loss: 0.2673\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9062 - loss: 0.2637 - val_auc: 0.7929 - val_binary_accuracy: 0.9057 - val_loss: 0.2662\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9083 - loss: 0.2622 - val_auc: 0.7957 - val_binary_accuracy: 0.9070 - val_loss: 0.2653\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.7975 - val_binary_accuracy: 0.9079 - val_loss: 0.2640\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9091 - loss: 0.2601 - val_auc: 0.7994 - val_binary_accuracy: 0.9085 - val_loss: 0.2632\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9096 - loss: 0.2593 - val_auc: 0.8001 - val_binary_accuracy: 0.9091 - val_loss: 0.2626\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9100 - loss: 0.2586 - val_auc: 0.8017 - val_binary_accuracy: 0.9094 - val_loss: 0.2622\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7809 - binary_accuracy: 0.9092 - loss: 0.2677\n",
      "Fold 4 Metrics: Loss = 0.2622, Accuracy = 0.9094, AUC = 0.8017\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6977 - binary_accuracy: 0.9040 - loss: 0.2969 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9040 - loss: 0.2689 - val_auc: 0.7955 - val_binary_accuracy: 0.9047 - val_loss: 0.2596\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9045 - loss: 0.2668 - val_auc: 0.7981 - val_binary_accuracy: 0.9060 - val_loss: 0.2578\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9057 - loss: 0.2653 - val_auc: 0.8018 - val_binary_accuracy: 0.9087 - val_loss: 0.2560\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.8029 - val_binary_accuracy: 0.9087 - val_loss: 0.2553\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9084 - loss: 0.2627 - val_auc: 0.8040 - val_binary_accuracy: 0.9093 - val_loss: 0.2545\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9087 - loss: 0.2618 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2537\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9094 - loss: 0.2611 - val_auc: 0.8062 - val_binary_accuracy: 0.9104 - val_loss: 0.2530\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9100 - loss: 0.2602 - val_auc: 0.8068 - val_binary_accuracy: 0.9104 - val_loss: 0.2525\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9084 - loss: 0.2513\n",
      "Fold 5 Metrics: Loss = 0.2525, Accuracy = 0.9104, AUC = 0.8068\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2582\n",
      "Average Accuracy: 0.9096\n",
      "Average AUC: 0.8025\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 1, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6868 - binary_accuracy: 0.9069 - loss: 0.2956 - val_auc: 0.7720 - val_binary_accuracy: 0.9044 - val_loss: 0.2714\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9075 - loss: 0.2586 - val_auc: 0.7812 - val_binary_accuracy: 0.9069 - val_loss: 0.2663\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9093 - loss: 0.2549 - val_auc: 0.7856 - val_binary_accuracy: 0.9082 - val_loss: 0.2640\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9118 - loss: 0.2526 - val_auc: 0.7884 - val_binary_accuracy: 0.9079 - val_loss: 0.2622\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9130 - loss: 0.2509 - val_auc: 0.7903 - val_binary_accuracy: 0.9085 - val_loss: 0.2610\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9129 - loss: 0.2493 - val_auc: 0.7918 - val_binary_accuracy: 0.9085 - val_loss: 0.2604\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9128 - loss: 0.2484 - val_auc: 0.7930 - val_binary_accuracy: 0.9085 - val_loss: 0.2600\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9127 - loss: 0.2475 - val_auc: 0.7938 - val_binary_accuracy: 0.9087 - val_loss: 0.2597\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8133 - binary_accuracy: 0.9127 - loss: 0.2469 - val_auc: 0.7941 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9126 - loss: 0.2463 - val_auc: 0.7949 - val_binary_accuracy: 0.9090 - val_loss: 0.2591\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7946 - binary_accuracy: 0.9128 - loss: 0.2521\n",
      "Fold 1 Metrics: Loss = 0.2591, Accuracy = 0.9090, AUC = 0.7949\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6517 - binary_accuracy: 0.8179 - loss: 0.3826 - val_auc: 0.7930 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8002 - val_binary_accuracy: 0.9042 - val_loss: 0.2628\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9042 - loss: 0.2661 - val_auc: 0.8058 - val_binary_accuracy: 0.9048 - val_loss: 0.2597\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9064 - loss: 0.2636 - val_auc: 0.8082 - val_binary_accuracy: 0.9060 - val_loss: 0.2586\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9069 - loss: 0.2619 - val_auc: 0.8095 - val_binary_accuracy: 0.9062 - val_loss: 0.2579\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.8110 - val_binary_accuracy: 0.9072 - val_loss: 0.2570\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9081 - loss: 0.2598 - val_auc: 0.8115 - val_binary_accuracy: 0.9073 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9080 - loss: 0.2591 - val_auc: 0.8116 - val_binary_accuracy: 0.9076 - val_loss: 0.2568\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9079 - loss: 0.2584 - val_auc: 0.8129 - val_binary_accuracy: 0.9082 - val_loss: 0.2565\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9083 - loss: 0.2578 - val_auc: 0.8133 - val_binary_accuracy: 0.9084 - val_loss: 0.2565\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8198 - binary_accuracy: 0.9127 - loss: 0.2454\n",
      "Fold 2 Metrics: Loss = 0.2565, Accuracy = 0.9084, AUC = 0.8133\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6423 - binary_accuracy: 0.8182 - loss: 0.3870 - val_auc: 0.7731 - val_binary_accuracy: 0.9042 - val_loss: 0.2711\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9052 - loss: 0.2688 - val_auc: 0.7804 - val_binary_accuracy: 0.9045 - val_loss: 0.2677\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9071 - loss: 0.2651 - val_auc: 0.7852 - val_binary_accuracy: 0.9079 - val_loss: 0.2652\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9081 - loss: 0.2633 - val_auc: 0.7890 - val_binary_accuracy: 0.9102 - val_loss: 0.2631\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9090 - loss: 0.2618 - val_auc: 0.7941 - val_binary_accuracy: 0.9099 - val_loss: 0.2611\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9095 - loss: 0.2605 - val_auc: 0.7981 - val_binary_accuracy: 0.9103 - val_loss: 0.2593\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9094 - loss: 0.2595 - val_auc: 0.8009 - val_binary_accuracy: 0.9113 - val_loss: 0.2581\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9096 - loss: 0.2587 - val_auc: 0.8031 - val_binary_accuracy: 0.9113 - val_loss: 0.2570\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9094 - loss: 0.2581 - val_auc: 0.8049 - val_binary_accuracy: 0.9115 - val_loss: 0.2562\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9096 - loss: 0.2576 - val_auc: 0.8059 - val_binary_accuracy: 0.9113 - val_loss: 0.2557\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9125 - loss: 0.2569\n",
      "Fold 3 Metrics: Loss = 0.2557, Accuracy = 0.9113, AUC = 0.8059\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6984 - binary_accuracy: 0.9049 - loss: 0.2910 - val_auc: 0.7864 - val_binary_accuracy: 0.9051 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7942 - val_binary_accuracy: 0.9066 - val_loss: 0.2623\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.7989 - val_binary_accuracy: 0.9078 - val_loss: 0.2601\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9095 - loss: 0.2601 - val_auc: 0.8015 - val_binary_accuracy: 0.9084 - val_loss: 0.2583\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9104 - loss: 0.2586 - val_auc: 0.8059 - val_binary_accuracy: 0.9087 - val_loss: 0.2570\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9109 - loss: 0.2575 - val_auc: 0.8062 - val_binary_accuracy: 0.9093 - val_loss: 0.2563\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9107 - loss: 0.2567 - val_auc: 0.8087 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7990 - binary_accuracy: 0.9108 - loss: 0.2559 - val_auc: 0.8093 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9110 - loss: 0.2555 - val_auc: 0.8103 - val_binary_accuracy: 0.9095 - val_loss: 0.2552\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9113 - loss: 0.2550 - val_auc: 0.8101 - val_binary_accuracy: 0.9095 - val_loss: 0.2549\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7899 - binary_accuracy: 0.9090 - loss: 0.2617\n",
      "Fold 4 Metrics: Loss = 0.2549, Accuracy = 0.9095, AUC = 0.8101\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6479 - binary_accuracy: 0.8353 - loss: 0.3740 - val_auc: 0.7840 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9040 - loss: 0.2720 - val_auc: 0.7910 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9044 - loss: 0.2683 - val_auc: 0.7960 - val_binary_accuracy: 0.9067 - val_loss: 0.2589\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9064 - loss: 0.2662 - val_auc: 0.7995 - val_binary_accuracy: 0.9079 - val_loss: 0.2572\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7868 - binary_accuracy: 0.9084 - loss: 0.2645 - val_auc: 0.8025 - val_binary_accuracy: 0.9095 - val_loss: 0.2556\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7902 - binary_accuracy: 0.9086 - loss: 0.2630 - val_auc: 0.8039 - val_binary_accuracy: 0.9100 - val_loss: 0.2545\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7913 - binary_accuracy: 0.9089 - loss: 0.2617 - val_auc: 0.8054 - val_binary_accuracy: 0.9101 - val_loss: 0.2537\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7936 - binary_accuracy: 0.9093 - loss: 0.2608 - val_auc: 0.8058 - val_binary_accuracy: 0.9107 - val_loss: 0.2531\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9098 - loss: 0.2600 - val_auc: 0.8060 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9102 - loss: 0.2594 - val_auc: 0.8069 - val_binary_accuracy: 0.9107 - val_loss: 0.2522\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8153 - binary_accuracy: 0.9089 - loss: 0.2510\n",
      "Fold 5 Metrics: Loss = 0.2522, Accuracy = 0.9107, AUC = 0.8069\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2557\n",
      "Average Accuracy: 0.9098\n",
      "Average AUC: 0.8062\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 1, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6850 - binary_accuracy: 0.8710 - loss: 0.3234 - val_auc: 0.7733 - val_binary_accuracy: 0.9051 - val_loss: 0.2710\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.7813 - val_binary_accuracy: 0.9076 - val_loss: 0.2667\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9107 - loss: 0.2548 - val_auc: 0.7862 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7903 - val_binary_accuracy: 0.9088 - val_loss: 0.2613\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9128 - loss: 0.2501 - val_auc: 0.7922 - val_binary_accuracy: 0.9087 - val_loss: 0.2602\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8095 - binary_accuracy: 0.9126 - loss: 0.2488 - val_auc: 0.7933 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9127 - loss: 0.2477 - val_auc: 0.7948 - val_binary_accuracy: 0.9088 - val_loss: 0.2590\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8135 - binary_accuracy: 0.9127 - loss: 0.2469 - val_auc: 0.7953 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8146 - binary_accuracy: 0.9128 - loss: 0.2462 - val_auc: 0.7952 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8154 - binary_accuracy: 0.9127 - loss: 0.2457 - val_auc: 0.7962 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7961 - binary_accuracy: 0.9129 - loss: 0.2514\n",
      "Fold 1 Metrics: Loss = 0.2586, Accuracy = 0.9088, AUC = 0.7962\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6677 - binary_accuracy: 0.8441 - loss: 0.3601 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2654\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9036 - loss: 0.2691 - val_auc: 0.8037 - val_binary_accuracy: 0.9054 - val_loss: 0.2597\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9055 - loss: 0.2651 - val_auc: 0.8071 - val_binary_accuracy: 0.9068 - val_loss: 0.2577\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9074 - loss: 0.2630 - val_auc: 0.8099 - val_binary_accuracy: 0.9073 - val_loss: 0.2569\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9077 - loss: 0.2616 - val_auc: 0.8116 - val_binary_accuracy: 0.9078 - val_loss: 0.2558\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9078 - loss: 0.2605 - val_auc: 0.8123 - val_binary_accuracy: 0.9079 - val_loss: 0.2555\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9085 - loss: 0.2597 - val_auc: 0.8131 - val_binary_accuracy: 0.9081 - val_loss: 0.2549\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9084 - loss: 0.2589 - val_auc: 0.8136 - val_binary_accuracy: 0.9084 - val_loss: 0.2546\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9085 - loss: 0.2582 - val_auc: 0.8140 - val_binary_accuracy: 0.9090 - val_loss: 0.2543\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9084 - loss: 0.2576 - val_auc: 0.8145 - val_binary_accuracy: 0.9088 - val_loss: 0.2541\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8208 - binary_accuracy: 0.9133 - loss: 0.2435\n",
      "Fold 2 Metrics: Loss = 0.2541, Accuracy = 0.9088, AUC = 0.8145\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6643 - binary_accuracy: 0.8778 - loss: 0.3242 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9067 - loss: 0.2680 - val_auc: 0.7863 - val_binary_accuracy: 0.9075 - val_loss: 0.2657\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9081 - loss: 0.2653 - val_auc: 0.7920 - val_binary_accuracy: 0.9097 - val_loss: 0.2632\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9085 - loss: 0.2632 - val_auc: 0.7953 - val_binary_accuracy: 0.9100 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9092 - loss: 0.2618 - val_auc: 0.7988 - val_binary_accuracy: 0.9107 - val_loss: 0.2594\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9092 - loss: 0.2609 - val_auc: 0.8003 - val_binary_accuracy: 0.9110 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9096 - loss: 0.2600 - val_auc: 0.8029 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9099 - loss: 0.2594 - val_auc: 0.8035 - val_binary_accuracy: 0.9112 - val_loss: 0.2564\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9098 - loss: 0.2589 - val_auc: 0.8053 - val_binary_accuracy: 0.9110 - val_loss: 0.2557\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7922 - binary_accuracy: 0.9098 - loss: 0.2585 - val_auc: 0.8063 - val_binary_accuracy: 0.9109 - val_loss: 0.2553\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9118 - loss: 0.2562\n",
      "Fold 3 Metrics: Loss = 0.2553, Accuracy = 0.9109, AUC = 0.8063\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7242 - binary_accuracy: 0.9052 - loss: 0.2848 - val_auc: 0.7915 - val_binary_accuracy: 0.9070 - val_loss: 0.2633\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9078 - loss: 0.2645 - val_auc: 0.7983 - val_binary_accuracy: 0.9081 - val_loss: 0.2597\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9098 - loss: 0.2612 - val_auc: 0.8017 - val_binary_accuracy: 0.9094 - val_loss: 0.2577\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9100 - loss: 0.2594 - val_auc: 0.8051 - val_binary_accuracy: 0.9098 - val_loss: 0.2564\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9106 - loss: 0.2580 - val_auc: 0.8077 - val_binary_accuracy: 0.9097 - val_loss: 0.2554\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9111 - loss: 0.2572 - val_auc: 0.8084 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9109 - loss: 0.2566 - val_auc: 0.8094 - val_binary_accuracy: 0.9091 - val_loss: 0.2543\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9109 - loss: 0.2561 - val_auc: 0.8105 - val_binary_accuracy: 0.9093 - val_loss: 0.2539\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9111 - loss: 0.2557 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2536\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9110 - loss: 0.2553 - val_auc: 0.8117 - val_binary_accuracy: 0.9093 - val_loss: 0.2535\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7926 - binary_accuracy: 0.9089 - loss: 0.2605\n",
      "Fold 4 Metrics: Loss = 0.2535, Accuracy = 0.9093, AUC = 0.8117\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6878 - binary_accuracy: 0.8724 - loss: 0.3236 - val_auc: 0.7872 - val_binary_accuracy: 0.9045 - val_loss: 0.2643\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9059 - loss: 0.2700 - val_auc: 0.7952 - val_binary_accuracy: 0.9081 - val_loss: 0.2600\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9086 - loss: 0.2667 - val_auc: 0.7990 - val_binary_accuracy: 0.9090 - val_loss: 0.2569\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9090 - loss: 0.2644 - val_auc: 0.8026 - val_binary_accuracy: 0.9098 - val_loss: 0.2549\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9092 - loss: 0.2627 - val_auc: 0.8057 - val_binary_accuracy: 0.9103 - val_loss: 0.2531\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9095 - loss: 0.2615 - val_auc: 0.8067 - val_binary_accuracy: 0.9106 - val_loss: 0.2527\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9097 - loss: 0.2605 - val_auc: 0.8076 - val_binary_accuracy: 0.9109 - val_loss: 0.2521\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9102 - loss: 0.2598 - val_auc: 0.8080 - val_binary_accuracy: 0.9109 - val_loss: 0.2519\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9105 - loss: 0.2593 - val_auc: 0.8081 - val_binary_accuracy: 0.9112 - val_loss: 0.2518\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9105 - loss: 0.2589 - val_auc: 0.8085 - val_binary_accuracy: 0.9112 - val_loss: 0.2518\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9094 - loss: 0.2510\n",
      "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9112, AUC = 0.8085\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2547\n",
      "Average Accuracy: 0.9098\n",
      "Average AUC: 0.8074\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 2, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5174 - binary_accuracy: 0.5824 - loss: 0.6365 - val_auc: 0.7352 - val_binary_accuracy: 0.9044 - val_loss: 0.3114\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7387 - binary_accuracy: 0.9069 - loss: 0.2987 - val_auc: 0.7471 - val_binary_accuracy: 0.9044 - val_loss: 0.2900\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9069 - loss: 0.2792 - val_auc: 0.7612 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9069 - loss: 0.2687 - val_auc: 0.7653 - val_binary_accuracy: 0.9044 - val_loss: 0.2737\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.7718 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9069 - loss: 0.2593 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9069 - loss: 0.2575 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9069 - loss: 0.2563 - val_auc: 0.7763 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9069 - loss: 0.2556 - val_auc: 0.7774 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9070 - loss: 0.2550 - val_auc: 0.7796 - val_binary_accuracy: 0.9045 - val_loss: 0.2656\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7781 - binary_accuracy: 0.9086 - loss: 0.2584\n",
      "Fold 1 Metrics: Loss = 0.2656, Accuracy = 0.9045, AUC = 0.7796\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.4830 - binary_accuracy: 0.8103 - loss: 0.4890 - val_auc: 0.6652 - val_binary_accuracy: 0.9042 - val_loss: 0.3137\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.6821 - binary_accuracy: 0.9029 - loss: 0.3148 - val_auc: 0.7370 - val_binary_accuracy: 0.9042 - val_loss: 0.3088\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7247 - binary_accuracy: 0.9029 - loss: 0.3110 - val_auc: 0.7555 - val_binary_accuracy: 0.9042 - val_loss: 0.3041\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7427 - binary_accuracy: 0.9029 - loss: 0.3017 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2867\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9029 - loss: 0.2871 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2750\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9029 - loss: 0.2775 - val_auc: 0.7827 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9029 - loss: 0.2730 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2709 - val_auc: 0.7922 - val_binary_accuracy: 0.9042 - val_loss: 0.2637\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9029 - loss: 0.2699 - val_auc: 0.7948 - val_binary_accuracy: 0.9042 - val_loss: 0.2627\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9029 - loss: 0.2693 - val_auc: 0.8002 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7975 - binary_accuracy: 0.9092 - loss: 0.2542\n",
      "Fold 2 Metrics: Loss = 0.2623, Accuracy = 0.9042, AUC = 0.8002\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5581 - binary_accuracy: 0.6994 - loss: 0.5267 - val_auc: 0.7585 - val_binary_accuracy: 0.9042 - val_loss: 0.2914\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7546 - binary_accuracy: 0.9051 - loss: 0.2867 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2786\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9051 - loss: 0.2750 - val_auc: 0.7714 - val_binary_accuracy: 0.9042 - val_loss: 0.2728\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9051 - loss: 0.2698 - val_auc: 0.7789 - val_binary_accuracy: 0.9042 - val_loss: 0.2709\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7759 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9051 - loss: 0.2662 - val_auc: 0.7798 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9051 - loss: 0.2650 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7838 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9051 - loss: 0.2629 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9051 - loss: 0.2620 - val_auc: 0.7877 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7815 - binary_accuracy: 0.9046 - loss: 0.2655\n",
      "Fold 3 Metrics: Loss = 0.2652, Accuracy = 0.9042, AUC = 0.7877\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5508 - binary_accuracy: 0.8437 - loss: 0.4380 - val_auc: 0.7529 - val_binary_accuracy: 0.9044 - val_loss: 0.2950\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7393 - binary_accuracy: 0.9047 - loss: 0.2905 - val_auc: 0.7674 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9047 - loss: 0.2774 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2739\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9047 - loss: 0.2707 - val_auc: 0.7860 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9047 - loss: 0.2674 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9047 - loss: 0.2660 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9047 - loss: 0.2650 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9047 - loss: 0.2643 - val_auc: 0.7931 - val_binary_accuracy: 0.9044 - val_loss: 0.2653\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9047 - loss: 0.2636 - val_auc: 0.7944 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9047 - loss: 0.2630 - val_auc: 0.7947 - val_binary_accuracy: 0.9044 - val_loss: 0.2644\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7729 - binary_accuracy: 0.9049 - loss: 0.2691\n",
      "Fold 4 Metrics: Loss = 0.2644, Accuracy = 0.9044, AUC = 0.7947\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5074 - binary_accuracy: 0.7590 - loss: 0.4816 - val_auc: 0.7335 - val_binary_accuracy: 0.9044 - val_loss: 0.3036\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7281 - binary_accuracy: 0.9040 - loss: 0.3030 - val_auc: 0.7601 - val_binary_accuracy: 0.9044 - val_loss: 0.2946\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7483 - binary_accuracy: 0.9040 - loss: 0.2945 - val_auc: 0.7685 - val_binary_accuracy: 0.9044 - val_loss: 0.2823\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9040 - loss: 0.2834 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2738\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9040 - loss: 0.2769 - val_auc: 0.7779 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9040 - loss: 0.2725 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9040 - loss: 0.2719 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7885 - val_binary_accuracy: 0.9044 - val_loss: 0.2632\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9040 - loss: 0.2711 - val_auc: 0.7895 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7987 - binary_accuracy: 0.9013 - loss: 0.2630\n",
      "Fold 5 Metrics: Loss = 0.2626, Accuracy = 0.9044, AUC = 0.7895\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2640\n",
      "Average Accuracy: 0.9044\n",
      "Average AUC: 0.7904\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 2, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - auc: 0.5151 - binary_accuracy: 0.6644 - loss: 0.5768 - val_auc: 0.7096 - val_binary_accuracy: 0.9044 - val_loss: 0.3085\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7242 - binary_accuracy: 0.9069 - loss: 0.2999 - val_auc: 0.7472 - val_binary_accuracy: 0.9044 - val_loss: 0.2943\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9069 - loss: 0.2826 - val_auc: 0.7603 - val_binary_accuracy: 0.9044 - val_loss: 0.2804\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9069 - loss: 0.2683 - val_auc: 0.7607 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9069 - loss: 0.2616 - val_auc: 0.7689 - val_binary_accuracy: 0.9044 - val_loss: 0.2704\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2596 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2696\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9069 - loss: 0.2587 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9069 - loss: 0.2581 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9069 - loss: 0.2576 - val_auc: 0.7752 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9069 - loss: 0.2571 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7735 - binary_accuracy: 0.9084 - loss: 0.2604\n",
      "Fold 1 Metrics: Loss = 0.2680, Accuracy = 0.9044, AUC = 0.7751\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5828 - binary_accuracy: 0.9020 - loss: 0.3681 - val_auc: 0.7650 - val_binary_accuracy: 0.9042 - val_loss: 0.2861\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9029 - loss: 0.2832 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2711 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2650\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9029 - loss: 0.2675 - val_auc: 0.8000 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9048 - loss: 0.2648 - val_auc: 0.8026 - val_binary_accuracy: 0.9047 - val_loss: 0.2616\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9063 - loss: 0.2628 - val_auc: 0.8053 - val_binary_accuracy: 0.9062 - val_loss: 0.2609\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.8073 - val_binary_accuracy: 0.9069 - val_loss: 0.2602\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9075 - loss: 0.2603 - val_auc: 0.8085 - val_binary_accuracy: 0.9075 - val_loss: 0.2595\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9078 - loss: 0.2594 - val_auc: 0.8092 - val_binary_accuracy: 0.9079 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.8113 - val_binary_accuracy: 0.9082 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8159 - binary_accuracy: 0.9121 - loss: 0.2488\n",
      "Fold 2 Metrics: Loss = 0.2587, Accuracy = 0.9082, AUC = 0.8113\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5187 - binary_accuracy: 0.7906 - loss: 0.4414 - val_auc: 0.7587 - val_binary_accuracy: 0.9042 - val_loss: 0.2873\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9051 - loss: 0.2828 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7817 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9051 - loss: 0.2665 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2673\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9051 - loss: 0.2635 - val_auc: 0.7881 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9051 - loss: 0.2629 - val_auc: 0.7891 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9051 - loss: 0.2624 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2649\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9058 - loss: 0.2616 - val_auc: 0.7917 - val_binary_accuracy: 0.9079 - val_loss: 0.2639\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9074 - loss: 0.2644\n",
      "Fold 3 Metrics: Loss = 0.2639, Accuracy = 0.9079, AUC = 0.7917\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5575 - binary_accuracy: 0.9047 - loss: 0.3670 - val_auc: 0.7704 - val_binary_accuracy: 0.9044 - val_loss: 0.2877\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7604 - binary_accuracy: 0.9047 - loss: 0.2814 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9047 - loss: 0.2677 - val_auc: 0.7826 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9047 - loss: 0.2653 - val_auc: 0.7867 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9050 - loss: 0.2641 - val_auc: 0.7887 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9066 - loss: 0.2633 - val_auc: 0.7932 - val_binary_accuracy: 0.9053 - val_loss: 0.2648\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9083 - loss: 0.2622 - val_auc: 0.7934 - val_binary_accuracy: 0.9067 - val_loss: 0.2640\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9091 - loss: 0.2612 - val_auc: 0.7963 - val_binary_accuracy: 0.9070 - val_loss: 0.2631\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9094 - loss: 0.2602 - val_auc: 0.7984 - val_binary_accuracy: 0.9078 - val_loss: 0.2622\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9097 - loss: 0.2593 - val_auc: 0.8003 - val_binary_accuracy: 0.9088 - val_loss: 0.2612\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7793 - binary_accuracy: 0.9080 - loss: 0.2669\n",
      "Fold 4 Metrics: Loss = 0.2612, Accuracy = 0.9088, AUC = 0.8003\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5635 - binary_accuracy: 0.8763 - loss: 0.3911 - val_auc: 0.7609 - val_binary_accuracy: 0.9044 - val_loss: 0.2932\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7480 - binary_accuracy: 0.9040 - loss: 0.2910 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2742\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9040 - loss: 0.2766 - val_auc: 0.7842 - val_binary_accuracy: 0.9044 - val_loss: 0.2644\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9040 - loss: 0.2706 - val_auc: 0.7881 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9040 - loss: 0.2687 - val_auc: 0.7936 - val_binary_accuracy: 0.9044 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9040 - loss: 0.2671 - val_auc: 0.7967 - val_binary_accuracy: 0.9060 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9058 - loss: 0.2654 - val_auc: 0.7970 - val_binary_accuracy: 0.9084 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9079 - loss: 0.2640 - val_auc: 0.7987 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9083 - loss: 0.2627 - val_auc: 0.7978 - val_binary_accuracy: 0.9097 - val_loss: 0.2558\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9090 - loss: 0.2615 - val_auc: 0.7997 - val_binary_accuracy: 0.9101 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8093 - binary_accuracy: 0.9079 - loss: 0.2532\n",
      "Fold 5 Metrics: Loss = 0.2552, Accuracy = 0.9101, AUC = 0.7997\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2614\n",
      "Average Accuracy: 0.9079\n",
      "Average AUC: 0.7956\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 2, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6283 - binary_accuracy: 0.9033 - loss: 0.3333 - val_auc: 0.7664 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9069 - loss: 0.2620 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9069 - loss: 0.2575 - val_auc: 0.7791 - val_binary_accuracy: 0.9041 - val_loss: 0.2672\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9072 - loss: 0.2550 - val_auc: 0.7825 - val_binary_accuracy: 0.9065 - val_loss: 0.2653\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9093 - loss: 0.2530 - val_auc: 0.7846 - val_binary_accuracy: 0.9079 - val_loss: 0.2638\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9110 - loss: 0.2512 - val_auc: 0.7873 - val_binary_accuracy: 0.9088 - val_loss: 0.2625\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9120 - loss: 0.2498 - val_auc: 0.7885 - val_binary_accuracy: 0.9084 - val_loss: 0.2616\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9123 - loss: 0.2487 - val_auc: 0.7895 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8114 - binary_accuracy: 0.9124 - loss: 0.2480 - val_auc: 0.7895 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8123 - binary_accuracy: 0.9124 - loss: 0.2473 - val_auc: 0.7904 - val_binary_accuracy: 0.9085 - val_loss: 0.2603\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7897 - binary_accuracy: 0.9113 - loss: 0.2530\n",
      "Fold 1 Metrics: Loss = 0.2603, Accuracy = 0.9085, AUC = 0.7904\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6523 - binary_accuracy: 0.9029 - loss: 0.3193 - val_auc: 0.7889 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9029 - loss: 0.2714 - val_auc: 0.7968 - val_binary_accuracy: 0.9042 - val_loss: 0.2625\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9038 - loss: 0.2674 - val_auc: 0.8027 - val_binary_accuracy: 0.9045 - val_loss: 0.2602\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9052 - loss: 0.2644 - val_auc: 0.8057 - val_binary_accuracy: 0.9065 - val_loss: 0.2578\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9068 - loss: 0.2623 - val_auc: 0.8072 - val_binary_accuracy: 0.9071 - val_loss: 0.2577\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9074 - loss: 0.2611 - val_auc: 0.8076 - val_binary_accuracy: 0.9078 - val_loss: 0.2574\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9079 - loss: 0.2602 - val_auc: 0.8087 - val_binary_accuracy: 0.9078 - val_loss: 0.2569\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9081 - loss: 0.2595 - val_auc: 0.8086 - val_binary_accuracy: 0.9084 - val_loss: 0.2570\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9087 - loss: 0.2589 - val_auc: 0.8100 - val_binary_accuracy: 0.9082 - val_loss: 0.2566\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9088 - loss: 0.2582 - val_auc: 0.8098 - val_binary_accuracy: 0.9087 - val_loss: 0.2568\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8164 - binary_accuracy: 0.9116 - loss: 0.2460\n",
      "Fold 2 Metrics: Loss = 0.2568, Accuracy = 0.9087, AUC = 0.8098\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6286 - binary_accuracy: 0.8816 - loss: 0.3469 - val_auc: 0.7731 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9051 - loss: 0.2696 - val_auc: 0.7800 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9059 - loss: 0.2659 - val_auc: 0.7851 - val_binary_accuracy: 0.9072 - val_loss: 0.2658\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9076 - loss: 0.2641 - val_auc: 0.7897 - val_binary_accuracy: 0.9093 - val_loss: 0.2637\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9081 - loss: 0.2629 - val_auc: 0.7945 - val_binary_accuracy: 0.9100 - val_loss: 0.2616\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.7986 - val_binary_accuracy: 0.9109 - val_loss: 0.2597\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9091 - loss: 0.2604 - val_auc: 0.8017 - val_binary_accuracy: 0.9109 - val_loss: 0.2583\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9094 - loss: 0.2597 - val_auc: 0.8042 - val_binary_accuracy: 0.9113 - val_loss: 0.2573\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9094 - loss: 0.2591 - val_auc: 0.8054 - val_binary_accuracy: 0.9113 - val_loss: 0.2566\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9099 - loss: 0.2587 - val_auc: 0.8057 - val_binary_accuracy: 0.9113 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7978 - binary_accuracy: 0.9127 - loss: 0.2572\n",
      "Fold 3 Metrics: Loss = 0.2561, Accuracy = 0.9113, AUC = 0.8057\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6091 - binary_accuracy: 0.8293 - loss: 0.3819 - val_auc: 0.7752 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9047 - loss: 0.2691 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9050 - loss: 0.2652 - val_auc: 0.7943 - val_binary_accuracy: 0.9047 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9079 - loss: 0.2629 - val_auc: 0.7995 - val_binary_accuracy: 0.9070 - val_loss: 0.2615\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9097 - loss: 0.2606 - val_auc: 0.8024 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9105 - loss: 0.2594 - val_auc: 0.8044 - val_binary_accuracy: 0.9082 - val_loss: 0.2582\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9111 - loss: 0.2584 - val_auc: 0.8060 - val_binary_accuracy: 0.9084 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9114 - loss: 0.2575 - val_auc: 0.8074 - val_binary_accuracy: 0.9084 - val_loss: 0.2569\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9113 - loss: 0.2567 - val_auc: 0.8085 - val_binary_accuracy: 0.9081 - val_loss: 0.2567\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9112 - loss: 0.2562 - val_auc: 0.8098 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9084 - loss: 0.2616\n",
      "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9087, AUC = 0.8098\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6192 - binary_accuracy: 0.9038 - loss: 0.3399 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9040 - loss: 0.2737 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2611\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9048 - loss: 0.2690 - val_auc: 0.7961 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7984 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9087 - loss: 0.2644 - val_auc: 0.8018 - val_binary_accuracy: 0.9101 - val_loss: 0.2547\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9089 - loss: 0.2628 - val_auc: 0.8031 - val_binary_accuracy: 0.9107 - val_loss: 0.2539\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8042 - val_binary_accuracy: 0.9107 - val_loss: 0.2533\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9094 - loss: 0.2609 - val_auc: 0.8044 - val_binary_accuracy: 0.9106 - val_loss: 0.2532\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8049 - val_binary_accuracy: 0.9109 - val_loss: 0.2530\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8049 - val_binary_accuracy: 0.9110 - val_loss: 0.2528\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8138 - binary_accuracy: 0.9091 - loss: 0.2512\n",
      "Fold 5 Metrics: Loss = 0.2528, Accuracy = 0.9110, AUC = 0.8049\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2564\n",
      "Average Accuracy: 0.9096\n",
      "Average AUC: 0.8041\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 2, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6988 - binary_accuracy: 0.9069 - loss: 0.2914 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9072 - loss: 0.2590 - val_auc: 0.7819 - val_binary_accuracy: 0.9048 - val_loss: 0.2660\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9094 - loss: 0.2551 - val_auc: 0.7877 - val_binary_accuracy: 0.9060 - val_loss: 0.2628\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8045 - binary_accuracy: 0.9112 - loss: 0.2520 - val_auc: 0.7907 - val_binary_accuracy: 0.9076 - val_loss: 0.2610\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9123 - loss: 0.2499 - val_auc: 0.7921 - val_binary_accuracy: 0.9078 - val_loss: 0.2601\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9125 - loss: 0.2485 - val_auc: 0.7936 - val_binary_accuracy: 0.9087 - val_loss: 0.2592\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8116 - binary_accuracy: 0.9124 - loss: 0.2475 - val_auc: 0.7944 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8131 - binary_accuracy: 0.9128 - loss: 0.2468 - val_auc: 0.7945 - val_binary_accuracy: 0.9091 - val_loss: 0.2586\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9129 - loss: 0.2462 - val_auc: 0.7945 - val_binary_accuracy: 0.9093 - val_loss: 0.2586\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8148 - binary_accuracy: 0.9125 - loss: 0.2457 - val_auc: 0.7951 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7937 - binary_accuracy: 0.9128 - loss: 0.2518\n",
      "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9091, AUC = 0.7951\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6524 - binary_accuracy: 0.8633 - loss: 0.3412 - val_auc: 0.7960 - val_binary_accuracy: 0.9042 - val_loss: 0.2636\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9040 - loss: 0.2687 - val_auc: 0.8037 - val_binary_accuracy: 0.9056 - val_loss: 0.2591\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9053 - loss: 0.2643 - val_auc: 0.8077 - val_binary_accuracy: 0.9068 - val_loss: 0.2571\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9072 - loss: 0.2621 - val_auc: 0.8092 - val_binary_accuracy: 0.9076 - val_loss: 0.2560\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9077 - loss: 0.2607 - val_auc: 0.8105 - val_binary_accuracy: 0.9079 - val_loss: 0.2554\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8005 - binary_accuracy: 0.9079 - loss: 0.2598 - val_auc: 0.8100 - val_binary_accuracy: 0.9085 - val_loss: 0.2552\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8020 - binary_accuracy: 0.9083 - loss: 0.2592 - val_auc: 0.8104 - val_binary_accuracy: 0.9085 - val_loss: 0.2550\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9081 - loss: 0.2587 - val_auc: 0.8103 - val_binary_accuracy: 0.9085 - val_loss: 0.2549\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9080 - loss: 0.2581 - val_auc: 0.8106 - val_binary_accuracy: 0.9087 - val_loss: 0.2548\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9083 - loss: 0.2576 - val_auc: 0.8106 - val_binary_accuracy: 0.9085 - val_loss: 0.2550\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9121 - loss: 0.2445\n",
      "Fold 2 Metrics: Loss = 0.2550, Accuracy = 0.9085, AUC = 0.8106\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6260 - binary_accuracy: 0.8325 - loss: 0.3854 - val_auc: 0.7763 - val_binary_accuracy: 0.9042 - val_loss: 0.2705\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9055 - loss: 0.2685 - val_auc: 0.7850 - val_binary_accuracy: 0.9053 - val_loss: 0.2663\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9072 - loss: 0.2656 - val_auc: 0.7905 - val_binary_accuracy: 0.9087 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9079 - loss: 0.2643 - val_auc: 0.7946 - val_binary_accuracy: 0.9106 - val_loss: 0.2615\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.7972 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9094 - loss: 0.2625 - val_auc: 0.7997 - val_binary_accuracy: 0.9110 - val_loss: 0.2584\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9096 - loss: 0.2619 - val_auc: 0.8014 - val_binary_accuracy: 0.9113 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9101 - loss: 0.2614 - val_auc: 0.8029 - val_binary_accuracy: 0.9116 - val_loss: 0.2568\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9103 - loss: 0.2609 - val_auc: 0.8046 - val_binary_accuracy: 0.9116 - val_loss: 0.2563\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9103 - loss: 0.2603 - val_auc: 0.8062 - val_binary_accuracy: 0.9115 - val_loss: 0.2559\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7977 - binary_accuracy: 0.9130 - loss: 0.2568\n",
      "Fold 3 Metrics: Loss = 0.2559, Accuracy = 0.9115, AUC = 0.8062\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6158 - binary_accuracy: 0.8419 - loss: 0.3678 - val_auc: 0.7857 - val_binary_accuracy: 0.9048 - val_loss: 0.2655\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9065 - loss: 0.2662 - val_auc: 0.7949 - val_binary_accuracy: 0.9087 - val_loss: 0.2609\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9083 - loss: 0.2627 - val_auc: 0.8004 - val_binary_accuracy: 0.9088 - val_loss: 0.2583\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9098 - loss: 0.2606 - val_auc: 0.8030 - val_binary_accuracy: 0.9095 - val_loss: 0.2569\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9103 - loss: 0.2594 - val_auc: 0.8044 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7929 - binary_accuracy: 0.9106 - loss: 0.2585 - val_auc: 0.8063 - val_binary_accuracy: 0.9093 - val_loss: 0.2554\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9112 - loss: 0.2577 - val_auc: 0.8084 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9118 - loss: 0.2571 - val_auc: 0.8090 - val_binary_accuracy: 0.9097 - val_loss: 0.2542\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9117 - loss: 0.2568 - val_auc: 0.8098 - val_binary_accuracy: 0.9097 - val_loss: 0.2539\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9119 - loss: 0.2564 - val_auc: 0.8104 - val_binary_accuracy: 0.9097 - val_loss: 0.2537\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7914 - binary_accuracy: 0.9099 - loss: 0.2603\n",
      "Fold 4 Metrics: Loss = 0.2537, Accuracy = 0.9097, AUC = 0.8104\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6509 - binary_accuracy: 0.8786 - loss: 0.3291 - val_auc: 0.7903 - val_binary_accuracy: 0.9045 - val_loss: 0.2618\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.7960 - val_binary_accuracy: 0.9082 - val_loss: 0.2584\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9070 - loss: 0.2680 - val_auc: 0.7986 - val_binary_accuracy: 0.9084 - val_loss: 0.2561\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9087 - loss: 0.2659 - val_auc: 0.8028 - val_binary_accuracy: 0.9094 - val_loss: 0.2543\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9091 - loss: 0.2642 - val_auc: 0.8048 - val_binary_accuracy: 0.9101 - val_loss: 0.2530\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9091 - loss: 0.2629 - val_auc: 0.8060 - val_binary_accuracy: 0.9109 - val_loss: 0.2522\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8063 - val_binary_accuracy: 0.9109 - val_loss: 0.2517\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9098 - loss: 0.2611 - val_auc: 0.8072 - val_binary_accuracy: 0.9110 - val_loss: 0.2515\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9103 - loss: 0.2605 - val_auc: 0.8070 - val_binary_accuracy: 0.9112 - val_loss: 0.2513\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9100 - loss: 0.2600 - val_auc: 0.8078 - val_binary_accuracy: 0.9110 - val_loss: 0.2511\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9094 - loss: 0.2501\n",
      "Fold 5 Metrics: Loss = 0.2511, Accuracy = 0.9110, AUC = 0.8078\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2549\n",
      "Average Accuracy: 0.9100\n",
      "Average AUC: 0.8060\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 2, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7176 - binary_accuracy: 0.9069 - loss: 0.2854 - val_auc: 0.7773 - val_binary_accuracy: 0.9048 - val_loss: 0.2695\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9097 - loss: 0.2587 - val_auc: 0.7868 - val_binary_accuracy: 0.9066 - val_loss: 0.2653\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9119 - loss: 0.2544 - val_auc: 0.7917 - val_binary_accuracy: 0.9078 - val_loss: 0.2632\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9115 - loss: 0.2520 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2631\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9121 - loss: 0.2503 - val_auc: 0.7946 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8084 - binary_accuracy: 0.9123 - loss: 0.2491 - val_auc: 0.7955 - val_binary_accuracy: 0.9078 - val_loss: 0.2616\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8101 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7961 - val_binary_accuracy: 0.9082 - val_loss: 0.2606\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9127 - loss: 0.2474 - val_auc: 0.7959 - val_binary_accuracy: 0.9082 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8131 - binary_accuracy: 0.9123 - loss: 0.2468 - val_auc: 0.7962 - val_binary_accuracy: 0.9082 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8138 - binary_accuracy: 0.9127 - loss: 0.2464 - val_auc: 0.7964 - val_binary_accuracy: 0.9082 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7964 - binary_accuracy: 0.9118 - loss: 0.2504\n",
      "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9082, AUC = 0.7964\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6800 - binary_accuracy: 0.8850 - loss: 0.3162 - val_auc: 0.7986 - val_binary_accuracy: 0.9047 - val_loss: 0.2627\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9045 - loss: 0.2695 - val_auc: 0.8064 - val_binary_accuracy: 0.9060 - val_loss: 0.2596\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9060 - loss: 0.2654 - val_auc: 0.8089 - val_binary_accuracy: 0.9082 - val_loss: 0.2580\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9076 - loss: 0.2627 - val_auc: 0.8092 - val_binary_accuracy: 0.9096 - val_loss: 0.2566\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9085 - loss: 0.2609 - val_auc: 0.8099 - val_binary_accuracy: 0.9103 - val_loss: 0.2556\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9087 - loss: 0.2600 - val_auc: 0.8100 - val_binary_accuracy: 0.9099 - val_loss: 0.2546\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9081 - loss: 0.2592 - val_auc: 0.8112 - val_binary_accuracy: 0.9103 - val_loss: 0.2539\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9078 - loss: 0.2586 - val_auc: 0.8109 - val_binary_accuracy: 0.9102 - val_loss: 0.2535\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9079 - loss: 0.2581 - val_auc: 0.8131 - val_binary_accuracy: 0.9103 - val_loss: 0.2529\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8050 - binary_accuracy: 0.9078 - loss: 0.2577 - val_auc: 0.8121 - val_binary_accuracy: 0.9100 - val_loss: 0.2533\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8181 - binary_accuracy: 0.9130 - loss: 0.2431\n",
      "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9100, AUC = 0.8121\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6425 - binary_accuracy: 0.8758 - loss: 0.3350 - val_auc: 0.7791 - val_binary_accuracy: 0.9051 - val_loss: 0.2682\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7620 - binary_accuracy: 0.9071 - loss: 0.2725 - val_auc: 0.7861 - val_binary_accuracy: 0.9082 - val_loss: 0.2651\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7685 - binary_accuracy: 0.9073 - loss: 0.2692 - val_auc: 0.7920 - val_binary_accuracy: 0.9102 - val_loss: 0.2624\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9085 - loss: 0.2666 - val_auc: 0.7964 - val_binary_accuracy: 0.9104 - val_loss: 0.2602\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9090 - loss: 0.2646 - val_auc: 0.7996 - val_binary_accuracy: 0.9112 - val_loss: 0.2583\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9096 - loss: 0.2639 - val_auc: 0.8011 - val_binary_accuracy: 0.9115 - val_loss: 0.2571\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9097 - loss: 0.2631 - val_auc: 0.8029 - val_binary_accuracy: 0.9116 - val_loss: 0.2562\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9100 - loss: 0.2625 - val_auc: 0.8047 - val_binary_accuracy: 0.9115 - val_loss: 0.2556\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9110 - loss: 0.2618 - val_auc: 0.8052 - val_binary_accuracy: 0.9116 - val_loss: 0.2553\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9108 - loss: 0.2612 - val_auc: 0.8055 - val_binary_accuracy: 0.9116 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7976 - binary_accuracy: 0.9134 - loss: 0.2556\n",
      "Fold 3 Metrics: Loss = 0.2551, Accuracy = 0.9116, AUC = 0.8055\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6487 - binary_accuracy: 0.8869 - loss: 0.3241 - val_auc: 0.7897 - val_binary_accuracy: 0.9063 - val_loss: 0.2639\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9071 - loss: 0.2666 - val_auc: 0.7988 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9088 - loss: 0.2630 - val_auc: 0.8036 - val_binary_accuracy: 0.9087 - val_loss: 0.2572\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9097 - loss: 0.2610 - val_auc: 0.8060 - val_binary_accuracy: 0.9081 - val_loss: 0.2559\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9102 - loss: 0.2597 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2552\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9106 - loss: 0.2588 - val_auc: 0.8088 - val_binary_accuracy: 0.9091 - val_loss: 0.2546\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9107 - loss: 0.2581 - val_auc: 0.8095 - val_binary_accuracy: 0.9093 - val_loss: 0.2543\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9109 - loss: 0.2575 - val_auc: 0.8100 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9110 - loss: 0.2570 - val_auc: 0.8105 - val_binary_accuracy: 0.9094 - val_loss: 0.2539\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9113 - loss: 0.2566 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2538\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9083 - loss: 0.2609\n",
      "Fold 4 Metrics: Loss = 0.2538, Accuracy = 0.9091, AUC = 0.8113\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6596 - binary_accuracy: 0.8855 - loss: 0.3214 - val_auc: 0.7902 - val_binary_accuracy: 0.9041 - val_loss: 0.2671\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9043 - loss: 0.2730 - val_auc: 0.7974 - val_binary_accuracy: 0.9053 - val_loss: 0.2647\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9062 - loss: 0.2696 - val_auc: 0.8024 - val_binary_accuracy: 0.9090 - val_loss: 0.2619\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9069 - loss: 0.2669 - val_auc: 0.8047 - val_binary_accuracy: 0.9094 - val_loss: 0.2594\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8062 - val_binary_accuracy: 0.9107 - val_loss: 0.2573\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9083 - loss: 0.2640 - val_auc: 0.8075 - val_binary_accuracy: 0.9116 - val_loss: 0.2554\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2630 - val_auc: 0.8076 - val_binary_accuracy: 0.9115 - val_loss: 0.2539\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8082 - val_binary_accuracy: 0.9113 - val_loss: 0.2529\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8086 - val_binary_accuracy: 0.9115 - val_loss: 0.2519\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9093 - loss: 0.2607 - val_auc: 0.8095 - val_binary_accuracy: 0.9118 - val_loss: 0.2515\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9096 - loss: 0.2499\n",
      "Fold 5 Metrics: Loss = 0.2515, Accuracy = 0.9118, AUC = 0.8095\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2545\n",
      "Average Accuracy: 0.9101\n",
      "Average AUC: 0.8070\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 3, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5016 - binary_accuracy: 0.6917 - loss: 0.5461 - val_auc: 0.7261 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6942 - binary_accuracy: 0.9069 - loss: 0.3066 - val_auc: 0.7271 - val_binary_accuracy: 0.9044 - val_loss: 0.3083\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9069 - loss: 0.3004 - val_auc: 0.7529 - val_binary_accuracy: 0.9044 - val_loss: 0.2989\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9069 - loss: 0.2879 - val_auc: 0.7558 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9069 - loss: 0.2709 - val_auc: 0.7661 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7747 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9069 - loss: 0.2585 - val_auc: 0.7771 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9069 - loss: 0.2570 - val_auc: 0.7775 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9069 - loss: 0.2563 - val_auc: 0.7803 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9069 - loss: 0.2557 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7775 - binary_accuracy: 0.9084 - loss: 0.2589\n",
      "Fold 1 Metrics: Loss = 0.2662, Accuracy = 0.9044, AUC = 0.7814\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5037 - binary_accuracy: 0.5797 - loss: 0.6377 - val_auc: 0.6403 - val_binary_accuracy: 0.9042 - val_loss: 0.3163\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6298 - binary_accuracy: 0.9029 - loss: 0.3170 - val_auc: 0.7354 - val_binary_accuracy: 0.9042 - val_loss: 0.3102\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7345 - binary_accuracy: 0.9029 - loss: 0.3117 - val_auc: 0.7564 - val_binary_accuracy: 0.9042 - val_loss: 0.3024\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7552 - binary_accuracy: 0.9029 - loss: 0.3026 - val_auc: 0.7788 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9029 - loss: 0.2889 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2743\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9029 - loss: 0.2769 - val_auc: 0.7942 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2729 - val_auc: 0.7966 - val_binary_accuracy: 0.9042 - val_loss: 0.2640\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9029 - loss: 0.2695 - val_auc: 0.7981 - val_binary_accuracy: 0.9042 - val_loss: 0.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9029 - loss: 0.2679 - val_auc: 0.8014 - val_binary_accuracy: 0.9042 - val_loss: 0.2612\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9029 - loss: 0.2666 - val_auc: 0.8023 - val_binary_accuracy: 0.9042 - val_loss: 0.2609\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8054 - binary_accuracy: 0.9092 - loss: 0.2511\n",
      "Fold 2 Metrics: Loss = 0.2609, Accuracy = 0.9042, AUC = 0.8023\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5094 - binary_accuracy: 0.9051 - loss: 0.4287 - val_auc: 0.7078 - val_binary_accuracy: 0.9042 - val_loss: 0.3112\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7050 - binary_accuracy: 0.9051 - loss: 0.3059 - val_auc: 0.7609 - val_binary_accuracy: 0.9042 - val_loss: 0.2882\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7575 - binary_accuracy: 0.9051 - loss: 0.2824 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2735\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9051 - loss: 0.2706 - val_auc: 0.7745 - val_binary_accuracy: 0.9042 - val_loss: 0.2705\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9051 - loss: 0.2681 - val_auc: 0.7803 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9051 - loss: 0.2664 - val_auc: 0.7845 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7839 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9051 - loss: 0.2650 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2670\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9051 - loss: 0.2643 - val_auc: 0.7866 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9051 - loss: 0.2635 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7821 - binary_accuracy: 0.9046 - loss: 0.2655\n",
      "Fold 3 Metrics: Loss = 0.2657, Accuracy = 0.9042, AUC = 0.7876\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5206 - binary_accuracy: 0.9047 - loss: 0.3544 - val_auc: 0.7491 - val_binary_accuracy: 0.9044 - val_loss: 0.3113\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7073 - binary_accuracy: 0.9047 - loss: 0.3089 - val_auc: 0.7533 - val_binary_accuracy: 0.9044 - val_loss: 0.3009\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7386 - binary_accuracy: 0.9047 - loss: 0.2960 - val_auc: 0.7657 - val_binary_accuracy: 0.9044 - val_loss: 0.2825\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9047 - loss: 0.2777 - val_auc: 0.7776 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9047 - loss: 0.2692 - val_auc: 0.7773 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9047 - loss: 0.2675 - val_auc: 0.7821 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9047 - loss: 0.2670 - val_auc: 0.7812 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9047 - loss: 0.2666 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9047 - loss: 0.2659 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7650 - binary_accuracy: 0.9049 - loss: 0.2728\n",
      "Fold 4 Metrics: Loss = 0.2692, Accuracy = 0.9044, AUC = 0.7828\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5026 - binary_accuracy: 0.6269 - loss: 0.5922 - val_auc: 0.7004 - val_binary_accuracy: 0.9044 - val_loss: 0.3140\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6943 - binary_accuracy: 0.9040 - loss: 0.3128 - val_auc: 0.7520 - val_binary_accuracy: 0.9044 - val_loss: 0.3028\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7483 - binary_accuracy: 0.9040 - loss: 0.3011 - val_auc: 0.7717 - val_binary_accuracy: 0.9044 - val_loss: 0.2867\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7598 - binary_accuracy: 0.9040 - loss: 0.2865 - val_auc: 0.7743 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2758 - val_auc: 0.7890 - val_binary_accuracy: 0.9044 - val_loss: 0.2651\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7925 - val_binary_accuracy: 0.9044 - val_loss: 0.2629\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9040 - loss: 0.2702 - val_auc: 0.7928 - val_binary_accuracy: 0.9044 - val_loss: 0.2619\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9040 - loss: 0.2694 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2612\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9040 - loss: 0.2688 - val_auc: 0.7941 - val_binary_accuracy: 0.9044 - val_loss: 0.2605\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9040 - loss: 0.2681 - val_auc: 0.7955 - val_binary_accuracy: 0.9044 - val_loss: 0.2600\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8072 - binary_accuracy: 0.9013 - loss: 0.2585\n",
      "Fold 5 Metrics: Loss = 0.2600, Accuracy = 0.9044, AUC = 0.7955\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2644\n",
      "Average Accuracy: 0.9043\n",
      "Average AUC: 0.7899\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 3, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5001 - binary_accuracy: 0.6835 - loss: 0.5494 - val_auc: 0.6707 - val_binary_accuracy: 0.9044 - val_loss: 0.3132\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6898 - binary_accuracy: 0.9069 - loss: 0.3056 - val_auc: 0.7449 - val_binary_accuracy: 0.9044 - val_loss: 0.3041\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7515 - binary_accuracy: 0.9069 - loss: 0.2922 - val_auc: 0.7589 - val_binary_accuracy: 0.9044 - val_loss: 0.2818\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9069 - loss: 0.2695 - val_auc: 0.7672 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9069 - loss: 0.2617 - val_auc: 0.7753 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9069 - loss: 0.2589 - val_auc: 0.7799 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9069 - loss: 0.2572 - val_auc: 0.7831 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9069 - loss: 0.2562 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2648\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9069 - loss: 0.2551 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8045 - binary_accuracy: 0.9069 - loss: 0.2539 - val_auc: 0.7895 - val_binary_accuracy: 0.9044 - val_loss: 0.2628\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9084 - loss: 0.2555\n",
      "Fold 1 Metrics: Loss = 0.2628, Accuracy = 0.9044, AUC = 0.7895\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5494 - binary_accuracy: 0.8115 - loss: 0.4208 - val_auc: 0.7633 - val_binary_accuracy: 0.9042 - val_loss: 0.2972\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7539 - binary_accuracy: 0.9029 - loss: 0.2931 - val_auc: 0.7887 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9029 - loss: 0.2732 - val_auc: 0.7956 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8009 - val_binary_accuracy: 0.9042 - val_loss: 0.2638\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9029 - loss: 0.2683 - val_auc: 0.8026 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9029 - loss: 0.2668 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9036 - loss: 0.2652 - val_auc: 0.8050 - val_binary_accuracy: 0.9042 - val_loss: 0.2616\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9052 - loss: 0.2638 - val_auc: 0.8064 - val_binary_accuracy: 0.9051 - val_loss: 0.2616\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9063 - loss: 0.2625 - val_auc: 0.8069 - val_binary_accuracy: 0.9059 - val_loss: 0.2612\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9075 - loss: 0.2614 - val_auc: 0.8078 - val_binary_accuracy: 0.9068 - val_loss: 0.2607\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8112 - binary_accuracy: 0.9104 - loss: 0.2513\n",
      "Fold 2 Metrics: Loss = 0.2607, Accuracy = 0.9068, AUC = 0.8078\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5586 - binary_accuracy: 0.9051 - loss: 0.3586 - val_auc: 0.7628 - val_binary_accuracy: 0.9042 - val_loss: 0.2854\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7576 - binary_accuracy: 0.9051 - loss: 0.2787 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9051 - loss: 0.2676 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9051 - loss: 0.2660 - val_auc: 0.7837 - val_binary_accuracy: 0.9042 - val_loss: 0.2676\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9051 - loss: 0.2648 - val_auc: 0.7870 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9051 - loss: 0.2636 - val_auc: 0.7890 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9053 - loss: 0.2624 - val_auc: 0.7912 - val_binary_accuracy: 0.9042 - val_loss: 0.2644\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9070 - loss: 0.2615 - val_auc: 0.7935 - val_binary_accuracy: 0.9090 - val_loss: 0.2633\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9086 - loss: 0.2608 - val_auc: 0.7945 - val_binary_accuracy: 0.9093 - val_loss: 0.2621\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9095 - loss: 0.2600 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2609\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2619\n",
      "Fold 3 Metrics: Loss = 0.2609, Accuracy = 0.9094, AUC = 0.7978\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5424 - binary_accuracy: 0.9047 - loss: 0.3808 - val_auc: 0.7546 - val_binary_accuracy: 0.9044 - val_loss: 0.2978\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7434 - binary_accuracy: 0.9047 - loss: 0.2896 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9047 - loss: 0.2698 - val_auc: 0.7893 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9047 - loss: 0.2653 - val_auc: 0.7930 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9047 - loss: 0.2639 - val_auc: 0.7951 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9048 - loss: 0.2629 - val_auc: 0.7961 - val_binary_accuracy: 0.9044 - val_loss: 0.2652\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9059 - loss: 0.2616 - val_auc: 0.7985 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9086 - loss: 0.2603 - val_auc: 0.8002 - val_binary_accuracy: 0.9060 - val_loss: 0.2621\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9100 - loss: 0.2592 - val_auc: 0.8014 - val_binary_accuracy: 0.9081 - val_loss: 0.2608\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9101 - loss: 0.2583 - val_auc: 0.8034 - val_binary_accuracy: 0.9088 - val_loss: 0.2598\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7852 - binary_accuracy: 0.9078 - loss: 0.2646\n",
      "Fold 4 Metrics: Loss = 0.2598, Accuracy = 0.9088, AUC = 0.8034\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5186 - binary_accuracy: 0.6762 - loss: 0.5585 - val_auc: 0.7575 - val_binary_accuracy: 0.9044 - val_loss: 0.3071\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7405 - binary_accuracy: 0.9040 - loss: 0.3036 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2812\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9040 - loss: 0.2809 - val_auc: 0.7861 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9040 - loss: 0.2711 - val_auc: 0.7940 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9040 - loss: 0.2684 - val_auc: 0.7970 - val_binary_accuracy: 0.9044 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9040 - loss: 0.2667 - val_auc: 0.7980 - val_binary_accuracy: 0.9044 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9043 - loss: 0.2650 - val_auc: 0.7993 - val_binary_accuracy: 0.9084 - val_loss: 0.2575\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9073 - loss: 0.2638 - val_auc: 0.8002 - val_binary_accuracy: 0.9100 - val_loss: 0.2566\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8002 - val_binary_accuracy: 0.9101 - val_loss: 0.2559\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9088 - loss: 0.2622 - val_auc: 0.8009 - val_binary_accuracy: 0.9094 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8121 - binary_accuracy: 0.9078 - loss: 0.2525\n",
      "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9094, AUC = 0.8009\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2598\n",
      "Average Accuracy: 0.9078\n",
      "Average AUC: 0.7999\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 3, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6031 - binary_accuracy: 0.9069 - loss: 0.3197 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2756\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9069 - loss: 0.2629 - val_auc: 0.7730 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9070 - loss: 0.2584 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9072 - loss: 0.2563 - val_auc: 0.7797 - val_binary_accuracy: 0.9062 - val_loss: 0.2662\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9104 - loss: 0.2543 - val_auc: 0.7826 - val_binary_accuracy: 0.9075 - val_loss: 0.2648\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9123 - loss: 0.2523 - val_auc: 0.7852 - val_binary_accuracy: 0.9078 - val_loss: 0.2636\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7873 - val_binary_accuracy: 0.9087 - val_loss: 0.2624\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9124 - loss: 0.2491 - val_auc: 0.7896 - val_binary_accuracy: 0.9085 - val_loss: 0.2614\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8104 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7899 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8115 - binary_accuracy: 0.9130 - loss: 0.2474 - val_auc: 0.7907 - val_binary_accuracy: 0.9088 - val_loss: 0.2606\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9132 - loss: 0.2533\n",
      "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9088, AUC = 0.7907\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5975 - binary_accuracy: 0.8692 - loss: 0.3589 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9029 - loss: 0.2736 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9030 - loss: 0.2682 - val_auc: 0.8016 - val_binary_accuracy: 0.9042 - val_loss: 0.2607\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9038 - loss: 0.2656 - val_auc: 0.8044 - val_binary_accuracy: 0.9050 - val_loss: 0.2588\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9063 - loss: 0.2629 - val_auc: 0.8071 - val_binary_accuracy: 0.9066 - val_loss: 0.2583\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9070 - loss: 0.2611 - val_auc: 0.8083 - val_binary_accuracy: 0.9073 - val_loss: 0.2578\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9075 - loss: 0.2599 - val_auc: 0.8082 - val_binary_accuracy: 0.9078 - val_loss: 0.2577\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9077 - loss: 0.2591 - val_auc: 0.8086 - val_binary_accuracy: 0.9078 - val_loss: 0.2578\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9079 - loss: 0.2585 - val_auc: 0.8084 - val_binary_accuracy: 0.9085 - val_loss: 0.2580\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9078 - loss: 0.2579 - val_auc: 0.8094 - val_binary_accuracy: 0.9087 - val_loss: 0.2580\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8141 - binary_accuracy: 0.9121 - loss: 0.2476\n",
      "Fold 2 Metrics: Loss = 0.2580, Accuracy = 0.9087, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5699 - binary_accuracy: 0.8448 - loss: 0.3757 - val_auc: 0.7576 - val_binary_accuracy: 0.9042 - val_loss: 0.2835\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9051 - loss: 0.2760 - val_auc: 0.7803 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9052 - loss: 0.2670 - val_auc: 0.7852 - val_binary_accuracy: 0.9048 - val_loss: 0.2661\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9068 - loss: 0.2648 - val_auc: 0.7893 - val_binary_accuracy: 0.9088 - val_loss: 0.2642\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.7928 - val_binary_accuracy: 0.9099 - val_loss: 0.2626\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9090 - loss: 0.2623 - val_auc: 0.7958 - val_binary_accuracy: 0.9104 - val_loss: 0.2610\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9095 - loss: 0.2614 - val_auc: 0.7977 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9092 - loss: 0.2607 - val_auc: 0.7994 - val_binary_accuracy: 0.9109 - val_loss: 0.2586\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9094 - loss: 0.2600 - val_auc: 0.8016 - val_binary_accuracy: 0.9110 - val_loss: 0.2575\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9095 - loss: 0.2595 - val_auc: 0.8036 - val_binary_accuracy: 0.9112 - val_loss: 0.2567\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7953 - binary_accuracy: 0.9127 - loss: 0.2575\n",
      "Fold 3 Metrics: Loss = 0.2567, Accuracy = 0.9112, AUC = 0.8036\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5847 - binary_accuracy: 0.8714 - loss: 0.3584 - val_auc: 0.7733 - val_binary_accuracy: 0.9044 - val_loss: 0.2755\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9047 - loss: 0.2713 - val_auc: 0.7870 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9049 - loss: 0.2652 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9068 - loss: 0.2631 - val_auc: 0.7971 - val_binary_accuracy: 0.9056 - val_loss: 0.2607\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9090 - loss: 0.2613 - val_auc: 0.8003 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9090 - loss: 0.2599 - val_auc: 0.8023 - val_binary_accuracy: 0.9082 - val_loss: 0.2579\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9096 - loss: 0.2589 - val_auc: 0.8048 - val_binary_accuracy: 0.9087 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9100 - loss: 0.2583 - val_auc: 0.8058 - val_binary_accuracy: 0.9094 - val_loss: 0.2569\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7958 - binary_accuracy: 0.9097 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9100 - loss: 0.2572 - val_auc: 0.8083 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7889 - binary_accuracy: 0.9088 - loss: 0.2624\n",
      "Fold 4 Metrics: Loss = 0.2562, Accuracy = 0.9093, AUC = 0.8083\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6027 - binary_accuracy: 0.8854 - loss: 0.3512 - val_auc: 0.7779 - val_binary_accuracy: 0.9044 - val_loss: 0.2725\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9040 - loss: 0.2747 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9040 - loss: 0.2703 - val_auc: 0.7929 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9040 - loss: 0.2686 - val_auc: 0.7954 - val_binary_accuracy: 0.9044 - val_loss: 0.2588\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9047 - loss: 0.2667 - val_auc: 0.7974 - val_binary_accuracy: 0.9085 - val_loss: 0.2572\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9078 - loss: 0.2652 - val_auc: 0.8014 - val_binary_accuracy: 0.9093 - val_loss: 0.2560\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8041 - val_binary_accuracy: 0.9093 - val_loss: 0.2548\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9094 - loss: 0.2625 - val_auc: 0.8067 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9094 - loss: 0.2615 - val_auc: 0.8085 - val_binary_accuracy: 0.9100 - val_loss: 0.2525\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9096 - loss: 0.2606 - val_auc: 0.8098 - val_binary_accuracy: 0.9103 - val_loss: 0.2516\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8184 - binary_accuracy: 0.9086 - loss: 0.2501\n",
      "Fold 5 Metrics: Loss = 0.2516, Accuracy = 0.9103, AUC = 0.8098\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2566\n",
      "Average Accuracy: 0.9096\n",
      "Average AUC: 0.8044\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 3, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6540 - binary_accuracy: 0.9069 - loss: 0.3076 - val_auc: 0.7724 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9071 - loss: 0.2598 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9089 - loss: 0.2558 - val_auc: 0.7864 - val_binary_accuracy: 0.9051 - val_loss: 0.2639\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9105 - loss: 0.2528 - val_auc: 0.7896 - val_binary_accuracy: 0.9068 - val_loss: 0.2623\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9116 - loss: 0.2507 - val_auc: 0.7923 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9119 - loss: 0.2493 - val_auc: 0.7935 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9126 - loss: 0.2482 - val_auc: 0.7942 - val_binary_accuracy: 0.9084 - val_loss: 0.2594\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9125 - loss: 0.2474 - val_auc: 0.7944 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8133 - binary_accuracy: 0.9127 - loss: 0.2466 - val_auc: 0.7948 - val_binary_accuracy: 0.9088 - val_loss: 0.2588\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8141 - binary_accuracy: 0.9129 - loss: 0.2461 - val_auc: 0.7951 - val_binary_accuracy: 0.9085 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7937 - binary_accuracy: 0.9122 - loss: 0.2515\n",
      "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9085, AUC = 0.7951\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6455 - binary_accuracy: 0.9029 - loss: 0.3099 - val_auc: 0.7958 - val_binary_accuracy: 0.9042 - val_loss: 0.2653\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9040 - loss: 0.2706 - val_auc: 0.8024 - val_binary_accuracy: 0.9053 - val_loss: 0.2601\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9055 - loss: 0.2660 - val_auc: 0.8055 - val_binary_accuracy: 0.9065 - val_loss: 0.2584\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9069 - loss: 0.2634 - val_auc: 0.8074 - val_binary_accuracy: 0.9072 - val_loss: 0.2561\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8087 - val_binary_accuracy: 0.9087 - val_loss: 0.2550\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9082 - loss: 0.2602 - val_auc: 0.8090 - val_binary_accuracy: 0.9088 - val_loss: 0.2547\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9082 - loss: 0.2594 - val_auc: 0.8096 - val_binary_accuracy: 0.9088 - val_loss: 0.2548\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9085 - loss: 0.2587 - val_auc: 0.8089 - val_binary_accuracy: 0.9087 - val_loss: 0.2550\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9085 - loss: 0.2582 - val_auc: 0.8093 - val_binary_accuracy: 0.9087 - val_loss: 0.2549\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9087 - loss: 0.2578 - val_auc: 0.8095 - val_binary_accuracy: 0.9088 - val_loss: 0.2548\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8161 - binary_accuracy: 0.9127 - loss: 0.2442\n",
      "Fold 2 Metrics: Loss = 0.2548, Accuracy = 0.9088, AUC = 0.8095\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6080 - binary_accuracy: 0.8568 - loss: 0.3631 - val_auc: 0.7791 - val_binary_accuracy: 0.9042 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9053 - loss: 0.2690 - val_auc: 0.7862 - val_binary_accuracy: 0.9050 - val_loss: 0.2660\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9073 - loss: 0.2666 - val_auc: 0.7899 - val_binary_accuracy: 0.9088 - val_loss: 0.2636\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9081 - loss: 0.2650 - val_auc: 0.7936 - val_binary_accuracy: 0.9096 - val_loss: 0.2615\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.7955 - val_binary_accuracy: 0.9103 - val_loss: 0.2599\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9090 - loss: 0.2633 - val_auc: 0.7979 - val_binary_accuracy: 0.9107 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9094 - loss: 0.2626 - val_auc: 0.7990 - val_binary_accuracy: 0.9109 - val_loss: 0.2578\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9095 - loss: 0.2619 - val_auc: 0.8009 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9096 - loss: 0.2613 - val_auc: 0.8020 - val_binary_accuracy: 0.9115 - val_loss: 0.2565\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.8031 - val_binary_accuracy: 0.9115 - val_loss: 0.2560\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9134 - loss: 0.2566\n",
      "Fold 3 Metrics: Loss = 0.2560, Accuracy = 0.9115, AUC = 0.8031\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5836 - binary_accuracy: 0.8179 - loss: 0.4140 - val_auc: 0.7830 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9047 - loss: 0.2675 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9065 - loss: 0.2640 - val_auc: 0.7958 - val_binary_accuracy: 0.9064 - val_loss: 0.2612\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2618 - val_auc: 0.7993 - val_binary_accuracy: 0.9088 - val_loss: 0.2591\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9094 - loss: 0.2601 - val_auc: 0.8026 - val_binary_accuracy: 0.9091 - val_loss: 0.2571\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9103 - loss: 0.2588 - val_auc: 0.8045 - val_binary_accuracy: 0.9095 - val_loss: 0.2560\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9107 - loss: 0.2580 - val_auc: 0.8057 - val_binary_accuracy: 0.9094 - val_loss: 0.2554\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9108 - loss: 0.2573 - val_auc: 0.8067 - val_binary_accuracy: 0.9098 - val_loss: 0.2551\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.8079 - val_binary_accuracy: 0.9097 - val_loss: 0.2547\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9115 - loss: 0.2564 - val_auc: 0.8084 - val_binary_accuracy: 0.9095 - val_loss: 0.2544\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7896 - binary_accuracy: 0.9085 - loss: 0.2608\n",
      "Fold 4 Metrics: Loss = 0.2544, Accuracy = 0.9095, AUC = 0.8084\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6257 - binary_accuracy: 0.9040 - loss: 0.3208 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9043 - loss: 0.2727 - val_auc: 0.7930 - val_binary_accuracy: 0.9079 - val_loss: 0.2598\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9061 - loss: 0.2698 - val_auc: 0.7960 - val_binary_accuracy: 0.9081 - val_loss: 0.2577\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9084 - loss: 0.2675 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2560\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9086 - loss: 0.2656 - val_auc: 0.8022 - val_binary_accuracy: 0.9094 - val_loss: 0.2547\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9092 - loss: 0.2641 - val_auc: 0.8050 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9092 - loss: 0.2628 - val_auc: 0.8059 - val_binary_accuracy: 0.9106 - val_loss: 0.2528\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9094 - loss: 0.2619 - val_auc: 0.8069 - val_binary_accuracy: 0.9107 - val_loss: 0.2521\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9095 - loss: 0.2611 - val_auc: 0.8078 - val_binary_accuracy: 0.9113 - val_loss: 0.2516\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8084 - val_binary_accuracy: 0.9115 - val_loss: 0.2513\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9096 - loss: 0.2489\n",
      "Fold 5 Metrics: Loss = 0.2513, Accuracy = 0.9115, AUC = 0.8084\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2551\n",
      "Average Accuracy: 0.9100\n",
      "Average AUC: 0.8049\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 3, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6561 - binary_accuracy: 0.8901 - loss: 0.3053 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9076 - loss: 0.2608 - val_auc: 0.7809 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9097 - loss: 0.2570 - val_auc: 0.7871 - val_binary_accuracy: 0.9054 - val_loss: 0.2666\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9108 - loss: 0.2539 - val_auc: 0.7910 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8040 - binary_accuracy: 0.9117 - loss: 0.2515 - val_auc: 0.7933 - val_binary_accuracy: 0.9075 - val_loss: 0.2631\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9119 - loss: 0.2498 - val_auc: 0.7942 - val_binary_accuracy: 0.9081 - val_loss: 0.2620\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8095 - binary_accuracy: 0.9125 - loss: 0.2486 - val_auc: 0.7946 - val_binary_accuracy: 0.9087 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8115 - binary_accuracy: 0.9128 - loss: 0.2476 - val_auc: 0.7958 - val_binary_accuracy: 0.9087 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8130 - binary_accuracy: 0.9132 - loss: 0.2468 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2593\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8140 - binary_accuracy: 0.9131 - loss: 0.2462 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2589\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9118 - loss: 0.2508\n",
      "Fold 1 Metrics: Loss = 0.2589, Accuracy = 0.9084, AUC = 0.7962\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6743 - binary_accuracy: 0.9031 - loss: 0.3031 - val_auc: 0.7991 - val_binary_accuracy: 0.9042 - val_loss: 0.2653\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9043 - loss: 0.2697 - val_auc: 0.8052 - val_binary_accuracy: 0.9060 - val_loss: 0.2627\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9065 - loss: 0.2656 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2609\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9079 - loss: 0.2630 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2599\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8083 - val_binary_accuracy: 0.9090 - val_loss: 0.2589\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7987 - binary_accuracy: 0.9082 - loss: 0.2606 - val_auc: 0.8086 - val_binary_accuracy: 0.9093 - val_loss: 0.2580\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8008 - binary_accuracy: 0.9084 - loss: 0.2599 - val_auc: 0.8092 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9083 - loss: 0.2593 - val_auc: 0.8100 - val_binary_accuracy: 0.9094 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9083 - loss: 0.2587 - val_auc: 0.8103 - val_binary_accuracy: 0.9093 - val_loss: 0.2555\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9083 - loss: 0.2583 - val_auc: 0.8105 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9124 - loss: 0.2453\n",
      "Fold 2 Metrics: Loss = 0.2550, Accuracy = 0.9093, AUC = 0.8105\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6393 - binary_accuracy: 0.8865 - loss: 0.3228 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7624 - binary_accuracy: 0.9060 - loss: 0.2722 - val_auc: 0.7872 - val_binary_accuracy: 0.9073 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9076 - loss: 0.2690 - val_auc: 0.7918 - val_binary_accuracy: 0.9102 - val_loss: 0.2628\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9085 - loss: 0.2667 - val_auc: 0.7959 - val_binary_accuracy: 0.9110 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9090 - loss: 0.2650 - val_auc: 0.7991 - val_binary_accuracy: 0.9113 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9093 - loss: 0.2638 - val_auc: 0.8011 - val_binary_accuracy: 0.9113 - val_loss: 0.2582\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9094 - loss: 0.2629 - val_auc: 0.8033 - val_binary_accuracy: 0.9113 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9099 - loss: 0.2621 - val_auc: 0.8050 - val_binary_accuracy: 0.9115 - val_loss: 0.2563\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9100 - loss: 0.2615 - val_auc: 0.8059 - val_binary_accuracy: 0.9118 - val_loss: 0.2557\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9098 - loss: 0.2609 - val_auc: 0.8069 - val_binary_accuracy: 0.9115 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7990 - binary_accuracy: 0.9130 - loss: 0.2559\n",
      "Fold 3 Metrics: Loss = 0.2552, Accuracy = 0.9115, AUC = 0.8069\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6251 - binary_accuracy: 0.8866 - loss: 0.3383 - val_auc: 0.7882 - val_binary_accuracy: 0.9051 - val_loss: 0.2648\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9059 - loss: 0.2676 - val_auc: 0.7959 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9081 - loss: 0.2646 - val_auc: 0.8012 - val_binary_accuracy: 0.9085 - val_loss: 0.2582\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9090 - loss: 0.2622 - val_auc: 0.8046 - val_binary_accuracy: 0.9085 - val_loss: 0.2566\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9100 - loss: 0.2605 - val_auc: 0.8065 - val_binary_accuracy: 0.9087 - val_loss: 0.2557\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9100 - loss: 0.2595 - val_auc: 0.8072 - val_binary_accuracy: 0.9085 - val_loss: 0.2551\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8085 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9107 - loss: 0.2580 - val_auc: 0.8092 - val_binary_accuracy: 0.9093 - val_loss: 0.2544\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9107 - loss: 0.2575 - val_auc: 0.8100 - val_binary_accuracy: 0.9091 - val_loss: 0.2542\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9109 - loss: 0.2571 - val_auc: 0.8101 - val_binary_accuracy: 0.9093 - val_loss: 0.2540\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7920 - binary_accuracy: 0.9086 - loss: 0.2607\n",
      "Fold 4 Metrics: Loss = 0.2540, Accuracy = 0.9093, AUC = 0.8101\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6250 - binary_accuracy: 0.8698 - loss: 0.3534 - val_auc: 0.7891 - val_binary_accuracy: 0.9075 - val_loss: 0.2658\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9045 - loss: 0.2732 - val_auc: 0.7945 - val_binary_accuracy: 0.9082 - val_loss: 0.2639\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9057 - loss: 0.2704 - val_auc: 0.7990 - val_binary_accuracy: 0.9081 - val_loss: 0.2625\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9074 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9085 - val_loss: 0.2616\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9082 - loss: 0.2662 - val_auc: 0.8042 - val_binary_accuracy: 0.9087 - val_loss: 0.2600\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9085 - loss: 0.2648 - val_auc: 0.8050 - val_binary_accuracy: 0.9101 - val_loss: 0.2582\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9087 - loss: 0.2638 - val_auc: 0.8062 - val_binary_accuracy: 0.9103 - val_loss: 0.2564\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9092 - loss: 0.2630 - val_auc: 0.8072 - val_binary_accuracy: 0.9115 - val_loss: 0.2547\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9092 - loss: 0.2622 - val_auc: 0.8072 - val_binary_accuracy: 0.9121 - val_loss: 0.2537\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9096 - loss: 0.2615 - val_auc: 0.8083 - val_binary_accuracy: 0.9116 - val_loss: 0.2527\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9095 - loss: 0.2509\n",
      "Fold 5 Metrics: Loss = 0.2527, Accuracy = 0.9116, AUC = 0.8083\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2552\n",
      "Average Accuracy: 0.9100\n",
      "Average AUC: 0.8064\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 4, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4969 - binary_accuracy: 0.3356 - loss: 1.0198 - val_auc: 0.4997 - val_binary_accuracy: 0.9044 - val_loss: 0.3583\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4961 - binary_accuracy: 0.9069 - loss: 0.3372 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3189\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5076 - binary_accuracy: 0.9069 - loss: 0.3124 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3155\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5098 - binary_accuracy: 0.9069 - loss: 0.3099 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3151\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5093 - binary_accuracy: 0.9069 - loss: 0.3095 - val_auc: 0.4999 - val_binary_accuracy: 0.9044 - val_loss: 0.3150\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5691 - binary_accuracy: 0.9069 - loss: 0.3093 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5973 - binary_accuracy: 0.9069 - loss: 0.3088 - val_auc: 0.7049 - val_binary_accuracy: 0.9044 - val_loss: 0.3133\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7355 - binary_accuracy: 0.9069 - loss: 0.3064 - val_auc: 0.7475 - val_binary_accuracy: 0.9044 - val_loss: 0.3039\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9069 - loss: 0.2901 - val_auc: 0.7627 - val_binary_accuracy: 0.9044 - val_loss: 0.2786\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7697 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7680 - binary_accuracy: 0.9084 - loss: 0.2622\n",
      "Fold 1 Metrics: Loss = 0.2700, Accuracy = 0.9044, AUC = 0.7697\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5046 - binary_accuracy: 0.9029 - loss: 0.3812 - val_auc: 0.6797 - val_binary_accuracy: 0.9042 - val_loss: 0.3142\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6695 - binary_accuracy: 0.9029 - loss: 0.3158 - val_auc: 0.7519 - val_binary_accuracy: 0.9042 - val_loss: 0.3039\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7421 - binary_accuracy: 0.9029 - loss: 0.2995 - val_auc: 0.7911 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2751 - val_auc: 0.7948 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9029 - loss: 0.2696 - val_auc: 0.8021 - val_binary_accuracy: 0.9042 - val_loss: 0.2644\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9029 - loss: 0.2673 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2635\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9029 - loss: 0.2657 - val_auc: 0.8057 - val_binary_accuracy: 0.9042 - val_loss: 0.2629\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9030 - loss: 0.2643 - val_auc: 0.8063 - val_binary_accuracy: 0.9042 - val_loss: 0.2622\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7975 - binary_accuracy: 0.9047 - loss: 0.2632 - val_auc: 0.8064 - val_binary_accuracy: 0.9051 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9061 - loss: 0.2622 - val_auc: 0.8080 - val_binary_accuracy: 0.9056 - val_loss: 0.2609\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8113 - binary_accuracy: 0.9099 - loss: 0.2505\n",
      "Fold 2 Metrics: Loss = 0.2609, Accuracy = 0.9056, AUC = 0.8080\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5037 - binary_accuracy: 0.8728 - loss: 0.4521 - val_auc: 0.6925 - val_binary_accuracy: 0.9042 - val_loss: 0.3140\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6814 - binary_accuracy: 0.9051 - loss: 0.3107 - val_auc: 0.7450 - val_binary_accuracy: 0.9042 - val_loss: 0.3009\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7463 - binary_accuracy: 0.9051 - loss: 0.2936 - val_auc: 0.7699 - val_binary_accuracy: 0.9042 - val_loss: 0.2784\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9051 - loss: 0.2740 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9051 - loss: 0.2682 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7799 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7802 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9051 - loss: 0.2645 - val_auc: 0.7831 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9051 - loss: 0.2639 - val_auc: 0.7844 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7804 - binary_accuracy: 0.9046 - loss: 0.2672\n",
      "Fold 3 Metrics: Loss = 0.2674, Accuracy = 0.9042, AUC = 0.7844\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - auc: 0.4974 - binary_accuracy: 0.6128 - loss: 0.6017 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3166\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4971 - binary_accuracy: 0.9047 - loss: 0.3151 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3153\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5004 - binary_accuracy: 0.9047 - loss: 0.3146 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3152\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5160 - binary_accuracy: 0.9047 - loss: 0.3144 - val_auc: 0.6853 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6210 - binary_accuracy: 0.9047 - loss: 0.3129 - val_auc: 0.7450 - val_binary_accuracy: 0.9044 - val_loss: 0.3091\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7349 - binary_accuracy: 0.9047 - loss: 0.3057 - val_auc: 0.7712 - val_binary_accuracy: 0.9044 - val_loss: 0.2949\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7509 - binary_accuracy: 0.9047 - loss: 0.2897 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2800\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7627 - binary_accuracy: 0.9047 - loss: 0.2754 - val_auc: 0.7768 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9047 - loss: 0.2701 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2726\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9047 - loss: 0.2681 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7635 - binary_accuracy: 0.9049 - loss: 0.2743\n",
      "Fold 4 Metrics: Loss = 0.2712, Accuracy = 0.9044, AUC = 0.7828\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5041 - binary_accuracy: 0.7764 - loss: 0.4915 - val_auc: 0.6729 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5882 - binary_accuracy: 0.9040 - loss: 0.3149 - val_auc: 0.7296 - val_binary_accuracy: 0.9044 - val_loss: 0.3122\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7166 - binary_accuracy: 0.9040 - loss: 0.3122 - val_auc: 0.7463 - val_binary_accuracy: 0.9044 - val_loss: 0.3044\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7387 - binary_accuracy: 0.9040 - loss: 0.3013 - val_auc: 0.7674 - val_binary_accuracy: 0.9044 - val_loss: 0.2817\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7552 - binary_accuracy: 0.9040 - loss: 0.2832 - val_auc: 0.7707 - val_binary_accuracy: 0.9044 - val_loss: 0.2714\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7643 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9040 - loss: 0.2729 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2655\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9040 - loss: 0.2717 - val_auc: 0.7822 - val_binary_accuracy: 0.9044 - val_loss: 0.2646\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9040 - loss: 0.2710 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2640\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9040 - loss: 0.2705 - val_auc: 0.7897 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8000 - binary_accuracy: 0.9013 - loss: 0.2621\n",
      "Fold 5 Metrics: Loss = 0.2635, Accuracy = 0.9044, AUC = 0.7897\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2666\n",
      "Average Accuracy: 0.9046\n",
      "Average AUC: 0.7869\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 4, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4990 - binary_accuracy: 0.7259 - loss: 0.4959 - val_auc: 0.6752 - val_binary_accuracy: 0.9044 - val_loss: 0.3144\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6313 - binary_accuracy: 0.9069 - loss: 0.3070 - val_auc: 0.7469 - val_binary_accuracy: 0.9044 - val_loss: 0.2975\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9069 - loss: 0.2813 - val_auc: 0.7646 - val_binary_accuracy: 0.9044 - val_loss: 0.2733\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9069 - loss: 0.2623 - val_auc: 0.7768 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9069 - loss: 0.2584 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9069 - loss: 0.2567 - val_auc: 0.7826 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7997 - binary_accuracy: 0.9069 - loss: 0.2556 - val_auc: 0.7866 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9069 - loss: 0.2546 - val_auc: 0.7901 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9070 - loss: 0.2536 - val_auc: 0.7907 - val_binary_accuracy: 0.9044 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9078 - loss: 0.2525 - val_auc: 0.7926 - val_binary_accuracy: 0.9069 - val_loss: 0.2607\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7934 - binary_accuracy: 0.9111 - loss: 0.2528\n",
      "Fold 1 Metrics: Loss = 0.2607, Accuracy = 0.9069, AUC = 0.7926\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5150 - binary_accuracy: 0.9029 - loss: 0.3443 - val_auc: 0.7261 - val_binary_accuracy: 0.9042 - val_loss: 0.3104\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7228 - binary_accuracy: 0.9029 - loss: 0.3022 - val_auc: 0.7919 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9029 - loss: 0.2716 - val_auc: 0.8001 - val_binary_accuracy: 0.9042 - val_loss: 0.2641\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9029 - loss: 0.2686 - val_auc: 0.8026 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9037 - loss: 0.2671 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9046 - loss: 0.2655 - val_auc: 0.8045 - val_binary_accuracy: 0.9056 - val_loss: 0.2614\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9066 - loss: 0.2639 - val_auc: 0.8050 - val_binary_accuracy: 0.9063 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.8069 - val_binary_accuracy: 0.9069 - val_loss: 0.2594\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9075 - loss: 0.2612 - val_auc: 0.8076 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9078 - loss: 0.2604 - val_auc: 0.8076 - val_binary_accuracy: 0.9082 - val_loss: 0.2588\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8108 - binary_accuracy: 0.9118 - loss: 0.2494\n",
      "Fold 2 Metrics: Loss = 0.2588, Accuracy = 0.9082, AUC = 0.8076\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5068 - binary_accuracy: 0.8865 - loss: 0.3881 - val_auc: 0.7022 - val_binary_accuracy: 0.9042 - val_loss: 0.3133\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6946 - binary_accuracy: 0.9051 - loss: 0.3082 - val_auc: 0.7682 - val_binary_accuracy: 0.9042 - val_loss: 0.2854\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7616 - binary_accuracy: 0.9051 - loss: 0.2770 - val_auc: 0.7730 - val_binary_accuracy: 0.9042 - val_loss: 0.2713\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9051 - loss: 0.2686 - val_auc: 0.7775 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7823 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9051 - loss: 0.2659 - val_auc: 0.7843 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9059 - loss: 0.2647 - val_auc: 0.7862 - val_binary_accuracy: 0.9082 - val_loss: 0.2654\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9079 - loss: 0.2636 - val_auc: 0.7873 - val_binary_accuracy: 0.9097 - val_loss: 0.2646\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9084 - loss: 0.2631 - val_auc: 0.7884 - val_binary_accuracy: 0.9102 - val_loss: 0.2638\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.7900 - val_binary_accuracy: 0.9103 - val_loss: 0.2632\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7847 - binary_accuracy: 0.9115 - loss: 0.2633\n",
      "Fold 3 Metrics: Loss = 0.2632, Accuracy = 0.9103, AUC = 0.7900\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5048 - binary_accuracy: 0.6734 - loss: 0.5628 - val_auc: 0.7008 - val_binary_accuracy: 0.9044 - val_loss: 0.3131\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6866 - binary_accuracy: 0.9047 - loss: 0.3106 - val_auc: 0.7548 - val_binary_accuracy: 0.9044 - val_loss: 0.2990\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7447 - binary_accuracy: 0.9047 - loss: 0.2920 - val_auc: 0.7681 - val_binary_accuracy: 0.9044 - val_loss: 0.2774\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9047 - loss: 0.2733 - val_auc: 0.7790 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9047 - loss: 0.2688 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2734\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9047 - loss: 0.2679 - val_auc: 0.7866 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9047 - loss: 0.2674 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9047 - loss: 0.2665 - val_auc: 0.7878 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9047 - loss: 0.2658 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9047 - loss: 0.2650 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7716 - binary_accuracy: 0.9049 - loss: 0.2734\n",
      "Fold 4 Metrics: Loss = 0.2680, Accuracy = 0.9044, AUC = 0.7924\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5250 - binary_accuracy: 0.9040 - loss: 0.3465 - val_auc: 0.7361 - val_binary_accuracy: 0.9044 - val_loss: 0.3061\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7318 - binary_accuracy: 0.9040 - loss: 0.2972 - val_auc: 0.7815 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7854 - val_binary_accuracy: 0.9044 - val_loss: 0.2632\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9040 - loss: 0.2719 - val_auc: 0.7871 - val_binary_accuracy: 0.9044 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9040 - loss: 0.2690 - val_auc: 0.7925 - val_binary_accuracy: 0.9044 - val_loss: 0.2590\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9041 - loss: 0.2673 - val_auc: 0.7960 - val_binary_accuracy: 0.9072 - val_loss: 0.2575\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.7983 - val_binary_accuracy: 0.9093 - val_loss: 0.2560\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2642 - val_auc: 0.8011 - val_binary_accuracy: 0.9100 - val_loss: 0.2547\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9087 - loss: 0.2630 - val_auc: 0.8025 - val_binary_accuracy: 0.9107 - val_loss: 0.2537\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8133 - binary_accuracy: 0.9093 - loss: 0.2513\n",
      "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9107, AUC = 0.8025\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2609\n",
      "Average Accuracy: 0.9081\n",
      "Average AUC: 0.7970\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 4, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5312 - binary_accuracy: 0.8037 - loss: 0.4185 - val_auc: 0.7559 - val_binary_accuracy: 0.9044 - val_loss: 0.2886\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9069 - loss: 0.2722 - val_auc: 0.7699 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7748 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9070 - loss: 0.2568 - val_auc: 0.7811 - val_binary_accuracy: 0.9044 - val_loss: 0.2661\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9078 - loss: 0.2548 - val_auc: 0.7855 - val_binary_accuracy: 0.9071 - val_loss: 0.2647\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9101 - loss: 0.2532 - val_auc: 0.7873 - val_binary_accuracy: 0.9085 - val_loss: 0.2635\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9121 - loss: 0.2518 - val_auc: 0.7886 - val_binary_accuracy: 0.9096 - val_loss: 0.2626\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8066 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7890 - val_binary_accuracy: 0.9100 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9131 - loss: 0.2495 - val_auc: 0.7893 - val_binary_accuracy: 0.9099 - val_loss: 0.2610\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7880 - binary_accuracy: 0.9131 - loss: 0.2545\n",
      "Fold 1 Metrics: Loss = 0.2610, Accuracy = 0.9099, AUC = 0.7893\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5575 - binary_accuracy: 0.9029 - loss: 0.3253 - val_auc: 0.7887 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9029 - loss: 0.2727 - val_auc: 0.8010 - val_binary_accuracy: 0.9042 - val_loss: 0.2620\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9036 - loss: 0.2681 - val_auc: 0.8052 - val_binary_accuracy: 0.9042 - val_loss: 0.2599\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9044 - loss: 0.2652 - val_auc: 0.8097 - val_binary_accuracy: 0.9051 - val_loss: 0.2574\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9052 - loss: 0.2629 - val_auc: 0.8098 - val_binary_accuracy: 0.9065 - val_loss: 0.2565\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9065 - loss: 0.2613 - val_auc: 0.8099 - val_binary_accuracy: 0.9071 - val_loss: 0.2560\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9067 - loss: 0.2602 - val_auc: 0.8104 - val_binary_accuracy: 0.9076 - val_loss: 0.2560\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9078 - loss: 0.2595 - val_auc: 0.8109 - val_binary_accuracy: 0.9084 - val_loss: 0.2557\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9073 - loss: 0.2589 - val_auc: 0.8114 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9075 - loss: 0.2584 - val_auc: 0.8107 - val_binary_accuracy: 0.9090 - val_loss: 0.2563\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8160 - binary_accuracy: 0.9130 - loss: 0.2456\n",
      "Fold 2 Metrics: Loss = 0.2563, Accuracy = 0.9090, AUC = 0.8107\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5587 - binary_accuracy: 0.8865 - loss: 0.3486 - val_auc: 0.7627 - val_binary_accuracy: 0.9042 - val_loss: 0.2795\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9051 - loss: 0.2726 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9051 - loss: 0.2673 - val_auc: 0.7875 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9052 - loss: 0.2654 - val_auc: 0.7923 - val_binary_accuracy: 0.9059 - val_loss: 0.2640\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9061 - loss: 0.2636 - val_auc: 0.7946 - val_binary_accuracy: 0.9097 - val_loss: 0.2620\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9085 - loss: 0.2626 - val_auc: 0.7963 - val_binary_accuracy: 0.9100 - val_loss: 0.2603\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9089 - loss: 0.2616 - val_auc: 0.7992 - val_binary_accuracy: 0.9102 - val_loss: 0.2591\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9091 - loss: 0.2610 - val_auc: 0.7993 - val_binary_accuracy: 0.9115 - val_loss: 0.2584\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.7996 - val_binary_accuracy: 0.9113 - val_loss: 0.2578\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9101 - loss: 0.2599 - val_auc: 0.8005 - val_binary_accuracy: 0.9110 - val_loss: 0.2574\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7935 - binary_accuracy: 0.9123 - loss: 0.2578\n",
      "Fold 3 Metrics: Loss = 0.2574, Accuracy = 0.9110, AUC = 0.8005\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5406 - binary_accuracy: 0.9043 - loss: 0.3519 - val_auc: 0.7755 - val_binary_accuracy: 0.9044 - val_loss: 0.2751\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9047 - loss: 0.2710 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7918 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9060 - loss: 0.2643 - val_auc: 0.7959 - val_binary_accuracy: 0.9072 - val_loss: 0.2626\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9085 - loss: 0.2623 - val_auc: 0.7982 - val_binary_accuracy: 0.9076 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9097 - loss: 0.2608 - val_auc: 0.8011 - val_binary_accuracy: 0.9085 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9104 - loss: 0.2596 - val_auc: 0.8037 - val_binary_accuracy: 0.9097 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9110 - loss: 0.2586 - val_auc: 0.8063 - val_binary_accuracy: 0.9104 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9112 - loss: 0.2579 - val_auc: 0.8073 - val_binary_accuracy: 0.9106 - val_loss: 0.2554\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9114 - loss: 0.2573 - val_auc: 0.8079 - val_binary_accuracy: 0.9104 - val_loss: 0.2549\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7903 - binary_accuracy: 0.9099 - loss: 0.2603\n",
      "Fold 4 Metrics: Loss = 0.2549, Accuracy = 0.9104, AUC = 0.8079\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5695 - binary_accuracy: 0.9040 - loss: 0.3262 - val_auc: 0.7827 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.7938 - val_binary_accuracy: 0.9044 - val_loss: 0.2604\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9041 - loss: 0.2694 - val_auc: 0.7970 - val_binary_accuracy: 0.9073 - val_loss: 0.2585\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9066 - loss: 0.2670 - val_auc: 0.7983 - val_binary_accuracy: 0.9081 - val_loss: 0.2575\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9079 - loss: 0.2656 - val_auc: 0.8006 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8025 - val_binary_accuracy: 0.9095 - val_loss: 0.2547\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8033 - val_binary_accuracy: 0.9104 - val_loss: 0.2539\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9089 - loss: 0.2623 - val_auc: 0.8048 - val_binary_accuracy: 0.9107 - val_loss: 0.2533\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9088 - loss: 0.2617 - val_auc: 0.8058 - val_binary_accuracy: 0.9109 - val_loss: 0.2529\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9087 - loss: 0.2611 - val_auc: 0.8069 - val_binary_accuracy: 0.9109 - val_loss: 0.2526\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8163 - binary_accuracy: 0.9092 - loss: 0.2503\n",
      "Fold 5 Metrics: Loss = 0.2526, Accuracy = 0.9109, AUC = 0.8069\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2565\n",
      "Average Accuracy: 0.9102\n",
      "Average AUC: 0.8031\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 4, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6197 - binary_accuracy: 0.9069 - loss: 0.3147 - val_auc: 0.7702 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9069 - loss: 0.2611 - val_auc: 0.7781 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9071 - loss: 0.2578 - val_auc: 0.7843 - val_binary_accuracy: 0.9044 - val_loss: 0.2651\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9092 - loss: 0.2548 - val_auc: 0.7886 - val_binary_accuracy: 0.9062 - val_loss: 0.2639\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9116 - loss: 0.2522 - val_auc: 0.7908 - val_binary_accuracy: 0.9081 - val_loss: 0.2624\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8073 - binary_accuracy: 0.9117 - loss: 0.2502 - val_auc: 0.7922 - val_binary_accuracy: 0.9085 - val_loss: 0.2612\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9122 - loss: 0.2488 - val_auc: 0.7934 - val_binary_accuracy: 0.9084 - val_loss: 0.2602\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8111 - binary_accuracy: 0.9129 - loss: 0.2479 - val_auc: 0.7930 - val_binary_accuracy: 0.9082 - val_loss: 0.2595\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9133 - loss: 0.2472 - val_auc: 0.7943 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8130 - binary_accuracy: 0.9133 - loss: 0.2466 - val_auc: 0.7937 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7931 - binary_accuracy: 0.9124 - loss: 0.2511\n",
      "Fold 1 Metrics: Loss = 0.2588, Accuracy = 0.9085, AUC = 0.7937\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5774 - binary_accuracy: 0.8554 - loss: 0.3685 - val_auc: 0.7944 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2710 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2600\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9040 - loss: 0.2665 - val_auc: 0.8060 - val_binary_accuracy: 0.9050 - val_loss: 0.2584\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9055 - loss: 0.2638 - val_auc: 0.8064 - val_binary_accuracy: 0.9066 - val_loss: 0.2574\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9068 - loss: 0.2621 - val_auc: 0.8075 - val_binary_accuracy: 0.9075 - val_loss: 0.2561\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9075 - loss: 0.2608 - val_auc: 0.8077 - val_binary_accuracy: 0.9082 - val_loss: 0.2557\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9075 - loss: 0.2600 - val_auc: 0.8078 - val_binary_accuracy: 0.9081 - val_loss: 0.2555\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9077 - loss: 0.2593 - val_auc: 0.8079 - val_binary_accuracy: 0.9081 - val_loss: 0.2552\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.8088 - val_binary_accuracy: 0.9084 - val_loss: 0.2550\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9080 - loss: 0.2582 - val_auc: 0.8093 - val_binary_accuracy: 0.9085 - val_loss: 0.2549\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9118 - loss: 0.2445\n",
      "Fold 2 Metrics: Loss = 0.2549, Accuracy = 0.9085, AUC = 0.8093\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6086 - binary_accuracy: 0.9051 - loss: 0.3213 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9051 - loss: 0.2719 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9057 - loss: 0.2687 - val_auc: 0.7903 - val_binary_accuracy: 0.9060 - val_loss: 0.2641\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9075 - loss: 0.2669 - val_auc: 0.7944 - val_binary_accuracy: 0.9093 - val_loss: 0.2616\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9084 - loss: 0.2655 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9088 - loss: 0.2644 - val_auc: 0.8006 - val_binary_accuracy: 0.9102 - val_loss: 0.2583\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9094 - loss: 0.2633 - val_auc: 0.8016 - val_binary_accuracy: 0.9109 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9098 - loss: 0.2625 - val_auc: 0.8036 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9096 - loss: 0.2618 - val_auc: 0.8048 - val_binary_accuracy: 0.9109 - val_loss: 0.2558\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8052 - val_binary_accuracy: 0.9112 - val_loss: 0.2554\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7985 - binary_accuracy: 0.9124 - loss: 0.2559\n",
      "Fold 3 Metrics: Loss = 0.2554, Accuracy = 0.9112, AUC = 0.8052\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5807 - binary_accuracy: 0.9047 - loss: 0.3278 - val_auc: 0.7863 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9050 - loss: 0.2676 - val_auc: 0.7948 - val_binary_accuracy: 0.9057 - val_loss: 0.2624\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9071 - loss: 0.2640 - val_auc: 0.7995 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9095 - loss: 0.2618 - val_auc: 0.8028 - val_binary_accuracy: 0.9097 - val_loss: 0.2571\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9104 - loss: 0.2604 - val_auc: 0.8042 - val_binary_accuracy: 0.9097 - val_loss: 0.2562\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9106 - loss: 0.2595 - val_auc: 0.8053 - val_binary_accuracy: 0.9095 - val_loss: 0.2558\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9108 - loss: 0.2588 - val_auc: 0.8070 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9110 - loss: 0.2582 - val_auc: 0.8077 - val_binary_accuracy: 0.9091 - val_loss: 0.2552\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9112 - loss: 0.2578 - val_auc: 0.8083 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9113 - loss: 0.2574 - val_auc: 0.8093 - val_binary_accuracy: 0.9090 - val_loss: 0.2547\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7916 - binary_accuracy: 0.9077 - loss: 0.2608\n",
      "Fold 4 Metrics: Loss = 0.2547, Accuracy = 0.9090, AUC = 0.8093\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5985 - binary_accuracy: 0.9040 - loss: 0.3231 - val_auc: 0.7888 - val_binary_accuracy: 0.9044 - val_loss: 0.2640\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9041 - loss: 0.2728 - val_auc: 0.7949 - val_binary_accuracy: 0.9079 - val_loss: 0.2604\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9053 - loss: 0.2700 - val_auc: 0.7979 - val_binary_accuracy: 0.9082 - val_loss: 0.2588\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9075 - loss: 0.2680 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9080 - loss: 0.2666 - val_auc: 0.8024 - val_binary_accuracy: 0.9106 - val_loss: 0.2561\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.8038 - val_binary_accuracy: 0.9104 - val_loss: 0.2549\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.8046 - val_binary_accuracy: 0.9112 - val_loss: 0.2540\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9093 - loss: 0.2630 - val_auc: 0.8059 - val_binary_accuracy: 0.9104 - val_loss: 0.2532\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.8061 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9093 - loss: 0.2615 - val_auc: 0.8066 - val_binary_accuracy: 0.9109 - val_loss: 0.2522\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9086 - loss: 0.2498\n",
      "Fold 5 Metrics: Loss = 0.2522, Accuracy = 0.9109, AUC = 0.8066\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2552\n",
      "Average Accuracy: 0.9096\n",
      "Average AUC: 0.8048\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 4, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6381 - binary_accuracy: 0.8901 - loss: 0.3081 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9076 - loss: 0.2585 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9098 - loss: 0.2556 - val_auc: 0.7888 - val_binary_accuracy: 0.9062 - val_loss: 0.2658\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9115 - loss: 0.2531 - val_auc: 0.7911 - val_binary_accuracy: 0.9075 - val_loss: 0.2642\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9120 - loss: 0.2511 - val_auc: 0.7925 - val_binary_accuracy: 0.9078 - val_loss: 0.2633\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8077 - binary_accuracy: 0.9122 - loss: 0.2497 - val_auc: 0.7945 - val_binary_accuracy: 0.9084 - val_loss: 0.2617\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9128 - loss: 0.2485 - val_auc: 0.7945 - val_binary_accuracy: 0.9084 - val_loss: 0.2607\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8114 - binary_accuracy: 0.9130 - loss: 0.2476 - val_auc: 0.7954 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9129 - loss: 0.2470 - val_auc: 0.7955 - val_binary_accuracy: 0.9081 - val_loss: 0.2596\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7946 - binary_accuracy: 0.9114 - loss: 0.2515\n",
      "Fold 1 Metrics: Loss = 0.2596, Accuracy = 0.9081, AUC = 0.7955\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5940 - binary_accuracy: 0.8692 - loss: 0.3557 - val_auc: 0.7984 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9033 - loss: 0.2711 - val_auc: 0.8041 - val_binary_accuracy: 0.9044 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9048 - loss: 0.2683 - val_auc: 0.8066 - val_binary_accuracy: 0.9062 - val_loss: 0.2617\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9061 - loss: 0.2657 - val_auc: 0.8072 - val_binary_accuracy: 0.9069 - val_loss: 0.2608\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8071 - val_binary_accuracy: 0.9075 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9081 - loss: 0.2622 - val_auc: 0.8075 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9085 - loss: 0.2611 - val_auc: 0.8068 - val_binary_accuracy: 0.9085 - val_loss: 0.2600\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9088 - loss: 0.2603 - val_auc: 0.8077 - val_binary_accuracy: 0.9087 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9089 - loss: 0.2596 - val_auc: 0.8080 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9091 - loss: 0.2591 - val_auc: 0.8089 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9129 - loss: 0.2485\n",
      "Fold 2 Metrics: Loss = 0.2582, Accuracy = 0.9091, AUC = 0.8089\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6086 - binary_accuracy: 0.8865 - loss: 0.3291 - val_auc: 0.7805 - val_binary_accuracy: 0.9042 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9051 - loss: 0.2737 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9052 - loss: 0.2709 - val_auc: 0.7893 - val_binary_accuracy: 0.9057 - val_loss: 0.2650\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.7923 - val_binary_accuracy: 0.9097 - val_loss: 0.2637\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9076 - loss: 0.2675 - val_auc: 0.7948 - val_binary_accuracy: 0.9102 - val_loss: 0.2625\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9085 - loss: 0.2661 - val_auc: 0.7970 - val_binary_accuracy: 0.9106 - val_loss: 0.2612\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9089 - loss: 0.2650 - val_auc: 0.7995 - val_binary_accuracy: 0.9110 - val_loss: 0.2600\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9093 - loss: 0.2640 - val_auc: 0.8004 - val_binary_accuracy: 0.9109 - val_loss: 0.2589\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9093 - loss: 0.2633 - val_auc: 0.8019 - val_binary_accuracy: 0.9109 - val_loss: 0.2580\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9096 - loss: 0.2628 - val_auc: 0.8033 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7952 - binary_accuracy: 0.9124 - loss: 0.2578\n",
      "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9109, AUC = 0.8033\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5841 - binary_accuracy: 0.8714 - loss: 0.3610 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9055 - loss: 0.2683 - val_auc: 0.7940 - val_binary_accuracy: 0.9070 - val_loss: 0.2619\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9078 - loss: 0.2653 - val_auc: 0.7998 - val_binary_accuracy: 0.9085 - val_loss: 0.2591\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9090 - loss: 0.2630 - val_auc: 0.8024 - val_binary_accuracy: 0.9094 - val_loss: 0.2571\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9099 - loss: 0.2615 - val_auc: 0.8052 - val_binary_accuracy: 0.9082 - val_loss: 0.2561\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9099 - loss: 0.2604 - val_auc: 0.8064 - val_binary_accuracy: 0.9088 - val_loss: 0.2554\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9103 - loss: 0.2597 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9107 - loss: 0.2590 - val_auc: 0.8081 - val_binary_accuracy: 0.9090 - val_loss: 0.2547\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9108 - loss: 0.2585 - val_auc: 0.8087 - val_binary_accuracy: 0.9091 - val_loss: 0.2545\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9108 - loss: 0.2580 - val_auc: 0.8094 - val_binary_accuracy: 0.9091 - val_loss: 0.2543\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7911 - binary_accuracy: 0.9087 - loss: 0.2614\n",
      "Fold 4 Metrics: Loss = 0.2543, Accuracy = 0.9091, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6132 - binary_accuracy: 0.9040 - loss: 0.3212 - val_auc: 0.7890 - val_binary_accuracy: 0.9048 - val_loss: 0.2685\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9041 - loss: 0.2740 - val_auc: 0.7950 - val_binary_accuracy: 0.9078 - val_loss: 0.2656\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9052 - loss: 0.2709 - val_auc: 0.7987 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9073 - loss: 0.2684 - val_auc: 0.8017 - val_binary_accuracy: 0.9076 - val_loss: 0.2627\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9078 - loss: 0.2667 - val_auc: 0.8041 - val_binary_accuracy: 0.9087 - val_loss: 0.2610\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9084 - loss: 0.2653 - val_auc: 0.8053 - val_binary_accuracy: 0.9091 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9089 - loss: 0.2641 - val_auc: 0.8064 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9098 - loss: 0.2631 - val_auc: 0.8077 - val_binary_accuracy: 0.9106 - val_loss: 0.2553\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9096 - loss: 0.2622 - val_auc: 0.8074 - val_binary_accuracy: 0.9112 - val_loss: 0.2541\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9098 - loss: 0.2615 - val_auc: 0.8082 - val_binary_accuracy: 0.9113 - val_loss: 0.2531\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9092 - loss: 0.2512\n",
      "Fold 5 Metrics: Loss = 0.2531, Accuracy = 0.9113, AUC = 0.8082\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2564\n",
      "Average Accuracy: 0.9097\n",
      "Average AUC: 0.8051\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 5, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4973 - binary_accuracy: 0.7440 - loss: 0.5121 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3162\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5044 - binary_accuracy: 0.9069 - loss: 0.3101 - val_auc: 0.4999 - val_binary_accuracy: 0.9044 - val_loss: 0.3150\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5662 - binary_accuracy: 0.9069 - loss: 0.3091 - val_auc: 0.7259 - val_binary_accuracy: 0.9044 - val_loss: 0.3125\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7352 - binary_accuracy: 0.9069 - loss: 0.3041 - val_auc: 0.7583 - val_binary_accuracy: 0.9044 - val_loss: 0.2982\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7614 - binary_accuracy: 0.9069 - loss: 0.2857 - val_auc: 0.7465 - val_binary_accuracy: 0.9044 - val_loss: 0.2798\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.7755 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9069 - loss: 0.2613 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9069 - loss: 0.2595 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9069 - loss: 0.2578 - val_auc: 0.7835 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9069 - loss: 0.2569 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7856 - binary_accuracy: 0.9084 - loss: 0.2585\n",
      "Fold 1 Metrics: Loss = 0.2671, Accuracy = 0.9044, AUC = 0.7839\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5018 - binary_accuracy: 0.9029 - loss: 0.4375 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3155\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5285 - binary_accuracy: 0.9029 - loss: 0.3185 - val_auc: 0.7104 - val_binary_accuracy: 0.9042 - val_loss: 0.3150\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6496 - binary_accuracy: 0.9029 - loss: 0.3174 - val_auc: 0.7353 - val_binary_accuracy: 0.9042 - val_loss: 0.3104\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7362 - binary_accuracy: 0.9029 - loss: 0.3084 - val_auc: 0.7837 - val_binary_accuracy: 0.9042 - val_loss: 0.2815\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9029 - loss: 0.2819 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9029 - loss: 0.2731 - val_auc: 0.7931 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9029 - loss: 0.2711 - val_auc: 0.7961 - val_binary_accuracy: 0.9042 - val_loss: 0.2643\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9029 - loss: 0.2700 - val_auc: 0.7974 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2689 - val_auc: 0.7995 - val_binary_accuracy: 0.9042 - val_loss: 0.2621\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9029 - loss: 0.2681 - val_auc: 0.8006 - val_binary_accuracy: 0.9042 - val_loss: 0.2611\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8018 - binary_accuracy: 0.9092 - loss: 0.2522\n",
      "Fold 2 Metrics: Loss = 0.2611, Accuracy = 0.9042, AUC = 0.8006\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4998 - binary_accuracy: 0.7474 - loss: 0.4956 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3158\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4981 - binary_accuracy: 0.9051 - loss: 0.3138 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3155\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5111 - binary_accuracy: 0.9051 - loss: 0.3136 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3153\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5305 - binary_accuracy: 0.9051 - loss: 0.3133 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3146\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5968 - binary_accuracy: 0.9051 - loss: 0.3124 - val_auc: 0.7238 - val_binary_accuracy: 0.9042 - val_loss: 0.3115\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7208 - binary_accuracy: 0.9051 - loss: 0.3061 - val_auc: 0.7651 - val_binary_accuracy: 0.9042 - val_loss: 0.2848\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7559 - binary_accuracy: 0.9051 - loss: 0.2801 - val_auc: 0.7686 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9051 - loss: 0.2730 - val_auc: 0.7718 - val_binary_accuracy: 0.9042 - val_loss: 0.2725\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7622 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2725\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9051 - loss: 0.2691 - val_auc: 0.7719 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7689 - binary_accuracy: 0.9046 - loss: 0.2724\n",
      "Fold 3 Metrics: Loss = 0.2723, Accuracy = 0.9042, AUC = 0.7719\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4987 - binary_accuracy: 0.9047 - loss: 0.3930 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5932 - binary_accuracy: 0.9047 - loss: 0.3133 - val_auc: 0.7478 - val_binary_accuracy: 0.9044 - val_loss: 0.3086\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7324 - binary_accuracy: 0.9047 - loss: 0.3026 - val_auc: 0.7721 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9047 - loss: 0.2778 - val_auc: 0.7746 - val_binary_accuracy: 0.9044 - val_loss: 0.2757\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9047 - loss: 0.2697 - val_auc: 0.7784 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9047 - loss: 0.2678 - val_auc: 0.7677 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9047 - loss: 0.2673 - val_auc: 0.7790 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7833 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2655 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2678\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9047 - loss: 0.2652 - val_auc: 0.7777 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7564 - binary_accuracy: 0.9049 - loss: 0.2730\n",
      "Fold 4 Metrics: Loss = 0.2683, Accuracy = 0.9044, AUC = 0.7777\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5013 - binary_accuracy: 0.9040 - loss: 0.4339 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3152\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5197 - binary_accuracy: 0.9040 - loss: 0.3159 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6066 - binary_accuracy: 0.9040 - loss: 0.3148 - val_auc: 0.7457 - val_binary_accuracy: 0.9044 - val_loss: 0.3095\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7343 - binary_accuracy: 0.9040 - loss: 0.3048 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2764\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9040 - loss: 0.2780 - val_auc: 0.7844 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9040 - loss: 0.2727 - val_auc: 0.7884 - val_binary_accuracy: 0.9044 - val_loss: 0.2636\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9040 - loss: 0.2714 - val_auc: 0.7879 - val_binary_accuracy: 0.9044 - val_loss: 0.2630\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9040 - loss: 0.2703 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2625\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9040 - loss: 0.2696 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2625\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9040 - loss: 0.2692 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2619\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8004 - binary_accuracy: 0.9013 - loss: 0.2606\n",
      "Fold 5 Metrics: Loss = 0.2619, Accuracy = 0.9044, AUC = 0.7917\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2662\n",
      "Average Accuracy: 0.9043\n",
      "Average AUC: 0.7852\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 5, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5026 - binary_accuracy: 0.9069 - loss: 0.3597 - val_auc: 0.6572 - val_binary_accuracy: 0.9044 - val_loss: 0.3142\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6451 - binary_accuracy: 0.9069 - loss: 0.3047 - val_auc: 0.7599 - val_binary_accuracy: 0.9044 - val_loss: 0.2794\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.7708 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9069 - loss: 0.2602 - val_auc: 0.7748 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9069 - loss: 0.2587 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9069 - loss: 0.2579 - val_auc: 0.7780 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9069 - loss: 0.2572 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9069 - loss: 0.2566 - val_auc: 0.7803 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9069 - loss: 0.2560 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9069 - loss: 0.2551 - val_auc: 0.7861 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7829 - binary_accuracy: 0.9084 - loss: 0.2585\n",
      "Fold 1 Metrics: Loss = 0.2649, Accuracy = 0.9044, AUC = 0.7861\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5047 - binary_accuracy: 0.9029 - loss: 0.3619 - val_auc: 0.7054 - val_binary_accuracy: 0.9042 - val_loss: 0.3143\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6909 - binary_accuracy: 0.9029 - loss: 0.3084 - val_auc: 0.7925 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9029 - loss: 0.2722 - val_auc: 0.7999 - val_binary_accuracy: 0.9042 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9029 - loss: 0.2690 - val_auc: 0.8028 - val_binary_accuracy: 0.9042 - val_loss: 0.2633\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9029 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9042 - val_loss: 0.2633\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9029 - loss: 0.2669 - val_auc: 0.8054 - val_binary_accuracy: 0.9042 - val_loss: 0.2627\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9029 - loss: 0.2664 - val_auc: 0.8052 - val_binary_accuracy: 0.9042 - val_loss: 0.2626\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7906 - binary_accuracy: 0.9035 - loss: 0.2658 - val_auc: 0.8054 - val_binary_accuracy: 0.9042 - val_loss: 0.2625\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9049 - loss: 0.2650 - val_auc: 0.8058 - val_binary_accuracy: 0.9050 - val_loss: 0.2620\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9062 - loss: 0.2642 - val_auc: 0.8061 - val_binary_accuracy: 0.9062 - val_loss: 0.2615\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8058 - binary_accuracy: 0.9101 - loss: 0.2528\n",
      "Fold 2 Metrics: Loss = 0.2615, Accuracy = 0.9062, AUC = 0.8061\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5010 - binary_accuracy: 0.7300 - loss: 0.4890 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3154\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5254 - binary_accuracy: 0.9051 - loss: 0.3129 - val_auc: 0.7501 - val_binary_accuracy: 0.9042 - val_loss: 0.3068\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7356 - binary_accuracy: 0.9051 - loss: 0.2949 - val_auc: 0.7756 - val_binary_accuracy: 0.9042 - val_loss: 0.2748\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9051 - loss: 0.2704 - val_auc: 0.7812 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9051 - loss: 0.2673 - val_auc: 0.7856 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2676\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9051 - loss: 0.2654 - val_auc: 0.7883 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9051 - loss: 0.2651 - val_auc: 0.7908 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9052 - loss: 0.2643 - val_auc: 0.7913 - val_binary_accuracy: 0.9063 - val_loss: 0.2643\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9062 - loss: 0.2637 - val_auc: 0.7925 - val_binary_accuracy: 0.9100 - val_loss: 0.2632\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7864 - binary_accuracy: 0.9103 - loss: 0.2638\n",
      "Fold 3 Metrics: Loss = 0.2632, Accuracy = 0.9100, AUC = 0.7925\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4988 - binary_accuracy: 0.8179 - loss: 0.4269 - val_auc: 0.6953 - val_binary_accuracy: 0.9044 - val_loss: 0.3144\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6380 - binary_accuracy: 0.9047 - loss: 0.3116 - val_auc: 0.7670 - val_binary_accuracy: 0.9044 - val_loss: 0.2962\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7441 - binary_accuracy: 0.9047 - loss: 0.2865 - val_auc: 0.7732 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9047 - loss: 0.2683 - val_auc: 0.7796 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9047 - loss: 0.2664 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9050 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9045 - val_loss: 0.2640\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9076 - loss: 0.2622 - val_auc: 0.7892 - val_binary_accuracy: 0.9073 - val_loss: 0.2642\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9091 - loss: 0.2608 - val_auc: 0.7937 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9097 - loss: 0.2598 - val_auc: 0.7958 - val_binary_accuracy: 0.9082 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.7973 - val_binary_accuracy: 0.9088 - val_loss: 0.2603\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7782 - binary_accuracy: 0.9085 - loss: 0.2655\n",
      "Fold 4 Metrics: Loss = 0.2603, Accuracy = 0.9088, AUC = 0.7973\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5080 - binary_accuracy: 0.7764 - loss: 0.4473 - val_auc: 0.6901 - val_binary_accuracy: 0.9044 - val_loss: 0.3133\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6971 - binary_accuracy: 0.9040 - loss: 0.3102 - val_auc: 0.7698 - val_binary_accuracy: 0.9044 - val_loss: 0.2806\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7589 - binary_accuracy: 0.9040 - loss: 0.2803 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2645\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9040 - loss: 0.2713 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9040 - loss: 0.2694 - val_auc: 0.7942 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9040 - loss: 0.2682 - val_auc: 0.7950 - val_binary_accuracy: 0.9044 - val_loss: 0.2599\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9040 - loss: 0.2674 - val_auc: 0.7961 - val_binary_accuracy: 0.9044 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9040 - loss: 0.2667 - val_auc: 0.7972 - val_binary_accuracy: 0.9044 - val_loss: 0.2589\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9040 - loss: 0.2659 - val_auc: 0.7993 - val_binary_accuracy: 0.9044 - val_loss: 0.2581\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9044 - loss: 0.2653 - val_auc: 0.7986 - val_binary_accuracy: 0.9081 - val_loss: 0.2576\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8077 - binary_accuracy: 0.9069 - loss: 0.2551\n",
      "Fold 5 Metrics: Loss = 0.2576, Accuracy = 0.9081, AUC = 0.7986\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2615\n",
      "Average Accuracy: 0.9075\n",
      "Average AUC: 0.7961\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 5, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5420 - binary_accuracy: 0.9069 - loss: 0.3254 - val_auc: 0.7619 - val_binary_accuracy: 0.9044 - val_loss: 0.2807\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9069 - loss: 0.2660 - val_auc: 0.7734 - val_binary_accuracy: 0.9044 - val_loss: 0.2726\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9069 - loss: 0.2603 - val_auc: 0.7774 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9069 - loss: 0.2581 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9071 - loss: 0.2562 - val_auc: 0.7832 - val_binary_accuracy: 0.9056 - val_loss: 0.2658\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8002 - binary_accuracy: 0.9091 - loss: 0.2545 - val_auc: 0.7851 - val_binary_accuracy: 0.9078 - val_loss: 0.2641\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9118 - loss: 0.2532 - val_auc: 0.7867 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9122 - loss: 0.2518 - val_auc: 0.7875 - val_binary_accuracy: 0.9090 - val_loss: 0.2609\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9129 - loss: 0.2507 - val_auc: 0.7894 - val_binary_accuracy: 0.9091 - val_loss: 0.2602\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9132 - loss: 0.2496 - val_auc: 0.7899 - val_binary_accuracy: 0.9088 - val_loss: 0.2597\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7861 - binary_accuracy: 0.9128 - loss: 0.2532\n",
      "Fold 1 Metrics: Loss = 0.2597, Accuracy = 0.9088, AUC = 0.7899\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5275 - binary_accuracy: 0.8436 - loss: 0.3803 - val_auc: 0.7777 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9029 - loss: 0.2805 - val_auc: 0.7999 - val_binary_accuracy: 0.9042 - val_loss: 0.2628\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2687 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2598\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9031 - loss: 0.2663 - val_auc: 0.8063 - val_binary_accuracy: 0.9042 - val_loss: 0.2588\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9057 - loss: 0.2644 - val_auc: 0.8079 - val_binary_accuracy: 0.9066 - val_loss: 0.2587\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9068 - loss: 0.2629 - val_auc: 0.8081 - val_binary_accuracy: 0.9075 - val_loss: 0.2586\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9076 - loss: 0.2617 - val_auc: 0.8057 - val_binary_accuracy: 0.9072 - val_loss: 0.2591\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9083 - loss: 0.2609 - val_auc: 0.8058 - val_binary_accuracy: 0.9072 - val_loss: 0.2594\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9083 - loss: 0.2603 - val_auc: 0.8066 - val_binary_accuracy: 0.9075 - val_loss: 0.2598\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9084 - loss: 0.2597 - val_auc: 0.8069 - val_binary_accuracy: 0.9082 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9128 - loss: 0.2491\n",
      "Fold 2 Metrics: Loss = 0.2599, Accuracy = 0.9082, AUC = 0.8069\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5089 - binary_accuracy: 0.7474 - loss: 0.4985 - val_auc: 0.7218 - val_binary_accuracy: 0.9042 - val_loss: 0.3102\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7207 - binary_accuracy: 0.9051 - loss: 0.2970 - val_auc: 0.7743 - val_binary_accuracy: 0.9042 - val_loss: 0.2752\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9051 - loss: 0.2705 - val_auc: 0.7817 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7897 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9059 - loss: 0.2653 - val_auc: 0.7896 - val_binary_accuracy: 0.9097 - val_loss: 0.2642\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.7916 - val_binary_accuracy: 0.9099 - val_loss: 0.2625\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9088 - loss: 0.2635 - val_auc: 0.7947 - val_binary_accuracy: 0.9104 - val_loss: 0.2607\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7970 - val_binary_accuracy: 0.9112 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9090 - loss: 0.2620 - val_auc: 0.7987 - val_binary_accuracy: 0.9116 - val_loss: 0.2582\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9134 - loss: 0.2586\n",
      "Fold 3 Metrics: Loss = 0.2582, Accuracy = 0.9116, AUC = 0.7987\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5045 - binary_accuracy: 0.9047 - loss: 0.3483 - val_auc: 0.7596 - val_binary_accuracy: 0.9044 - val_loss: 0.2908\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7565 - binary_accuracy: 0.9047 - loss: 0.2779 - val_auc: 0.7874 - val_binary_accuracy: 0.9044 - val_loss: 0.2658\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9047 - loss: 0.2657 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2642\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9049 - loss: 0.2636 - val_auc: 0.7943 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9064 - loss: 0.2620 - val_auc: 0.7993 - val_binary_accuracy: 0.9066 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9089 - loss: 0.2606 - val_auc: 0.8023 - val_binary_accuracy: 0.9082 - val_loss: 0.2580\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9098 - loss: 0.2597 - val_auc: 0.8035 - val_binary_accuracy: 0.9085 - val_loss: 0.2568\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9093 - loss: 0.2589 - val_auc: 0.8057 - val_binary_accuracy: 0.9087 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9098 - loss: 0.2586 - val_auc: 0.8056 - val_binary_accuracy: 0.9088 - val_loss: 0.2560\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9102 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9091 - val_loss: 0.2557\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9087 - loss: 0.2614\n",
      "Fold 4 Metrics: Loss = 0.2557, Accuracy = 0.9091, AUC = 0.8071\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5529 - binary_accuracy: 0.9040 - loss: 0.3187 - val_auc: 0.7836 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.7918 - val_binary_accuracy: 0.9044 - val_loss: 0.2614\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9040 - loss: 0.2702 - val_auc: 0.7938 - val_binary_accuracy: 0.9045 - val_loss: 0.2605\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9047 - loss: 0.2684 - val_auc: 0.7953 - val_binary_accuracy: 0.9079 - val_loss: 0.2590\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9073 - loss: 0.2670 - val_auc: 0.7974 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9083 - loss: 0.2658 - val_auc: 0.7999 - val_binary_accuracy: 0.9091 - val_loss: 0.2565\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9083 - loss: 0.2648 - val_auc: 0.8004 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8026 - val_binary_accuracy: 0.9091 - val_loss: 0.2548\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9089 - loss: 0.2631 - val_auc: 0.8036 - val_binary_accuracy: 0.9098 - val_loss: 0.2541\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8037 - val_binary_accuracy: 0.9103 - val_loss: 0.2536\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8138 - binary_accuracy: 0.9081 - loss: 0.2509\n",
      "Fold 5 Metrics: Loss = 0.2536, Accuracy = 0.9103, AUC = 0.8037\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2574\n",
      "Average Accuracy: 0.9096\n",
      "Average AUC: 0.8013\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 5, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5788 - binary_accuracy: 0.8757 - loss: 0.3350 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9069 - loss: 0.2623 - val_auc: 0.7760 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9069 - loss: 0.2591 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9071 - loss: 0.2567 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9089 - loss: 0.2543 - val_auc: 0.7881 - val_binary_accuracy: 0.9065 - val_loss: 0.2633\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8040 - binary_accuracy: 0.9113 - loss: 0.2522 - val_auc: 0.7906 - val_binary_accuracy: 0.9079 - val_loss: 0.2618\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9121 - loss: 0.2505 - val_auc: 0.7912 - val_binary_accuracy: 0.9087 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8085 - binary_accuracy: 0.9120 - loss: 0.2494 - val_auc: 0.7919 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8105 - binary_accuracy: 0.9127 - loss: 0.2484 - val_auc: 0.7918 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8116 - binary_accuracy: 0.9131 - loss: 0.2476 - val_auc: 0.7925 - val_binary_accuracy: 0.9090 - val_loss: 0.2592\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7916 - binary_accuracy: 0.9130 - loss: 0.2516\n",
      "Fold 1 Metrics: Loss = 0.2592, Accuracy = 0.9090, AUC = 0.7925\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5215 - binary_accuracy: 0.8554 - loss: 0.3773 - val_auc: 0.7895 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9029 - loss: 0.2742 - val_auc: 0.7998 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8044 - val_binary_accuracy: 0.9042 - val_loss: 0.2604\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9030 - loss: 0.2676 - val_auc: 0.8065 - val_binary_accuracy: 0.9042 - val_loss: 0.2592\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9052 - loss: 0.2652 - val_auc: 0.8082 - val_binary_accuracy: 0.9062 - val_loss: 0.2580\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9064 - loss: 0.2632 - val_auc: 0.8087 - val_binary_accuracy: 0.9075 - val_loss: 0.2570\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9075 - loss: 0.2616 - val_auc: 0.8086 - val_binary_accuracy: 0.9078 - val_loss: 0.2564\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9081 - loss: 0.2606 - val_auc: 0.8084 - val_binary_accuracy: 0.9078 - val_loss: 0.2559\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9080 - loss: 0.2598 - val_auc: 0.8092 - val_binary_accuracy: 0.9084 - val_loss: 0.2555\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9084 - loss: 0.2592 - val_auc: 0.8089 - val_binary_accuracy: 0.9084 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9123 - loss: 0.2447\n",
      "Fold 2 Metrics: Loss = 0.2551, Accuracy = 0.9084, AUC = 0.8089\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5237 - binary_accuracy: 0.8325 - loss: 0.4001 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2727\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7596 - binary_accuracy: 0.9051 - loss: 0.2740 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2702 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2665\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9053 - loss: 0.2684 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9068 - loss: 0.2673 - val_auc: 0.7928 - val_binary_accuracy: 0.9100 - val_loss: 0.2627\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7952 - val_binary_accuracy: 0.9103 - val_loss: 0.2610\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9083 - loss: 0.2653 - val_auc: 0.7984 - val_binary_accuracy: 0.9110 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9085 - loss: 0.2646 - val_auc: 0.8002 - val_binary_accuracy: 0.9113 - val_loss: 0.2585\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8018 - val_binary_accuracy: 0.9112 - val_loss: 0.2576\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9089 - loss: 0.2632 - val_auc: 0.8034 - val_binary_accuracy: 0.9112 - val_loss: 0.2570\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7960 - binary_accuracy: 0.9128 - loss: 0.2577\n",
      "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9112, AUC = 0.8034\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5373 - binary_accuracy: 0.8714 - loss: 0.3583 - val_auc: 0.7820 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9047 - loss: 0.2687 - val_auc: 0.7899 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9065 - loss: 0.2651 - val_auc: 0.7940 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9094 - loss: 0.2631 - val_auc: 0.7965 - val_binary_accuracy: 0.9090 - val_loss: 0.2596\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.7982 - val_binary_accuracy: 0.9093 - val_loss: 0.2586\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9099 - loss: 0.2606 - val_auc: 0.8004 - val_binary_accuracy: 0.9097 - val_loss: 0.2578\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9106 - loss: 0.2599 - val_auc: 0.8022 - val_binary_accuracy: 0.9095 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9106 - loss: 0.2593 - val_auc: 0.8034 - val_binary_accuracy: 0.9098 - val_loss: 0.2566\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9110 - loss: 0.2589 - val_auc: 0.8048 - val_binary_accuracy: 0.9095 - val_loss: 0.2562\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9112 - loss: 0.2584 - val_auc: 0.8057 - val_binary_accuracy: 0.9097 - val_loss: 0.2557\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7869 - binary_accuracy: 0.9091 - loss: 0.2618\n",
      "Fold 4 Metrics: Loss = 0.2557, Accuracy = 0.9097, AUC = 0.8057\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5867 - binary_accuracy: 0.9040 - loss: 0.3168 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9041 - loss: 0.2742 - val_auc: 0.7943 - val_binary_accuracy: 0.9073 - val_loss: 0.2612\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9042 - loss: 0.2710 - val_auc: 0.7981 - val_binary_accuracy: 0.9069 - val_loss: 0.2596\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9065 - loss: 0.2689 - val_auc: 0.8007 - val_binary_accuracy: 0.9091 - val_loss: 0.2583\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9083 - loss: 0.2673 - val_auc: 0.8028 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9082 - loss: 0.2659 - val_auc: 0.8045 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9090 - loss: 0.2647 - val_auc: 0.8057 - val_binary_accuracy: 0.9106 - val_loss: 0.2546\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.8075 - val_binary_accuracy: 0.9110 - val_loss: 0.2534\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9094 - loss: 0.2629 - val_auc: 0.8077 - val_binary_accuracy: 0.9115 - val_loss: 0.2524\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9095 - loss: 0.2620 - val_auc: 0.8085 - val_binary_accuracy: 0.9121 - val_loss: 0.2518\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9102 - loss: 0.2490\n",
      "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9121, AUC = 0.8085\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2558\n",
      "Average Accuracy: 0.9101\n",
      "Average AUC: 0.8038\n",
      "----------------------------------------\n",
      "Performing training for: ('sigmoid', 5, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5900 - binary_accuracy: 0.8901 - loss: 0.3228 - val_auc: 0.7708 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2701\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2596 - val_auc: 0.7834 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9072 - loss: 0.2571 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9102 - loss: 0.2549 - val_auc: 0.7906 - val_binary_accuracy: 0.9065 - val_loss: 0.2654\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9115 - loss: 0.2530 - val_auc: 0.7923 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8049 - binary_accuracy: 0.9119 - loss: 0.2514 - val_auc: 0.7938 - val_binary_accuracy: 0.9088 - val_loss: 0.2632\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9124 - loss: 0.2502 - val_auc: 0.7938 - val_binary_accuracy: 0.9087 - val_loss: 0.2623\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9131 - loss: 0.2493 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2613\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9128 - loss: 0.2484 - val_auc: 0.7945 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7941 - binary_accuracy: 0.9117 - loss: 0.2521\n",
      "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9085, AUC = 0.7945\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5756 - binary_accuracy: 0.8847 - loss: 0.3358 - val_auc: 0.7968 - val_binary_accuracy: 0.9042 - val_loss: 0.2679\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.8036 - val_binary_accuracy: 0.9042 - val_loss: 0.2654\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9041 - loss: 0.2690 - val_auc: 0.8057 - val_binary_accuracy: 0.9047 - val_loss: 0.2633\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9062 - loss: 0.2658 - val_auc: 0.8066 - val_binary_accuracy: 0.9066 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9066 - loss: 0.2637 - val_auc: 0.8076 - val_binary_accuracy: 0.9068 - val_loss: 0.2605\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9075 - loss: 0.2621 - val_auc: 0.8079 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9077 - loss: 0.2610 - val_auc: 0.8076 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9080 - loss: 0.2603 - val_auc: 0.8082 - val_binary_accuracy: 0.9079 - val_loss: 0.2599\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8012 - binary_accuracy: 0.9078 - loss: 0.2597 - val_auc: 0.8088 - val_binary_accuracy: 0.9079 - val_loss: 0.2595\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9080 - loss: 0.2593 - val_auc: 0.8085 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9116 - loss: 0.2494\n",
      "Fold 2 Metrics: Loss = 0.2590, Accuracy = 0.9078, AUC = 0.8085\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - auc: 0.5779 - binary_accuracy: 0.8865 - loss: 0.3352 - val_auc: 0.7785 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7545 - binary_accuracy: 0.9051 - loss: 0.2757 - val_auc: 0.7834 - val_binary_accuracy: 0.9042 - val_loss: 0.2678\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9051 - loss: 0.2719 - val_auc: 0.7873 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9051 - loss: 0.2700 - val_auc: 0.7896 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9054 - loss: 0.2687 - val_auc: 0.7923 - val_binary_accuracy: 0.9090 - val_loss: 0.2638\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9068 - loss: 0.2675 - val_auc: 0.7952 - val_binary_accuracy: 0.9099 - val_loss: 0.2624\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9082 - loss: 0.2664 - val_auc: 0.7980 - val_binary_accuracy: 0.9109 - val_loss: 0.2612\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9087 - loss: 0.2653 - val_auc: 0.7999 - val_binary_accuracy: 0.9107 - val_loss: 0.2601\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9091 - loss: 0.2644 - val_auc: 0.8019 - val_binary_accuracy: 0.9107 - val_loss: 0.2591\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8037 - val_binary_accuracy: 0.9112 - val_loss: 0.2580\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9126 - loss: 0.2589\n",
      "Fold 3 Metrics: Loss = 0.2580, Accuracy = 0.9112, AUC = 0.8037\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5519 - binary_accuracy: 0.8866 - loss: 0.3507 - val_auc: 0.7860 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9047 - loss: 0.2698 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2636\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9054 - loss: 0.2668 - val_auc: 0.7966 - val_binary_accuracy: 0.9081 - val_loss: 0.2608\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9080 - loss: 0.2648 - val_auc: 0.7992 - val_binary_accuracy: 0.9094 - val_loss: 0.2593\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8004 - val_binary_accuracy: 0.9090 - val_loss: 0.2582\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9098 - loss: 0.2620 - val_auc: 0.8016 - val_binary_accuracy: 0.9090 - val_loss: 0.2577\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9104 - loss: 0.2611 - val_auc: 0.8030 - val_binary_accuracy: 0.9084 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9107 - loss: 0.2603 - val_auc: 0.8049 - val_binary_accuracy: 0.9091 - val_loss: 0.2563\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9109 - loss: 0.2596 - val_auc: 0.8061 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9112 - loss: 0.2591 - val_auc: 0.8070 - val_binary_accuracy: 0.9093 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9092 - loss: 0.2622\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9093, AUC = 0.8070\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5931 - binary_accuracy: 0.9040 - loss: 0.3197 - val_auc: 0.7878 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9040 - loss: 0.2748 - val_auc: 0.7934 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9041 - loss: 0.2720 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2633\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9048 - loss: 0.2699 - val_auc: 0.7999 - val_binary_accuracy: 0.9093 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9070 - loss: 0.2679 - val_auc: 0.8018 - val_binary_accuracy: 0.9091 - val_loss: 0.2620\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9085 - loss: 0.2664 - val_auc: 0.8035 - val_binary_accuracy: 0.9097 - val_loss: 0.2618\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9081 - loss: 0.2652 - val_auc: 0.8056 - val_binary_accuracy: 0.9097 - val_loss: 0.2613\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9090 - loss: 0.2642 - val_auc: 0.8070 - val_binary_accuracy: 0.9101 - val_loss: 0.2605\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9092 - loss: 0.2633 - val_auc: 0.8072 - val_binary_accuracy: 0.9097 - val_loss: 0.2595\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9093 - loss: 0.2627 - val_auc: 0.8085 - val_binary_accuracy: 0.9103 - val_loss: 0.2583\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8171 - binary_accuracy: 0.9119 - loss: 0.2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 67%|   | 2/3 [55:17<27:40, 1660.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Metrics: Loss = 0.2583, Accuracy = 0.9103, AUC = 0.8085\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2582\n",
      "Average Accuracy: 0.9094\n",
      "Average AUC: 0.8044\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 1, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5266 - binary_accuracy: 0.6977 - loss: 0.5188 - val_auc: 0.6882 - val_binary_accuracy: 0.9041 - val_loss: 0.2958\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7066 - binary_accuracy: 0.9069 - loss: 0.2843 - val_auc: 0.7156 - val_binary_accuracy: 0.9044 - val_loss: 0.2857\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7444 - binary_accuracy: 0.9069 - loss: 0.2756 - val_auc: 0.7374 - val_binary_accuracy: 0.9042 - val_loss: 0.2824\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7606 - binary_accuracy: 0.9069 - loss: 0.2714 - val_auc: 0.7393 - val_binary_accuracy: 0.9044 - val_loss: 0.2792\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9069 - loss: 0.2688 - val_auc: 0.7333 - val_binary_accuracy: 0.9044 - val_loss: 0.2777\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7395 - val_binary_accuracy: 0.9044 - val_loss: 0.2770\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9069 - loss: 0.2660 - val_auc: 0.7345 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9069 - loss: 0.2652 - val_auc: 0.7471 - val_binary_accuracy: 0.9041 - val_loss: 0.2758\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9069 - loss: 0.2645 - val_auc: 0.7442 - val_binary_accuracy: 0.9041 - val_loss: 0.2753\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9069 - loss: 0.2639 - val_auc: 0.7444 - val_binary_accuracy: 0.9041 - val_loss: 0.2749\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7428 - binary_accuracy: 0.9081 - loss: 0.2662\n",
      "Fold 1 Metrics: Loss = 0.2749, Accuracy = 0.9041, AUC = 0.7444\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5584 - binary_accuracy: 0.7373 - loss: 0.5031 - val_auc: 0.7282 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7379 - binary_accuracy: 0.9029 - loss: 0.2878 - val_auc: 0.7527 - val_binary_accuracy: 0.9042 - val_loss: 0.2819\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7542 - binary_accuracy: 0.9029 - loss: 0.2822 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7659 - binary_accuracy: 0.9029 - loss: 0.2775 - val_auc: 0.7833 - val_binary_accuracy: 0.9042 - val_loss: 0.2716\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2734 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7802 - binary_accuracy: 0.9029 - loss: 0.2704 - val_auc: 0.7926 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2685 - val_auc: 0.7953 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7872 - binary_accuracy: 0.9043 - loss: 0.2676 - val_auc: 0.7943 - val_binary_accuracy: 0.9053 - val_loss: 0.2657\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9072 - loss: 0.2666 - val_auc: 0.7934 - val_binary_accuracy: 0.9065 - val_loss: 0.2658\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7911 - val_binary_accuracy: 0.9076 - val_loss: 0.2662\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9112 - loss: 0.2568\n",
      "Fold 2 Metrics: Loss = 0.2662, Accuracy = 0.9076, AUC = 0.7911\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5662 - binary_accuracy: 0.8890 - loss: 0.3588 - val_auc: 0.7475 - val_binary_accuracy: 0.9042 - val_loss: 0.2856\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7347 - binary_accuracy: 0.9051 - loss: 0.2849 - val_auc: 0.7552 - val_binary_accuracy: 0.9042 - val_loss: 0.2783\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7453 - binary_accuracy: 0.9051 - loss: 0.2784 - val_auc: 0.7623 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7551 - binary_accuracy: 0.9051 - loss: 0.2734 - val_auc: 0.7645 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7613 - binary_accuracy: 0.9051 - loss: 0.2702 - val_auc: 0.7666 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7656 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7695 - val_binary_accuracy: 0.9042 - val_loss: 0.2701\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2667 - val_auc: 0.7708 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9051 - loss: 0.2656 - val_auc: 0.7716 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9051 - loss: 0.2645 - val_auc: 0.7711 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9051 - loss: 0.2637 - val_auc: 0.7710 - val_binary_accuracy: 0.9042 - val_loss: 0.2683\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7722 - binary_accuracy: 0.9046 - loss: 0.2666\n",
      "Fold 3 Metrics: Loss = 0.2683, Accuracy = 0.9042, AUC = 0.7710\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6024 - binary_accuracy: 0.9021 - loss: 0.3401 - val_auc: 0.7602 - val_binary_accuracy: 0.9044 - val_loss: 0.2823\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7582 - binary_accuracy: 0.9047 - loss: 0.2790 - val_auc: 0.7630 - val_binary_accuracy: 0.9044 - val_loss: 0.2767\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9047 - loss: 0.2731 - val_auc: 0.7760 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9047 - loss: 0.2720 - val_auc: 0.7770 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7708 - binary_accuracy: 0.9047 - loss: 0.2704 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7707 - binary_accuracy: 0.9047 - loss: 0.2693 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9047 - loss: 0.2689 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2709\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9047 - loss: 0.2682 - val_auc: 0.7795 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9048 - loss: 0.2670 - val_auc: 0.7808 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9074 - loss: 0.2667 - val_auc: 0.7824 - val_binary_accuracy: 0.9048 - val_loss: 0.2698\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7642 - binary_accuracy: 0.9049 - loss: 0.2719\n",
      "Fold 4 Metrics: Loss = 0.2698, Accuracy = 0.9048, AUC = 0.7824\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5597 - binary_accuracy: 0.8180 - loss: 0.4326 - val_auc: 0.7197 - val_binary_accuracy: 0.9044 - val_loss: 0.2887\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7302 - binary_accuracy: 0.9040 - loss: 0.2872 - val_auc: 0.7675 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9040 - loss: 0.2770 - val_auc: 0.7802 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9040 - loss: 0.2736 - val_auc: 0.7830 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9049 - loss: 0.2708 - val_auc: 0.7877 - val_binary_accuracy: 0.9060 - val_loss: 0.2647\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9062 - loss: 0.2690 - val_auc: 0.7919 - val_binary_accuracy: 0.9075 - val_loss: 0.2610\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9074 - loss: 0.2680 - val_auc: 0.7888 - val_binary_accuracy: 0.9078 - val_loss: 0.2629\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9072 - loss: 0.2666 - val_auc: 0.7949 - val_binary_accuracy: 0.9094 - val_loss: 0.2591\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9082 - loss: 0.2663 - val_auc: 0.7945 - val_binary_accuracy: 0.9097 - val_loss: 0.2593\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9084 - loss: 0.2655 - val_auc: 0.7912 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8006 - binary_accuracy: 0.9073 - loss: 0.2610\n",
      "Fold 5 Metrics: Loss = 0.2611, Accuracy = 0.9094, AUC = 0.7912\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2680\n",
      "Average Accuracy: 0.9060\n",
      "Average AUC: 0.7760\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 1, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6618 - binary_accuracy: 0.7700 - loss: 0.4375 - val_auc: 0.7479 - val_binary_accuracy: 0.9044 - val_loss: 0.2784\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9069 - loss: 0.2648 - val_auc: 0.7617 - val_binary_accuracy: 0.9068 - val_loss: 0.2727\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9091 - loss: 0.2596 - val_auc: 0.7696 - val_binary_accuracy: 0.9079 - val_loss: 0.2694\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9095 - loss: 0.2574 - val_auc: 0.7734 - val_binary_accuracy: 0.9081 - val_loss: 0.2678\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9104 - loss: 0.2564 - val_auc: 0.7732 - val_binary_accuracy: 0.9087 - val_loss: 0.2672\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9107 - loss: 0.2558 - val_auc: 0.7736 - val_binary_accuracy: 0.9090 - val_loss: 0.2666\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9107 - loss: 0.2551 - val_auc: 0.7745 - val_binary_accuracy: 0.9088 - val_loss: 0.2660\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7958 - binary_accuracy: 0.9107 - loss: 0.2548 - val_auc: 0.7762 - val_binary_accuracy: 0.9091 - val_loss: 0.2655\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9113 - loss: 0.2546 - val_auc: 0.7766 - val_binary_accuracy: 0.9091 - val_loss: 0.2650\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9121 - loss: 0.2540 - val_auc: 0.7768 - val_binary_accuracy: 0.9093 - val_loss: 0.2646\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7754 - binary_accuracy: 0.9131 - loss: 0.2572\n",
      "Fold 1 Metrics: Loss = 0.2646, Accuracy = 0.9093, AUC = 0.7768\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6894 - binary_accuracy: 0.9016 - loss: 0.3190 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7709 - binary_accuracy: 0.9029 - loss: 0.2740 - val_auc: 0.7883 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9037 - loss: 0.2711 - val_auc: 0.7929 - val_binary_accuracy: 0.9042 - val_loss: 0.2669\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9057 - loss: 0.2695 - val_auc: 0.7960 - val_binary_accuracy: 0.9050 - val_loss: 0.2655\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9069 - loss: 0.2677 - val_auc: 0.7993 - val_binary_accuracy: 0.9056 - val_loss: 0.2648\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9070 - loss: 0.2667 - val_auc: 0.8006 - val_binary_accuracy: 0.9065 - val_loss: 0.2644\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9062 - loss: 0.2661 - val_auc: 0.8025 - val_binary_accuracy: 0.9065 - val_loss: 0.2614\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9066 - loss: 0.2653 - val_auc: 0.8017 - val_binary_accuracy: 0.9071 - val_loss: 0.2617\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9068 - loss: 0.2647 - val_auc: 0.8018 - val_binary_accuracy: 0.9078 - val_loss: 0.2604\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9070 - loss: 0.2630 - val_auc: 0.8031 - val_binary_accuracy: 0.9078 - val_loss: 0.2610\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8067 - binary_accuracy: 0.9119 - loss: 0.2508\n",
      "Fold 2 Metrics: Loss = 0.2610, Accuracy = 0.9078, AUC = 0.8031\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6874 - binary_accuracy: 0.8978 - loss: 0.3120 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2732\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7691 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7731 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7778 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9051 - loss: 0.2667 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7767 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7801 - val_binary_accuracy: 0.9047 - val_loss: 0.2676\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7792 - binary_accuracy: 0.9063 - loss: 0.2644 - val_auc: 0.7807 - val_binary_accuracy: 0.9069 - val_loss: 0.2670\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7811 - binary_accuracy: 0.9069 - loss: 0.2635 - val_auc: 0.7826 - val_binary_accuracy: 0.9075 - val_loss: 0.2663\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9071 - loss: 0.2626 - val_auc: 0.7835 - val_binary_accuracy: 0.9081 - val_loss: 0.2658\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7845 - binary_accuracy: 0.9075 - loss: 0.2619 - val_auc: 0.7850 - val_binary_accuracy: 0.9087 - val_loss: 0.2658\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7841 - binary_accuracy: 0.9077 - loss: 0.2616 - val_auc: 0.7867 - val_binary_accuracy: 0.9087 - val_loss: 0.2646\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7809 - binary_accuracy: 0.9096 - loss: 0.2653\n",
      "Fold 3 Metrics: Loss = 0.2646, Accuracy = 0.9087, AUC = 0.7867\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6057 - binary_accuracy: 0.6792 - loss: 0.5916 - val_auc: 0.7379 - val_binary_accuracy: 0.9044 - val_loss: 0.2846\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7347 - binary_accuracy: 0.9047 - loss: 0.2840 - val_auc: 0.7619 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7603 - binary_accuracy: 0.9048 - loss: 0.2746 - val_auc: 0.7738 - val_binary_accuracy: 0.9053 - val_loss: 0.2711\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7704 - binary_accuracy: 0.9059 - loss: 0.2706 - val_auc: 0.7752 - val_binary_accuracy: 0.9050 - val_loss: 0.2708\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7742 - binary_accuracy: 0.9068 - loss: 0.2688 - val_auc: 0.7797 - val_binary_accuracy: 0.9059 - val_loss: 0.2690\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7792 - binary_accuracy: 0.9080 - loss: 0.2661 - val_auc: 0.7833 - val_binary_accuracy: 0.9072 - val_loss: 0.2668\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9075 - loss: 0.2648 - val_auc: 0.7847 - val_binary_accuracy: 0.9085 - val_loss: 0.2656\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.7862 - val_binary_accuracy: 0.9081 - val_loss: 0.2653\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9091 - loss: 0.2630 - val_auc: 0.7871 - val_binary_accuracy: 0.9082 - val_loss: 0.2657\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9091 - loss: 0.2625 - val_auc: 0.7867 - val_binary_accuracy: 0.9082 - val_loss: 0.2664\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7648 - binary_accuracy: 0.9080 - loss: 0.2720\n",
      "Fold 4 Metrics: Loss = 0.2664, Accuracy = 0.9082, AUC = 0.7867\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6366 - binary_accuracy: 0.8897 - loss: 0.3399 - val_auc: 0.7799 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7812 - val_binary_accuracy: 0.9044 - val_loss: 0.2659\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7665 - binary_accuracy: 0.9043 - loss: 0.2737 - val_auc: 0.7878 - val_binary_accuracy: 0.9048 - val_loss: 0.2625\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7714 - binary_accuracy: 0.9061 - loss: 0.2713 - val_auc: 0.7884 - val_binary_accuracy: 0.9054 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7717 - binary_accuracy: 0.9065 - loss: 0.2710 - val_auc: 0.7891 - val_binary_accuracy: 0.9057 - val_loss: 0.2612\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2707 - val_auc: 0.7896 - val_binary_accuracy: 0.9066 - val_loss: 0.2603\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9072 - loss: 0.2694 - val_auc: 0.7900 - val_binary_accuracy: 0.9067 - val_loss: 0.2599\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9074 - loss: 0.2688 - val_auc: 0.7916 - val_binary_accuracy: 0.9084 - val_loss: 0.2593\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9073 - loss: 0.2686 - val_auc: 0.7900 - val_binary_accuracy: 0.9088 - val_loss: 0.2590\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9075 - loss: 0.2680 - val_auc: 0.7930 - val_binary_accuracy: 0.9084 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8015 - binary_accuracy: 0.9076 - loss: 0.2594\n",
      "Fold 5 Metrics: Loss = 0.2586, Accuracy = 0.9084, AUC = 0.7930\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2630\n",
      "Average Accuracy: 0.9085\n",
      "Average AUC: 0.7892\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 1, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7272 - binary_accuracy: 0.9069 - loss: 0.2821 - val_auc: 0.7683 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9069 - loss: 0.2599 - val_auc: 0.7758 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9073 - loss: 0.2565 - val_auc: 0.7821 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9078 - loss: 0.2540 - val_auc: 0.7857 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9090 - loss: 0.2519 - val_auc: 0.7861 - val_binary_accuracy: 0.9072 - val_loss: 0.2627\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9106 - loss: 0.2507 - val_auc: 0.7890 - val_binary_accuracy: 0.9079 - val_loss: 0.2617\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8086 - binary_accuracy: 0.9114 - loss: 0.2500 - val_auc: 0.7901 - val_binary_accuracy: 0.9088 - val_loss: 0.2606\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8097 - binary_accuracy: 0.9125 - loss: 0.2490 - val_auc: 0.7901 - val_binary_accuracy: 0.9103 - val_loss: 0.2601\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9131 - loss: 0.2481 - val_auc: 0.7910 - val_binary_accuracy: 0.9100 - val_loss: 0.2597\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9127 - loss: 0.2478 - val_auc: 0.7913 - val_binary_accuracy: 0.9104 - val_loss: 0.2595\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7898 - binary_accuracy: 0.9133 - loss: 0.2522\n",
      "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9104, AUC = 0.7913\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6781 - binary_accuracy: 0.9029 - loss: 0.3073 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2719 - val_auc: 0.7997 - val_binary_accuracy: 0.9042 - val_loss: 0.2645\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9035 - loss: 0.2684 - val_auc: 0.8021 - val_binary_accuracy: 0.9045 - val_loss: 0.2634\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9052 - loss: 0.2665 - val_auc: 0.8043 - val_binary_accuracy: 0.9057 - val_loss: 0.2623\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9057 - loss: 0.2656 - val_auc: 0.8046 - val_binary_accuracy: 0.9069 - val_loss: 0.2592\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7906 - binary_accuracy: 0.9071 - loss: 0.2644 - val_auc: 0.8049 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9077 - loss: 0.2635 - val_auc: 0.8068 - val_binary_accuracy: 0.9081 - val_loss: 0.2588\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7944 - binary_accuracy: 0.9078 - loss: 0.2625 - val_auc: 0.8068 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7956 - binary_accuracy: 0.9087 - loss: 0.2621 - val_auc: 0.8081 - val_binary_accuracy: 0.9088 - val_loss: 0.2593\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9082 - loss: 0.2617 - val_auc: 0.8089 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8161 - binary_accuracy: 0.9124 - loss: 0.2463\n",
      "Fold 2 Metrics: Loss = 0.2576, Accuracy = 0.9094, AUC = 0.8089\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7279 - binary_accuracy: 0.9051 - loss: 0.2831 - val_auc: 0.7758 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9055 - loss: 0.2684 - val_auc: 0.7836 - val_binary_accuracy: 0.9063 - val_loss: 0.2677\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9068 - loss: 0.2654 - val_auc: 0.7907 - val_binary_accuracy: 0.9088 - val_loss: 0.2641\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9079 - loss: 0.2637 - val_auc: 0.7966 - val_binary_accuracy: 0.9096 - val_loss: 0.2616\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9080 - loss: 0.2620 - val_auc: 0.8013 - val_binary_accuracy: 0.9102 - val_loss: 0.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9091 - loss: 0.2613 - val_auc: 0.8036 - val_binary_accuracy: 0.9100 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9089 - loss: 0.2605 - val_auc: 0.8052 - val_binary_accuracy: 0.9109 - val_loss: 0.2573\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7884 - binary_accuracy: 0.9092 - loss: 0.2602 - val_auc: 0.8060 - val_binary_accuracy: 0.9112 - val_loss: 0.2567\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9095 - loss: 0.2596 - val_auc: 0.8072 - val_binary_accuracy: 0.9112 - val_loss: 0.2562\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9095 - loss: 0.2590 - val_auc: 0.8076 - val_binary_accuracy: 0.9113 - val_loss: 0.2559\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8000 - binary_accuracy: 0.9124 - loss: 0.2562\n",
      "Fold 3 Metrics: Loss = 0.2559, Accuracy = 0.9113, AUC = 0.8076\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6208 - binary_accuracy: 0.7267 - loss: 0.6144 - val_auc: 0.7587 - val_binary_accuracy: 0.9044 - val_loss: 0.2768\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7610 - binary_accuracy: 0.9047 - loss: 0.2750 - val_auc: 0.7804 - val_binary_accuracy: 0.9045 - val_loss: 0.2693\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9057 - loss: 0.2667 - val_auc: 0.7873 - val_binary_accuracy: 0.9050 - val_loss: 0.2670\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9066 - loss: 0.2642 - val_auc: 0.7935 - val_binary_accuracy: 0.9057 - val_loss: 0.2660\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7865 - binary_accuracy: 0.9071 - loss: 0.2629 - val_auc: 0.7933 - val_binary_accuracy: 0.9079 - val_loss: 0.2636\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9075 - loss: 0.2619 - val_auc: 0.7934 - val_binary_accuracy: 0.9069 - val_loss: 0.2662\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9088 - loss: 0.2614 - val_auc: 0.7942 - val_binary_accuracy: 0.9078 - val_loss: 0.2659\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9093 - loss: 0.2606 - val_auc: 0.7964 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9094 - loss: 0.2599 - val_auc: 0.7970 - val_binary_accuracy: 0.9085 - val_loss: 0.2636\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7927 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.7980 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7776 - binary_accuracy: 0.9085 - loss: 0.2684\n",
      "Fold 4 Metrics: Loss = 0.2631, Accuracy = 0.9082, AUC = 0.7980\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7277 - binary_accuracy: 0.9040 - loss: 0.2875 - val_auc: 0.7910 - val_binary_accuracy: 0.9057 - val_loss: 0.2616\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9043 - loss: 0.2694 - val_auc: 0.7962 - val_binary_accuracy: 0.9054 - val_loss: 0.2582\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9063 - loss: 0.2659 - val_auc: 0.7976 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9069 - loss: 0.2637 - val_auc: 0.8015 - val_binary_accuracy: 0.9081 - val_loss: 0.2557\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9072 - loss: 0.2636 - val_auc: 0.8047 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8041 - val_binary_accuracy: 0.9094 - val_loss: 0.2534\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9085 - loss: 0.2607 - val_auc: 0.8050 - val_binary_accuracy: 0.9097 - val_loss: 0.2531\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7957 - binary_accuracy: 0.9087 - loss: 0.2601 - val_auc: 0.8056 - val_binary_accuracy: 0.9103 - val_loss: 0.2528\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7969 - binary_accuracy: 0.9093 - loss: 0.2594 - val_auc: 0.8049 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7966 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.8069 - val_binary_accuracy: 0.9110 - val_loss: 0.2523\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9089 - loss: 0.2508\n",
      "Fold 5 Metrics: Loss = 0.2523, Accuracy = 0.9110, AUC = 0.8069\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2577\n",
      "Average Accuracy: 0.9101\n",
      "Average AUC: 0.8025\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 1, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7450 - binary_accuracy: 0.9069 - loss: 0.2758 - val_auc: 0.7784 - val_binary_accuracy: 0.9056 - val_loss: 0.2687\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7951 - binary_accuracy: 0.9083 - loss: 0.2566 - val_auc: 0.7872 - val_binary_accuracy: 0.9053 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9087 - loss: 0.2532 - val_auc: 0.7890 - val_binary_accuracy: 0.9069 - val_loss: 0.2620\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8047 - binary_accuracy: 0.9116 - loss: 0.2515 - val_auc: 0.7903 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9125 - loss: 0.2502 - val_auc: 0.7907 - val_binary_accuracy: 0.9084 - val_loss: 0.2609\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8094 - binary_accuracy: 0.9126 - loss: 0.2490 - val_auc: 0.7918 - val_binary_accuracy: 0.9096 - val_loss: 0.2603\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8102 - binary_accuracy: 0.9125 - loss: 0.2482 - val_auc: 0.7943 - val_binary_accuracy: 0.9094 - val_loss: 0.2590\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8120 - binary_accuracy: 0.9126 - loss: 0.2471 - val_auc: 0.7947 - val_binary_accuracy: 0.9097 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8136 - binary_accuracy: 0.9134 - loss: 0.2463 - val_auc: 0.7955 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8152 - binary_accuracy: 0.9136 - loss: 0.2457 - val_auc: 0.7972 - val_binary_accuracy: 0.9094 - val_loss: 0.2584\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9130 - loss: 0.2519\n",
      "Fold 1 Metrics: Loss = 0.2584, Accuracy = 0.9094, AUC = 0.7972\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6504 - binary_accuracy: 0.7876 - loss: 0.4939 - val_auc: 0.7916 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7828 - binary_accuracy: 0.9029 - loss: 0.2700 - val_auc: 0.8022 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7915 - binary_accuracy: 0.9042 - loss: 0.2653 - val_auc: 0.8065 - val_binary_accuracy: 0.9045 - val_loss: 0.2610\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9061 - loss: 0.2631 - val_auc: 0.8095 - val_binary_accuracy: 0.9056 - val_loss: 0.2591\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9067 - loss: 0.2620 - val_auc: 0.8092 - val_binary_accuracy: 0.9063 - val_loss: 0.2585\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9075 - loss: 0.2608 - val_auc: 0.8089 - val_binary_accuracy: 0.9069 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7989 - binary_accuracy: 0.9084 - loss: 0.2606 - val_auc: 0.8106 - val_binary_accuracy: 0.9073 - val_loss: 0.2573\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8010 - binary_accuracy: 0.9082 - loss: 0.2597 - val_auc: 0.8104 - val_binary_accuracy: 0.9078 - val_loss: 0.2573\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9086 - loss: 0.2596 - val_auc: 0.8090 - val_binary_accuracy: 0.9075 - val_loss: 0.2577\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8022 - binary_accuracy: 0.9076 - loss: 0.2593 - val_auc: 0.8099 - val_binary_accuracy: 0.9081 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8163 - binary_accuracy: 0.9121 - loss: 0.2474\n",
      "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9081, AUC = 0.8099\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6593 - binary_accuracy: 0.8358 - loss: 0.3686 - val_auc: 0.7730 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9056 - loss: 0.2678 - val_auc: 0.7836 - val_binary_accuracy: 0.9072 - val_loss: 0.2660\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9079 - loss: 0.2644 - val_auc: 0.7903 - val_binary_accuracy: 0.9090 - val_loss: 0.2631\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9084 - loss: 0.2629 - val_auc: 0.7951 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9092 - loss: 0.2618 - val_auc: 0.7962 - val_binary_accuracy: 0.9097 - val_loss: 0.2599\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9095 - loss: 0.2610 - val_auc: 0.7950 - val_binary_accuracy: 0.9096 - val_loss: 0.2597\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9091 - loss: 0.2602 - val_auc: 0.7995 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9096 - loss: 0.2593 - val_auc: 0.8022 - val_binary_accuracy: 0.9106 - val_loss: 0.2576\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7903 - binary_accuracy: 0.9098 - loss: 0.2591 - val_auc: 0.8015 - val_binary_accuracy: 0.9109 - val_loss: 0.2574\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7908 - binary_accuracy: 0.9093 - loss: 0.2590 - val_auc: 0.8032 - val_binary_accuracy: 0.9113 - val_loss: 0.2575\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7936 - binary_accuracy: 0.9123 - loss: 0.2592\n",
      "Fold 3 Metrics: Loss = 0.2575, Accuracy = 0.9113, AUC = 0.8032\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7258 - binary_accuracy: 0.9049 - loss: 0.2833 - val_auc: 0.7871 - val_binary_accuracy: 0.9054 - val_loss: 0.2654\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9080 - loss: 0.2650 - val_auc: 0.7945 - val_binary_accuracy: 0.9079 - val_loss: 0.2623\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7878 - binary_accuracy: 0.9099 - loss: 0.2616 - val_auc: 0.7993 - val_binary_accuracy: 0.9078 - val_loss: 0.2598\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9104 - loss: 0.2595 - val_auc: 0.7999 - val_binary_accuracy: 0.9079 - val_loss: 0.2598\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7929 - binary_accuracy: 0.9102 - loss: 0.2587 - val_auc: 0.8000 - val_binary_accuracy: 0.9090 - val_loss: 0.2591\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9101 - loss: 0.2590 - val_auc: 0.8015 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9104 - loss: 0.2579 - val_auc: 0.8010 - val_binary_accuracy: 0.9091 - val_loss: 0.2589\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9102 - loss: 0.2578 - val_auc: 0.8010 - val_binary_accuracy: 0.9091 - val_loss: 0.2586\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7952 - binary_accuracy: 0.9102 - loss: 0.2577 - val_auc: 0.8026 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7966 - binary_accuracy: 0.9102 - loss: 0.2569 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2589\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7858 - binary_accuracy: 0.9084 - loss: 0.2648\n",
      "Fold 4 Metrics: Loss = 0.2589, Accuracy = 0.9087, AUC = 0.8037\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7170 - binary_accuracy: 0.9007 - loss: 0.2948 - val_auc: 0.7877 - val_binary_accuracy: 0.9045 - val_loss: 0.2642\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7721 - binary_accuracy: 0.9062 - loss: 0.2709 - val_auc: 0.7960 - val_binary_accuracy: 0.9063 - val_loss: 0.2594\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9072 - loss: 0.2680 - val_auc: 0.7969 - val_binary_accuracy: 0.9082 - val_loss: 0.2571\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9080 - loss: 0.2658 - val_auc: 0.8007 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9079 - loss: 0.2643 - val_auc: 0.8047 - val_binary_accuracy: 0.9095 - val_loss: 0.2544\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9085 - loss: 0.2628 - val_auc: 0.8059 - val_binary_accuracy: 0.9100 - val_loss: 0.2533\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9089 - loss: 0.2621 - val_auc: 0.8063 - val_binary_accuracy: 0.9106 - val_loss: 0.2530\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9094 - loss: 0.2615 - val_auc: 0.8069 - val_binary_accuracy: 0.9106 - val_loss: 0.2523\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9098 - loss: 0.2609 - val_auc: 0.8058 - val_binary_accuracy: 0.9100 - val_loss: 0.2532\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8063 - val_binary_accuracy: 0.9098 - val_loss: 0.2536\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8166 - binary_accuracy: 0.9075 - loss: 0.2519\n",
      "Fold 5 Metrics: Loss = 0.2536, Accuracy = 0.9098, AUC = 0.8063\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2574\n",
      "Average Accuracy: 0.9095\n",
      "Average AUC: 0.8041\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 1, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7411 - binary_accuracy: 0.9076 - loss: 0.2779 - val_auc: 0.7812 - val_binary_accuracy: 0.9053 - val_loss: 0.2688\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9103 - loss: 0.2552 - val_auc: 0.7894 - val_binary_accuracy: 0.9066 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9114 - loss: 0.2526 - val_auc: 0.7911 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8064 - binary_accuracy: 0.9118 - loss: 0.2506 - val_auc: 0.7926 - val_binary_accuracy: 0.9079 - val_loss: 0.2629\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9121 - loss: 0.2496 - val_auc: 0.7926 - val_binary_accuracy: 0.9076 - val_loss: 0.2626\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9125 - loss: 0.2487 - val_auc: 0.7943 - val_binary_accuracy: 0.9078 - val_loss: 0.2618\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9130 - loss: 0.2482 - val_auc: 0.7932 - val_binary_accuracy: 0.9082 - val_loss: 0.2620\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8119 - binary_accuracy: 0.9131 - loss: 0.2475 - val_auc: 0.7942 - val_binary_accuracy: 0.9084 - val_loss: 0.2607\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8129 - binary_accuracy: 0.9130 - loss: 0.2470 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9132 - loss: 0.2463 - val_auc: 0.7956 - val_binary_accuracy: 0.9081 - val_loss: 0.2602\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9114 - loss: 0.2519\n",
      "Fold 1 Metrics: Loss = 0.2602, Accuracy = 0.9081, AUC = 0.7956\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6722 - binary_accuracy: 0.8454 - loss: 0.3876 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9038 - loss: 0.2691 - val_auc: 0.8036 - val_binary_accuracy: 0.9060 - val_loss: 0.2605\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9059 - loss: 0.2651 - val_auc: 0.8067 - val_binary_accuracy: 0.9065 - val_loss: 0.2591\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9063 - loss: 0.2635 - val_auc: 0.8077 - val_binary_accuracy: 0.9068 - val_loss: 0.2582\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7963 - binary_accuracy: 0.9077 - loss: 0.2620 - val_auc: 0.8086 - val_binary_accuracy: 0.9071 - val_loss: 0.2570\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7978 - binary_accuracy: 0.9075 - loss: 0.2610 - val_auc: 0.8077 - val_binary_accuracy: 0.9075 - val_loss: 0.2579\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7976 - binary_accuracy: 0.9081 - loss: 0.2607 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2573\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9084 - loss: 0.2602 - val_auc: 0.8079 - val_binary_accuracy: 0.9079 - val_loss: 0.2567\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8006 - binary_accuracy: 0.9082 - loss: 0.2595 - val_auc: 0.8077 - val_binary_accuracy: 0.9079 - val_loss: 0.2573\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9081 - loss: 0.2593 - val_auc: 0.8085 - val_binary_accuracy: 0.9082 - val_loss: 0.2571\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8184 - binary_accuracy: 0.9118 - loss: 0.2458\n",
      "Fold 2 Metrics: Loss = 0.2571, Accuracy = 0.9082, AUC = 0.8085\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7200 - binary_accuracy: 0.9013 - loss: 0.2934 - val_auc: 0.7870 - val_binary_accuracy: 0.9059 - val_loss: 0.2656\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9067 - loss: 0.2680 - val_auc: 0.7945 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9078 - loss: 0.2657 - val_auc: 0.7981 - val_binary_accuracy: 0.9090 - val_loss: 0.2602\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9078 - loss: 0.2643 - val_auc: 0.7971 - val_binary_accuracy: 0.9099 - val_loss: 0.2597\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8005 - val_binary_accuracy: 0.9100 - val_loss: 0.2582\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9090 - loss: 0.2627 - val_auc: 0.8011 - val_binary_accuracy: 0.9102 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9092 - loss: 0.2621 - val_auc: 0.8014 - val_binary_accuracy: 0.9106 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9098 - loss: 0.2614 - val_auc: 0.8027 - val_binary_accuracy: 0.9107 - val_loss: 0.2570\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9100 - loss: 0.2608 - val_auc: 0.8022 - val_binary_accuracy: 0.9102 - val_loss: 0.2578\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9096 - loss: 0.2605 - val_auc: 0.8036 - val_binary_accuracy: 0.9106 - val_loss: 0.2570\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9112 - loss: 0.2577\n",
      "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9106, AUC = 0.8036\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7369 - binary_accuracy: 0.9059 - loss: 0.2818 - val_auc: 0.7948 - val_binary_accuracy: 0.9082 - val_loss: 0.2608\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9097 - loss: 0.2631 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2580\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9110 - loss: 0.2609 - val_auc: 0.8008 - val_binary_accuracy: 0.9082 - val_loss: 0.2578\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9107 - loss: 0.2596 - val_auc: 0.8025 - val_binary_accuracy: 0.9085 - val_loss: 0.2570\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9107 - loss: 0.2587 - val_auc: 0.8047 - val_binary_accuracy: 0.9093 - val_loss: 0.2564\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9109 - loss: 0.2581 - val_auc: 0.8047 - val_binary_accuracy: 0.9091 - val_loss: 0.2562\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9107 - loss: 0.2573 - val_auc: 0.8056 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9110 - loss: 0.2574 - val_auc: 0.8054 - val_binary_accuracy: 0.9090 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7958 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2552\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9110 - loss: 0.2564 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2552\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7874 - binary_accuracy: 0.9081 - loss: 0.2626\n",
      "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9081, AUC = 0.8072\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7378 - binary_accuracy: 0.9045 - loss: 0.2839 - val_auc: 0.7956 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9069 - loss: 0.2696 - val_auc: 0.8026 - val_binary_accuracy: 0.9088 - val_loss: 0.2601\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9073 - loss: 0.2684 - val_auc: 0.8037 - val_binary_accuracy: 0.9088 - val_loss: 0.2564\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9081 - loss: 0.2660 - val_auc: 0.8060 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.8079 - val_binary_accuracy: 0.9093 - val_loss: 0.2534\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8073 - val_binary_accuracy: 0.9098 - val_loss: 0.2531\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9087 - loss: 0.2626 - val_auc: 0.8084 - val_binary_accuracy: 0.9095 - val_loss: 0.2527\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9087 - loss: 0.2621 - val_auc: 0.8082 - val_binary_accuracy: 0.9093 - val_loss: 0.2522\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9084 - loss: 0.2617 - val_auc: 0.8076 - val_binary_accuracy: 0.9098 - val_loss: 0.2519\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9090 - loss: 0.2609 - val_auc: 0.8089 - val_binary_accuracy: 0.9101 - val_loss: 0.2515\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9084 - loss: 0.2504\n",
      "Fold 5 Metrics: Loss = 0.2515, Accuracy = 0.9101, AUC = 0.8089\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2562\n",
      "Average Accuracy: 0.9090\n",
      "Average AUC: 0.8047\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 2, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6182 - binary_accuracy: 0.7984 - loss: 0.4154 - val_auc: 0.7467 - val_binary_accuracy: 0.9044 - val_loss: 0.2788\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9069 - loss: 0.2674 - val_auc: 0.7560 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9069 - loss: 0.2627 - val_auc: 0.7626 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9092 - loss: 0.2606 - val_auc: 0.7673 - val_binary_accuracy: 0.9059 - val_loss: 0.2701\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.7688 - val_binary_accuracy: 0.9059 - val_loss: 0.2698\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9106 - loss: 0.2581 - val_auc: 0.7702 - val_binary_accuracy: 0.9069 - val_loss: 0.2683\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9111 - loss: 0.2574 - val_auc: 0.7720 - val_binary_accuracy: 0.9072 - val_loss: 0.2674\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.7714 - val_binary_accuracy: 0.9073 - val_loss: 0.2673\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9111 - loss: 0.2571 - val_auc: 0.7740 - val_binary_accuracy: 0.9076 - val_loss: 0.2669\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9122 - loss: 0.2564 - val_auc: 0.7748 - val_binary_accuracy: 0.9078 - val_loss: 0.2669\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7723 - binary_accuracy: 0.9104 - loss: 0.2597\n",
      "Fold 1 Metrics: Loss = 0.2669, Accuracy = 0.9078, AUC = 0.7748\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5405 - binary_accuracy: 0.9022 - loss: 0.3564 - val_auc: 0.7345 - val_binary_accuracy: 0.9042 - val_loss: 0.2920\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7368 - binary_accuracy: 0.9029 - loss: 0.2893 - val_auc: 0.7651 - val_binary_accuracy: 0.9042 - val_loss: 0.2800\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7604 - binary_accuracy: 0.9029 - loss: 0.2777 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2739\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7654 - binary_accuracy: 0.9029 - loss: 0.2757 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9029 - loss: 0.2744 - val_auc: 0.7915 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9029 - loss: 0.2738 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2696\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9029 - loss: 0.2735 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2732 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9029 - loss: 0.2729 - val_auc: 0.7914 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.7974 - val_binary_accuracy: 0.9042 - val_loss: 0.2669\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7991 - binary_accuracy: 0.9092 - loss: 0.2580\n",
      "Fold 2 Metrics: Loss = 0.2669, Accuracy = 0.9042, AUC = 0.7974\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6537 - binary_accuracy: 0.8582 - loss: 0.3662 - val_auc: 0.7539 - val_binary_accuracy: 0.9042 - val_loss: 0.2782\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9051 - loss: 0.2736 - val_auc: 0.7799 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7812 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9051 - loss: 0.2656 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9051 - loss: 0.2652 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9051 - loss: 0.2646 - val_auc: 0.7864 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2642 - val_auc: 0.7865 - val_binary_accuracy: 0.9042 - val_loss: 0.2679\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9051 - loss: 0.2638 - val_auc: 0.7863 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7823 - binary_accuracy: 0.9046 - loss: 0.2684\n",
      "Fold 3 Metrics: Loss = 0.2677, Accuracy = 0.9042, AUC = 0.7863\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6045 - binary_accuracy: 0.8124 - loss: 0.4151 - val_auc: 0.7433 - val_binary_accuracy: 0.9044 - val_loss: 0.2850\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7468 - binary_accuracy: 0.9047 - loss: 0.2800 - val_auc: 0.7575 - val_binary_accuracy: 0.9044 - val_loss: 0.2764\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9047 - loss: 0.2709 - val_auc: 0.7677 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9050 - loss: 0.2684 - val_auc: 0.7764 - val_binary_accuracy: 0.9050 - val_loss: 0.2710\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9058 - loss: 0.2669 - val_auc: 0.7786 - val_binary_accuracy: 0.9056 - val_loss: 0.2689\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9064 - loss: 0.2661 - val_auc: 0.7781 - val_binary_accuracy: 0.9059 - val_loss: 0.2681\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7784 - binary_accuracy: 0.9072 - loss: 0.2651 - val_auc: 0.7782 - val_binary_accuracy: 0.9064 - val_loss: 0.2687\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.7836 - val_binary_accuracy: 0.9072 - val_loss: 0.2689\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9085 - loss: 0.2639 - val_auc: 0.7846 - val_binary_accuracy: 0.9079 - val_loss: 0.2688\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9081 - loss: 0.2634 - val_auc: 0.7845 - val_binary_accuracy: 0.9081 - val_loss: 0.2687\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7650 - binary_accuracy: 0.9084 - loss: 0.2739\n",
      "Fold 4 Metrics: Loss = 0.2687, Accuracy = 0.9081, AUC = 0.7845\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5155 - binary_accuracy: 0.7282 - loss: 0.5179 - val_auc: 0.6883 - val_binary_accuracy: 0.9044 - val_loss: 0.3035\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6826 - binary_accuracy: 0.9039 - loss: 0.3017 - val_auc: 0.7339 - val_binary_accuracy: 0.9044 - val_loss: 0.2869\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7254 - binary_accuracy: 0.9039 - loss: 0.2886 - val_auc: 0.7520 - val_binary_accuracy: 0.9044 - val_loss: 0.2769\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7356 - binary_accuracy: 0.9039 - loss: 0.2813 - val_auc: 0.7600 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7478 - binary_accuracy: 0.9039 - loss: 0.2801 - val_auc: 0.7637 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7571 - binary_accuracy: 0.9039 - loss: 0.2771 - val_auc: 0.7667 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9039 - loss: 0.2764 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7566 - binary_accuracy: 0.9039 - loss: 0.2760 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7574 - binary_accuracy: 0.9039 - loss: 0.2757 - val_auc: 0.7691 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9039 - loss: 0.2754 - val_auc: 0.7700 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7850 - binary_accuracy: 0.9013 - loss: 0.2659\n",
      "Fold 5 Metrics: Loss = 0.2671, Accuracy = 0.9044, AUC = 0.7700\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2675\n",
      "Average Accuracy: 0.9057\n",
      "Average AUC: 0.7826\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 2, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6210 - binary_accuracy: 0.8316 - loss: 0.3766 - val_auc: 0.7564 - val_binary_accuracy: 0.9044 - val_loss: 0.2802\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9069 - loss: 0.2693 - val_auc: 0.7684 - val_binary_accuracy: 0.9044 - val_loss: 0.2736\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9069 - loss: 0.2634 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9069 - loss: 0.2588 - val_auc: 0.7793 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9069 - loss: 0.2574 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9069 - loss: 0.2565 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9069 - loss: 0.2559 - val_auc: 0.7813 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9069 - loss: 0.2552 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9069 - loss: 0.2545 - val_auc: 0.7845 - val_binary_accuracy: 0.9044 - val_loss: 0.2672\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7878 - binary_accuracy: 0.9084 - loss: 0.2590\n",
      "Fold 1 Metrics: Loss = 0.2672, Accuracy = 0.9044, AUC = 0.7845\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6579 - binary_accuracy: 0.8703 - loss: 0.3423 - val_auc: 0.7854 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9029 - loss: 0.2735 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9034 - loss: 0.2714 - val_auc: 0.7927 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9034 - loss: 0.2691 - val_auc: 0.7955 - val_binary_accuracy: 0.9048 - val_loss: 0.2655\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9051 - loss: 0.2676 - val_auc: 0.7972 - val_binary_accuracy: 0.9051 - val_loss: 0.2669\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9049 - loss: 0.2666 - val_auc: 0.8002 - val_binary_accuracy: 0.9062 - val_loss: 0.2674\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9057 - loss: 0.2654 - val_auc: 0.7997 - val_binary_accuracy: 0.9063 - val_loss: 0.2652\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9066 - loss: 0.2645 - val_auc: 0.8026 - val_binary_accuracy: 0.9059 - val_loss: 0.2649\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9064 - loss: 0.2640 - val_auc: 0.8047 - val_binary_accuracy: 0.9066 - val_loss: 0.2629\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9071 - loss: 0.2631 - val_auc: 0.8060 - val_binary_accuracy: 0.9071 - val_loss: 0.2616\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8109 - binary_accuracy: 0.9111 - loss: 0.2509\n",
      "Fold 2 Metrics: Loss = 0.2616, Accuracy = 0.9071, AUC = 0.8060\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5777 - binary_accuracy: 0.8146 - loss: 0.4277 - val_auc: 0.7277 - val_binary_accuracy: 0.9042 - val_loss: 0.2887\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7181 - binary_accuracy: 0.9051 - loss: 0.2872 - val_auc: 0.7590 - val_binary_accuracy: 0.9042 - val_loss: 0.2760\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7548 - binary_accuracy: 0.9051 - loss: 0.2739 - val_auc: 0.7703 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2695 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2721\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9051 - loss: 0.2681 - val_auc: 0.7765 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7710 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7782 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7795 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7723 - binary_accuracy: 0.9051 - loss: 0.2679 - val_auc: 0.7821 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7848 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7783 - binary_accuracy: 0.9046 - loss: 0.2700\n",
      "Fold 3 Metrics: Loss = 0.2694, Accuracy = 0.9042, AUC = 0.7848\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6428 - binary_accuracy: 0.8646 - loss: 0.3499 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9048 - loss: 0.2689 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9049 - loss: 0.2668 - val_auc: 0.7831 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9062 - loss: 0.2653 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9060 - loss: 0.2640 - val_auc: 0.7878 - val_binary_accuracy: 0.9064 - val_loss: 0.2660\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9068 - loss: 0.2631 - val_auc: 0.7898 - val_binary_accuracy: 0.9070 - val_loss: 0.2658\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9081 - loss: 0.2624 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2640\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9081 - loss: 0.2617 - val_auc: 0.7935 - val_binary_accuracy: 0.9081 - val_loss: 0.2637\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9084 - loss: 0.2609 - val_auc: 0.7947 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9085 - loss: 0.2604 - val_auc: 0.7917 - val_binary_accuracy: 0.9084 - val_loss: 0.2649\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7694 - binary_accuracy: 0.9074 - loss: 0.2708\n",
      "Fold 4 Metrics: Loss = 0.2649, Accuracy = 0.9084, AUC = 0.7917\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6287 - binary_accuracy: 0.8434 - loss: 0.3650 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7647 - binary_accuracy: 0.9040 - loss: 0.2751 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2643\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9040 - loss: 0.2722 - val_auc: 0.7903 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.7912 - val_binary_accuracy: 0.9044 - val_loss: 0.2613\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9040 - loss: 0.2701 - val_auc: 0.7929 - val_binary_accuracy: 0.9044 - val_loss: 0.2607\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2610\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9041 - loss: 0.2688 - val_auc: 0.7926 - val_binary_accuracy: 0.9044 - val_loss: 0.2596\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9046 - loss: 0.2674 - val_auc: 0.7946 - val_binary_accuracy: 0.9054 - val_loss: 0.2588\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9053 - loss: 0.2668 - val_auc: 0.7965 - val_binary_accuracy: 0.9044 - val_loss: 0.2580\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9042 - loss: 0.2663 - val_auc: 0.7954 - val_binary_accuracy: 0.9078 - val_loss: 0.2580\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8084 - binary_accuracy: 0.9055 - loss: 0.2550\n",
      "Fold 5 Metrics: Loss = 0.2580, Accuracy = 0.9078, AUC = 0.7954\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2642\n",
      "Average Accuracy: 0.9064\n",
      "Average AUC: 0.7925\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 2, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7302 - binary_accuracy: 0.9069 - loss: 0.2803 - val_auc: 0.7687 - val_binary_accuracy: 0.9044 - val_loss: 0.2716\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9079 - loss: 0.2593 - val_auc: 0.7789 - val_binary_accuracy: 0.9069 - val_loss: 0.2654\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9100 - loss: 0.2550 - val_auc: 0.7823 - val_binary_accuracy: 0.9068 - val_loss: 0.2640\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9106 - loss: 0.2526 - val_auc: 0.7833 - val_binary_accuracy: 0.9073 - val_loss: 0.2637\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8049 - binary_accuracy: 0.9118 - loss: 0.2509 - val_auc: 0.7853 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8066 - binary_accuracy: 0.9122 - loss: 0.2496 - val_auc: 0.7853 - val_binary_accuracy: 0.9084 - val_loss: 0.2628\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8084 - binary_accuracy: 0.9125 - loss: 0.2487 - val_auc: 0.7856 - val_binary_accuracy: 0.9091 - val_loss: 0.2626\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9130 - loss: 0.2485 - val_auc: 0.7869 - val_binary_accuracy: 0.9096 - val_loss: 0.2618\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8111 - binary_accuracy: 0.9126 - loss: 0.2473 - val_auc: 0.7876 - val_binary_accuracy: 0.9094 - val_loss: 0.2616\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8124 - binary_accuracy: 0.9130 - loss: 0.2466 - val_auc: 0.7878 - val_binary_accuracy: 0.9094 - val_loss: 0.2616\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7879 - binary_accuracy: 0.9129 - loss: 0.2539\n",
      "Fold 1 Metrics: Loss = 0.2616, Accuracy = 0.9094, AUC = 0.7878\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.7044 - binary_accuracy: 0.8960 - loss: 0.3059 - val_auc: 0.7818 - val_binary_accuracy: 0.9051 - val_loss: 0.2685\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9045 - loss: 0.2723 - val_auc: 0.7957 - val_binary_accuracy: 0.9057 - val_loss: 0.2623\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9050 - loss: 0.2676 - val_auc: 0.8027 - val_binary_accuracy: 0.9054 - val_loss: 0.2587\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9061 - loss: 0.2645 - val_auc: 0.8040 - val_binary_accuracy: 0.9059 - val_loss: 0.2576\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9062 - loss: 0.2628 - val_auc: 0.8042 - val_binary_accuracy: 0.9062 - val_loss: 0.2574\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9073 - loss: 0.2617 - val_auc: 0.8032 - val_binary_accuracy: 0.9065 - val_loss: 0.2574\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9070 - loss: 0.2612 - val_auc: 0.8021 - val_binary_accuracy: 0.9069 - val_loss: 0.2572\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9074 - loss: 0.2604 - val_auc: 0.8037 - val_binary_accuracy: 0.9068 - val_loss: 0.2576\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9072 - loss: 0.2599 - val_auc: 0.8041 - val_binary_accuracy: 0.9066 - val_loss: 0.2578\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8020 - binary_accuracy: 0.9071 - loss: 0.2595 - val_auc: 0.8032 - val_binary_accuracy: 0.9066 - val_loss: 0.2582\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8091 - binary_accuracy: 0.9102 - loss: 0.2482\n",
      "Fold 2 Metrics: Loss = 0.2582, Accuracy = 0.9066, AUC = 0.8032\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7223 - binary_accuracy: 0.9053 - loss: 0.2857 - val_auc: 0.7872 - val_binary_accuracy: 0.9051 - val_loss: 0.2662\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9063 - loss: 0.2711 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2626\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.7959 - val_binary_accuracy: 0.9065 - val_loss: 0.2615\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9081 - loss: 0.2654 - val_auc: 0.7966 - val_binary_accuracy: 0.9088 - val_loss: 0.2607\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9086 - loss: 0.2641 - val_auc: 0.7980 - val_binary_accuracy: 0.9096 - val_loss: 0.2597\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9089 - loss: 0.2630 - val_auc: 0.7982 - val_binary_accuracy: 0.9100 - val_loss: 0.2590\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8013 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9090 - loss: 0.2614 - val_auc: 0.8016 - val_binary_accuracy: 0.9107 - val_loss: 0.2584\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9096 - loss: 0.2612 - val_auc: 0.8015 - val_binary_accuracy: 0.9110 - val_loss: 0.2577\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2574\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7950 - binary_accuracy: 0.9123 - loss: 0.2580\n",
      "Fold 3 Metrics: Loss = 0.2574, Accuracy = 0.9107, AUC = 0.8029\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6472 - binary_accuracy: 0.8780 - loss: 0.3309 - val_auc: 0.7821 - val_binary_accuracy: 0.9048 - val_loss: 0.2671\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9063 - loss: 0.2671 - val_auc: 0.7907 - val_binary_accuracy: 0.9073 - val_loss: 0.2628\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9084 - loss: 0.2652 - val_auc: 0.7940 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9089 - loss: 0.2633 - val_auc: 0.7953 - val_binary_accuracy: 0.9082 - val_loss: 0.2607\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9099 - loss: 0.2627 - val_auc: 0.7957 - val_binary_accuracy: 0.9093 - val_loss: 0.2595\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.7978 - val_binary_accuracy: 0.9097 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9104 - loss: 0.2598 - val_auc: 0.8003 - val_binary_accuracy: 0.9100 - val_loss: 0.2579\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9102 - loss: 0.2595 - val_auc: 0.8008 - val_binary_accuracy: 0.9109 - val_loss: 0.2585\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9106 - loss: 0.2586 - val_auc: 0.8022 - val_binary_accuracy: 0.9104 - val_loss: 0.2578\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9103 - loss: 0.2583 - val_auc: 0.8015 - val_binary_accuracy: 0.9101 - val_loss: 0.2577\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7813 - binary_accuracy: 0.9099 - loss: 0.2636\n",
      "Fold 4 Metrics: Loss = 0.2577, Accuracy = 0.9101, AUC = 0.8015\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6722 - binary_accuracy: 0.9038 - loss: 0.3049 - val_auc: 0.7820 - val_binary_accuracy: 0.9050 - val_loss: 0.2658\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9042 - loss: 0.2749 - val_auc: 0.7932 - val_binary_accuracy: 0.9045 - val_loss: 0.2604\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2704 - val_auc: 0.7930 - val_binary_accuracy: 0.9059 - val_loss: 0.2605\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9070 - loss: 0.2689 - val_auc: 0.7959 - val_binary_accuracy: 0.9097 - val_loss: 0.2572\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9082 - loss: 0.2667 - val_auc: 0.7991 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9083 - loss: 0.2654 - val_auc: 0.8011 - val_binary_accuracy: 0.9107 - val_loss: 0.2552\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9086 - loss: 0.2640 - val_auc: 0.8025 - val_binary_accuracy: 0.9113 - val_loss: 0.2546\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9093 - loss: 0.2632 - val_auc: 0.8036 - val_binary_accuracy: 0.9113 - val_loss: 0.2538\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8044 - val_binary_accuracy: 0.9113 - val_loss: 0.2534\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9096 - loss: 0.2624 - val_auc: 0.8062 - val_binary_accuracy: 0.9118 - val_loss: 0.2528\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9100 - loss: 0.2509\n",
      "Fold 5 Metrics: Loss = 0.2528, Accuracy = 0.9118, AUC = 0.8062\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2576\n",
      "Average Accuracy: 0.9097\n",
      "Average AUC: 0.8003\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 2, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.7228 - binary_accuracy: 0.9067 - loss: 0.2842 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9083 - loss: 0.2595 - val_auc: 0.7859 - val_binary_accuracy: 0.9069 - val_loss: 0.2660\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9104 - loss: 0.2555 - val_auc: 0.7893 - val_binary_accuracy: 0.9062 - val_loss: 0.2652\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8012 - binary_accuracy: 0.9113 - loss: 0.2529 - val_auc: 0.7898 - val_binary_accuracy: 0.9072 - val_loss: 0.2645\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9122 - loss: 0.2506 - val_auc: 0.7907 - val_binary_accuracy: 0.9082 - val_loss: 0.2632\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9121 - loss: 0.2489 - val_auc: 0.7918 - val_binary_accuracy: 0.9081 - val_loss: 0.2616\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8102 - binary_accuracy: 0.9129 - loss: 0.2478 - val_auc: 0.7920 - val_binary_accuracy: 0.9079 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9126 - loss: 0.2468 - val_auc: 0.7926 - val_binary_accuracy: 0.9081 - val_loss: 0.2603\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8135 - binary_accuracy: 0.9131 - loss: 0.2461 - val_auc: 0.7921 - val_binary_accuracy: 0.9091 - val_loss: 0.2598\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8144 - binary_accuracy: 0.9131 - loss: 0.2455 - val_auc: 0.7924 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7912 - binary_accuracy: 0.9129 - loss: 0.2519\n",
      "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9094, AUC = 0.7924\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6794 - binary_accuracy: 0.8797 - loss: 0.3308 - val_auc: 0.8003 - val_binary_accuracy: 0.9057 - val_loss: 0.2620\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9054 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9065 - val_loss: 0.2609\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.8038 - val_binary_accuracy: 0.9075 - val_loss: 0.2594\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9075 - loss: 0.2639 - val_auc: 0.8055 - val_binary_accuracy: 0.9082 - val_loss: 0.2584\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9080 - loss: 0.2621 - val_auc: 0.8062 - val_binary_accuracy: 0.9068 - val_loss: 0.2581\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9085 - loss: 0.2610 - val_auc: 0.8077 - val_binary_accuracy: 0.9081 - val_loss: 0.2569\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.8082 - val_binary_accuracy: 0.9082 - val_loss: 0.2564\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9083 - loss: 0.2594 - val_auc: 0.8093 - val_binary_accuracy: 0.9081 - val_loss: 0.2555\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9081 - loss: 0.2591 - val_auc: 0.8086 - val_binary_accuracy: 0.9085 - val_loss: 0.2558\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9081 - loss: 0.2588 - val_auc: 0.8088 - val_binary_accuracy: 0.9079 - val_loss: 0.2557\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9115 - loss: 0.2464\n",
      "Fold 2 Metrics: Loss = 0.2557, Accuracy = 0.9079, AUC = 0.8088\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7255 - binary_accuracy: 0.8980 - loss: 0.2938 - val_auc: 0.7890 - val_binary_accuracy: 0.9068 - val_loss: 0.2669\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9067 - loss: 0.2703 - val_auc: 0.7921 - val_binary_accuracy: 0.9068 - val_loss: 0.2653\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.7951 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9080 - loss: 0.2667 - val_auc: 0.7981 - val_binary_accuracy: 0.9090 - val_loss: 0.2613\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9082 - loss: 0.2653 - val_auc: 0.7986 - val_binary_accuracy: 0.9091 - val_loss: 0.2612\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8002 - val_binary_accuracy: 0.9093 - val_loss: 0.2607\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2593\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9087 - loss: 0.2630 - val_auc: 0.8005 - val_binary_accuracy: 0.9096 - val_loss: 0.2589\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8017 - val_binary_accuracy: 0.9099 - val_loss: 0.2582\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2572\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7949 - binary_accuracy: 0.9116 - loss: 0.2581\n",
      "Fold 3 Metrics: Loss = 0.2572, Accuracy = 0.9107, AUC = 0.8029\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6892 - binary_accuracy: 0.8896 - loss: 0.3105 - val_auc: 0.7928 - val_binary_accuracy: 0.9087 - val_loss: 0.2617\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9066 - loss: 0.2673 - val_auc: 0.7984 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9078 - loss: 0.2639 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2586\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9083 - loss: 0.2625 - val_auc: 0.8014 - val_binary_accuracy: 0.9091 - val_loss: 0.2569\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9088 - loss: 0.2611 - val_auc: 0.8038 - val_binary_accuracy: 0.9098 - val_loss: 0.2565\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9087 - loss: 0.2606 - val_auc: 0.8011 - val_binary_accuracy: 0.9088 - val_loss: 0.2571\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9090 - loss: 0.2596 - val_auc: 0.8024 - val_binary_accuracy: 0.9094 - val_loss: 0.2563\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.8035 - val_binary_accuracy: 0.9094 - val_loss: 0.2559\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9098 - loss: 0.2588 - val_auc: 0.8040 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9097 - loss: 0.2584 - val_auc: 0.8060 - val_binary_accuracy: 0.9097 - val_loss: 0.2550\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7860 - binary_accuracy: 0.9088 - loss: 0.2620\n",
      "Fold 4 Metrics: Loss = 0.2550, Accuracy = 0.9097, AUC = 0.8060\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6383 - binary_accuracy: 0.8697 - loss: 0.3769 - val_auc: 0.7925 - val_binary_accuracy: 0.9090 - val_loss: 0.2635\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9050 - loss: 0.2729 - val_auc: 0.7996 - val_binary_accuracy: 0.9085 - val_loss: 0.2635\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9046 - loss: 0.2706 - val_auc: 0.8026 - val_binary_accuracy: 0.9103 - val_loss: 0.2606\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9076 - loss: 0.2680 - val_auc: 0.8032 - val_binary_accuracy: 0.9101 - val_loss: 0.2565\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9089 - loss: 0.2664 - val_auc: 0.8036 - val_binary_accuracy: 0.9109 - val_loss: 0.2557\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9091 - loss: 0.2654 - val_auc: 0.8045 - val_binary_accuracy: 0.9107 - val_loss: 0.2539\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9094 - loss: 0.2643 - val_auc: 0.8040 - val_binary_accuracy: 0.9104 - val_loss: 0.2533\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9103 - loss: 0.2633 - val_auc: 0.8042 - val_binary_accuracy: 0.9110 - val_loss: 0.2530\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9106 - loss: 0.2627 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2526\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9101 - loss: 0.2621 - val_auc: 0.8061 - val_binary_accuracy: 0.9113 - val_loss: 0.2527\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9094 - loss: 0.2504\n",
      "Fold 5 Metrics: Loss = 0.2527, Accuracy = 0.9113, AUC = 0.8061\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2560\n",
      "Average Accuracy: 0.9098\n",
      "Average AUC: 0.8032\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 2, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7019 - binary_accuracy: 0.8908 - loss: 0.3147 - val_auc: 0.7819 - val_binary_accuracy: 0.9054 - val_loss: 0.2656\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9098 - loss: 0.2581 - val_auc: 0.7872 - val_binary_accuracy: 0.9078 - val_loss: 0.2634\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9109 - loss: 0.2548 - val_auc: 0.7884 - val_binary_accuracy: 0.9078 - val_loss: 0.2646\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9115 - loss: 0.2530 - val_auc: 0.7906 - val_binary_accuracy: 0.9079 - val_loss: 0.2642\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9119 - loss: 0.2513 - val_auc: 0.7908 - val_binary_accuracy: 0.9078 - val_loss: 0.2635\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9120 - loss: 0.2501 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2625\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9122 - loss: 0.2493 - val_auc: 0.7936 - val_binary_accuracy: 0.9087 - val_loss: 0.2618\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9124 - loss: 0.2486 - val_auc: 0.7933 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8096 - binary_accuracy: 0.9129 - loss: 0.2479 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2607\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8105 - binary_accuracy: 0.9131 - loss: 0.2475 - val_auc: 0.7947 - val_binary_accuracy: 0.9084 - val_loss: 0.2606\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9108 - loss: 0.2526\n",
      "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9084, AUC = 0.7947\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7231 - binary_accuracy: 0.9035 - loss: 0.2977 - val_auc: 0.7994 - val_binary_accuracy: 0.9056 - val_loss: 0.2685\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9050 - loss: 0.2684 - val_auc: 0.8049 - val_binary_accuracy: 0.9065 - val_loss: 0.2631\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9059 - loss: 0.2655 - val_auc: 0.8050 - val_binary_accuracy: 0.9072 - val_loss: 0.2612\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9073 - loss: 0.2636 - val_auc: 0.8075 - val_binary_accuracy: 0.9081 - val_loss: 0.2599\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9071 - loss: 0.2624 - val_auc: 0.8096 - val_binary_accuracy: 0.9082 - val_loss: 0.2594\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9081 - loss: 0.2612 - val_auc: 0.8101 - val_binary_accuracy: 0.9079 - val_loss: 0.2591\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9087 - loss: 0.2605 - val_auc: 0.8096 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9084 - loss: 0.2598 - val_auc: 0.8099 - val_binary_accuracy: 0.9084 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9092 - loss: 0.2593 - val_auc: 0.8106 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9092 - loss: 0.2592 - val_auc: 0.8111 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8190 - binary_accuracy: 0.9134 - loss: 0.2492\n",
      "Fold 2 Metrics: Loss = 0.2587, Accuracy = 0.9091, AUC = 0.8111\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7099 - binary_accuracy: 0.9052 - loss: 0.2995 - val_auc: 0.7868 - val_binary_accuracy: 0.9085 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7685 - binary_accuracy: 0.9083 - loss: 0.2690 - val_auc: 0.7927 - val_binary_accuracy: 0.9104 - val_loss: 0.2645\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9086 - loss: 0.2666 - val_auc: 0.7960 - val_binary_accuracy: 0.9106 - val_loss: 0.2623\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9080 - loss: 0.2658 - val_auc: 0.7983 - val_binary_accuracy: 0.9107 - val_loss: 0.2614\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.8003 - val_binary_accuracy: 0.9107 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8008 - val_binary_accuracy: 0.9112 - val_loss: 0.2601\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7775 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8021 - val_binary_accuracy: 0.9110 - val_loss: 0.2592\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7786 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8037 - val_binary_accuracy: 0.9112 - val_loss: 0.2590\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9087 - loss: 0.2631 - val_auc: 0.8038 - val_binary_accuracy: 0.9112 - val_loss: 0.2590\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9094 - loss: 0.2631 - val_auc: 0.8050 - val_binary_accuracy: 0.9110 - val_loss: 0.2576\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7977 - binary_accuracy: 0.9121 - loss: 0.2584\n",
      "Fold 3 Metrics: Loss = 0.2576, Accuracy = 0.9110, AUC = 0.8050\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6967 - binary_accuracy: 0.8868 - loss: 0.3252 - val_auc: 0.7942 - val_binary_accuracy: 0.9087 - val_loss: 0.2616\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9065 - loss: 0.2666 - val_auc: 0.7995 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9084 - loss: 0.2642 - val_auc: 0.8013 - val_binary_accuracy: 0.9067 - val_loss: 0.2587\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9085 - loss: 0.2625 - val_auc: 0.8037 - val_binary_accuracy: 0.9066 - val_loss: 0.2576\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8041 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8054 - val_binary_accuracy: 0.9094 - val_loss: 0.2558\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9104 - loss: 0.2599 - val_auc: 0.8067 - val_binary_accuracy: 0.9094 - val_loss: 0.2551\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9105 - loss: 0.2594 - val_auc: 0.8090 - val_binary_accuracy: 0.9093 - val_loss: 0.2540\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9105 - loss: 0.2590 - val_auc: 0.8088 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9107 - loss: 0.2586 - val_auc: 0.8094 - val_binary_accuracy: 0.9093 - val_loss: 0.2539\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7899 - binary_accuracy: 0.9091 - loss: 0.2620\n",
      "Fold 4 Metrics: Loss = 0.2539, Accuracy = 0.9093, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6883 - binary_accuracy: 0.8934 - loss: 0.3195 - val_auc: 0.7951 - val_binary_accuracy: 0.9087 - val_loss: 0.2591\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9060 - loss: 0.2712 - val_auc: 0.8000 - val_binary_accuracy: 0.9057 - val_loss: 0.2620\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.8027 - val_binary_accuracy: 0.9088 - val_loss: 0.2615\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9079 - loss: 0.2657 - val_auc: 0.8038 - val_binary_accuracy: 0.9094 - val_loss: 0.2619\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9081 - loss: 0.2650 - val_auc: 0.8050 - val_binary_accuracy: 0.9095 - val_loss: 0.2609\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9082 - loss: 0.2643 - val_auc: 0.8055 - val_binary_accuracy: 0.9091 - val_loss: 0.2598\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2635 - val_auc: 0.8056 - val_binary_accuracy: 0.9091 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8069 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.8066 - val_binary_accuracy: 0.9095 - val_loss: 0.2588\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9086 - loss: 0.2624 - val_auc: 0.8070 - val_binary_accuracy: 0.9079 - val_loss: 0.2591\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9088 - loss: 0.2563\n",
      "Fold 5 Metrics: Loss = 0.2591, Accuracy = 0.9079, AUC = 0.8070\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2580\n",
      "Average Accuracy: 0.9091\n",
      "Average AUC: 0.8054\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 3, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6231 - binary_accuracy: 0.9069 - loss: 0.3285 - val_auc: 0.7382 - val_binary_accuracy: 0.9044 - val_loss: 0.2813\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9069 - loss: 0.2674 - val_auc: 0.7482 - val_binary_accuracy: 0.9044 - val_loss: 0.2780\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9070 - loss: 0.2644 - val_auc: 0.7539 - val_binary_accuracy: 0.9044 - val_loss: 0.2757\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9070 - loss: 0.2631 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2730\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9070 - loss: 0.2620 - val_auc: 0.7639 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9070 - loss: 0.2618 - val_auc: 0.7644 - val_binary_accuracy: 0.9044 - val_loss: 0.2721\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.7645 - val_binary_accuracy: 0.9044 - val_loss: 0.2715\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9070 - loss: 0.2613 - val_auc: 0.7656 - val_binary_accuracy: 0.9044 - val_loss: 0.2715\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9069 - loss: 0.2610 - val_auc: 0.7660 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9069 - loss: 0.2608 - val_auc: 0.7669 - val_binary_accuracy: 0.9042 - val_loss: 0.2712\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7601 - binary_accuracy: 0.9082 - loss: 0.2640\n",
      "Fold 1 Metrics: Loss = 0.2712, Accuracy = 0.9042, AUC = 0.7669\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6295 - binary_accuracy: 0.8972 - loss: 0.3282 - val_auc: 0.7588 - val_binary_accuracy: 0.9042 - val_loss: 0.2822\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7492 - binary_accuracy: 0.9029 - loss: 0.2815 - val_auc: 0.7734 - val_binary_accuracy: 0.9042 - val_loss: 0.2742\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9029 - loss: 0.2763 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7646 - binary_accuracy: 0.9029 - loss: 0.2744 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2704\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9029 - loss: 0.2728 - val_auc: 0.7898 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9029 - loss: 0.2707 - val_auc: 0.7922 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.7952 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9029 - loss: 0.2695 - val_auc: 0.7962 - val_binary_accuracy: 0.9042 - val_loss: 0.2647\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9029 - loss: 0.2691 - val_auc: 0.7973 - val_binary_accuracy: 0.9042 - val_loss: 0.2643\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2689 - val_auc: 0.7991 - val_binary_accuracy: 0.9042 - val_loss: 0.2642\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7969 - binary_accuracy: 0.9092 - loss: 0.2540\n",
      "Fold 2 Metrics: Loss = 0.2642, Accuracy = 0.9042, AUC = 0.7991\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5201 - binary_accuracy: 0.9051 - loss: 0.3335 - val_auc: 0.7416 - val_binary_accuracy: 0.9042 - val_loss: 0.2879\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7409 - binary_accuracy: 0.9051 - loss: 0.2804 - val_auc: 0.7647 - val_binary_accuracy: 0.9042 - val_loss: 0.2747\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9051 - loss: 0.2696 - val_auc: 0.7767 - val_binary_accuracy: 0.9042 - val_loss: 0.2728\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9061 - loss: 0.2685 - val_auc: 0.7792 - val_binary_accuracy: 0.9066 - val_loss: 0.2711\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9066 - loss: 0.2674 - val_auc: 0.7848 - val_binary_accuracy: 0.9075 - val_loss: 0.2694\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9075 - loss: 0.2666 - val_auc: 0.7859 - val_binary_accuracy: 0.9076 - val_loss: 0.2671\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7886 - val_binary_accuracy: 0.9087 - val_loss: 0.2653\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9083 - loss: 0.2654 - val_auc: 0.7886 - val_binary_accuracy: 0.9099 - val_loss: 0.2642\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9089 - loss: 0.2650 - val_auc: 0.7896 - val_binary_accuracy: 0.9104 - val_loss: 0.2635\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9085 - loss: 0.2645 - val_auc: 0.7904 - val_binary_accuracy: 0.9100 - val_loss: 0.2631\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7841 - binary_accuracy: 0.9098 - loss: 0.2643\n",
      "Fold 3 Metrics: Loss = 0.2631, Accuracy = 0.9100, AUC = 0.7904\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5469 - binary_accuracy: 0.9047 - loss: 0.3493 - val_auc: 0.7014 - val_binary_accuracy: 0.9044 - val_loss: 0.2931\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7048 - binary_accuracy: 0.9047 - loss: 0.2899 - val_auc: 0.7433 - val_binary_accuracy: 0.9044 - val_loss: 0.2826\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7378 - binary_accuracy: 0.9047 - loss: 0.2812 - val_auc: 0.7586 - val_binary_accuracy: 0.9044 - val_loss: 0.2754\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7527 - binary_accuracy: 0.9047 - loss: 0.2763 - val_auc: 0.7696 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9047 - loss: 0.2738 - val_auc: 0.7721 - val_binary_accuracy: 0.9044 - val_loss: 0.2711\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9047 - loss: 0.2711 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9047 - loss: 0.2684 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9047 - loss: 0.2656 - val_auc: 0.7881 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9047 - loss: 0.2644 - val_auc: 0.7869 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9047 - loss: 0.2640 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7729 - binary_accuracy: 0.9049 - loss: 0.2698\n",
      "Fold 4 Metrics: Loss = 0.2675, Accuracy = 0.9044, AUC = 0.7872\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5982 - binary_accuracy: 0.9036 - loss: 0.3237 - val_auc: 0.7556 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7469 - binary_accuracy: 0.9037 - loss: 0.2794 - val_auc: 0.7687 - val_binary_accuracy: 0.9044 - val_loss: 0.2672\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7578 - binary_accuracy: 0.9039 - loss: 0.2767 - val_auc: 0.7793 - val_binary_accuracy: 0.9044 - val_loss: 0.2652\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7633 - binary_accuracy: 0.9039 - loss: 0.2742 - val_auc: 0.7822 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9040 - loss: 0.2730 - val_auc: 0.7838 - val_binary_accuracy: 0.9044 - val_loss: 0.2631\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9040 - loss: 0.2721 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2627\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9040 - loss: 0.2715 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2623\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.7875 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9040 - loss: 0.2698 - val_auc: 0.7885 - val_binary_accuracy: 0.9044 - val_loss: 0.2615\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8049 - binary_accuracy: 0.9013 - loss: 0.2585\n",
      "Fold 5 Metrics: Loss = 0.2615, Accuracy = 0.9044, AUC = 0.7885\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2655\n",
      "Average Accuracy: 0.9055\n",
      "Average AUC: 0.7864\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 3, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5706 - binary_accuracy: 0.9066 - loss: 0.3155 - val_auc: 0.7594 - val_binary_accuracy: 0.9044 - val_loss: 0.2817\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7713 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9069 - loss: 0.2621 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9071 - loss: 0.2591 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9083 - loss: 0.2572 - val_auc: 0.7832 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9089 - loss: 0.2557 - val_auc: 0.7820 - val_binary_accuracy: 0.9088 - val_loss: 0.2669\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9096 - loss: 0.2547 - val_auc: 0.7833 - val_binary_accuracy: 0.9082 - val_loss: 0.2650\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9111 - loss: 0.2537 - val_auc: 0.7852 - val_binary_accuracy: 0.9099 - val_loss: 0.2645\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9124 - loss: 0.2530 - val_auc: 0.7863 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9119 - loss: 0.2516 - val_auc: 0.7849 - val_binary_accuracy: 0.9090 - val_loss: 0.2644\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7846 - binary_accuracy: 0.9112 - loss: 0.2573\n",
      "Fold 1 Metrics: Loss = 0.2644, Accuracy = 0.9090, AUC = 0.7849\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6661 - binary_accuracy: 0.8577 - loss: 0.3449 - val_auc: 0.7872 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9043 - loss: 0.2716 - val_auc: 0.7932 - val_binary_accuracy: 0.9053 - val_loss: 0.2657\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9052 - loss: 0.2673 - val_auc: 0.7994 - val_binary_accuracy: 0.9065 - val_loss: 0.2612\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9059 - loss: 0.2646 - val_auc: 0.8019 - val_binary_accuracy: 0.9084 - val_loss: 0.2586\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9071 - loss: 0.2633 - val_auc: 0.8000 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9072 - loss: 0.2620 - val_auc: 0.7998 - val_binary_accuracy: 0.9093 - val_loss: 0.2592\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9082 - loss: 0.2609 - val_auc: 0.7977 - val_binary_accuracy: 0.9079 - val_loss: 0.2615\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9081 - loss: 0.2608 - val_auc: 0.7983 - val_binary_accuracy: 0.9078 - val_loss: 0.2618\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9087 - loss: 0.2607 - val_auc: 0.7985 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9098 - loss: 0.2605 - val_auc: 0.7985 - val_binary_accuracy: 0.9078 - val_loss: 0.2620\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8050 - binary_accuracy: 0.9118 - loss: 0.2514\n",
      "Fold 2 Metrics: Loss = 0.2620, Accuracy = 0.9078, AUC = 0.7985\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6525 - binary_accuracy: 0.8428 - loss: 0.3592 - val_auc: 0.7640 - val_binary_accuracy: 0.9048 - val_loss: 0.2753\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9058 - loss: 0.2722 - val_auc: 0.7723 - val_binary_accuracy: 0.9053 - val_loss: 0.2711\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7656 - binary_accuracy: 0.9063 - loss: 0.2700 - val_auc: 0.7733 - val_binary_accuracy: 0.9065 - val_loss: 0.2698\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9078 - loss: 0.2686 - val_auc: 0.7787 - val_binary_accuracy: 0.9082 - val_loss: 0.2690\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9086 - loss: 0.2673 - val_auc: 0.7782 - val_binary_accuracy: 0.9084 - val_loss: 0.2691\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9087 - loss: 0.2662 - val_auc: 0.7768 - val_binary_accuracy: 0.9084 - val_loss: 0.2689\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9085 - loss: 0.2655 - val_auc: 0.7776 - val_binary_accuracy: 0.9087 - val_loss: 0.2687\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9092 - loss: 0.2650 - val_auc: 0.7792 - val_binary_accuracy: 0.9088 - val_loss: 0.2685\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9094 - loss: 0.2646 - val_auc: 0.7790 - val_binary_accuracy: 0.9097 - val_loss: 0.2682\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9096 - loss: 0.2641 - val_auc: 0.7801 - val_binary_accuracy: 0.9093 - val_loss: 0.2679\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7731 - binary_accuracy: 0.9104 - loss: 0.2692\n",
      "Fold 3 Metrics: Loss = 0.2679, Accuracy = 0.9093, AUC = 0.7801\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6619 - binary_accuracy: 0.8546 - loss: 0.3482 - val_auc: 0.7817 - val_binary_accuracy: 0.9044 - val_loss: 0.2696\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9051 - loss: 0.2686 - val_auc: 0.7863 - val_binary_accuracy: 0.9047 - val_loss: 0.2671\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9069 - loss: 0.2656 - val_auc: 0.7906 - val_binary_accuracy: 0.9066 - val_loss: 0.2644\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.7924 - val_binary_accuracy: 0.9078 - val_loss: 0.2624\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9085 - loss: 0.2618 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2613\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2610 - val_auc: 0.7961 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9095 - loss: 0.2603 - val_auc: 0.7966 - val_binary_accuracy: 0.9087 - val_loss: 0.2610\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.7969 - val_binary_accuracy: 0.9087 - val_loss: 0.2609\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9100 - loss: 0.2595 - val_auc: 0.7972 - val_binary_accuracy: 0.9085 - val_loss: 0.2611\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9095 - loss: 0.2592 - val_auc: 0.7974 - val_binary_accuracy: 0.9084 - val_loss: 0.2613\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7778 - binary_accuracy: 0.9078 - loss: 0.2679\n",
      "Fold 4 Metrics: Loss = 0.2613, Accuracy = 0.9084, AUC = 0.7974\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7020 - binary_accuracy: 0.9041 - loss: 0.3018 - val_auc: 0.7885 - val_binary_accuracy: 0.9056 - val_loss: 0.2620\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9056 - loss: 0.2711 - val_auc: 0.7952 - val_binary_accuracy: 0.9063 - val_loss: 0.2594\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9071 - loss: 0.2690 - val_auc: 0.7975 - val_binary_accuracy: 0.9075 - val_loss: 0.2583\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9078 - loss: 0.2681 - val_auc: 0.7964 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9080 - loss: 0.2668 - val_auc: 0.7975 - val_binary_accuracy: 0.9097 - val_loss: 0.2574\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9080 - loss: 0.2657 - val_auc: 0.7985 - val_binary_accuracy: 0.9101 - val_loss: 0.2568\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8006 - val_binary_accuracy: 0.9091 - val_loss: 0.2561\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9075 - loss: 0.2642 - val_auc: 0.8026 - val_binary_accuracy: 0.9093 - val_loss: 0.2557\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.8023 - val_binary_accuracy: 0.9085 - val_loss: 0.2554\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9088 - loss: 0.2629 - val_auc: 0.8029 - val_binary_accuracy: 0.9085 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8135 - binary_accuracy: 0.9076 - loss: 0.2521\n",
      "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9085, AUC = 0.8029\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2621\n",
      "Average Accuracy: 0.9086\n",
      "Average AUC: 0.7928\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 3, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7186 - binary_accuracy: 0.9060 - loss: 0.2886 - val_auc: 0.7727 - val_binary_accuracy: 0.9044 - val_loss: 0.2707\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9082 - loss: 0.2591 - val_auc: 0.7799 - val_binary_accuracy: 0.9047 - val_loss: 0.2673\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9102 - loss: 0.2556 - val_auc: 0.7833 - val_binary_accuracy: 0.9054 - val_loss: 0.2650\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9120 - loss: 0.2533 - val_auc: 0.7855 - val_binary_accuracy: 0.9069 - val_loss: 0.2636\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9124 - loss: 0.2516 - val_auc: 0.7865 - val_binary_accuracy: 0.9072 - val_loss: 0.2628\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9124 - loss: 0.2504 - val_auc: 0.7874 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9127 - loss: 0.2496 - val_auc: 0.7857 - val_binary_accuracy: 0.9075 - val_loss: 0.2630\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9125 - loss: 0.2492 - val_auc: 0.7863 - val_binary_accuracy: 0.9078 - val_loss: 0.2631\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9126 - loss: 0.2493 - val_auc: 0.7871 - val_binary_accuracy: 0.9078 - val_loss: 0.2629\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9128 - loss: 0.2487 - val_auc: 0.7882 - val_binary_accuracy: 0.9082 - val_loss: 0.2622\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7870 - binary_accuracy: 0.9111 - loss: 0.2548\n",
      "Fold 1 Metrics: Loss = 0.2622, Accuracy = 0.9082, AUC = 0.7882\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6992 - binary_accuracy: 0.8989 - loss: 0.3037 - val_auc: 0.7879 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9037 - loss: 0.2709 - val_auc: 0.7982 - val_binary_accuracy: 0.9057 - val_loss: 0.2619\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9041 - loss: 0.2673 - val_auc: 0.7975 - val_binary_accuracy: 0.9063 - val_loss: 0.2609\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9058 - loss: 0.2652 - val_auc: 0.7974 - val_binary_accuracy: 0.9059 - val_loss: 0.2613\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9051 - loss: 0.2639 - val_auc: 0.7987 - val_binary_accuracy: 0.9069 - val_loss: 0.2601\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9059 - loss: 0.2635 - val_auc: 0.8015 - val_binary_accuracy: 0.9071 - val_loss: 0.2588\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9074 - loss: 0.2622 - val_auc: 0.8029 - val_binary_accuracy: 0.9072 - val_loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9077 - loss: 0.2613 - val_auc: 0.8046 - val_binary_accuracy: 0.9072 - val_loss: 0.2578\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9077 - loss: 0.2605 - val_auc: 0.8030 - val_binary_accuracy: 0.9069 - val_loss: 0.2586\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9077 - loss: 0.2605 - val_auc: 0.8030 - val_binary_accuracy: 0.9076 - val_loss: 0.2573\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8101 - binary_accuracy: 0.9118 - loss: 0.2467\n",
      "Fold 2 Metrics: Loss = 0.2573, Accuracy = 0.9076, AUC = 0.8030\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6749 - binary_accuracy: 0.8913 - loss: 0.3076 - val_auc: 0.7857 - val_binary_accuracy: 0.9053 - val_loss: 0.2664\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9064 - loss: 0.2713 - val_auc: 0.7879 - val_binary_accuracy: 0.9060 - val_loss: 0.2645\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9080 - loss: 0.2680 - val_auc: 0.7892 - val_binary_accuracy: 0.9099 - val_loss: 0.2658\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9080 - loss: 0.2651 - val_auc: 0.7945 - val_binary_accuracy: 0.9066 - val_loss: 0.2623\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9088 - loss: 0.2652 - val_auc: 0.7955 - val_binary_accuracy: 0.9069 - val_loss: 0.2615\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9088 - loss: 0.2644 - val_auc: 0.7971 - val_binary_accuracy: 0.9079 - val_loss: 0.2607\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9085 - loss: 0.2638 - val_auc: 0.7976 - val_binary_accuracy: 0.9091 - val_loss: 0.2596\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9085 - loss: 0.2631 - val_auc: 0.7983 - val_binary_accuracy: 0.9103 - val_loss: 0.2587\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9083 - loss: 0.2626 - val_auc: 0.7992 - val_binary_accuracy: 0.9106 - val_loss: 0.2583\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9082 - loss: 0.2622 - val_auc: 0.7996 - val_binary_accuracy: 0.9110 - val_loss: 0.2576\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9120 - loss: 0.2585\n",
      "Fold 3 Metrics: Loss = 0.2576, Accuracy = 0.9110, AUC = 0.7996\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6600 - binary_accuracy: 0.8742 - loss: 0.3284 - val_auc: 0.7844 - val_binary_accuracy: 0.9087 - val_loss: 0.2645\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9076 - loss: 0.2683 - val_auc: 0.7922 - val_binary_accuracy: 0.9084 - val_loss: 0.2601\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9092 - loss: 0.2638 - val_auc: 0.7939 - val_binary_accuracy: 0.9088 - val_loss: 0.2591\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9100 - loss: 0.2618 - val_auc: 0.7971 - val_binary_accuracy: 0.9087 - val_loss: 0.2583\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9105 - loss: 0.2604 - val_auc: 0.7999 - val_binary_accuracy: 0.9084 - val_loss: 0.2574\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9109 - loss: 0.2595 - val_auc: 0.8009 - val_binary_accuracy: 0.9085 - val_loss: 0.2572\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9112 - loss: 0.2591 - val_auc: 0.8001 - val_binary_accuracy: 0.9082 - val_loss: 0.2573\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9112 - loss: 0.2586 - val_auc: 0.8033 - val_binary_accuracy: 0.9082 - val_loss: 0.2569\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2583 - val_auc: 0.8029 - val_binary_accuracy: 0.9082 - val_loss: 0.2562\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9112 - loss: 0.2580 - val_auc: 0.8042 - val_binary_accuracy: 0.9091 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9085 - loss: 0.2616\n",
      "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9091, AUC = 0.8042\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6394 - binary_accuracy: 0.8589 - loss: 0.3551 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2648\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9040 - loss: 0.2752 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2607\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9045 - loss: 0.2725 - val_auc: 0.7961 - val_binary_accuracy: 0.9084 - val_loss: 0.2589\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9039 - loss: 0.2714 - val_auc: 0.8021 - val_binary_accuracy: 0.9098 - val_loss: 0.2562\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9056 - loss: 0.2692 - val_auc: 0.8040 - val_binary_accuracy: 0.9085 - val_loss: 0.2552\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.8037 - val_binary_accuracy: 0.9088 - val_loss: 0.2547\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9079 - loss: 0.2659 - val_auc: 0.8036 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2648 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2551\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9087 - loss: 0.2639 - val_auc: 0.8045 - val_binary_accuracy: 0.9093 - val_loss: 0.2549\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9088 - loss: 0.2632 - val_auc: 0.8044 - val_binary_accuracy: 0.9093 - val_loss: 0.2551\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8142 - binary_accuracy: 0.9077 - loss: 0.2534\n",
      "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9093, AUC = 0.8044\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2577\n",
      "Average Accuracy: 0.9091\n",
      "Average AUC: 0.7999\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 3, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6982 - binary_accuracy: 0.8899 - loss: 0.3054 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2685\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9073 - loss: 0.2610 - val_auc: 0.7826 - val_binary_accuracy: 0.9054 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9083 - loss: 0.2567 - val_auc: 0.7850 - val_binary_accuracy: 0.9056 - val_loss: 0.2643\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9093 - loss: 0.2549 - val_auc: 0.7874 - val_binary_accuracy: 0.9075 - val_loss: 0.2633\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8008 - binary_accuracy: 0.9098 - loss: 0.2530 - val_auc: 0.7896 - val_binary_accuracy: 0.9093 - val_loss: 0.2622\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9109 - loss: 0.2515 - val_auc: 0.7911 - val_binary_accuracy: 0.9090 - val_loss: 0.2611\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9120 - loss: 0.2505 - val_auc: 0.7922 - val_binary_accuracy: 0.9088 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9127 - loss: 0.2495 - val_auc: 0.7918 - val_binary_accuracy: 0.9087 - val_loss: 0.2602\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9130 - loss: 0.2491 - val_auc: 0.7932 - val_binary_accuracy: 0.9084 - val_loss: 0.2602\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9129 - loss: 0.2483 - val_auc: 0.7927 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9126 - loss: 0.2516\n",
      "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9087, AUC = 0.7927\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7276 - binary_accuracy: 0.9039 - loss: 0.2906 - val_auc: 0.8012 - val_binary_accuracy: 0.9068 - val_loss: 0.2673\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9055 - loss: 0.2699 - val_auc: 0.8019 - val_binary_accuracy: 0.9073 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9065 - loss: 0.2660 - val_auc: 0.8020 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9066 - loss: 0.2647 - val_auc: 0.8039 - val_binary_accuracy: 0.9069 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9074 - loss: 0.2629 - val_auc: 0.8043 - val_binary_accuracy: 0.9082 - val_loss: 0.2611\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9077 - loss: 0.2627 - val_auc: 0.8082 - val_binary_accuracy: 0.9071 - val_loss: 0.2602\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9082 - loss: 0.2618 - val_auc: 0.8084 - val_binary_accuracy: 0.9068 - val_loss: 0.2603\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9073 - loss: 0.2622 - val_auc: 0.8097 - val_binary_accuracy: 0.9053 - val_loss: 0.2602\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9077 - loss: 0.2618 - val_auc: 0.8109 - val_binary_accuracy: 0.9068 - val_loss: 0.2596\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9070 - loss: 0.2611 - val_auc: 0.8111 - val_binary_accuracy: 0.9069 - val_loss: 0.2596\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8178 - binary_accuracy: 0.9106 - loss: 0.2501\n",
      "Fold 2 Metrics: Loss = 0.2596, Accuracy = 0.9069, AUC = 0.8111\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7209 - binary_accuracy: 0.9055 - loss: 0.2889 - val_auc: 0.7895 - val_binary_accuracy: 0.9068 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9072 - loss: 0.2686 - val_auc: 0.7918 - val_binary_accuracy: 0.9051 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9074 - loss: 0.2679 - val_auc: 0.7945 - val_binary_accuracy: 0.9066 - val_loss: 0.2654\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9076 - loss: 0.2671 - val_auc: 0.7964 - val_binary_accuracy: 0.9056 - val_loss: 0.2639\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9072 - loss: 0.2664 - val_auc: 0.7968 - val_binary_accuracy: 0.9071 - val_loss: 0.2637\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9086 - loss: 0.2653 - val_auc: 0.7985 - val_binary_accuracy: 0.9056 - val_loss: 0.2619\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9083 - loss: 0.2647 - val_auc: 0.7982 - val_binary_accuracy: 0.9066 - val_loss: 0.2624\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.7989 - val_binary_accuracy: 0.9072 - val_loss: 0.2618\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8003 - val_binary_accuracy: 0.9084 - val_loss: 0.2605\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8008 - val_binary_accuracy: 0.9088 - val_loss: 0.2600\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7933 - binary_accuracy: 0.9100 - loss: 0.2607\n",
      "Fold 3 Metrics: Loss = 0.2600, Accuracy = 0.9088, AUC = 0.8008\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7056 - binary_accuracy: 0.8967 - loss: 0.2995 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2625\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9074 - loss: 0.2666 - val_auc: 0.7962 - val_binary_accuracy: 0.9075 - val_loss: 0.2614\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9079 - loss: 0.2637 - val_auc: 0.7978 - val_binary_accuracy: 0.9084 - val_loss: 0.2601\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9084 - loss: 0.2616 - val_auc: 0.7988 - val_binary_accuracy: 0.9087 - val_loss: 0.2592\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2605 - val_auc: 0.8013 - val_binary_accuracy: 0.9087 - val_loss: 0.2575\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9102 - loss: 0.2595 - val_auc: 0.8031 - val_binary_accuracy: 0.9093 - val_loss: 0.2571\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.8035 - val_binary_accuracy: 0.9097 - val_loss: 0.2568\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2582 - val_auc: 0.8035 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9106 - loss: 0.2583 - val_auc: 0.8044 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9112 - loss: 0.2577 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2561\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7875 - binary_accuracy: 0.9083 - loss: 0.2636\n",
      "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9094, AUC = 0.8062\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7007 - binary_accuracy: 0.9041 - loss: 0.2985 - val_auc: 0.7899 - val_binary_accuracy: 0.9066 - val_loss: 0.2644\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9056 - loss: 0.2744 - val_auc: 0.7980 - val_binary_accuracy: 0.9072 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9069 - loss: 0.2705 - val_auc: 0.8010 - val_binary_accuracy: 0.9084 - val_loss: 0.2629\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9073 - loss: 0.2680 - val_auc: 0.8044 - val_binary_accuracy: 0.9085 - val_loss: 0.2612\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9076 - loss: 0.2666 - val_auc: 0.8042 - val_binary_accuracy: 0.9090 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9070 - loss: 0.2655 - val_auc: 0.8077 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9084 - loss: 0.2638 - val_auc: 0.8081 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8086 - val_binary_accuracy: 0.9090 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8089 - val_binary_accuracy: 0.9109 - val_loss: 0.2550\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9094 - loss: 0.2618 - val_auc: 0.8090 - val_binary_accuracy: 0.9115 - val_loss: 0.2543\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9097 - loss: 0.2522\n",
      "Fold 5 Metrics: Loss = 0.2543, Accuracy = 0.9115, AUC = 0.8090\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2579\n",
      "Average Accuracy: 0.9091\n",
      "Average AUC: 0.8040\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 3, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7155 - binary_accuracy: 0.9054 - loss: 0.2915 - val_auc: 0.7776 - val_binary_accuracy: 0.9045 - val_loss: 0.2668\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9086 - loss: 0.2600 - val_auc: 0.7844 - val_binary_accuracy: 0.9081 - val_loss: 0.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9106 - loss: 0.2559 - val_auc: 0.7884 - val_binary_accuracy: 0.9093 - val_loss: 0.2613\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9111 - loss: 0.2545 - val_auc: 0.7904 - val_binary_accuracy: 0.9094 - val_loss: 0.2608\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9118 - loss: 0.2529 - val_auc: 0.7904 - val_binary_accuracy: 0.9088 - val_loss: 0.2622\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9111 - loss: 0.2521 - val_auc: 0.7908 - val_binary_accuracy: 0.9093 - val_loss: 0.2624\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9120 - loss: 0.2511 - val_auc: 0.7907 - val_binary_accuracy: 0.9096 - val_loss: 0.2622\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9122 - loss: 0.2503 - val_auc: 0.7912 - val_binary_accuracy: 0.9097 - val_loss: 0.2623\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9126 - loss: 0.2501 - val_auc: 0.7921 - val_binary_accuracy: 0.9093 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8058 - binary_accuracy: 0.9130 - loss: 0.2500 - val_auc: 0.7916 - val_binary_accuracy: 0.9090 - val_loss: 0.2615\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7895 - binary_accuracy: 0.9121 - loss: 0.2539\n",
      "Fold 1 Metrics: Loss = 0.2615, Accuracy = 0.9090, AUC = 0.7916\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - auc: 0.7058 - binary_accuracy: 0.9016 - loss: 0.3067 - val_auc: 0.8011 - val_binary_accuracy: 0.9045 - val_loss: 0.2670\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9034 - loss: 0.2702 - val_auc: 0.8061 - val_binary_accuracy: 0.9072 - val_loss: 0.2626\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9061 - loss: 0.2669 - val_auc: 0.8086 - val_binary_accuracy: 0.9082 - val_loss: 0.2598\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9063 - loss: 0.2648 - val_auc: 0.8084 - val_binary_accuracy: 0.9081 - val_loss: 0.2599\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9070 - loss: 0.2638 - val_auc: 0.8094 - val_binary_accuracy: 0.9075 - val_loss: 0.2613\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9074 - loss: 0.2635 - val_auc: 0.8095 - val_binary_accuracy: 0.9071 - val_loss: 0.2621\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9071 - loss: 0.2628 - val_auc: 0.8095 - val_binary_accuracy: 0.9071 - val_loss: 0.2615\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9080 - loss: 0.2623 - val_auc: 0.8093 - val_binary_accuracy: 0.9069 - val_loss: 0.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9079 - loss: 0.2618 - val_auc: 0.8097 - val_binary_accuracy: 0.9065 - val_loss: 0.2633\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8111 - val_binary_accuracy: 0.9066 - val_loss: 0.2624\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9101 - loss: 0.2539\n",
      "Fold 2 Metrics: Loss = 0.2624, Accuracy = 0.9066, AUC = 0.8111\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7028 - binary_accuracy: 0.8871 - loss: 0.3199 - val_auc: 0.7849 - val_binary_accuracy: 0.9075 - val_loss: 0.2674\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9070 - loss: 0.2691 - val_auc: 0.7910 - val_binary_accuracy: 0.9088 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9075 - loss: 0.2676 - val_auc: 0.7931 - val_binary_accuracy: 0.9102 - val_loss: 0.2620\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9066 - loss: 0.2686 - val_auc: 0.7954 - val_binary_accuracy: 0.9100 - val_loss: 0.2611\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9067 - loss: 0.2673 - val_auc: 0.7965 - val_binary_accuracy: 0.9094 - val_loss: 0.2618\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9077 - loss: 0.2670 - val_auc: 0.7979 - val_binary_accuracy: 0.9107 - val_loss: 0.2617\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9079 - loss: 0.2662 - val_auc: 0.7992 - val_binary_accuracy: 0.9107 - val_loss: 0.2616\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9077 - loss: 0.2661 - val_auc: 0.7977 - val_binary_accuracy: 0.9106 - val_loss: 0.2624\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9072 - loss: 0.2659 - val_auc: 0.8003 - val_binary_accuracy: 0.9103 - val_loss: 0.2615\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9084 - loss: 0.2648 - val_auc: 0.7996 - val_binary_accuracy: 0.9103 - val_loss: 0.2625\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7917 - binary_accuracy: 0.9101 - loss: 0.2635\n",
      "Fold 3 Metrics: Loss = 0.2625, Accuracy = 0.9103, AUC = 0.7996\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6977 - binary_accuracy: 0.9047 - loss: 0.3033 - val_auc: 0.7941 - val_binary_accuracy: 0.9062 - val_loss: 0.2647\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9066 - loss: 0.2681 - val_auc: 0.7963 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9071 - loss: 0.2652 - val_auc: 0.7989 - val_binary_accuracy: 0.9087 - val_loss: 0.2612\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9079 - loss: 0.2638 - val_auc: 0.8008 - val_binary_accuracy: 0.9047 - val_loss: 0.2661\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8018 - val_binary_accuracy: 0.9098 - val_loss: 0.2606\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9094 - loss: 0.2620 - val_auc: 0.8039 - val_binary_accuracy: 0.9088 - val_loss: 0.2584\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9102 - loss: 0.2611 - val_auc: 0.8054 - val_binary_accuracy: 0.9094 - val_loss: 0.2575\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9106 - loss: 0.2604 - val_auc: 0.8066 - val_binary_accuracy: 0.9098 - val_loss: 0.2569\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9107 - loss: 0.2600 - val_auc: 0.8066 - val_binary_accuracy: 0.9098 - val_loss: 0.2569\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9106 - loss: 0.2593 - val_auc: 0.8087 - val_binary_accuracy: 0.9095 - val_loss: 0.2565\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7896 - binary_accuracy: 0.9087 - loss: 0.2656\n",
      "Fold 4 Metrics: Loss = 0.2565, Accuracy = 0.9095, AUC = 0.8087\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6900 - binary_accuracy: 0.9031 - loss: 0.3169 - val_auc: 0.7962 - val_binary_accuracy: 0.9093 - val_loss: 0.2583\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7672 - binary_accuracy: 0.9044 - loss: 0.2726 - val_auc: 0.8012 - val_binary_accuracy: 0.9093 - val_loss: 0.2577\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9064 - loss: 0.2681 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2581\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9072 - loss: 0.2658 - val_auc: 0.8042 - val_binary_accuracy: 0.9090 - val_loss: 0.2584\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9078 - loss: 0.2646 - val_auc: 0.8042 - val_binary_accuracy: 0.9087 - val_loss: 0.2575\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9084 - loss: 0.2640 - val_auc: 0.8046 - val_binary_accuracy: 0.9095 - val_loss: 0.2588\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9085 - loss: 0.2638 - val_auc: 0.8046 - val_binary_accuracy: 0.9100 - val_loss: 0.2587\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8055 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9083 - loss: 0.2629 - val_auc: 0.8066 - val_binary_accuracy: 0.9107 - val_loss: 0.2576\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9089 - loss: 0.2626 - val_auc: 0.8068 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8149 - binary_accuracy: 0.9102 - loss: 0.2535\n",
      "Fold 5 Metrics: Loss = 0.2573, Accuracy = 0.9091, AUC = 0.8068\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2600\n",
      "Average Accuracy: 0.9089\n",
      "Average AUC: 0.8036\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 4, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6476 - binary_accuracy: 0.8983 - loss: 0.3192 - val_auc: 0.7569 - val_binary_accuracy: 0.9040 - val_loss: 0.2772\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7598 - val_binary_accuracy: 0.9040 - val_loss: 0.2751\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9068 - loss: 0.2630 - val_auc: 0.7618 - val_binary_accuracy: 0.9040 - val_loss: 0.2753\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9068 - loss: 0.2627 - val_auc: 0.7640 - val_binary_accuracy: 0.9038 - val_loss: 0.2747\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9068 - loss: 0.2619 - val_auc: 0.7646 - val_binary_accuracy: 0.9038 - val_loss: 0.2740\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9068 - loss: 0.2614 - val_auc: 0.7650 - val_binary_accuracy: 0.9038 - val_loss: 0.2738\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9069 - loss: 0.2610 - val_auc: 0.7653 - val_binary_accuracy: 0.9038 - val_loss: 0.2738\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7663 - val_binary_accuracy: 0.9038 - val_loss: 0.2735\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9069 - loss: 0.2603 - val_auc: 0.7658 - val_binary_accuracy: 0.9038 - val_loss: 0.2730\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2601 - val_auc: 0.7674 - val_binary_accuracy: 0.9038 - val_loss: 0.2727\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7665 - binary_accuracy: 0.9078 - loss: 0.2653\n",
      "Fold 1 Metrics: Loss = 0.2727, Accuracy = 0.9038, AUC = 0.7674\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5976 - binary_accuracy: 0.8574 - loss: 0.3663 - val_auc: 0.7235 - val_binary_accuracy: 0.9042 - val_loss: 0.2919\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7143 - binary_accuracy: 0.9029 - loss: 0.2893 - val_auc: 0.7334 - val_binary_accuracy: 0.9042 - val_loss: 0.2892\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7256 - binary_accuracy: 0.9029 - loss: 0.2847 - val_auc: 0.7427 - val_binary_accuracy: 0.9042 - val_loss: 0.2839\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7418 - binary_accuracy: 0.9029 - loss: 0.2799 - val_auc: 0.7575 - val_binary_accuracy: 0.9042 - val_loss: 0.2784\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7509 - binary_accuracy: 0.9029 - loss: 0.2768 - val_auc: 0.7835 - val_binary_accuracy: 0.9042 - val_loss: 0.2731\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7626 - binary_accuracy: 0.9029 - loss: 0.2743 - val_auc: 0.7865 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9029 - loss: 0.2726 - val_auc: 0.7858 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9029 - loss: 0.2719 - val_auc: 0.7888 - val_binary_accuracy: 0.9042 - val_loss: 0.2709\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2707 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2713\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9029 - loss: 0.2709 - val_auc: 0.7875 - val_binary_accuracy: 0.9042 - val_loss: 0.2717\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7795 - binary_accuracy: 0.9092 - loss: 0.2621\n",
      "Fold 2 Metrics: Loss = 0.2717, Accuracy = 0.9042, AUC = 0.7875\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6142 - binary_accuracy: 0.9045 - loss: 0.3365 - val_auc: 0.7581 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7563 - binary_accuracy: 0.9048 - loss: 0.2747 - val_auc: 0.7709 - val_binary_accuracy: 0.9042 - val_loss: 0.2748\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9051 - loss: 0.2687 - val_auc: 0.7749 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7773 - val_binary_accuracy: 0.9041 - val_loss: 0.2727\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7809 - val_binary_accuracy: 0.9041 - val_loss: 0.2716\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7819 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9052 - loss: 0.2641 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9052 - loss: 0.2634 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9051 - loss: 0.2630 - val_auc: 0.7866 - val_binary_accuracy: 0.9042 - val_loss: 0.2672\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9051 - loss: 0.2627 - val_auc: 0.7878 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7824 - binary_accuracy: 0.9046 - loss: 0.2674\n",
      "Fold 3 Metrics: Loss = 0.2668, Accuracy = 0.9042, AUC = 0.7878\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4936 - binary_accuracy: 0.8270 - loss: 0.4017 - val_auc: 0.4962 - val_binary_accuracy: 0.9044 - val_loss: 0.3157\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5056 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4973 - val_binary_accuracy: 0.9044 - val_loss: 0.3157\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5047 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4976 - val_binary_accuracy: 0.9044 - val_loss: 0.3158\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5095 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4977 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5098 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4978 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5085 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4982 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5084 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4982 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5086 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5007 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5086 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5009 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5093 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5037 - val_binary_accuracy: 0.9044 - val_loss: 0.3158\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.5056 - binary_accuracy: 0.9049 - loss: 0.3146\n",
      "Fold 4 Metrics: Loss = 0.3158, Accuracy = 0.9044, AUC = 0.5037\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6141 - binary_accuracy: 0.8867 - loss: 0.3614 - val_auc: 0.7363 - val_binary_accuracy: 0.9044 - val_loss: 0.2835\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7209 - binary_accuracy: 0.9040 - loss: 0.2870 - val_auc: 0.7400 - val_binary_accuracy: 0.9044 - val_loss: 0.2800\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7253 - binary_accuracy: 0.9040 - loss: 0.2848 - val_auc: 0.7499 - val_binary_accuracy: 0.9045 - val_loss: 0.2768\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7319 - binary_accuracy: 0.9039 - loss: 0.2826 - val_auc: 0.7638 - val_binary_accuracy: 0.9045 - val_loss: 0.2738\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7450 - binary_accuracy: 0.9039 - loss: 0.2790 - val_auc: 0.7665 - val_binary_accuracy: 0.9044 - val_loss: 0.2721\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7503 - binary_accuracy: 0.9038 - loss: 0.2774 - val_auc: 0.7707 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7519 - binary_accuracy: 0.9039 - loss: 0.2781 - val_auc: 0.7705 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7553 - binary_accuracy: 0.9039 - loss: 0.2771 - val_auc: 0.7736 - val_binary_accuracy: 0.9044 - val_loss: 0.2678\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7564 - binary_accuracy: 0.9039 - loss: 0.2753 - val_auc: 0.7763 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9039 - loss: 0.2752 - val_auc: 0.7754 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9013 - loss: 0.2665\n",
      "Fold 5 Metrics: Loss = 0.2664, Accuracy = 0.9044, AUC = 0.7754\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2787\n",
      "Average Accuracy: 0.9042\n",
      "Average AUC: 0.7244\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 4, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6469 - binary_accuracy: 0.9069 - loss: 0.3076 - val_auc: 0.7691 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9068 - loss: 0.2585 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9070 - loss: 0.2564 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9072 - loss: 0.2549 - val_auc: 0.7883 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9075 - loss: 0.2535 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2655\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9085 - loss: 0.2521 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2642\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9085 - loss: 0.2515 - val_auc: 0.7904 - val_binary_accuracy: 0.9051 - val_loss: 0.2641\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8073 - binary_accuracy: 0.9104 - loss: 0.2506 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2622\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9105 - loss: 0.2500 - val_auc: 0.7925 - val_binary_accuracy: 0.9063 - val_loss: 0.2620\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7918 - binary_accuracy: 0.9094 - loss: 0.2548\n",
      "Fold 1 Metrics: Loss = 0.2620, Accuracy = 0.9063, AUC = 0.7925\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6112 - binary_accuracy: 0.8474 - loss: 0.3625 - val_auc: 0.7593 - val_binary_accuracy: 0.9042 - val_loss: 0.2813\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7562 - binary_accuracy: 0.9028 - loss: 0.2805 - val_auc: 0.7715 - val_binary_accuracy: 0.9041 - val_loss: 0.2794\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9040 - loss: 0.2762 - val_auc: 0.7959 - val_binary_accuracy: 0.9053 - val_loss: 0.2630\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2688 - val_auc: 0.7993 - val_binary_accuracy: 0.9056 - val_loss: 0.2637\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9052 - loss: 0.2676 - val_auc: 0.7997 - val_binary_accuracy: 0.9053 - val_loss: 0.2632\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9052 - loss: 0.2667 - val_auc: 0.8000 - val_binary_accuracy: 0.9063 - val_loss: 0.2607\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9066 - loss: 0.2654 - val_auc: 0.8003 - val_binary_accuracy: 0.9066 - val_loss: 0.2605\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9064 - loss: 0.2647 - val_auc: 0.8012 - val_binary_accuracy: 0.9063 - val_loss: 0.2603\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9067 - loss: 0.2631 - val_auc: 0.8048 - val_binary_accuracy: 0.9066 - val_loss: 0.2595\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9071 - loss: 0.2634 - val_auc: 0.8021 - val_binary_accuracy: 0.9072 - val_loss: 0.2603\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8054 - binary_accuracy: 0.9113 - loss: 0.2502\n",
      "Fold 2 Metrics: Loss = 0.2603, Accuracy = 0.9072, AUC = 0.8021\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6254 - binary_accuracy: 0.8785 - loss: 0.3328 - val_auc: 0.7636 - val_binary_accuracy: 0.9042 - val_loss: 0.2742\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9057 - loss: 0.2729 - val_auc: 0.7714 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9057 - loss: 0.2714 - val_auc: 0.7759 - val_binary_accuracy: 0.9047 - val_loss: 0.2708\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9063 - loss: 0.2688 - val_auc: 0.7749 - val_binary_accuracy: 0.9059 - val_loss: 0.2697\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7704 - binary_accuracy: 0.9064 - loss: 0.2677 - val_auc: 0.7763 - val_binary_accuracy: 0.9084 - val_loss: 0.2684\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9073 - loss: 0.2669 - val_auc: 0.7775 - val_binary_accuracy: 0.9073 - val_loss: 0.2684\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9065 - loss: 0.2664 - val_auc: 0.7790 - val_binary_accuracy: 0.9073 - val_loss: 0.2673\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9072 - loss: 0.2657 - val_auc: 0.7827 - val_binary_accuracy: 0.9076 - val_loss: 0.2661\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9081 - loss: 0.2653 - val_auc: 0.7839 - val_binary_accuracy: 0.9072 - val_loss: 0.2658\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9082 - loss: 0.2649 - val_auc: 0.7824 - val_binary_accuracy: 0.9075 - val_loss: 0.2657\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7762 - binary_accuracy: 0.9084 - loss: 0.2651\n",
      "Fold 3 Metrics: Loss = 0.2657, Accuracy = 0.9075, AUC = 0.7824\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6732 - binary_accuracy: 0.9052 - loss: 0.3074 - val_auc: 0.7863 - val_binary_accuracy: 0.9063 - val_loss: 0.2671\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9079 - loss: 0.2681 - val_auc: 0.7978 - val_binary_accuracy: 0.9075 - val_loss: 0.2623\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9087 - loss: 0.2650 - val_auc: 0.8024 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2632 - val_auc: 0.8036 - val_binary_accuracy: 0.9081 - val_loss: 0.2594\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9094 - loss: 0.2618 - val_auc: 0.8049 - val_binary_accuracy: 0.9082 - val_loss: 0.2586\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8057 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8049 - val_binary_accuracy: 0.9088 - val_loss: 0.2588\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9099 - loss: 0.2601 - val_auc: 0.8061 - val_binary_accuracy: 0.9090 - val_loss: 0.2587\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9097 - loss: 0.2598 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2586\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9097 - loss: 0.2596 - val_auc: 0.8076 - val_binary_accuracy: 0.9091 - val_loss: 0.2584\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7949 - binary_accuracy: 0.9090 - loss: 0.2623\n",
      "Fold 4 Metrics: Loss = 0.2584, Accuracy = 0.9091, AUC = 0.8076\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6298 - binary_accuracy: 0.9040 - loss: 0.3124 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9039 - loss: 0.2767 - val_auc: 0.7848 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9038 - loss: 0.2732 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2633\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9036 - loss: 0.2715 - val_auc: 0.7863 - val_binary_accuracy: 0.9044 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9042 - loss: 0.2696 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2610\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9038 - loss: 0.2686 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2602\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9053 - loss: 0.2677 - val_auc: 0.7962 - val_binary_accuracy: 0.9101 - val_loss: 0.2589\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9060 - loss: 0.2670 - val_auc: 0.7951 - val_binary_accuracy: 0.9106 - val_loss: 0.2581\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9070 - loss: 0.2659 - val_auc: 0.7973 - val_binary_accuracy: 0.9112 - val_loss: 0.2576\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2656 - val_auc: 0.7970 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8080 - binary_accuracy: 0.9111 - loss: 0.2538\n",
      "Fold 5 Metrics: Loss = 0.2571, Accuracy = 0.9112, AUC = 0.7970\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2607\n",
      "Average Accuracy: 0.9083\n",
      "Average AUC: 0.7963\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 4, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7309 - binary_accuracy: 0.9069 - loss: 0.2815 - val_auc: 0.7759 - val_binary_accuracy: 0.9048 - val_loss: 0.2681\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9086 - loss: 0.2589 - val_auc: 0.7823 - val_binary_accuracy: 0.9056 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9091 - loss: 0.2556 - val_auc: 0.7835 - val_binary_accuracy: 0.9054 - val_loss: 0.2649\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9088 - loss: 0.2539 - val_auc: 0.7848 - val_binary_accuracy: 0.9069 - val_loss: 0.2629\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9099 - loss: 0.2526 - val_auc: 0.7862 - val_binary_accuracy: 0.9100 - val_loss: 0.2617\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9102 - loss: 0.2520 - val_auc: 0.7867 - val_binary_accuracy: 0.9099 - val_loss: 0.2616\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9113 - loss: 0.2511 - val_auc: 0.7886 - val_binary_accuracy: 0.9096 - val_loss: 0.2612\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9114 - loss: 0.2505 - val_auc: 0.7881 - val_binary_accuracy: 0.9099 - val_loss: 0.2608\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9117 - loss: 0.2498 - val_auc: 0.7888 - val_binary_accuracy: 0.9099 - val_loss: 0.2605\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9120 - loss: 0.2491 - val_auc: 0.7889 - val_binary_accuracy: 0.9096 - val_loss: 0.2603\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7861 - binary_accuracy: 0.9128 - loss: 0.2534\n",
      "Fold 1 Metrics: Loss = 0.2603, Accuracy = 0.9096, AUC = 0.7889\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6884 - binary_accuracy: 0.8922 - loss: 0.3070 - val_auc: 0.7908 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9029 - loss: 0.2733 - val_auc: 0.8033 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9038 - loss: 0.2673 - val_auc: 0.8096 - val_binary_accuracy: 0.9042 - val_loss: 0.2601\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9056 - loss: 0.2648 - val_auc: 0.8118 - val_binary_accuracy: 0.9042 - val_loss: 0.2590\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9060 - loss: 0.2634 - val_auc: 0.8124 - val_binary_accuracy: 0.9042 - val_loss: 0.2589\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9056 - loss: 0.2627 - val_auc: 0.8121 - val_binary_accuracy: 0.9042 - val_loss: 0.2596\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9050 - loss: 0.2618 - val_auc: 0.8112 - val_binary_accuracy: 0.9047 - val_loss: 0.2597\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9061 - loss: 0.2609 - val_auc: 0.8109 - val_binary_accuracy: 0.9047 - val_loss: 0.2595\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9069 - loss: 0.2601 - val_auc: 0.8107 - val_binary_accuracy: 0.9051 - val_loss: 0.2585\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9079 - loss: 0.2598 - val_auc: 0.8099 - val_binary_accuracy: 0.9051 - val_loss: 0.2586\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9100 - loss: 0.2487\n",
      "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9051, AUC = 0.8099\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6706 - binary_accuracy: 0.8878 - loss: 0.3112 - val_auc: 0.7894 - val_binary_accuracy: 0.9065 - val_loss: 0.2684\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9063 - loss: 0.2710 - val_auc: 0.7957 - val_binary_accuracy: 0.9084 - val_loss: 0.2655\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9074 - loss: 0.2681 - val_auc: 0.7979 - val_binary_accuracy: 0.9099 - val_loss: 0.2635\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9089 - loss: 0.2666 - val_auc: 0.7986 - val_binary_accuracy: 0.9079 - val_loss: 0.2644\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9090 - loss: 0.2659 - val_auc: 0.7970 - val_binary_accuracy: 0.9066 - val_loss: 0.2641\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9084 - loss: 0.2657 - val_auc: 0.7996 - val_binary_accuracy: 0.9053 - val_loss: 0.2624\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9080 - loss: 0.2651 - val_auc: 0.7999 - val_binary_accuracy: 0.9053 - val_loss: 0.2614\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9087 - loss: 0.2644 - val_auc: 0.8002 - val_binary_accuracy: 0.9054 - val_loss: 0.2611\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8011 - val_binary_accuracy: 0.9054 - val_loss: 0.2609\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9086 - loss: 0.2632 - val_auc: 0.8008 - val_binary_accuracy: 0.9054 - val_loss: 0.2608\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9058 - loss: 0.2620\n",
      "Fold 3 Metrics: Loss = 0.2608, Accuracy = 0.9054, AUC = 0.8008\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7012 - binary_accuracy: 0.9004 - loss: 0.2989 - val_auc: 0.7891 - val_binary_accuracy: 0.9072 - val_loss: 0.2649\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9075 - loss: 0.2686 - val_auc: 0.7877 - val_binary_accuracy: 0.9079 - val_loss: 0.2645\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9086 - loss: 0.2659 - val_auc: 0.7927 - val_binary_accuracy: 0.9090 - val_loss: 0.2622\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9096 - loss: 0.2634 - val_auc: 0.7951 - val_binary_accuracy: 0.9095 - val_loss: 0.2610\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9096 - loss: 0.2622 - val_auc: 0.7975 - val_binary_accuracy: 0.9097 - val_loss: 0.2594\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9099 - loss: 0.2613 - val_auc: 0.7966 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.7971 - val_binary_accuracy: 0.9082 - val_loss: 0.2596\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9101 - loss: 0.2600 - val_auc: 0.7978 - val_binary_accuracy: 0.9082 - val_loss: 0.2595\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9103 - loss: 0.2594 - val_auc: 0.7976 - val_binary_accuracy: 0.9081 - val_loss: 0.2598\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9109 - loss: 0.2592 - val_auc: 0.7963 - val_binary_accuracy: 0.9085 - val_loss: 0.2599\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7777 - binary_accuracy: 0.9082 - loss: 0.2666\n",
      "Fold 4 Metrics: Loss = 0.2599, Accuracy = 0.9085, AUC = 0.7963\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6674 - binary_accuracy: 0.9039 - loss: 0.3090 - val_auc: 0.7882 - val_binary_accuracy: 0.9036 - val_loss: 0.2714\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9042 - loss: 0.2758 - val_auc: 0.7931 - val_binary_accuracy: 0.9038 - val_loss: 0.2647\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9045 - loss: 0.2723 - val_auc: 0.7967 - val_binary_accuracy: 0.9047 - val_loss: 0.2590\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9059 - loss: 0.2694 - val_auc: 0.7981 - val_binary_accuracy: 0.9060 - val_loss: 0.2573\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9066 - loss: 0.2671 - val_auc: 0.8001 - val_binary_accuracy: 0.9078 - val_loss: 0.2562\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9074 - loss: 0.2658 - val_auc: 0.8005 - val_binary_accuracy: 0.9073 - val_loss: 0.2559\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8017 - val_binary_accuracy: 0.9088 - val_loss: 0.2557\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8021 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9094 - loss: 0.2630 - val_auc: 0.8023 - val_binary_accuracy: 0.9088 - val_loss: 0.2553\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8027 - val_binary_accuracy: 0.9093 - val_loss: 0.2553\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.9075 - loss: 0.2533\n",
      "Fold 5 Metrics: Loss = 0.2553, Accuracy = 0.9093, AUC = 0.8027\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2590\n",
      "Average Accuracy: 0.9076\n",
      "Average AUC: 0.7998\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 4, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7170 - binary_accuracy: 0.9062 - loss: 0.2874 - val_auc: 0.7769 - val_binary_accuracy: 0.9045 - val_loss: 0.2674\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9063 - loss: 0.2616 - val_auc: 0.7833 - val_binary_accuracy: 0.9062 - val_loss: 0.2640\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9076 - loss: 0.2578 - val_auc: 0.7875 - val_binary_accuracy: 0.9076 - val_loss: 0.2623\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9091 - loss: 0.2555 - val_auc: 0.7903 - val_binary_accuracy: 0.9079 - val_loss: 0.2618\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9098 - loss: 0.2537 - val_auc: 0.7909 - val_binary_accuracy: 0.9079 - val_loss: 0.2608\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9104 - loss: 0.2525 - val_auc: 0.7931 - val_binary_accuracy: 0.9076 - val_loss: 0.2604\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9111 - loss: 0.2514 - val_auc: 0.7918 - val_binary_accuracy: 0.9088 - val_loss: 0.2602\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9123 - loss: 0.2508 - val_auc: 0.7924 - val_binary_accuracy: 0.9082 - val_loss: 0.2606\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9120 - loss: 0.2495 - val_auc: 0.7917 - val_binary_accuracy: 0.9084 - val_loss: 0.2609\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9126 - loss: 0.2489 - val_auc: 0.7926 - val_binary_accuracy: 0.9073 - val_loss: 0.2619\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7877 - binary_accuracy: 0.9115 - loss: 0.2551\n",
      "Fold 1 Metrics: Loss = 0.2619, Accuracy = 0.9073, AUC = 0.7926\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7122 - binary_accuracy: 0.8908 - loss: 0.3019 - val_auc: 0.7951 - val_binary_accuracy: 0.9042 - val_loss: 0.2736\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9029 - loss: 0.2708 - val_auc: 0.8036 - val_binary_accuracy: 0.9059 - val_loss: 0.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9052 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9085 - val_loss: 0.2620\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9065 - loss: 0.2649 - val_auc: 0.8022 - val_binary_accuracy: 0.9060 - val_loss: 0.2644\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9062 - loss: 0.2635 - val_auc: 0.8047 - val_binary_accuracy: 0.9073 - val_loss: 0.2643\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9079 - loss: 0.2625 - val_auc: 0.8024 - val_binary_accuracy: 0.9072 - val_loss: 0.2644\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9084 - loss: 0.2621 - val_auc: 0.8017 - val_binary_accuracy: 0.9062 - val_loss: 0.2645\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9082 - loss: 0.2619 - val_auc: 0.8079 - val_binary_accuracy: 0.9060 - val_loss: 0.2634\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9081 - loss: 0.2612 - val_auc: 0.8081 - val_binary_accuracy: 0.9057 - val_loss: 0.2628\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9081 - loss: 0.2608 - val_auc: 0.8064 - val_binary_accuracy: 0.9053 - val_loss: 0.2640\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8128 - binary_accuracy: 0.9099 - loss: 0.2548\n",
      "Fold 2 Metrics: Loss = 0.2640, Accuracy = 0.9053, AUC = 0.8064\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7225 - binary_accuracy: 0.8978 - loss: 0.2938 - val_auc: 0.7896 - val_binary_accuracy: 0.9048 - val_loss: 0.2683\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9068 - loss: 0.2687 - val_auc: 0.7924 - val_binary_accuracy: 0.9054 - val_loss: 0.2647\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9062 - loss: 0.2689 - val_auc: 0.7954 - val_binary_accuracy: 0.9073 - val_loss: 0.2624\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9070 - loss: 0.2683 - val_auc: 0.7969 - val_binary_accuracy: 0.9054 - val_loss: 0.2632\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9073 - loss: 0.2669 - val_auc: 0.7973 - val_binary_accuracy: 0.9075 - val_loss: 0.2621\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9088 - loss: 0.2654 - val_auc: 0.7995 - val_binary_accuracy: 0.9059 - val_loss: 0.2623\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9088 - loss: 0.2655 - val_auc: 0.7997 - val_binary_accuracy: 0.9059 - val_loss: 0.2628\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8017 - val_binary_accuracy: 0.9054 - val_loss: 0.2628\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9090 - loss: 0.2648 - val_auc: 0.8025 - val_binary_accuracy: 0.9047 - val_loss: 0.2630\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9084 - loss: 0.2647 - val_auc: 0.8046 - val_binary_accuracy: 0.9056 - val_loss: 0.2620\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7969 - binary_accuracy: 0.9058 - loss: 0.2628\n",
      "Fold 3 Metrics: Loss = 0.2620, Accuracy = 0.9056, AUC = 0.8046\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7177 - binary_accuracy: 0.9056 - loss: 0.2889 - val_auc: 0.7918 - val_binary_accuracy: 0.9056 - val_loss: 0.2641\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9074 - loss: 0.2679 - val_auc: 0.7957 - val_binary_accuracy: 0.9059 - val_loss: 0.2622\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9083 - loss: 0.2656 - val_auc: 0.7999 - val_binary_accuracy: 0.9067 - val_loss: 0.2603\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9071 - loss: 0.2633 - val_auc: 0.8017 - val_binary_accuracy: 0.9075 - val_loss: 0.2592\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9084 - loss: 0.2619 - val_auc: 0.8021 - val_binary_accuracy: 0.9094 - val_loss: 0.2588\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9090 - loss: 0.2612 - val_auc: 0.8021 - val_binary_accuracy: 0.9098 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9091 - loss: 0.2607 - val_auc: 0.8014 - val_binary_accuracy: 0.9093 - val_loss: 0.2591\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8013 - val_binary_accuracy: 0.9095 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8017 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9099 - loss: 0.2593 - val_auc: 0.8041 - val_binary_accuracy: 0.9084 - val_loss: 0.2591\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7847 - binary_accuracy: 0.9082 - loss: 0.2677\n",
      "Fold 4 Metrics: Loss = 0.2591, Accuracy = 0.9084, AUC = 0.8041\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7079 - binary_accuracy: 0.8894 - loss: 0.3020 - val_auc: 0.7946 - val_binary_accuracy: 0.9076 - val_loss: 0.2590\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9049 - loss: 0.2734 - val_auc: 0.8002 - val_binary_accuracy: 0.9079 - val_loss: 0.2577\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9064 - loss: 0.2691 - val_auc: 0.8024 - val_binary_accuracy: 0.9091 - val_loss: 0.2584\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9070 - loss: 0.2669 - val_auc: 0.8034 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9073 - loss: 0.2655 - val_auc: 0.8040 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9074 - loss: 0.2642 - val_auc: 0.8039 - val_binary_accuracy: 0.9093 - val_loss: 0.2561\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9084 - loss: 0.2635 - val_auc: 0.8043 - val_binary_accuracy: 0.9095 - val_loss: 0.2557\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9086 - loss: 0.2628 - val_auc: 0.8045 - val_binary_accuracy: 0.9097 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9084 - loss: 0.2623 - val_auc: 0.8047 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9084 - loss: 0.2618 - val_auc: 0.8069 - val_binary_accuracy: 0.9095 - val_loss: 0.2548\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9101 - loss: 0.2511\n",
      "Fold 5 Metrics: Loss = 0.2548, Accuracy = 0.9095, AUC = 0.8069\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2603\n",
      "Average Accuracy: 0.9072\n",
      "Average AUC: 0.8029\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 4, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6985 - binary_accuracy: 0.8899 - loss: 0.3071 - val_auc: 0.7799 - val_binary_accuracy: 0.9081 - val_loss: 0.2732\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9073 - loss: 0.2623 - val_auc: 0.7851 - val_binary_accuracy: 0.9048 - val_loss: 0.2637\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9086 - loss: 0.2582 - val_auc: 0.7885 - val_binary_accuracy: 0.9119 - val_loss: 0.2609\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9098 - loss: 0.2551 - val_auc: 0.7872 - val_binary_accuracy: 0.9103 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9114 - loss: 0.2539 - val_auc: 0.7890 - val_binary_accuracy: 0.9081 - val_loss: 0.2647\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9111 - loss: 0.2529 - val_auc: 0.7882 - val_binary_accuracy: 0.9099 - val_loss: 0.2660\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9120 - loss: 0.2523 - val_auc: 0.7898 - val_binary_accuracy: 0.9097 - val_loss: 0.2645\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8033 - binary_accuracy: 0.9124 - loss: 0.2512 - val_auc: 0.7897 - val_binary_accuracy: 0.9088 - val_loss: 0.2643\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9127 - loss: 0.2508 - val_auc: 0.7917 - val_binary_accuracy: 0.9088 - val_loss: 0.2646\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9111 - loss: 0.2524 - val_auc: 0.7914 - val_binary_accuracy: 0.9091 - val_loss: 0.2643\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7888 - binary_accuracy: 0.9119 - loss: 0.2559\n",
      "Fold 1 Metrics: Loss = 0.2643, Accuracy = 0.9091, AUC = 0.7914\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6840 - binary_accuracy: 0.8860 - loss: 0.3194 - val_auc: 0.8017 - val_binary_accuracy: 0.9060 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9037 - loss: 0.2699 - val_auc: 0.7980 - val_binary_accuracy: 0.9082 - val_loss: 0.2638\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9052 - loss: 0.2691 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2651\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9069 - loss: 0.2680 - val_auc: 0.8022 - val_binary_accuracy: 0.9091 - val_loss: 0.2636\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9070 - loss: 0.2654 - val_auc: 0.8038 - val_binary_accuracy: 0.9090 - val_loss: 0.2672\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9073 - loss: 0.2652 - val_auc: 0.8056 - val_binary_accuracy: 0.9090 - val_loss: 0.2673\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9080 - loss: 0.2652 - val_auc: 0.8075 - val_binary_accuracy: 0.9094 - val_loss: 0.2707\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9082 - loss: 0.2635 - val_auc: 0.8056 - val_binary_accuracy: 0.9088 - val_loss: 0.2662\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9075 - loss: 0.2638 - val_auc: 0.8079 - val_binary_accuracy: 0.9094 - val_loss: 0.2690\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9090 - loss: 0.2643 - val_auc: 0.8094 - val_binary_accuracy: 0.9076 - val_loss: 0.2668\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9113 - loss: 0.2576\n",
      "Fold 2 Metrics: Loss = 0.2668, Accuracy = 0.9076, AUC = 0.8094\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6674 - binary_accuracy: 0.8867 - loss: 0.3288 - val_auc: 0.7851 - val_binary_accuracy: 0.9050 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7624 - binary_accuracy: 0.9048 - loss: 0.2717 - val_auc: 0.7902 - val_binary_accuracy: 0.9078 - val_loss: 0.2668\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9075 - loss: 0.2677 - val_auc: 0.7931 - val_binary_accuracy: 0.9096 - val_loss: 0.2634\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9065 - loss: 0.2688 - val_auc: 0.7939 - val_binary_accuracy: 0.9112 - val_loss: 0.2629\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9069 - loss: 0.2684 - val_auc: 0.7966 - val_binary_accuracy: 0.9109 - val_loss: 0.2616\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9063 - loss: 0.2695 - val_auc: 0.7955 - val_binary_accuracy: 0.9096 - val_loss: 0.2618\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9069 - loss: 0.2699 - val_auc: 0.7983 - val_binary_accuracy: 0.9109 - val_loss: 0.2608\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9067 - loss: 0.2675 - val_auc: 0.7994 - val_binary_accuracy: 0.9073 - val_loss: 0.2658\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9078 - loss: 0.2660 - val_auc: 0.7987 - val_binary_accuracy: 0.9112 - val_loss: 0.2624\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9082 - loss: 0.2661 - val_auc: 0.8020 - val_binary_accuracy: 0.9054 - val_loss: 0.2645\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7948 - binary_accuracy: 0.9059 - loss: 0.2651\n",
      "Fold 3 Metrics: Loss = 0.2645, Accuracy = 0.9054, AUC = 0.8020\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6779 - binary_accuracy: 0.8991 - loss: 0.3164 - val_auc: 0.7880 - val_binary_accuracy: 0.9038 - val_loss: 0.2694\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9054 - loss: 0.2715 - val_auc: 0.7949 - val_binary_accuracy: 0.9025 - val_loss: 0.2700\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9072 - loss: 0.2675 - val_auc: 0.7984 - val_binary_accuracy: 0.9041 - val_loss: 0.2680\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9076 - loss: 0.2666 - val_auc: 0.7982 - val_binary_accuracy: 0.9035 - val_loss: 0.2690\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9083 - loss: 0.2660 - val_auc: 0.8014 - val_binary_accuracy: 0.9017 - val_loss: 0.2681\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9082 - loss: 0.2641 - val_auc: 0.8040 - val_binary_accuracy: 0.9087 - val_loss: 0.2621\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.8042 - val_binary_accuracy: 0.9084 - val_loss: 0.2615\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8039 - val_binary_accuracy: 0.9095 - val_loss: 0.2602\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9095 - loss: 0.2614 - val_auc: 0.8040 - val_binary_accuracy: 0.9078 - val_loss: 0.2628\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2611 - val_auc: 0.8068 - val_binary_accuracy: 0.9082 - val_loss: 0.2565\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7854 - binary_accuracy: 0.9079 - loss: 0.2659\n",
      "Fold 4 Metrics: Loss = 0.2565, Accuracy = 0.9082, AUC = 0.8068\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6716 - binary_accuracy: 0.8855 - loss: 0.3284 - val_auc: 0.7931 - val_binary_accuracy: 0.9020 - val_loss: 0.2629\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7566 - binary_accuracy: 0.9030 - loss: 0.2780 - val_auc: 0.8001 - val_binary_accuracy: 0.9087 - val_loss: 0.2571\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9055 - loss: 0.2716 - val_auc: 0.8025 - val_binary_accuracy: 0.9085 - val_loss: 0.2571\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9064 - loss: 0.2688 - val_auc: 0.8052 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9067 - loss: 0.2671 - val_auc: 0.8062 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9074 - loss: 0.2661 - val_auc: 0.8079 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9074 - loss: 0.2657 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8077 - val_binary_accuracy: 0.9101 - val_loss: 0.2562\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8059 - val_binary_accuracy: 0.9104 - val_loss: 0.2555\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9097 - loss: 0.2629 - val_auc: 0.8078 - val_binary_accuracy: 0.9104 - val_loss: 0.2560\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9086 - loss: 0.2534\n",
      "Fold 5 Metrics: Loss = 0.2560, Accuracy = 0.9104, AUC = 0.8078\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2616\n",
      "Average Accuracy: 0.9082\n",
      "Average AUC: 0.8035\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 5, 16)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6146 - binary_accuracy: 0.9011 - loss: 0.3375 - val_auc: 0.7421 - val_binary_accuracy: 0.9038 - val_loss: 0.2842\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7610 - binary_accuracy: 0.9069 - loss: 0.2687 - val_auc: 0.7503 - val_binary_accuracy: 0.9041 - val_loss: 0.2796\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9069 - loss: 0.2657 - val_auc: 0.7475 - val_binary_accuracy: 0.9040 - val_loss: 0.2767\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9069 - loss: 0.2636 - val_auc: 0.7646 - val_binary_accuracy: 0.9040 - val_loss: 0.2741\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7649 - val_binary_accuracy: 0.9040 - val_loss: 0.2732\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9069 - loss: 0.2622 - val_auc: 0.7666 - val_binary_accuracy: 0.9040 - val_loss: 0.2727\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9069 - loss: 0.2620 - val_auc: 0.7651 - val_binary_accuracy: 0.9040 - val_loss: 0.2725\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7659 - val_binary_accuracy: 0.9040 - val_loss: 0.2723\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9069 - loss: 0.2616 - val_auc: 0.7654 - val_binary_accuracy: 0.9040 - val_loss: 0.2721\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9069 - loss: 0.2614 - val_auc: 0.7652 - val_binary_accuracy: 0.9040 - val_loss: 0.2719\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7591 - binary_accuracy: 0.9079 - loss: 0.2648\n",
      "Fold 1 Metrics: Loss = 0.2719, Accuracy = 0.9040, AUC = 0.7652\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5868 - binary_accuracy: 0.8233 - loss: 0.3924 - val_auc: 0.6861 - val_binary_accuracy: 0.9042 - val_loss: 0.2951\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6966 - binary_accuracy: 0.9029 - loss: 0.2874 - val_auc: 0.7223 - val_binary_accuracy: 0.9042 - val_loss: 0.2889\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7317 - binary_accuracy: 0.9029 - loss: 0.2829 - val_auc: 0.7781 - val_binary_accuracy: 0.9042 - val_loss: 0.2733\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9029 - loss: 0.2762 - val_auc: 0.7869 - val_binary_accuracy: 0.9042 - val_loss: 0.2711\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7629 - binary_accuracy: 0.9029 - loss: 0.2747 - val_auc: 0.7901 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9029 - loss: 0.2733 - val_auc: 0.7924 - val_binary_accuracy: 0.9042 - val_loss: 0.2672\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.7894 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9032 - loss: 0.2728 - val_auc: 0.7895 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9029 - loss: 0.2718 - val_auc: 0.7921 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9038 - loss: 0.2710 - val_auc: 0.7937 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7886 - binary_accuracy: 0.9092 - loss: 0.2573\n",
      "Fold 2 Metrics: Loss = 0.2659, Accuracy = 0.9042, AUC = 0.7937\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5018 - binary_accuracy: 0.8569 - loss: 0.3752 - val_auc: 0.4997 - val_binary_accuracy: 0.9042 - val_loss: 0.3157\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5982 - binary_accuracy: 0.9051 - loss: 0.3065 - val_auc: 0.7714 - val_binary_accuracy: 0.9042 - val_loss: 0.2797\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7594 - binary_accuracy: 0.9051 - loss: 0.2745 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9051 - loss: 0.2699 - val_auc: 0.7779 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9051 - loss: 0.2687 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7796 - val_binary_accuracy: 0.9042 - val_loss: 0.2719\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9051 - loss: 0.2672 - val_auc: 0.7815 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9051 - loss: 0.2669 - val_auc: 0.7784 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7802 - val_binary_accuracy: 0.9042 - val_loss: 0.2696\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9051 - loss: 0.2643 - val_auc: 0.7816 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7779 - binary_accuracy: 0.9046 - loss: 0.2690\n",
      "Fold 3 Metrics: Loss = 0.2693, Accuracy = 0.9042, AUC = 0.7816\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5972 - binary_accuracy: 0.8563 - loss: 0.3674 - val_auc: 0.7605 - val_binary_accuracy: 0.9048 - val_loss: 0.2780\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7537 - binary_accuracy: 0.9066 - loss: 0.2746 - val_auc: 0.7719 - val_binary_accuracy: 0.9069 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9076 - loss: 0.2687 - val_auc: 0.7793 - val_binary_accuracy: 0.9079 - val_loss: 0.2671\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9080 - loss: 0.2668 - val_auc: 0.7884 - val_binary_accuracy: 0.9081 - val_loss: 0.2649\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9077 - loss: 0.2653 - val_auc: 0.7904 - val_binary_accuracy: 0.9081 - val_loss: 0.2648\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.7916 - val_binary_accuracy: 0.9076 - val_loss: 0.2650\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9088 - loss: 0.2633 - val_auc: 0.7922 - val_binary_accuracy: 0.9082 - val_loss: 0.2649\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.7924 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.7927 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9094 - loss: 0.2619 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2647\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7690 - binary_accuracy: 0.9086 - loss: 0.2704\n",
      "Fold 4 Metrics: Loss = 0.2647, Accuracy = 0.9085, AUC = 0.7923\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5539 - binary_accuracy: 0.9038 - loss: 0.3430 - val_auc: 0.7328 - val_binary_accuracy: 0.9044 - val_loss: 0.2860\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7154 - binary_accuracy: 0.9040 - loss: 0.2896 - val_auc: 0.7559 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7375 - binary_accuracy: 0.9040 - loss: 0.2833 - val_auc: 0.7601 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7402 - binary_accuracy: 0.9040 - loss: 0.2814 - val_auc: 0.7622 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7418 - binary_accuracy: 0.9040 - loss: 0.2806 - val_auc: 0.7629 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7433 - binary_accuracy: 0.9040 - loss: 0.2801 - val_auc: 0.7624 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7432 - binary_accuracy: 0.9040 - loss: 0.2796 - val_auc: 0.7623 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7446 - binary_accuracy: 0.9040 - loss: 0.2793 - val_auc: 0.7618 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7443 - binary_accuracy: 0.9040 - loss: 0.2790 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7459 - binary_accuracy: 0.9040 - loss: 0.2787 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7784 - binary_accuracy: 0.9013 - loss: 0.2666\n",
      "Fold 5 Metrics: Loss = 0.2681, Accuracy = 0.9044, AUC = 0.7615\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2680\n",
      "Average Accuracy: 0.9051\n",
      "Average AUC: 0.7788\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 5, 32)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7006 - binary_accuracy: 0.9069 - loss: 0.2901 - val_auc: 0.7626 - val_binary_accuracy: 0.9044 - val_loss: 0.2774\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9069 - loss: 0.2667 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9069 - loss: 0.2631 - val_auc: 0.7772 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2752\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9069 - loss: 0.2609 - val_auc: 0.7797 - val_binary_accuracy: 0.9044 - val_loss: 0.2744\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9069 - loss: 0.2604 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9069 - loss: 0.2597 - val_auc: 0.7809 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9069 - loss: 0.2593 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9069 - loss: 0.2588 - val_auc: 0.7823 - val_binary_accuracy: 0.9044 - val_loss: 0.2702\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7835 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7794 - binary_accuracy: 0.9084 - loss: 0.2645\n",
      "Fold 1 Metrics: Loss = 0.2700, Accuracy = 0.9044, AUC = 0.7835\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6584 - binary_accuracy: 0.8835 - loss: 0.3277 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9037 - loss: 0.2734 - val_auc: 0.7959 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9029 - loss: 0.2712 - val_auc: 0.7965 - val_binary_accuracy: 0.9054 - val_loss: 0.2647\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9029 - loss: 0.2694 - val_auc: 0.8010 - val_binary_accuracy: 0.9042 - val_loss: 0.2626\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9039 - loss: 0.2668 - val_auc: 0.8040 - val_binary_accuracy: 0.9044 - val_loss: 0.2604\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9048 - loss: 0.2661 - val_auc: 0.8045 - val_binary_accuracy: 0.9056 - val_loss: 0.2601\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9058 - loss: 0.2650 - val_auc: 0.8053 - val_binary_accuracy: 0.9054 - val_loss: 0.2596\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9056 - loss: 0.2646 - val_auc: 0.8052 - val_binary_accuracy: 0.9054 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9064 - loss: 0.2643 - val_auc: 0.8047 - val_binary_accuracy: 0.9053 - val_loss: 0.2598\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9056 - loss: 0.2631 - val_auc: 0.8056 - val_binary_accuracy: 0.9051 - val_loss: 0.2600\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8100 - binary_accuracy: 0.9096 - loss: 0.2494\n",
      "Fold 2 Metrics: Loss = 0.2600, Accuracy = 0.9051, AUC = 0.8056\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5811 - binary_accuracy: 0.8507 - loss: 0.3665 - val_auc: 0.7571 - val_binary_accuracy: 0.9042 - val_loss: 0.2802\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9051 - loss: 0.2753 - val_auc: 0.7719 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7639 - binary_accuracy: 0.9051 - loss: 0.2722 - val_auc: 0.7703 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9051 - loss: 0.2710 - val_auc: 0.7728 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9051 - loss: 0.2694 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9051 - loss: 0.2688 - val_auc: 0.7819 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9051 - loss: 0.2689 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9051 - loss: 0.2668 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7826 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7771 - binary_accuracy: 0.9046 - loss: 0.2683\n",
      "Fold 3 Metrics: Loss = 0.2677, Accuracy = 0.9042, AUC = 0.7826\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6636 - binary_accuracy: 0.8729 - loss: 0.3319 - val_auc: 0.7745 - val_binary_accuracy: 0.9056 - val_loss: 0.2709\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9052 - loss: 0.2702 - val_auc: 0.7851 - val_binary_accuracy: 0.9073 - val_loss: 0.2644\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9067 - loss: 0.2659 - val_auc: 0.7946 - val_binary_accuracy: 0.9070 - val_loss: 0.2613\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2639 - val_auc: 0.7966 - val_binary_accuracy: 0.9081 - val_loss: 0.2593\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9081 - loss: 0.2626 - val_auc: 0.7977 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2615 - val_auc: 0.7975 - val_binary_accuracy: 0.9090 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9096 - loss: 0.2602 - val_auc: 0.7985 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9095 - loss: 0.2599 - val_auc: 0.7996 - val_binary_accuracy: 0.9079 - val_loss: 0.2582\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9101 - loss: 0.2590 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2592\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.8006 - val_binary_accuracy: 0.9075 - val_loss: 0.2589\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7793 - binary_accuracy: 0.9075 - loss: 0.2657\n",
      "Fold 4 Metrics: Loss = 0.2589, Accuracy = 0.9075, AUC = 0.8006\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6761 - binary_accuracy: 0.8716 - loss: 0.3302 - val_auc: 0.7795 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7591 - binary_accuracy: 0.9040 - loss: 0.2769 - val_auc: 0.7820 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7626 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7655 - binary_accuracy: 0.9040 - loss: 0.2747 - val_auc: 0.7855 - val_binary_accuracy: 0.9044 - val_loss: 0.2634\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7874 - val_binary_accuracy: 0.9044 - val_loss: 0.2628\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9040 - loss: 0.2734 - val_auc: 0.7876 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9040 - loss: 0.2730 - val_auc: 0.7910 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9040 - loss: 0.2724 - val_auc: 0.7899 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9040 - loss: 0.2716 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2613\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8038 - binary_accuracy: 0.9013 - loss: 0.2577\n",
      "Fold 5 Metrics: Loss = 0.2613, Accuracy = 0.9044, AUC = 0.7889\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2636\n",
      "Average Accuracy: 0.9051\n",
      "Average AUC: 0.7923\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 5, 64)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7032 - binary_accuracy: 0.8961 - loss: 0.2951 - val_auc: 0.7677 - val_binary_accuracy: 0.9048 - val_loss: 0.2721\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9072 - loss: 0.2615 - val_auc: 0.7749 - val_binary_accuracy: 0.9060 - val_loss: 0.2691\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9086 - loss: 0.2590 - val_auc: 0.7809 - val_binary_accuracy: 0.9081 - val_loss: 0.2654\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9092 - loss: 0.2572 - val_auc: 0.7846 - val_binary_accuracy: 0.9096 - val_loss: 0.2629\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9102 - loss: 0.2556 - val_auc: 0.7846 - val_binary_accuracy: 0.9090 - val_loss: 0.2627\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9115 - loss: 0.2539 - val_auc: 0.7869 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9123 - loss: 0.2530 - val_auc: 0.7871 - val_binary_accuracy: 0.9057 - val_loss: 0.2636\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9114 - loss: 0.2519 - val_auc: 0.7886 - val_binary_accuracy: 0.9068 - val_loss: 0.2628\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9111 - loss: 0.2516 - val_auc: 0.7897 - val_binary_accuracy: 0.9053 - val_loss: 0.2629\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9111 - loss: 0.2506 - val_auc: 0.7914 - val_binary_accuracy: 0.9054 - val_loss: 0.2625\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7902 - binary_accuracy: 0.9097 - loss: 0.2552\n",
      "Fold 1 Metrics: Loss = 0.2625, Accuracy = 0.9054, AUC = 0.7914\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6903 - binary_accuracy: 0.8854 - loss: 0.3112 - val_auc: 0.7976 - val_binary_accuracy: 0.9063 - val_loss: 0.2643\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.8024 - val_binary_accuracy: 0.9066 - val_loss: 0.2615\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9061 - loss: 0.2676 - val_auc: 0.8006 - val_binary_accuracy: 0.9069 - val_loss: 0.2632\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9064 - loss: 0.2669 - val_auc: 0.8002 - val_binary_accuracy: 0.9071 - val_loss: 0.2654\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9066 - loss: 0.2657 - val_auc: 0.8015 - val_binary_accuracy: 0.9072 - val_loss: 0.2643\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8034 - val_binary_accuracy: 0.9072 - val_loss: 0.2642\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9074 - loss: 0.2638 - val_auc: 0.8030 - val_binary_accuracy: 0.9073 - val_loss: 0.2629\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9070 - loss: 0.2635 - val_auc: 0.8028 - val_binary_accuracy: 0.9075 - val_loss: 0.2632\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9086 - loss: 0.2625 - val_auc: 0.8054 - val_binary_accuracy: 0.9071 - val_loss: 0.2627\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9079 - loss: 0.2617 - val_auc: 0.8055 - val_binary_accuracy: 0.9066 - val_loss: 0.2619\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9105 - loss: 0.2510\n",
      "Fold 2 Metrics: Loss = 0.2619, Accuracy = 0.9066, AUC = 0.8055\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7101 - binary_accuracy: 0.9050 - loss: 0.2927 - val_auc: 0.7822 - val_binary_accuracy: 0.9047 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9048 - loss: 0.2738 - val_auc: 0.7888 - val_binary_accuracy: 0.9054 - val_loss: 0.2690\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7666 - binary_accuracy: 0.9057 - loss: 0.2702 - val_auc: 0.7911 - val_binary_accuracy: 0.9053 - val_loss: 0.2658\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9062 - loss: 0.2679 - val_auc: 0.7912 - val_binary_accuracy: 0.9050 - val_loss: 0.2677\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9076 - loss: 0.2678 - val_auc: 0.7939 - val_binary_accuracy: 0.9051 - val_loss: 0.2667\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9077 - loss: 0.2673 - val_auc: 0.7965 - val_binary_accuracy: 0.9056 - val_loss: 0.2669\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9078 - loss: 0.2671 - val_auc: 0.7985 - val_binary_accuracy: 0.9050 - val_loss: 0.2650\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7982 - val_binary_accuracy: 0.9053 - val_loss: 0.2640\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7990 - val_binary_accuracy: 0.9060 - val_loss: 0.2628\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.7984 - val_binary_accuracy: 0.9068 - val_loss: 0.2609\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7910 - binary_accuracy: 0.9071 - loss: 0.2620\n",
      "Fold 3 Metrics: Loss = 0.2609, Accuracy = 0.9068, AUC = 0.7984\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6462 - binary_accuracy: 0.8846 - loss: 0.3234 - val_auc: 0.7892 - val_binary_accuracy: 0.9051 - val_loss: 0.2630\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9048 - loss: 0.2695 - val_auc: 0.7938 - val_binary_accuracy: 0.9063 - val_loss: 0.2610\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9071 - loss: 0.2671 - val_auc: 0.7968 - val_binary_accuracy: 0.9066 - val_loss: 0.2605\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9065 - loss: 0.2655 - val_auc: 0.7995 - val_binary_accuracy: 0.9081 - val_loss: 0.2593\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9082 - loss: 0.2636 - val_auc: 0.7995 - val_binary_accuracy: 0.9072 - val_loss: 0.2600\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9082 - loss: 0.2631 - val_auc: 0.8012 - val_binary_accuracy: 0.9075 - val_loss: 0.2587\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8026 - val_binary_accuracy: 0.9081 - val_loss: 0.2576\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9094 - loss: 0.2609 - val_auc: 0.8039 - val_binary_accuracy: 0.9078 - val_loss: 0.2571\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9095 - loss: 0.2605 - val_auc: 0.8058 - val_binary_accuracy: 0.9091 - val_loss: 0.2566\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9097 - loss: 0.2601 - val_auc: 0.8040 - val_binary_accuracy: 0.9087 - val_loss: 0.2566\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7852 - binary_accuracy: 0.9090 - loss: 0.2631\n",
      "Fold 4 Metrics: Loss = 0.2566, Accuracy = 0.9087, AUC = 0.8040\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6929 - binary_accuracy: 0.9040 - loss: 0.2997 - val_auc: 0.7949 - val_binary_accuracy: 0.9063 - val_loss: 0.2659\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9044 - loss: 0.2725 - val_auc: 0.7987 - val_binary_accuracy: 0.9079 - val_loss: 0.2643\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.8001 - val_binary_accuracy: 0.9070 - val_loss: 0.2618\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9055 - loss: 0.2680 - val_auc: 0.8014 - val_binary_accuracy: 0.9087 - val_loss: 0.2601\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9066 - loss: 0.2669 - val_auc: 0.8017 - val_binary_accuracy: 0.9091 - val_loss: 0.2588\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9079 - loss: 0.2657 - val_auc: 0.8008 - val_binary_accuracy: 0.9098 - val_loss: 0.2579\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9080 - loss: 0.2648 - val_auc: 0.8002 - val_binary_accuracy: 0.9100 - val_loss: 0.2567\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9092 - loss: 0.2636 - val_auc: 0.8027 - val_binary_accuracy: 0.9100 - val_loss: 0.2556\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9101 - loss: 0.2626 - val_auc: 0.8026 - val_binary_accuracy: 0.9098 - val_loss: 0.2551\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9101 - loss: 0.2623 - val_auc: 0.8028 - val_binary_accuracy: 0.9098 - val_loss: 0.2546\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8165 - binary_accuracy: 0.9080 - loss: 0.2513\n",
      "Fold 5 Metrics: Loss = 0.2546, Accuracy = 0.9098, AUC = 0.8028\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2593\n",
      "Average Accuracy: 0.9075\n",
      "Average AUC: 0.8004\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 5, 128)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6891 - binary_accuracy: 0.8898 - loss: 0.2983 - val_auc: 0.7726 - val_binary_accuracy: 0.9072 - val_loss: 0.2803\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9075 - loss: 0.2651 - val_auc: 0.7823 - val_binary_accuracy: 0.9087 - val_loss: 0.2650\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9087 - loss: 0.2590 - val_auc: 0.7844 - val_binary_accuracy: 0.9091 - val_loss: 0.2642\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9106 - loss: 0.2564 - val_auc: 0.7864 - val_binary_accuracy: 0.9096 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9111 - loss: 0.2539 - val_auc: 0.7872 - val_binary_accuracy: 0.9090 - val_loss: 0.2619\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9119 - loss: 0.2524 - val_auc: 0.7862 - val_binary_accuracy: 0.9094 - val_loss: 0.2626\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9129 - loss: 0.2518 - val_auc: 0.7882 - val_binary_accuracy: 0.9045 - val_loss: 0.2642\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9125 - loss: 0.2509 - val_auc: 0.7905 - val_binary_accuracy: 0.9073 - val_loss: 0.2626\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9136 - loss: 0.2506 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2647\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9107 - loss: 0.2519 - val_auc: 0.7902 - val_binary_accuracy: 0.9075 - val_loss: 0.2624\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7858 - binary_accuracy: 0.9106 - loss: 0.2559\n",
      "Fold 1 Metrics: Loss = 0.2624, Accuracy = 0.9075, AUC = 0.7902\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7181 - binary_accuracy: 0.9023 - loss: 0.2955 - val_auc: 0.7961 - val_binary_accuracy: 0.9053 - val_loss: 0.2736\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9028 - loss: 0.2721 - val_auc: 0.8051 - val_binary_accuracy: 0.9068 - val_loss: 0.2648\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9057 - loss: 0.2683 - val_auc: 0.8043 - val_binary_accuracy: 0.9084 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9067 - loss: 0.2666 - val_auc: 0.8036 - val_binary_accuracy: 0.9079 - val_loss: 0.2644\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9073 - loss: 0.2655 - val_auc: 0.8086 - val_binary_accuracy: 0.9081 - val_loss: 0.2640\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9073 - loss: 0.2638 - val_auc: 0.8096 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9073 - loss: 0.2626 - val_auc: 0.8102 - val_binary_accuracy: 0.9088 - val_loss: 0.2659\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9079 - loss: 0.2626 - val_auc: 0.8104 - val_binary_accuracy: 0.9088 - val_loss: 0.2678\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9085 - loss: 0.2625 - val_auc: 0.8103 - val_binary_accuracy: 0.9081 - val_loss: 0.2677\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9080 - loss: 0.2617 - val_auc: 0.8116 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8177 - binary_accuracy: 0.9127 - loss: 0.2547\n",
      "Fold 2 Metrics: Loss = 0.2636, Accuracy = 0.9082, AUC = 0.8116\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7121 - binary_accuracy: 0.8868 - loss: 0.2975 - val_auc: 0.7902 - val_binary_accuracy: 0.9047 - val_loss: 0.2664\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7666 - binary_accuracy: 0.9064 - loss: 0.2697 - val_auc: 0.7958 - val_binary_accuracy: 0.9066 - val_loss: 0.2655\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9070 - loss: 0.2679 - val_auc: 0.7986 - val_binary_accuracy: 0.9063 - val_loss: 0.2666\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9073 - loss: 0.2676 - val_auc: 0.7986 - val_binary_accuracy: 0.9081 - val_loss: 0.2621\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9070 - loss: 0.2690 - val_auc: 0.8012 - val_binary_accuracy: 0.9103 - val_loss: 0.2637\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9081 - loss: 0.2668 - val_auc: 0.8016 - val_binary_accuracy: 0.9093 - val_loss: 0.2650\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9078 - loss: 0.2664 - val_auc: 0.8017 - val_binary_accuracy: 0.9096 - val_loss: 0.2656\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.8025 - val_binary_accuracy: 0.9071 - val_loss: 0.2665\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9085 - loss: 0.2641 - val_auc: 0.8029 - val_binary_accuracy: 0.9057 - val_loss: 0.2660\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8027 - val_binary_accuracy: 0.9079 - val_loss: 0.2643\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7951 - binary_accuracy: 0.9082 - loss: 0.2656\n",
      "Fold 3 Metrics: Loss = 0.2643, Accuracy = 0.9079, AUC = 0.8027\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7232 - binary_accuracy: 0.8964 - loss: 0.2925 - val_auc: 0.7937 - val_binary_accuracy: 0.9064 - val_loss: 0.2670\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.7957 - val_binary_accuracy: 0.9056 - val_loss: 0.2658\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.7972 - val_binary_accuracy: 0.9050 - val_loss: 0.2676\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9081 - loss: 0.2639 - val_auc: 0.7979 - val_binary_accuracy: 0.9075 - val_loss: 0.2663\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7977 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9093 - loss: 0.2621 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2655\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9095 - loss: 0.2618 - val_auc: 0.7987 - val_binary_accuracy: 0.9082 - val_loss: 0.2629\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9099 - loss: 0.2612 - val_auc: 0.8001 - val_binary_accuracy: 0.9100 - val_loss: 0.2613\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2607 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2627\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9094 - loss: 0.2601 - val_auc: 0.8002 - val_binary_accuracy: 0.9095 - val_loss: 0.2606\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7807 - binary_accuracy: 0.9091 - loss: 0.2699\n",
      "Fold 4 Metrics: Loss = 0.2606, Accuracy = 0.9095, AUC = 0.8002\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7040 - binary_accuracy: 0.9036 - loss: 0.2973 - val_auc: 0.7878 - val_binary_accuracy: 0.9067 - val_loss: 0.2627\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9041 - loss: 0.2760 - val_auc: 0.7976 - val_binary_accuracy: 0.9075 - val_loss: 0.2586\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9063 - loss: 0.2704 - val_auc: 0.8002 - val_binary_accuracy: 0.9095 - val_loss: 0.2600\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9072 - loss: 0.2676 - val_auc: 0.8030 - val_binary_accuracy: 0.9101 - val_loss: 0.2597\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9077 - loss: 0.2663 - val_auc: 0.8040 - val_binary_accuracy: 0.9088 - val_loss: 0.2598\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8047 - val_binary_accuracy: 0.9103 - val_loss: 0.2597\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9083 - loss: 0.2642 - val_auc: 0.8050 - val_binary_accuracy: 0.9104 - val_loss: 0.2570\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9092 - loss: 0.2633 - val_auc: 0.8059 - val_binary_accuracy: 0.9107 - val_loss: 0.2574\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9081 - loss: 0.2634 - val_auc: 0.8061 - val_binary_accuracy: 0.9107 - val_loss: 0.2583\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9080 - loss: 0.2637 - val_auc: 0.8035 - val_binary_accuracy: 0.9094 - val_loss: 0.2575\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9094 - loss: 0.2534\n",
      "Fold 5 Metrics: Loss = 0.2575, Accuracy = 0.9094, AUC = 0.8035\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2617\n",
      "Average Accuracy: 0.9085\n",
      "Average AUC: 0.8017\n",
      "----------------------------------------\n",
      "Performing training for: ('tanh', 5, 256)\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6891 - binary_accuracy: 0.8859 - loss: 0.3075 - val_auc: 0.7797 - val_binary_accuracy: 0.9102 - val_loss: 0.2736\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9080 - loss: 0.2624 - val_auc: 0.7868 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9064 - loss: 0.2611 - val_auc: 0.7890 - val_binary_accuracy: 0.9103 - val_loss: 0.2617\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9092 - loss: 0.2579 - val_auc: 0.7894 - val_binary_accuracy: 0.9119 - val_loss: 0.2606\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9115 - loss: 0.2552 - val_auc: 0.7902 - val_binary_accuracy: 0.9103 - val_loss: 0.2633\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9114 - loss: 0.2541 - val_auc: 0.7910 - val_binary_accuracy: 0.9094 - val_loss: 0.2605\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9092 - loss: 0.2569 - val_auc: 0.7927 - val_binary_accuracy: 0.9118 - val_loss: 0.2637\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9124 - loss: 0.2555 - val_auc: 0.7904 - val_binary_accuracy: 0.9066 - val_loss: 0.2643\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9109 - loss: 0.2542 - val_auc: 0.7875 - val_binary_accuracy: 0.9088 - val_loss: 0.2627\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9115 - loss: 0.2561 - val_auc: 0.7898 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7844 - binary_accuracy: 0.9113 - loss: 0.2558\n",
      "Fold 1 Metrics: Loss = 0.2631, Accuracy = 0.9082, AUC = 0.7898\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6904 - binary_accuracy: 0.8845 - loss: 0.3209 - val_auc: 0.8003 - val_binary_accuracy: 0.9060 - val_loss: 0.2667\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9040 - loss: 0.2722 - val_auc: 0.8018 - val_binary_accuracy: 0.9081 - val_loss: 0.2638\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9057 - loss: 0.2689 - val_auc: 0.8025 - val_binary_accuracy: 0.9081 - val_loss: 0.2638\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9071 - loss: 0.2676 - val_auc: 0.8006 - val_binary_accuracy: 0.9078 - val_loss: 0.2662\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9071 - loss: 0.2675 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2649\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9057 - loss: 0.2692 - val_auc: 0.8060 - val_binary_accuracy: 0.9066 - val_loss: 0.2660\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9050 - loss: 0.2675 - val_auc: 0.7934 - val_binary_accuracy: 0.9088 - val_loss: 0.2690\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9057 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9096 - val_loss: 0.2650\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9070 - loss: 0.2656 - val_auc: 0.7989 - val_binary_accuracy: 0.9091 - val_loss: 0.2674\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9078 - loss: 0.2650 - val_auc: 0.8125 - val_binary_accuracy: 0.9094 - val_loss: 0.2620\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8172 - binary_accuracy: 0.9135 - loss: 0.2530\n",
      "Fold 2 Metrics: Loss = 0.2620, Accuracy = 0.9094, AUC = 0.8125\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6702 - binary_accuracy: 0.8862 - loss: 0.3217 - val_auc: 0.7878 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9043 - loss: 0.2728 - val_auc: 0.7924 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7658 - binary_accuracy: 0.9055 - loss: 0.2699 - val_auc: 0.7955 - val_binary_accuracy: 0.9078 - val_loss: 0.2668\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9063 - loss: 0.2700 - val_auc: 0.7952 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9053 - loss: 0.2719 - val_auc: 0.7937 - val_binary_accuracy: 0.9042 - val_loss: 0.2637\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9053 - loss: 0.2716 - val_auc: 0.7965 - val_binary_accuracy: 0.9093 - val_loss: 0.2663\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9075 - loss: 0.2690 - val_auc: 0.7963 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7640 - binary_accuracy: 0.9072 - loss: 0.2703 - val_auc: 0.7961 - val_binary_accuracy: 0.9090 - val_loss: 0.2607\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7630 - binary_accuracy: 0.9089 - loss: 0.2683 - val_auc: 0.7968 - val_binary_accuracy: 0.9066 - val_loss: 0.2639\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9077 - loss: 0.2685 - val_auc: 0.7962 - val_binary_accuracy: 0.9104 - val_loss: 0.2635\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7872 - binary_accuracy: 0.9115 - loss: 0.2634\n",
      "Fold 3 Metrics: Loss = 0.2635, Accuracy = 0.9104, AUC = 0.7962\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6836 - binary_accuracy: 0.9007 - loss: 0.3080 - val_auc: 0.7859 - val_binary_accuracy: 0.9056 - val_loss: 0.2716\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9044 - loss: 0.2734 - val_auc: 0.7899 - val_binary_accuracy: 0.9032 - val_loss: 0.2683\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9053 - loss: 0.2704 - val_auc: 0.7958 - val_binary_accuracy: 0.9087 - val_loss: 0.2708\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9059 - loss: 0.2687 - val_auc: 0.7993 - val_binary_accuracy: 0.8992 - val_loss: 0.2815\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9067 - loss: 0.2706 - val_auc: 0.7954 - val_binary_accuracy: 0.9085 - val_loss: 0.2641\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9078 - loss: 0.2652 - val_auc: 0.7958 - val_binary_accuracy: 0.9072 - val_loss: 0.2635\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9092 - loss: 0.2649 - val_auc: 0.7956 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9088 - loss: 0.2632 - val_auc: 0.7937 - val_binary_accuracy: 0.9051 - val_loss: 0.2675\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9092 - loss: 0.2638 - val_auc: 0.7939 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9088 - loss: 0.2671 - val_auc: 0.7916 - val_binary_accuracy: 0.9084 - val_loss: 0.2619\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7694 - binary_accuracy: 0.9085 - loss: 0.2711\n",
      "Fold 4 Metrics: Loss = 0.2619, Accuracy = 0.9084, AUC = 0.7916\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6762 - binary_accuracy: 0.8851 - loss: 0.3195 - val_auc: 0.7930 - val_binary_accuracy: 0.9084 - val_loss: 0.2611\n",
      "Epoch 2/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7539 - binary_accuracy: 0.9025 - loss: 0.2790 - val_auc: 0.7988 - val_binary_accuracy: 0.9075 - val_loss: 0.2572\n",
      "Epoch 3/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9053 - loss: 0.2720 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
      "Epoch 4/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9058 - loss: 0.2698 - val_auc: 0.8034 - val_binary_accuracy: 0.9097 - val_loss: 0.2588\n",
      "Epoch 5/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9063 - loss: 0.2684 - val_auc: 0.8045 - val_binary_accuracy: 0.9104 - val_loss: 0.2573\n",
      "Epoch 6/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9067 - loss: 0.2668 - val_auc: 0.8047 - val_binary_accuracy: 0.9098 - val_loss: 0.2571\n",
      "Epoch 7/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9097 - loss: 0.2655 - val_auc: 0.8072 - val_binary_accuracy: 0.9044 - val_loss: 0.2556\n",
      "Epoch 8/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9072 - loss: 0.2654 - val_auc: 0.8057 - val_binary_accuracy: 0.9101 - val_loss: 0.2554\n",
      "Epoch 9/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9071 - loss: 0.2701 - val_auc: 0.8062 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
      "Epoch 10/10\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9090 - loss: 0.2655 - val_auc: 0.8044 - val_binary_accuracy: 0.9098 - val_loss: 0.2548\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8136 - binary_accuracy: 0.9076 - loss: 0.2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [1:22:51<00:00, 1657.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Metrics: Loss = 0.2548, Accuracy = 0.9098, AUC = 0.8044\n",
      "\n",
      "--- K-Fold Cross-Validation Complete ---\n",
      "Average Loss: 0.2610\n",
      "Average Accuracy: 0.9093\n",
      "Average AUC: 0.7989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# setting a seed\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# defining options\n",
    "hidden_layer_configs = [1,2,3,4,5]\n",
    "activation_config = ['relu', 'sigmoid', 'tanh']\n",
    "node_configs = [16, 32, 64, 128, 256]\n",
    "\n",
    "comparison_list = []\n",
    "comparison_df_new = pd.DataFrame()\n",
    "\n",
    "# training models\n",
    "with tf.device('/GPU:0'):\n",
    "    for activation in tqdm.tqdm(activation_config):\n",
    "        for hl in hidden_layer_configs:\n",
    "            for nodes in node_configs:\n",
    "                print(\"-\"*40)\n",
    "                print(f\"Performing training for: {activation, hl, nodes}\")\n",
    "                print(\"-\"*40)\n",
    "                # train model\n",
    "                fold_loss, fold_accuracies, fold_aucs, _ = k_fold_cross_validation(hl=hl, nodes=nodes, activation=activation, epochs = 10)\n",
    "                # store output\n",
    "                comparison_list.append((activation, hl, nodes, fold_loss, fold_accuracies, fold_aucs))\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_list)\n",
    "comparison_df.to_csv(\"/content/drive/MyDrive/Data Analytics/Assignments/Group Project/model_comparison_five_fold_strat.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "anByv4R4hb0V",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1764608414251,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "anByv4R4hb0V"
   },
   "outputs": [],
   "source": [
    "comparison_df = pd.read_csv(PROCESSED_DIR / \"model_comparison_five_fold_strat_mac.csv\")\n",
    "comparison_df.columns = [\"act\", \"hl\", \"nodes\", \"loss\", \"acc\", \"auc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VmycvIWdhuWE",
   "metadata": {
    "executionInfo": {
     "elapsed": 42974,
     "status": "aborted",
     "timestamp": 1764598363404,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "VmycvIWdhuWE"
   },
   "outputs": [],
   "source": [
    "comparison_df[\"avg_loss\"] = comparison_df[\"loss\"].apply(lambda x: np.mean(ast.literal_eval(x)))\n",
    "comparison_df[\"avg_acc\"] = comparison_df[\"acc\"].apply(lambda x: np.mean(ast.literal_eval(x)))\n",
    "comparison_df[\"avg_auc\"] = comparison_df[\"auc\"].apply(lambda x: np.mean(ast.literal_eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "jVC4AixTiKlo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1764608414288,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "jVC4AixTiKlo",
    "outputId": "b8215659-5f4f-496f-88e6-4f14cf1413ab"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"act\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"relu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nodes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85,\n        \"min\": 64,\n        \"max\": 256,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0.31858211755752563, 0.36027613282203674, 0.25885921716690063, 0.25837039947509766, 0.2512544095516205]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0.9083800315856934, 0.8490705490112305, 0.9091177582740784, 0.9052678346633911, 0.9107274413108826]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0.7873588800430298, 0.81210857629776, 0.7963587045669556, 0.810806930065155, 0.8128728270530701]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007085299939217751,\n        \"min\": 0.2765244722366333,\n        \"max\": 0.29502456188201903,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2894684553146362\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0021013830792327172,\n        \"min\": 0.8942399024963379,\n        \"max\": 0.8998175263404846,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8965127229690552\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007605461845128445,\n        \"min\": 0.8024112820625305,\n        \"max\": 0.8039302110671998,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8039011836051941\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-93ee67a0-0bb2-4324-9dc7-4f540edec123\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>hl</th>\n",
       "      <th>nodes</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_acc</th>\n",
       "      <th>avg_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>[0.30871862173080444, 0.343106210231781, 0.261...</td>\n",
       "      <td>[0.9092652797698975, 0.8623487949371338, 0.909...</td>\n",
       "      <td>[0.7868945002555847, 0.8111099600791931, 0.796...</td>\n",
       "      <td>0.295025</td>\n",
       "      <td>0.894240</td>\n",
       "      <td>0.803930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>[0.31858211755752563, 0.36027613282203674, 0.2...</td>\n",
       "      <td>[0.9083800315856934, 0.8490705490112305, 0.909...</td>\n",
       "      <td>[0.7873588800430298, 0.81210857629776, 0.79635...</td>\n",
       "      <td>0.289468</td>\n",
       "      <td>0.896513</td>\n",
       "      <td>0.803901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.3157957196235657, 0.36118727922439575, 0.25...</td>\n",
       "      <td>[0.9079374670982361, 0.8591029644012451, 0.909...</td>\n",
       "      <td>[0.7880730032920837, 0.809856116771698, 0.7958...</td>\n",
       "      <td>0.292142</td>\n",
       "      <td>0.897191</td>\n",
       "      <td>0.802667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>[0.26953381299972534, 0.33885297179222107, 0.2...</td>\n",
       "      <td>[0.9117733836174011, 0.8619061708450317, 0.909...</td>\n",
       "      <td>[0.7870328426361084, 0.8068638443946838, 0.797...</td>\n",
       "      <td>0.276524</td>\n",
       "      <td>0.899818</td>\n",
       "      <td>0.802533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>[0.295051246881485, 0.37400567531585693, 0.262...</td>\n",
       "      <td>[0.9097079038619995, 0.8436116576194763, 0.908...</td>\n",
       "      <td>[0.7852222919464111, 0.811111330986023, 0.7942...</td>\n",
       "      <td>0.289289</td>\n",
       "      <td>0.895421</td>\n",
       "      <td>0.802411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93ee67a0-0bb2-4324-9dc7-4f540edec123')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-93ee67a0-0bb2-4324-9dc7-4f540edec123 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-93ee67a0-0bb2-4324-9dc7-4f540edec123');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-c1d25a33-d43d-4bbd-899d-0cce84d6c59f\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1d25a33-d43d-4bbd-899d-0cce84d6c59f')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-c1d25a33-d43d-4bbd-899d-0cce84d6c59f button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    act  hl  nodes                                               loss  \\\n",
       "3  relu   1    128  [0.30871862173080444, 0.343106210231781, 0.261...   \n",
       "4  relu   1    256  [0.31858211755752563, 0.36027613282203674, 0.2...   \n",
       "2  relu   1     64  [0.3157957196235657, 0.36118727922439575, 0.25...   \n",
       "9  relu   2    256  [0.26953381299972534, 0.33885297179222107, 0.2...   \n",
       "8  relu   2    128  [0.295051246881485, 0.37400567531585693, 0.262...   \n",
       "\n",
       "                                                 acc  \\\n",
       "3  [0.9092652797698975, 0.8623487949371338, 0.909...   \n",
       "4  [0.9083800315856934, 0.8490705490112305, 0.909...   \n",
       "2  [0.9079374670982361, 0.8591029644012451, 0.909...   \n",
       "9  [0.9117733836174011, 0.8619061708450317, 0.909...   \n",
       "8  [0.9097079038619995, 0.8436116576194763, 0.908...   \n",
       "\n",
       "                                                 auc  avg_loss   avg_acc  \\\n",
       "3  [0.7868945002555847, 0.8111099600791931, 0.796...  0.295025  0.894240   \n",
       "4  [0.7873588800430298, 0.81210857629776, 0.79635...  0.289468  0.896513   \n",
       "2  [0.7880730032920837, 0.809856116771698, 0.7958...  0.292142  0.897191   \n",
       "9  [0.7870328426361084, 0.8068638443946838, 0.797...  0.276524  0.899818   \n",
       "8  [0.7852222919464111, 0.811111330986023, 0.7942...  0.289289  0.895421   \n",
       "\n",
       "    avg_auc  \n",
       "3  0.803930  \n",
       "4  0.803901  \n",
       "2  0.802667  \n",
       "9  0.802533  \n",
       "8  0.802411  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.sort_values(by = [\"avg_auc\", \"avg_acc\"], ascending = [False, False]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8djlZJci05oD",
   "metadata": {
    "id": "8djlZJci05oD"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099hWGV8z_NF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6296,
     "status": "ok",
     "timestamp": 1764608420597,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "099hWGV8z_NF",
    "outputId": "456d3d88-1527-4f5e-e3c4-b190d3571e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# setting a seed\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# confusion matrix\n",
    "best_model, _, _ = train_and_evaluate_model(hl = 1, nodes = 128, activation = \"relu\", epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "C8eXy1kl1JHA",
   "metadata": {
    "executionInfo": {
     "elapsed": 42970,
     "status": "aborted",
     "timestamp": 1764598363406,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "C8eXy1kl1JHA"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pred_probs = \u001b[43mbest_model\u001b[49m.predict(test_x)\n\u001b[32m      2\u001b[39m y_pred = (pred_probs > \u001b[32m0.2\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)   \u001b[38;5;66;03m# convert probabilities to 0/1\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "pred_probs = best_model.predict(test_x)\n",
    "y_pred = (pred_probs > 0.2).astype(int)   # convert probabilities to 0/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KJlC_Hkyc6z7",
   "metadata": {
    "id": "KJlC_Hkyc6z7"
   },
   "source": [
    "### **Confusion matrix**\n",
    "\n",
    "*I am not sure, if that is the right way to evaluate it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YsY-yaAP1ZY4",
   "metadata": {
    "executionInfo": {
     "elapsed": 42967,
     "status": "aborted",
     "timestamp": 1764598363407,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "YsY-yaAP1ZY4"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_y, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qDmVlbUk55H8",
   "metadata": {
    "id": "qDmVlbUk55H8"
   },
   "source": [
    "# Evaluating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PU1dLc8tOpDv",
   "metadata": {
    "executionInfo": {
     "elapsed": 42964,
     "status": "aborted",
     "timestamp": 1764598363407,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "PU1dLc8tOpDv"
   },
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame(pred_probs, test_y).reset_index()\n",
    "evaluation.columns = [\"outcome\", \"pred_prob\"]\n",
    "\n",
    "model_probs = np.linspace(0.025, 0.975, num = 20)\n",
    "true_probs = []\n",
    "\n",
    "for prob in model_probs:\n",
    "    true_probs.append(evaluation[(evaluation[\"pred_prob\"] >= prob -0.025) & (evaluation[\"pred_prob\"] <= prob + 0.025)][\"outcome\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79YcRuXWCxu",
   "metadata": {
    "id": "b79YcRuXWCxu"
   },
   "source": [
    "There is no predicted probs above 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "AbkHeuuDVlB9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 111,
     "status": "ok",
     "timestamp": 1764608421711,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "AbkHeuuDVlB9",
    "outputId": "ec039f13-50e9-4bd1-daf0-1ee31a81c790"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_probs = np.linspace(0,1.01, num = 10)\n",
    "\n",
    "plt.plot(model_probs, true_probs, color = \"red\", marker='.', label = \"Model line\")\n",
    "plt.plot(plot_probs, plot_probs, alpha = 0.5, color = \"blue\", label = \"Ideal line\")\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "#plt.axvspan(0.9, 1, alpha=0.1, label = \"No shots with prob > 0.9\", color = \"red\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Model Probability\")\n",
    "plt.ylabel(\"True Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OAKQKJOWcV4E",
   "metadata": {
    "id": "OAKQKJOWcV4E"
   },
   "source": [
    "## Isometric regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "if5vt00o6GhD",
   "metadata": {
    "executionInfo": {
     "elapsed": 42960,
     "status": "aborted",
     "timestamp": 1764598363408,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "if5vt00o6GhD"
   },
   "outputs": [],
   "source": [
    "f_X = football_df.drop(\"shot_outcome_encoded\", axis = 1)\n",
    "f_y = football_df[\"shot_outcome_encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "iGAzQ_k86GhD",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1764608421823,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "iGAzQ_k86GhD"
   },
   "outputs": [],
   "source": [
    "# setting a seed\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# splitting the data\n",
    "f_train_x, f_test_x , f_train_y, f_test_y = train_test_split(\n",
    "    f_X, f_y,\n",
    "    test_size = 0.25,\n",
    "    random_state= 123,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WeezwtfN5_n-",
   "metadata": {
    "executionInfo": {
     "elapsed": 42990,
     "status": "aborted",
     "timestamp": 1764598363442,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "WeezwtfN5_n-"
   },
   "outputs": [],
   "source": [
    "# checking that both are the same\n",
    "sum(f_test_y == test_y.numpy()) == len(test_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2lURL85k6aQj",
   "metadata": {
    "executionInfo": {
     "elapsed": 42989,
     "status": "aborted",
     "timestamp": 1764598363443,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "2lURL85k6aQj"
   },
   "outputs": [],
   "source": [
    "# comparing statsbomb and our expected goal probabilities\n",
    "test = pd.concat([f_test_x[\"shot_statsbomb_xg\"].reset_index(), pd.DataFrame(pred_probs).reset_index()], axis = 1, ignore_index=True).drop([0,2], axis = 1)\n",
    "test.columns = [\"shot_statsbomb_xg\", \"pred_prob\"]\n",
    "test[\"diff\"] = test[\"shot_statsbomb_xg\"] - test[\"pred_prob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "Ie9x1trc7NDN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1764608421952,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "Ie9x1trc7NDN",
    "outputId": "217473aa-fc44-46fb-90d5-d3ab8d08eb5c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_i_r = sk_i.IsotonicRegression().fit(test[\"shot_statsbomb_xg\"], evaluation[\"outcome\"])\n",
    "i_r = sk_i.IsotonicRegression().fit(evaluation[\"pred_prob\"], evaluation[\"outcome\"])\n",
    "\n",
    "model_probs = np.linspace(0, 1, num=100)\n",
    "\n",
    "calibrated_probs = i_r.predict(model_probs)\n",
    "f_calibrated_probs = f_i_r.predict(model_probs)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot([0, 1], [0, 1])\n",
    "\n",
    "plt.plot(model_probs, f_calibrated_probs, color='black', alpha = 0.3, label = \"Statsb. perf.\")\n",
    "plt.plot(model_probs, calibrated_probs, color='red', label = \"Model perf.\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Model probability')\n",
    "plt.ylabel('Calibrated probability')\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fXcppND6-BxP",
   "metadata": {
    "id": "fXcppND6-BxP"
   },
   "source": [
    "## AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eqGunzpG7hI2",
   "metadata": {
    "executionInfo": {
     "elapsed": 42987,
     "status": "aborted",
     "timestamp": 1764598363446,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "eqGunzpG7hI2"
   },
   "outputs": [],
   "source": [
    "# Calculate AUC\n",
    "auc = roc_auc_score(test_y, pred_probs)\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_y, pred_probs)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ct1Lf38D-HWy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1764608422772,
     "user": {
      "displayName": "Fritz Hannes",
      "userId": "05631734269737957716"
     },
     "user_tz": 300
    },
    "id": "ct1Lf38D-HWy",
    "outputId": "e6c00892-7581-4f77-c1c0-27a1ea147d72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.4956\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate AUC\n",
    "auc = roc_auc_score(test_y, test[\"shot_statsbomb_xg\"])\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_y, test[\"shot_statsbomb_xg\"])\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr, tpr, color='black', label=f'SB ROC Curve (AUC = {auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
