{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4ba190db",
      "metadata": {
        "id": "4ba190db"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "133e8d59",
      "metadata": {
        "id": "133e8d59"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import ast\n",
        "import math\n",
        "import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Input\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import sklearn.isotonic as sk_i\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ea16aa4",
      "metadata": {
        "id": "2ea16aa4"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6SMrbzowm2VT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SMrbzowm2VT",
        "outputId": "d0e1fd0f-b88b-4021-b9ae-3ae40ea065b7"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df62e30",
      "metadata": {
        "id": "4df62e30"
      },
      "outputs": [],
      "source": [
        "football_df = pd.read_pickle(\"/content/drive/MyDrive/Data Analytics/Assignments/Group Project/football_processed.pickle\")\n",
        "football_model_df = pd.read_pickle(\"/content/drive/MyDrive/Data Analytics/Assignments/Group Project/football_model_processed.pickle\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0985d459",
      "metadata": {
        "id": "0985d459"
      },
      "source": [
        "# Looking at data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a635472",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a635472",
        "outputId": "d2d919ad-17ef-4ac7-e0f7-646f30584150"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['under_pressure', 'shot_open_goal', 'shot_first_time',\n",
              "       'shot_one_on_one', 'shot_outcome_encoded', 'player_x', 'player_y',\n",
              "       'distance_from_goal_center', 'distance_from_goal_left_post',\n",
              "       'distance_from_goal_right_post', 'body_part_head', 'body_part_other',\n",
              "       'body_part_foot', 'shot_technique_backheel',\n",
              "       'shot_technique_diving_header', 'shot_technique_half_volley',\n",
              "       'shot_technique_lob', 'shot_technique_normal',\n",
              "       'shot_technique_overhead_kick', 'shot_technique_volley',\n",
              "       'play_pattern_from_corner', 'play_pattern_from_counter',\n",
              "       'play_pattern_from_free_kick', 'play_pattern_from_goal_kick',\n",
              "       'play_pattern_from_keeper', 'play_pattern_from_kick_off',\n",
              "       'play_pattern_from_throw_in', 'play_pattern_other',\n",
              "       'play_pattern_regular_play', 'shot_type_free_kick',\n",
              "       'shot_type_open_play', 'goalkeeper_x', 'goalkeeper_y',\n",
              "       'gk_distance_from_goal_center', 'gk_distance_from_goal_left_post',\n",
              "       'gk_distance_from_goal_right_post', 'shot_angle', 'distance_player_gk'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "football_model_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8178d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c8178d6f",
        "outputId": "cb65947c-b4df-4c84-bc16-a706e19dd52a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1200 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15, 12))  # increase figure size\n",
        "sns.heatmap(football_model_df.corr(), annot=False, cmap=\"coolwarm\", center=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d05b33",
      "metadata": {
        "id": "82d05b33"
      },
      "source": [
        "# Preparing Data for training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125e8733",
      "metadata": {
        "id": "125e8733"
      },
      "source": [
        "Splitting train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9df5f83e",
      "metadata": {
        "id": "9df5f83e"
      },
      "outputs": [],
      "source": [
        "X = football_model_df.drop(\"shot_outcome_encoded\", axis = 1)\n",
        "y = football_model_df[\"shot_outcome_encoded\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1751dd9",
      "metadata": {
        "id": "b1751dd9"
      },
      "outputs": [],
      "source": [
        "# setting a seed\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# splitting the data\n",
        "train_x, test_x , train_y, test_y = train_test_split(\n",
        "    X, y,\n",
        "    test_size = 0.25,\n",
        "    random_state= 123,\n",
        "    stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mtm5jifSmwde",
      "metadata": {
        "id": "Mtm5jifSmwde"
      },
      "outputs": [],
      "source": [
        "train_x, train_y = tf.convert_to_tensor(train_x, dtype=tf.float32), tf.convert_to_tensor(train_y, dtype=tf.float32)\n",
        "test_x, test_y = tf.convert_to_tensor(test_x, dtype=tf.float32), tf.convert_to_tensor(test_y, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91aa2fa6",
      "metadata": {
        "id": "91aa2fa6"
      },
      "source": [
        "# Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-87hAuFrDlr8",
      "metadata": {
        "id": "-87hAuFrDlr8"
      },
      "source": [
        "## Defining Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d253ea",
      "metadata": {
        "id": "56d253ea"
      },
      "outputs": [],
      "source": [
        "def build_model(hl: int = 1, nodes: int = 32, activation: str = 'relu', epochs: int = 5, batches: int = 100):\n",
        "\n",
        "    # initiating model\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # adding input layer\n",
        "    model.add(Input(shape=(37,), name = \"Input_Layer\")) # 37 input columns\n",
        "\n",
        "    # adding hidden layers\n",
        "    for i in range(hl):\n",
        "        model.add(Dense(units = nodes, activation = activation, name = f\"HL_{i+1}\"))\n",
        "\n",
        "    # add output layer\n",
        "    model.add(Dense(units = 1, activation = \"sigmoid\", name = \"Output_Layer\"))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"binary_accuracy\", tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "189d9dad",
      "metadata": {
        "id": "189d9dad"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(hl: int = 1,\n",
        "                             nodes: int = 32,\n",
        "                             activation: str = 'relu',\n",
        "                             epochs: int = 5,\n",
        "                             batches: int = 100,\n",
        "                             train_x = train_x,\n",
        "                             train_y = train_y,\n",
        "                             test_x = test_x,\n",
        "                             test_y = test_y\n",
        "                             ):\n",
        "\n",
        "    model = build_model(hl, nodes, activation, epochs, batches)\n",
        "\n",
        "    # training the model\n",
        "    history = model.fit(\n",
        "        train_x,\n",
        "        train_y,\n",
        "        epochs = epochs,\n",
        "        batch_size = batches,\n",
        "        validation_data = (test_x, test_y),\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    # getting accuracies\n",
        "    eval_accuracies = model.evaluate(test_x, test_y)\n",
        "\n",
        "    return model, history, eval_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XvGeXqOLDr-k",
      "metadata": {
        "id": "XvGeXqOLDr-k"
      },
      "outputs": [],
      "source": [
        "def k_fold_cross_validation(hl: int = 1,\n",
        "                            nodes: int = 32,\n",
        "                            activation: str = 'relu',\n",
        "                            epochs: int = 5,\n",
        "                            batches: int = 100,\n",
        "                            k: int = 5,\n",
        "                            train_x = train_x,\n",
        "                            train_y = train_y\n",
        "                            ):\n",
        "\n",
        "    # set seed\n",
        "    seed = 123\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
        "\n",
        "    # Create empty lists to store metrics from each fold\n",
        "    fold_losses = []\n",
        "    fold_accuracies = []\n",
        "    fold_aucs = []\n",
        "\n",
        "    # Convert train_x and train_y to numpy for StratifiedKFold\n",
        "    train_x_np = train_x.numpy()\n",
        "    train_y_np = train_y.numpy()\n",
        "\n",
        "    # Loop through the splits\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(train_x_np, train_y_np)):\n",
        "        print(f\"\\n--- Starting Fold {fold+1}/{k} ---\")\n",
        "\n",
        "        # Create training and validation datasets for the current fold\n",
        "        fold_train_x = train_x_np[train_index]\n",
        "        fold_train_y = train_y_np[train_index]\n",
        "        fold_val_x = train_x_np[val_index]\n",
        "        fold_val_y = train_y_np[val_index]\n",
        "\n",
        "        # Convert to TensorFlow tensors\n",
        "        fold_train_x = tf.convert_to_tensor(fold_train_x, dtype=tf.float32)\n",
        "        fold_train_y = tf.convert_to_tensor(fold_train_y, dtype=tf.float32)\n",
        "        fold_val_x = tf.convert_to_tensor(fold_val_x, dtype=tf.float32)\n",
        "        fold_val_y = tf.convert_to_tensor(fold_val_y, dtype=tf.float32)\n",
        "\n",
        "        # Train and evaluate the model for the current fold\n",
        "        model, history, eval_accuracies = train_and_evaluate_model(\n",
        "            hl=hl,\n",
        "            nodes=nodes,\n",
        "            activation=activation,\n",
        "            epochs=epochs,\n",
        "            batches=batches,\n",
        "            train_x=fold_train_x,\n",
        "            train_y=fold_train_y,\n",
        "            test_x=fold_val_x,\n",
        "            test_y=fold_val_y\n",
        "        )\n",
        "\n",
        "        # eval_accuracies contains [loss, binary_accuracy, auc]\n",
        "        fold_losses.append(eval_accuracies[0])\n",
        "        fold_accuracies.append(eval_accuracies[1])\n",
        "        fold_aucs.append(eval_accuracies[2])\n",
        "\n",
        "        print(f\"Fold {fold+1} Metrics: Loss = {eval_accuracies[0]:.4f}, Accuracy = {eval_accuracies[1]:.4f}, AUC = {eval_accuracies[2]:.4f}\")\n",
        "\n",
        "    print(\"\\n--- K-Fold Cross-Validation Complete ---\")\n",
        "    print(f\"Average Loss: {np.mean(fold_losses):.4f}\")\n",
        "    print(f\"Average Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "    print(f\"Average AUC: {np.mean(fold_aucs):.4f}\")\n",
        "\n",
        "    return fold_losses, fold_accuracies, fold_aucs, model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4BBxgx0XgUrf",
      "metadata": {
        "id": "4BBxgx0XgUrf"
      },
      "source": [
        "# Looking at Training results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XIXijxpkDoEN",
      "metadata": {
        "id": "XIXijxpkDoEN"
      },
      "source": [
        "## Training the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FD-pBaOOGhGY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD-pBaOOGhGY",
        "outputId": "263c70df-0c15-4a58-f2f4-190631a56439"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Performing training for: ('relu', 1, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6250 - binary_accuracy: 0.7419 - loss: 2.9174 - val_auc: 0.7233 - val_binary_accuracy: 0.9023 - val_loss: 0.2893\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7684 - binary_accuracy: 0.8985 - loss: 0.2768 - val_auc: 0.7710 - val_binary_accuracy: 0.9034 - val_loss: 0.2737\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7898 - binary_accuracy: 0.9029 - loss: 0.2642 - val_auc: 0.7802 - val_binary_accuracy: 0.9062 - val_loss: 0.2763\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7945 - binary_accuracy: 0.9060 - loss: 0.2605 - val_auc: 0.7825 - val_binary_accuracy: 0.9068 - val_loss: 0.2724\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7973 - binary_accuracy: 0.9079 - loss: 0.2581 - val_auc: 0.7835 - val_binary_accuracy: 0.9072 - val_loss: 0.2663\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7994 - binary_accuracy: 0.9098 - loss: 0.2565 - val_auc: 0.7842 - val_binary_accuracy: 0.9066 - val_loss: 0.2645\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9096 - loss: 0.2557 - val_auc: 0.7851 - val_binary_accuracy: 0.9069 - val_loss: 0.2665\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9101 - loss: 0.2554 - val_auc: 0.7856 - val_binary_accuracy: 0.9054 - val_loss: 0.2695\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9103 - loss: 0.2554 - val_auc: 0.7869 - val_binary_accuracy: 0.9056 - val_loss: 0.2700\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7983 - binary_accuracy: 0.9108 - loss: 0.2551 - val_auc: 0.7872 - val_binary_accuracy: 0.9059 - val_loss: 0.2692\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7845 - binary_accuracy: 0.9087 - loss: 0.2646\n",
            "Fold 1 Metrics: Loss = 0.2692, Accuracy = 0.9059, AUC = 0.7872\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6458 - binary_accuracy: 0.7401 - loss: 1.6699 - val_auc: 0.7206 - val_binary_accuracy: 0.9065 - val_loss: 0.2979\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7412 - binary_accuracy: 0.9039 - loss: 0.2875 - val_auc: 0.7840 - val_binary_accuracy: 0.9081 - val_loss: 0.2675\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7819 - binary_accuracy: 0.9047 - loss: 0.2712 - val_auc: 0.7983 - val_binary_accuracy: 0.9096 - val_loss: 0.2613\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9052 - loss: 0.2674 - val_auc: 0.8031 - val_binary_accuracy: 0.9100 - val_loss: 0.2587\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7932 - binary_accuracy: 0.9062 - loss: 0.2653 - val_auc: 0.8059 - val_binary_accuracy: 0.9102 - val_loss: 0.2570\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7953 - binary_accuracy: 0.9070 - loss: 0.2639 - val_auc: 0.8074 - val_binary_accuracy: 0.9099 - val_loss: 0.2561\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7970 - binary_accuracy: 0.9073 - loss: 0.2630 - val_auc: 0.8096 - val_binary_accuracy: 0.9099 - val_loss: 0.2554\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9079 - loss: 0.2624 - val_auc: 0.8112 - val_binary_accuracy: 0.9099 - val_loss: 0.2546\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9081 - loss: 0.2619 - val_auc: 0.8117 - val_binary_accuracy: 0.9104 - val_loss: 0.2538\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8123 - val_binary_accuracy: 0.9104 - val_loss: 0.2533\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8149 - binary_accuracy: 0.9138 - loss: 0.2448\n",
            "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9104, AUC = 0.8123\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6087 - binary_accuracy: 0.8443 - loss: 0.4981 - val_auc: 0.7668 - val_binary_accuracy: 0.9063 - val_loss: 0.2722\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7682 - binary_accuracy: 0.9075 - loss: 0.2699 - val_auc: 0.7957 - val_binary_accuracy: 0.9071 - val_loss: 0.2641\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9079 - loss: 0.2636 - val_auc: 0.7999 - val_binary_accuracy: 0.9081 - val_loss: 0.2622\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9076 - loss: 0.2630 - val_auc: 0.8021 - val_binary_accuracy: 0.9093 - val_loss: 0.2608\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9084 - loss: 0.2627 - val_auc: 0.8034 - val_binary_accuracy: 0.9103 - val_loss: 0.2592\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7858 - binary_accuracy: 0.9091 - loss: 0.2625 - val_auc: 0.8041 - val_binary_accuracy: 0.9109 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9094 - loss: 0.2622 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2577\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9096 - loss: 0.2619 - val_auc: 0.8062 - val_binary_accuracy: 0.9110 - val_loss: 0.2572\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8057 - val_binary_accuracy: 0.9110 - val_loss: 0.2570\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9097 - loss: 0.2615 - val_auc: 0.8063 - val_binary_accuracy: 0.9110 - val_loss: 0.2568\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7996 - binary_accuracy: 0.9131 - loss: 0.2566\n",
            "Fold 3 Metrics: Loss = 0.2568, Accuracy = 0.9110, AUC = 0.8063\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6235 - binary_accuracy: 0.8994 - loss: 0.3500 - val_auc: 0.7747 - val_binary_accuracy: 0.9039 - val_loss: 0.2720\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7676 - binary_accuracy: 0.9040 - loss: 0.2741 - val_auc: 0.7865 - val_binary_accuracy: 0.9050 - val_loss: 0.2661\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7771 - binary_accuracy: 0.9056 - loss: 0.2696 - val_auc: 0.7906 - val_binary_accuracy: 0.9060 - val_loss: 0.2636\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7811 - binary_accuracy: 0.9065 - loss: 0.2672 - val_auc: 0.7939 - val_binary_accuracy: 0.9084 - val_loss: 0.2617\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7829 - binary_accuracy: 0.9073 - loss: 0.2656 - val_auc: 0.7964 - val_binary_accuracy: 0.9097 - val_loss: 0.2603\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7848 - binary_accuracy: 0.9078 - loss: 0.2644 - val_auc: 0.7986 - val_binary_accuracy: 0.9097 - val_loss: 0.2593\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2636 - val_auc: 0.8002 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7873 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8024 - val_binary_accuracy: 0.9100 - val_loss: 0.2572\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9090 - loss: 0.2625 - val_auc: 0.8033 - val_binary_accuracy: 0.9101 - val_loss: 0.2567\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9092 - loss: 0.2620 - val_auc: 0.8044 - val_binary_accuracy: 0.9103 - val_loss: 0.2563\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7873 - binary_accuracy: 0.9101 - loss: 0.2631\n",
            "Fold 4 Metrics: Loss = 0.2563, Accuracy = 0.9103, AUC = 0.8044\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6808 - binary_accuracy: 0.9036 - loss: 0.3078 - val_auc: 0.7917 - val_binary_accuracy: 0.8995 - val_loss: 0.2775\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7666 - binary_accuracy: 0.9011 - loss: 0.2789 - val_auc: 0.8004 - val_binary_accuracy: 0.8998 - val_loss: 0.2746\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7763 - binary_accuracy: 0.9021 - loss: 0.2731 - val_auc: 0.8049 - val_binary_accuracy: 0.9028 - val_loss: 0.2718\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7813 - binary_accuracy: 0.9043 - loss: 0.2693 - val_auc: 0.8059 - val_binary_accuracy: 0.9026 - val_loss: 0.2720\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9044 - loss: 0.2677 - val_auc: 0.8072 - val_binary_accuracy: 0.9032 - val_loss: 0.2711\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9052 - loss: 0.2666 - val_auc: 0.8078 - val_binary_accuracy: 0.9041 - val_loss: 0.2714\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9064 - loss: 0.2657 - val_auc: 0.8079 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9066 - loss: 0.2651 - val_auc: 0.8082 - val_binary_accuracy: 0.9054 - val_loss: 0.2698\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9070 - loss: 0.2646 - val_auc: 0.8076 - val_binary_accuracy: 0.9032 - val_loss: 0.2711\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9072 - loss: 0.2644 - val_auc: 0.8082 - val_binary_accuracy: 0.9036 - val_loss: 0.2706\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8170 - binary_accuracy: 0.9056 - loss: 0.2685\n",
            "Fold 5 Metrics: Loss = 0.2706, Accuracy = 0.9036, AUC = 0.8082\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2612\n",
            "Average Accuracy: 0.9083\n",
            "Average AUC: 0.8037\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 1, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6862 - binary_accuracy: 0.8592 - loss: 0.5908 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2762\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9071 - loss: 0.2693 - val_auc: 0.7723 - val_binary_accuracy: 0.9017 - val_loss: 0.2800\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.7786 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9106 - loss: 0.2594 - val_auc: 0.7839 - val_binary_accuracy: 0.9076 - val_loss: 0.2692\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7911 - binary_accuracy: 0.9115 - loss: 0.2565 - val_auc: 0.7872 - val_binary_accuracy: 0.9084 - val_loss: 0.2660\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9117 - loss: 0.2548 - val_auc: 0.7893 - val_binary_accuracy: 0.9085 - val_loss: 0.2638\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7968 - binary_accuracy: 0.9120 - loss: 0.2536 - val_auc: 0.7911 - val_binary_accuracy: 0.9090 - val_loss: 0.2623\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7984 - binary_accuracy: 0.9120 - loss: 0.2528 - val_auc: 0.7923 - val_binary_accuracy: 0.9090 - val_loss: 0.2615\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7932 - val_binary_accuracy: 0.9088 - val_loss: 0.2610\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9126 - loss: 0.2519 - val_auc: 0.7936 - val_binary_accuracy: 0.9088 - val_loss: 0.2605\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7857 - binary_accuracy: 0.9111 - loss: 0.2563\n",
            "Fold 1 Metrics: Loss = 0.2605, Accuracy = 0.9088, AUC = 0.7936\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6825 - binary_accuracy: 0.8857 - loss: 0.3480 - val_auc: 0.7850 - val_binary_accuracy: 0.9081 - val_loss: 0.2691\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7647 - binary_accuracy: 0.9056 - loss: 0.2777 - val_auc: 0.8016 - val_binary_accuracy: 0.9096 - val_loss: 0.2620\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7806 - binary_accuracy: 0.9065 - loss: 0.2707 - val_auc: 0.8064 - val_binary_accuracy: 0.9100 - val_loss: 0.2589\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7863 - binary_accuracy: 0.9068 - loss: 0.2678 - val_auc: 0.8093 - val_binary_accuracy: 0.9091 - val_loss: 0.2574\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9071 - loss: 0.2658 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2560\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7921 - binary_accuracy: 0.9075 - loss: 0.2644 - val_auc: 0.8114 - val_binary_accuracy: 0.9099 - val_loss: 0.2562\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7935 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8138 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9083 - loss: 0.2625 - val_auc: 0.8145 - val_binary_accuracy: 0.9099 - val_loss: 0.2559\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7972 - binary_accuracy: 0.9083 - loss: 0.2618 - val_auc: 0.8161 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9082 - loss: 0.2612 - val_auc: 0.8158 - val_binary_accuracy: 0.9090 - val_loss: 0.2553\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8227 - binary_accuracy: 0.9125 - loss: 0.2459\n",
            "Fold 2 Metrics: Loss = 0.2553, Accuracy = 0.9090, AUC = 0.8158\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7163 - binary_accuracy: 0.8859 - loss: 0.3651 - val_auc: 0.7699 - val_binary_accuracy: 0.8982 - val_loss: 0.2847\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7610 - binary_accuracy: 0.9030 - loss: 0.2754 - val_auc: 0.7911 - val_binary_accuracy: 0.9032 - val_loss: 0.2727\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7758 - binary_accuracy: 0.9063 - loss: 0.2673 - val_auc: 0.7974 - val_binary_accuracy: 0.9048 - val_loss: 0.2686\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7810 - binary_accuracy: 0.9072 - loss: 0.2647 - val_auc: 0.8013 - val_binary_accuracy: 0.9054 - val_loss: 0.2672\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7837 - binary_accuracy: 0.9080 - loss: 0.2631 - val_auc: 0.8034 - val_binary_accuracy: 0.9059 - val_loss: 0.2669\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2622 - val_auc: 0.8041 - val_binary_accuracy: 0.9057 - val_loss: 0.2666\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7869 - binary_accuracy: 0.9083 - loss: 0.2617 - val_auc: 0.8053 - val_binary_accuracy: 0.9056 - val_loss: 0.2675\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7876 - binary_accuracy: 0.9083 - loss: 0.2613 - val_auc: 0.8061 - val_binary_accuracy: 0.9057 - val_loss: 0.2676\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7886 - binary_accuracy: 0.9085 - loss: 0.2610 - val_auc: 0.8064 - val_binary_accuracy: 0.9056 - val_loss: 0.2677\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7890 - binary_accuracy: 0.9088 - loss: 0.2608 - val_auc: 0.8070 - val_binary_accuracy: 0.9056 - val_loss: 0.2678\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8043 - binary_accuracy: 0.9058 - loss: 0.2677\n",
            "Fold 3 Metrics: Loss = 0.2678, Accuracy = 0.9056, AUC = 0.8070\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6602 - binary_accuracy: 0.8776 - loss: 0.3897 - val_auc: 0.7762 - val_binary_accuracy: 0.9062 - val_loss: 0.2726\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7629 - binary_accuracy: 0.9050 - loss: 0.2777 - val_auc: 0.7908 - val_binary_accuracy: 0.9060 - val_loss: 0.2644\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7732 - binary_accuracy: 0.9068 - loss: 0.2709 - val_auc: 0.7972 - val_binary_accuracy: 0.9076 - val_loss: 0.2611\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7797 - binary_accuracy: 0.9078 - loss: 0.2675 - val_auc: 0.8001 - val_binary_accuracy: 0.9081 - val_loss: 0.2601\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7836 - binary_accuracy: 0.9080 - loss: 0.2655 - val_auc: 0.8028 - val_binary_accuracy: 0.9081 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7862 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8046 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7881 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2583\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7889 - binary_accuracy: 0.9082 - loss: 0.2621 - val_auc: 0.8077 - val_binary_accuracy: 0.9091 - val_loss: 0.2578\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7897 - binary_accuracy: 0.9083 - loss: 0.2617 - val_auc: 0.8084 - val_binary_accuracy: 0.9091 - val_loss: 0.2574\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7907 - binary_accuracy: 0.9090 - loss: 0.2613 - val_auc: 0.8090 - val_binary_accuracy: 0.9087 - val_loss: 0.2571\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9066 - loss: 0.2637\n",
            "Fold 4 Metrics: Loss = 0.2571, Accuracy = 0.9087, AUC = 0.8090\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6565 - binary_accuracy: 0.8934 - loss: 0.3689 - val_auc: 0.7838 - val_binary_accuracy: 0.9048 - val_loss: 0.2664\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7613 - binary_accuracy: 0.9052 - loss: 0.2762 - val_auc: 0.7952 - val_binary_accuracy: 0.9078 - val_loss: 0.2599\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7696 - binary_accuracy: 0.9075 - loss: 0.2717 - val_auc: 0.7998 - val_binary_accuracy: 0.9091 - val_loss: 0.2568\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9078 - loss: 0.2691 - val_auc: 0.8030 - val_binary_accuracy: 0.9106 - val_loss: 0.2558\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7778 - binary_accuracy: 0.9085 - loss: 0.2677 - val_auc: 0.8046 - val_binary_accuracy: 0.9104 - val_loss: 0.2548\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9087 - loss: 0.2668 - val_auc: 0.8068 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7806 - binary_accuracy: 0.9088 - loss: 0.2663 - val_auc: 0.8078 - val_binary_accuracy: 0.9101 - val_loss: 0.2534\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9077 - loss: 0.2656 - val_auc: 0.8072 - val_binary_accuracy: 0.9087 - val_loss: 0.2536\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7821 - binary_accuracy: 0.9082 - loss: 0.2655 - val_auc: 0.8076 - val_binary_accuracy: 0.9079 - val_loss: 0.2537\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7832 - binary_accuracy: 0.9089 - loss: 0.2651 - val_auc: 0.8080 - val_binary_accuracy: 0.9082 - val_loss: 0.2537\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9069 - loss: 0.2532\n",
            "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9082, AUC = 0.8080\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2589\n",
            "Average Accuracy: 0.9081\n",
            "Average AUC: 0.8067\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 1, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7034 - binary_accuracy: 0.8996 - loss: 0.3101 - val_auc: 0.7697 - val_binary_accuracy: 0.9081 - val_loss: 0.2725\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9089 - loss: 0.2643 - val_auc: 0.7847 - val_binary_accuracy: 0.9103 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9109 - loss: 0.2571 - val_auc: 0.7876 - val_binary_accuracy: 0.9099 - val_loss: 0.2676\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7957 - binary_accuracy: 0.9117 - loss: 0.2555 - val_auc: 0.7925 - val_binary_accuracy: 0.9097 - val_loss: 0.2603\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9120 - loss: 0.2532 - val_auc: 0.7931 - val_binary_accuracy: 0.9097 - val_loss: 0.2600\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9119 - loss: 0.2528 - val_auc: 0.7942 - val_binary_accuracy: 0.9097 - val_loss: 0.2597\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9122 - loss: 0.2521 - val_auc: 0.7947 - val_binary_accuracy: 0.9096 - val_loss: 0.2594\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9125 - loss: 0.2515 - val_auc: 0.7953 - val_binary_accuracy: 0.9099 - val_loss: 0.2593\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8048 - binary_accuracy: 0.9125 - loss: 0.2513 - val_auc: 0.7956 - val_binary_accuracy: 0.9093 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9127 - loss: 0.2508 - val_auc: 0.7962 - val_binary_accuracy: 0.9093 - val_loss: 0.2593\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7917 - binary_accuracy: 0.9135 - loss: 0.2520\n",
            "Fold 1 Metrics: Loss = 0.2593, Accuracy = 0.9093, AUC = 0.7962\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5927 - binary_accuracy: 0.8873 - loss: 0.7866 - val_auc: 0.7893 - val_binary_accuracy: 0.9068 - val_loss: 0.2654\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9050 - loss: 0.2744 - val_auc: 0.8040 - val_binary_accuracy: 0.9079 - val_loss: 0.2582\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7799 - binary_accuracy: 0.9065 - loss: 0.2693 - val_auc: 0.8073 - val_binary_accuracy: 0.9088 - val_loss: 0.2563\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7863 - binary_accuracy: 0.9064 - loss: 0.2670 - val_auc: 0.8056 - val_binary_accuracy: 0.9104 - val_loss: 0.2571\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9065 - loss: 0.2658 - val_auc: 0.8097 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7927 - binary_accuracy: 0.9067 - loss: 0.2643 - val_auc: 0.8107 - val_binary_accuracy: 0.9082 - val_loss: 0.2552\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7934 - binary_accuracy: 0.9068 - loss: 0.2639 - val_auc: 0.8125 - val_binary_accuracy: 0.9090 - val_loss: 0.2537\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7962 - binary_accuracy: 0.9070 - loss: 0.2629 - val_auc: 0.8124 - val_binary_accuracy: 0.9088 - val_loss: 0.2539\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9070 - loss: 0.2630 - val_auc: 0.8131 - val_binary_accuracy: 0.9085 - val_loss: 0.2533\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9075 - loss: 0.2623 - val_auc: 0.8130 - val_binary_accuracy: 0.9087 - val_loss: 0.2533\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8199 - binary_accuracy: 0.9122 - loss: 0.2438\n",
            "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9087, AUC = 0.8130\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6633 - binary_accuracy: 0.8966 - loss: 0.4320 - val_auc: 0.7971 - val_binary_accuracy: 0.9096 - val_loss: 0.2604\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7724 - binary_accuracy: 0.9059 - loss: 0.2692 - val_auc: 0.8024 - val_binary_accuracy: 0.9106 - val_loss: 0.2572\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7767 - binary_accuracy: 0.9061 - loss: 0.2674 - val_auc: 0.8041 - val_binary_accuracy: 0.9107 - val_loss: 0.2562\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7777 - binary_accuracy: 0.9063 - loss: 0.2667 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7786 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.8062 - val_binary_accuracy: 0.9107 - val_loss: 0.2557\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7803 - binary_accuracy: 0.9066 - loss: 0.2658 - val_auc: 0.8074 - val_binary_accuracy: 0.9116 - val_loss: 0.2554\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7817 - binary_accuracy: 0.9069 - loss: 0.2652 - val_auc: 0.8072 - val_binary_accuracy: 0.9112 - val_loss: 0.2555\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7825 - binary_accuracy: 0.9072 - loss: 0.2648 - val_auc: 0.8082 - val_binary_accuracy: 0.9122 - val_loss: 0.2550\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7831 - binary_accuracy: 0.9076 - loss: 0.2643 - val_auc: 0.8072 - val_binary_accuracy: 0.9121 - val_loss: 0.2556\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9075 - loss: 0.2640 - val_auc: 0.8074 - val_binary_accuracy: 0.9124 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8025 - binary_accuracy: 0.9128 - loss: 0.2555\n",
            "Fold 3 Metrics: Loss = 0.2552, Accuracy = 0.9124, AUC = 0.8074\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5709 - binary_accuracy: 0.7201 - loss: 4.4762 - val_auc: 0.7878 - val_binary_accuracy: 0.9041 - val_loss: 0.2668\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7690 - binary_accuracy: 0.9050 - loss: 0.2725 - val_auc: 0.8000 - val_binary_accuracy: 0.9081 - val_loss: 0.2606\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7791 - binary_accuracy: 0.9080 - loss: 0.2666 - val_auc: 0.8041 - val_binary_accuracy: 0.9078 - val_loss: 0.2594\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7819 - binary_accuracy: 0.9085 - loss: 0.2651 - val_auc: 0.8063 - val_binary_accuracy: 0.9064 - val_loss: 0.2598\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7838 - binary_accuracy: 0.9089 - loss: 0.2641 - val_auc: 0.8078 - val_binary_accuracy: 0.9072 - val_loss: 0.2585\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7865 - binary_accuracy: 0.9090 - loss: 0.2629 - val_auc: 0.8090 - val_binary_accuracy: 0.9088 - val_loss: 0.2567\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7886 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8087 - val_binary_accuracy: 0.9104 - val_loss: 0.2558\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9094 - loss: 0.2620 - val_auc: 0.8094 - val_binary_accuracy: 0.9104 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7879 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8103 - val_binary_accuracy: 0.9104 - val_loss: 0.2550\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7879 - binary_accuracy: 0.9089 - loss: 0.2620 - val_auc: 0.8102 - val_binary_accuracy: 0.9103 - val_loss: 0.2550\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7952 - binary_accuracy: 0.9090 - loss: 0.2614\n",
            "Fold 4 Metrics: Loss = 0.2550, Accuracy = 0.9103, AUC = 0.8102\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6283 - binary_accuracy: 0.8896 - loss: 0.8065 - val_auc: 0.7923 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9053 - loss: 0.2773 - val_auc: 0.7995 - val_binary_accuracy: 0.9097 - val_loss: 0.2592\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7657 - binary_accuracy: 0.9060 - loss: 0.2736 - val_auc: 0.8023 - val_binary_accuracy: 0.9073 - val_loss: 0.2591\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7692 - binary_accuracy: 0.9066 - loss: 0.2720 - val_auc: 0.8053 - val_binary_accuracy: 0.9073 - val_loss: 0.2592\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7710 - binary_accuracy: 0.9063 - loss: 0.2711 - val_auc: 0.8066 - val_binary_accuracy: 0.9067 - val_loss: 0.2597\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7718 - binary_accuracy: 0.9065 - loss: 0.2709 - val_auc: 0.8074 - val_binary_accuracy: 0.9066 - val_loss: 0.2588\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7732 - binary_accuracy: 0.9073 - loss: 0.2704 - val_auc: 0.8080 - val_binary_accuracy: 0.9064 - val_loss: 0.2585\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9070 - loss: 0.2697 - val_auc: 0.8082 - val_binary_accuracy: 0.9062 - val_loss: 0.2578\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7762 - binary_accuracy: 0.9072 - loss: 0.2693 - val_auc: 0.8085 - val_binary_accuracy: 0.9067 - val_loss: 0.2573\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7768 - binary_accuracy: 0.9072 - loss: 0.2691 - val_auc: 0.8083 - val_binary_accuracy: 0.9059 - val_loss: 0.2567\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8140 - binary_accuracy: 0.9062 - loss: 0.2557\n",
            "Fold 5 Metrics: Loss = 0.2567, Accuracy = 0.9059, AUC = 0.8083\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2559\n",
            "Average Accuracy: 0.9093\n",
            "Average AUC: 0.8070\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 1, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6756 - binary_accuracy: 0.8977 - loss: 0.4019 - val_auc: 0.7866 - val_binary_accuracy: 0.9085 - val_loss: 0.2622\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7899 - binary_accuracy: 0.9116 - loss: 0.2575 - val_auc: 0.7926 - val_binary_accuracy: 0.9100 - val_loss: 0.2600\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7940 - binary_accuracy: 0.9120 - loss: 0.2555 - val_auc: 0.7960 - val_binary_accuracy: 0.9104 - val_loss: 0.2591\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7984 - binary_accuracy: 0.9123 - loss: 0.2535 - val_auc: 0.7967 - val_binary_accuracy: 0.9100 - val_loss: 0.2590\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7998 - binary_accuracy: 0.9126 - loss: 0.2527 - val_auc: 0.7972 - val_binary_accuracy: 0.9096 - val_loss: 0.2587\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8011 - binary_accuracy: 0.9127 - loss: 0.2522 - val_auc: 0.7987 - val_binary_accuracy: 0.9094 - val_loss: 0.2582\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8031 - binary_accuracy: 0.9129 - loss: 0.2515 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8033 - binary_accuracy: 0.9130 - loss: 0.2514 - val_auc: 0.7990 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9132 - loss: 0.2509 - val_auc: 0.7989 - val_binary_accuracy: 0.9097 - val_loss: 0.2574\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8052 - binary_accuracy: 0.9132 - loss: 0.2507 - val_auc: 0.7983 - val_binary_accuracy: 0.9099 - val_loss: 0.2576\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7944 - binary_accuracy: 0.9140 - loss: 0.2500\n",
            "Fold 1 Metrics: Loss = 0.2576, Accuracy = 0.9099, AUC = 0.7983\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5951 - binary_accuracy: 0.8489 - loss: 0.9462 - val_auc: 0.8019 - val_binary_accuracy: 0.9059 - val_loss: 0.2635\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9057 - loss: 0.2711 - val_auc: 0.8111 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9069 - loss: 0.2685 - val_auc: 0.8111 - val_binary_accuracy: 0.9099 - val_loss: 0.2563\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7852 - binary_accuracy: 0.9067 - loss: 0.2683 - val_auc: 0.8115 - val_binary_accuracy: 0.9099 - val_loss: 0.2557\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9063 - loss: 0.2683 - val_auc: 0.8118 - val_binary_accuracy: 0.9104 - val_loss: 0.2554\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7856 - binary_accuracy: 0.9066 - loss: 0.2683 - val_auc: 0.8115 - val_binary_accuracy: 0.9104 - val_loss: 0.2557\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7856 - binary_accuracy: 0.9063 - loss: 0.2681 - val_auc: 0.8113 - val_binary_accuracy: 0.9100 - val_loss: 0.2559\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9065 - loss: 0.2679 - val_auc: 0.8113 - val_binary_accuracy: 0.9100 - val_loss: 0.2558\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7875 - binary_accuracy: 0.9067 - loss: 0.2673 - val_auc: 0.8120 - val_binary_accuracy: 0.9097 - val_loss: 0.2559\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9069 - loss: 0.2665 - val_auc: 0.8124 - val_binary_accuracy: 0.9099 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8201 - binary_accuracy: 0.9141 - loss: 0.2456\n",
            "Fold 2 Metrics: Loss = 0.2552, Accuracy = 0.9099, AUC = 0.8124\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6426 - binary_accuracy: 0.8351 - loss: 1.1844 - val_auc: 0.7773 - val_binary_accuracy: 0.9087 - val_loss: 0.2691\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7591 - binary_accuracy: 0.9047 - loss: 0.2747 - val_auc: 0.7910 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7657 - binary_accuracy: 0.9053 - loss: 0.2727 - val_auc: 0.7981 - val_binary_accuracy: 0.9038 - val_loss: 0.2686\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7738 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.8018 - val_binary_accuracy: 0.9004 - val_loss: 0.2724\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7756 - binary_accuracy: 0.9069 - loss: 0.2682 - val_auc: 0.8036 - val_binary_accuracy: 0.8972 - val_loss: 0.2742\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7772 - binary_accuracy: 0.9066 - loss: 0.2682 - val_auc: 0.8053 - val_binary_accuracy: 0.8969 - val_loss: 0.2742\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7776 - binary_accuracy: 0.9060 - loss: 0.2677 - val_auc: 0.8064 - val_binary_accuracy: 0.8969 - val_loss: 0.2747\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9065 - loss: 0.2677 - val_auc: 0.8074 - val_binary_accuracy: 0.8948 - val_loss: 0.2769\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7789 - binary_accuracy: 0.9064 - loss: 0.2673 - val_auc: 0.8078 - val_binary_accuracy: 0.8942 - val_loss: 0.2772\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7800 - binary_accuracy: 0.9066 - loss: 0.2670 - val_auc: 0.8081 - val_binary_accuracy: 0.8952 - val_loss: 0.2765\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8043 - binary_accuracy: 0.8954 - loss: 0.2766\n",
            "Fold 3 Metrics: Loss = 0.2765, Accuracy = 0.8952, AUC = 0.8081\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6570 - binary_accuracy: 0.8842 - loss: 0.5254 - val_auc: 0.7953 - val_binary_accuracy: 0.9085 - val_loss: 0.2630\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9084 - loss: 0.2721 - val_auc: 0.8073 - val_binary_accuracy: 0.9091 - val_loss: 0.2611\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9088 - loss: 0.2692 - val_auc: 0.8104 - val_binary_accuracy: 0.9090 - val_loss: 0.2599\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7772 - binary_accuracy: 0.9090 - loss: 0.2674 - val_auc: 0.8116 - val_binary_accuracy: 0.9090 - val_loss: 0.2589\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7794 - binary_accuracy: 0.9094 - loss: 0.2663 - val_auc: 0.8130 - val_binary_accuracy: 0.9097 - val_loss: 0.2582\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7804 - binary_accuracy: 0.9089 - loss: 0.2658 - val_auc: 0.8144 - val_binary_accuracy: 0.9097 - val_loss: 0.2564\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7822 - binary_accuracy: 0.9093 - loss: 0.2649 - val_auc: 0.8145 - val_binary_accuracy: 0.9097 - val_loss: 0.2562\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7826 - binary_accuracy: 0.9095 - loss: 0.2649 - val_auc: 0.8143 - val_binary_accuracy: 0.9095 - val_loss: 0.2561\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2644 - val_auc: 0.8142 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7843 - binary_accuracy: 0.9096 - loss: 0.2643 - val_auc: 0.8145 - val_binary_accuracy: 0.9098 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7978 - binary_accuracy: 0.9082 - loss: 0.2625\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9098, AUC = 0.8145\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5360 - binary_accuracy: 0.8048 - loss: 1.9087 - val_auc: 0.7869 - val_binary_accuracy: 0.9063 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7625 - binary_accuracy: 0.9056 - loss: 0.2748 - val_auc: 0.8003 - val_binary_accuracy: 0.9090 - val_loss: 0.2569\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9065 - loss: 0.2711 - val_auc: 0.8047 - val_binary_accuracy: 0.9051 - val_loss: 0.2613\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7709 - binary_accuracy: 0.9061 - loss: 0.2709 - val_auc: 0.8069 - val_binary_accuracy: 0.9019 - val_loss: 0.2670\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9063 - loss: 0.2703 - val_auc: 0.8073 - val_binary_accuracy: 0.9014 - val_loss: 0.2696\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7751 - binary_accuracy: 0.9061 - loss: 0.2699 - val_auc: 0.8077 - val_binary_accuracy: 0.9005 - val_loss: 0.2702\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7751 - binary_accuracy: 0.9064 - loss: 0.2701 - val_auc: 0.8078 - val_binary_accuracy: 0.8997 - val_loss: 0.2712\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7752 - binary_accuracy: 0.9063 - loss: 0.2702 - val_auc: 0.8079 - val_binary_accuracy: 0.8988 - val_loss: 0.2723\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7752 - binary_accuracy: 0.9065 - loss: 0.2706 - val_auc: 0.8079 - val_binary_accuracy: 0.8991 - val_loss: 0.2726\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7747 - binary_accuracy: 0.9063 - loss: 0.2707 - val_auc: 0.8083 - val_binary_accuracy: 0.8995 - val_loss: 0.2723\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9035 - loss: 0.2698\n",
            "Fold 5 Metrics: Loss = 0.2723, Accuracy = 0.8995, AUC = 0.8083\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2633\n",
            "Average Accuracy: 0.9049\n",
            "Average AUC: 0.8083\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 1, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7102 - binary_accuracy: 0.9002 - loss: 0.3113 - val_auc: 0.7878 - val_binary_accuracy: 0.9062 - val_loss: 0.2950\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9093 - loss: 0.2649 - val_auc: 0.7940 - val_binary_accuracy: 0.9072 - val_loss: 0.3029\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9096 - loss: 0.2626 - val_auc: 0.7944 - val_binary_accuracy: 0.9079 - val_loss: 0.3055\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9106 - loss: 0.2611 - val_auc: 0.7986 - val_binary_accuracy: 0.9078 - val_loss: 0.3028\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7866 - binary_accuracy: 0.9106 - loss: 0.2602 - val_auc: 0.7988 - val_binary_accuracy: 0.9081 - val_loss: 0.3022\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7889 - binary_accuracy: 0.9111 - loss: 0.2591 - val_auc: 0.8007 - val_binary_accuracy: 0.9081 - val_loss: 0.3000\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7902 - binary_accuracy: 0.9110 - loss: 0.2587 - val_auc: 0.7994 - val_binary_accuracy: 0.9081 - val_loss: 0.2919\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7928 - binary_accuracy: 0.9108 - loss: 0.2572 - val_auc: 0.7990 - val_binary_accuracy: 0.9081 - val_loss: 0.2882\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9112 - loss: 0.2564 - val_auc: 0.7994 - val_binary_accuracy: 0.9088 - val_loss: 0.2844\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7958 - binary_accuracy: 0.9111 - loss: 0.2556 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2794\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7957 - binary_accuracy: 0.9128 - loss: 0.2695\n",
            "Fold 1 Metrics: Loss = 0.2794, Accuracy = 0.9088, AUC = 0.7997\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6661 - binary_accuracy: 0.8791 - loss: 0.4294 - val_auc: 0.8100 - val_binary_accuracy: 0.8960 - val_loss: 0.2967\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7596 - binary_accuracy: 0.9035 - loss: 0.2802 - val_auc: 0.8109 - val_binary_accuracy: 0.8964 - val_loss: 0.2970\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9048 - loss: 0.2791 - val_auc: 0.8142 - val_binary_accuracy: 0.8979 - val_loss: 0.2922\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9052 - loss: 0.2777 - val_auc: 0.8110 - val_binary_accuracy: 0.8991 - val_loss: 0.2890\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7701 - binary_accuracy: 0.9056 - loss: 0.2762 - val_auc: 0.8113 - val_binary_accuracy: 0.8991 - val_loss: 0.2898\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7716 - binary_accuracy: 0.9055 - loss: 0.2758 - val_auc: 0.8125 - val_binary_accuracy: 0.8986 - val_loss: 0.2876\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9055 - loss: 0.2743 - val_auc: 0.8114 - val_binary_accuracy: 0.8986 - val_loss: 0.2883\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7757 - binary_accuracy: 0.9058 - loss: 0.2740 - val_auc: 0.8065 - val_binary_accuracy: 0.9007 - val_loss: 0.2841\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7784 - binary_accuracy: 0.9059 - loss: 0.2727 - val_auc: 0.8114 - val_binary_accuracy: 0.9023 - val_loss: 0.2745\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7812 - binary_accuracy: 0.9059 - loss: 0.2707 - val_auc: 0.8090 - val_binary_accuracy: 0.9054 - val_loss: 0.2709\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9082 - loss: 0.2627\n",
            "Fold 2 Metrics: Loss = 0.2709, Accuracy = 0.9054, AUC = 0.8090\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6325 - binary_accuracy: 0.8668 - loss: 0.6690 - val_auc: 0.7893 - val_binary_accuracy: 0.9063 - val_loss: 0.2674\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7722 - binary_accuracy: 0.9058 - loss: 0.2699 - val_auc: 0.7994 - val_binary_accuracy: 0.9017 - val_loss: 0.2711\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7725 - binary_accuracy: 0.9071 - loss: 0.2699 - val_auc: 0.8024 - val_binary_accuracy: 0.9023 - val_loss: 0.2673\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9061 - loss: 0.2710 - val_auc: 0.8041 - val_binary_accuracy: 0.9038 - val_loss: 0.2652\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9066 - loss: 0.2706 - val_auc: 0.8042 - val_binary_accuracy: 0.9026 - val_loss: 0.2683\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7737 - binary_accuracy: 0.9067 - loss: 0.2698 - val_auc: 0.8055 - val_binary_accuracy: 0.9013 - val_loss: 0.2680\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9070 - loss: 0.2690 - val_auc: 0.8053 - val_binary_accuracy: 0.9006 - val_loss: 0.2705\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7766 - binary_accuracy: 0.9071 - loss: 0.2684 - val_auc: 0.8061 - val_binary_accuracy: 0.9003 - val_loss: 0.2717\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.8058 - val_binary_accuracy: 0.9014 - val_loss: 0.2721\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7788 - binary_accuracy: 0.9072 - loss: 0.2672 - val_auc: 0.8059 - val_binary_accuracy: 0.8988 - val_loss: 0.2736\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8025 - binary_accuracy: 0.9010 - loss: 0.2736\n",
            "Fold 3 Metrics: Loss = 0.2736, Accuracy = 0.8988, AUC = 0.8059\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7025 - binary_accuracy: 0.8919 - loss: 0.3483 - val_auc: 0.8065 - val_binary_accuracy: 0.9081 - val_loss: 0.2577\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7717 - binary_accuracy: 0.9084 - loss: 0.2697 - val_auc: 0.8101 - val_binary_accuracy: 0.9026 - val_loss: 0.2593\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9081 - loss: 0.2691 - val_auc: 0.8120 - val_binary_accuracy: 0.9033 - val_loss: 0.2579\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9078 - loss: 0.2686 - val_auc: 0.8125 - val_binary_accuracy: 0.9069 - val_loss: 0.2551\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9088 - loss: 0.2676 - val_auc: 0.8118 - val_binary_accuracy: 0.9097 - val_loss: 0.2648\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9096 - loss: 0.2665 - val_auc: 0.8111 - val_binary_accuracy: 0.9100 - val_loss: 0.2961\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7777 - binary_accuracy: 0.9089 - loss: 0.2671 - val_auc: 0.8101 - val_binary_accuracy: 0.9090 - val_loss: 0.3140\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7748 - binary_accuracy: 0.9085 - loss: 0.2688 - val_auc: 0.8092 - val_binary_accuracy: 0.9091 - val_loss: 0.3189\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7715 - binary_accuracy: 0.9086 - loss: 0.2717 - val_auc: 0.8132 - val_binary_accuracy: 0.9095 - val_loss: 0.2976\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7718 - binary_accuracy: 0.9075 - loss: 0.2720 - val_auc: 0.8129 - val_binary_accuracy: 0.9098 - val_loss: 0.2836\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7967 - binary_accuracy: 0.9093 - loss: 0.2904\n",
            "Fold 4 Metrics: Loss = 0.2836, Accuracy = 0.9098, AUC = 0.8129\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6815 - binary_accuracy: 0.8778 - loss: 0.4993 - val_auc: 0.7960 - val_binary_accuracy: 0.8927 - val_loss: 0.2965\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7478 - binary_accuracy: 0.9037 - loss: 0.2840 - val_auc: 0.8031 - val_binary_accuracy: 0.8918 - val_loss: 0.2983\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7524 - binary_accuracy: 0.9039 - loss: 0.2828 - val_auc: 0.8050 - val_binary_accuracy: 0.8895 - val_loss: 0.2979\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7557 - binary_accuracy: 0.9038 - loss: 0.2810 - val_auc: 0.8066 - val_binary_accuracy: 0.8889 - val_loss: 0.2970\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7587 - binary_accuracy: 0.9036 - loss: 0.2797 - val_auc: 0.8074 - val_binary_accuracy: 0.8920 - val_loss: 0.2937\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7622 - binary_accuracy: 0.9041 - loss: 0.2781 - val_auc: 0.8080 - val_binary_accuracy: 0.8935 - val_loss: 0.2897\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7637 - binary_accuracy: 0.9046 - loss: 0.2772 - val_auc: 0.8079 - val_binary_accuracy: 0.8942 - val_loss: 0.2887\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9048 - loss: 0.2763 - val_auc: 0.8083 - val_binary_accuracy: 0.8941 - val_loss: 0.2876\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7663 - binary_accuracy: 0.9052 - loss: 0.2756 - val_auc: 0.8083 - val_binary_accuracy: 0.8939 - val_loss: 0.2867\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7681 - binary_accuracy: 0.9054 - loss: 0.2749 - val_auc: 0.8082 - val_binary_accuracy: 0.8954 - val_loss: 0.2848\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.8988 - loss: 0.2816\n",
            "Fold 5 Metrics: Loss = 0.2848, Accuracy = 0.8954, AUC = 0.8082\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2785\n",
            "Average Accuracy: 0.9037\n",
            "Average AUC: 0.8072\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 2, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6672 - binary_accuracy: 0.8183 - loss: 0.9800 - val_auc: 0.7084 - val_binary_accuracy: 0.9062 - val_loss: 0.2851\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7467 - binary_accuracy: 0.9104 - loss: 0.2730 - val_auc: 0.7630 - val_binary_accuracy: 0.9085 - val_loss: 0.2725\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9115 - loss: 0.2640 - val_auc: 0.7712 - val_binary_accuracy: 0.9078 - val_loss: 0.2701\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9116 - loss: 0.2609 - val_auc: 0.7749 - val_binary_accuracy: 0.9081 - val_loss: 0.2696\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9110 - loss: 0.2592 - val_auc: 0.7790 - val_binary_accuracy: 0.9088 - val_loss: 0.2691\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9110 - loss: 0.2577 - val_auc: 0.7828 - val_binary_accuracy: 0.9082 - val_loss: 0.2687\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9112 - loss: 0.2566 - val_auc: 0.7846 - val_binary_accuracy: 0.9088 - val_loss: 0.2677\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9117 - loss: 0.2557 - val_auc: 0.7861 - val_binary_accuracy: 0.9091 - val_loss: 0.2670\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9118 - loss: 0.2546 - val_auc: 0.7875 - val_binary_accuracy: 0.9091 - val_loss: 0.2667\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9122 - loss: 0.2539 - val_auc: 0.7892 - val_binary_accuracy: 0.9093 - val_loss: 0.2660\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7822 - binary_accuracy: 0.9124 - loss: 0.2588\n",
            "Fold 1 Metrics: Loss = 0.2660, Accuracy = 0.9093, AUC = 0.7892\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6465 - binary_accuracy: 0.8995 - loss: 0.4357 - val_auc: 0.7847 - val_binary_accuracy: 0.9057 - val_loss: 0.2662\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9039 - loss: 0.2732 - val_auc: 0.7982 - val_binary_accuracy: 0.9069 - val_loss: 0.2611\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9050 - loss: 0.2692 - val_auc: 0.8029 - val_binary_accuracy: 0.9078 - val_loss: 0.2584\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9053 - loss: 0.2669 - val_auc: 0.8064 - val_binary_accuracy: 0.9091 - val_loss: 0.2565\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9062 - loss: 0.2651 - val_auc: 0.8092 - val_binary_accuracy: 0.9097 - val_loss: 0.2555\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9067 - loss: 0.2640 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2546\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9072 - loss: 0.2629 - val_auc: 0.8124 - val_binary_accuracy: 0.9097 - val_loss: 0.2535\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9074 - loss: 0.2617 - val_auc: 0.8130 - val_binary_accuracy: 0.9099 - val_loss: 0.2538\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9083 - loss: 0.2610 - val_auc: 0.8145 - val_binary_accuracy: 0.9102 - val_loss: 0.2532\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9082 - loss: 0.2601 - val_auc: 0.8131 - val_binary_accuracy: 0.9100 - val_loss: 0.2538\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9138 - loss: 0.2447\n",
            "Fold 2 Metrics: Loss = 0.2538, Accuracy = 0.9100, AUC = 0.8131\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - auc: 0.6251 - binary_accuracy: 0.6070 - loss: 7.7190 - val_auc: 0.7514 - val_binary_accuracy: 0.8979 - val_loss: 0.3540\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7481 - binary_accuracy: 0.9018 - loss: 0.3162 - val_auc: 0.7567 - val_binary_accuracy: 0.9062 - val_loss: 0.2830\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7510 - binary_accuracy: 0.9061 - loss: 0.2809 - val_auc: 0.7641 - val_binary_accuracy: 0.9073 - val_loss: 0.2780\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7572 - binary_accuracy: 0.9071 - loss: 0.2766 - val_auc: 0.7705 - val_binary_accuracy: 0.9084 - val_loss: 0.2747\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7611 - binary_accuracy: 0.9078 - loss: 0.2740 - val_auc: 0.7745 - val_binary_accuracy: 0.9088 - val_loss: 0.2721\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9084 - loss: 0.2722 - val_auc: 0.7785 - val_binary_accuracy: 0.9099 - val_loss: 0.2698\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9087 - loss: 0.2710 - val_auc: 0.7810 - val_binary_accuracy: 0.9099 - val_loss: 0.2681\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9083 - loss: 0.2700 - val_auc: 0.7833 - val_binary_accuracy: 0.9102 - val_loss: 0.2663\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9085 - loss: 0.2693 - val_auc: 0.7858 - val_binary_accuracy: 0.9107 - val_loss: 0.2647\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9084 - loss: 0.2688 - val_auc: 0.7874 - val_binary_accuracy: 0.9106 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7845 - binary_accuracy: 0.9120 - loss: 0.2628\n",
            "Fold 3 Metrics: Loss = 0.2635, Accuracy = 0.9106, AUC = 0.7874\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6090 - binary_accuracy: 0.7314 - loss: 1.4009 - val_auc: 0.7550 - val_binary_accuracy: 0.9044 - val_loss: 0.2814\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7491 - binary_accuracy: 0.9039 - loss: 0.2804 - val_auc: 0.7699 - val_binary_accuracy: 0.9044 - val_loss: 0.2756\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9047 - loss: 0.2751 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9051 - loss: 0.2718 - val_auc: 0.7811 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9062 - loss: 0.2696 - val_auc: 0.7847 - val_binary_accuracy: 0.9048 - val_loss: 0.2687\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9075 - loss: 0.2675 - val_auc: 0.7883 - val_binary_accuracy: 0.9051 - val_loss: 0.2663\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9082 - loss: 0.2657 - val_auc: 0.7931 - val_binary_accuracy: 0.9067 - val_loss: 0.2641\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9091 - loss: 0.2642 - val_auc: 0.7973 - val_binary_accuracy: 0.9075 - val_loss: 0.2617\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9091 - loss: 0.2629 - val_auc: 0.8005 - val_binary_accuracy: 0.9075 - val_loss: 0.2599\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9097 - loss: 0.2620 - val_auc: 0.8028 - val_binary_accuracy: 0.9064 - val_loss: 0.2588\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7843 - binary_accuracy: 0.9057 - loss: 0.2647\n",
            "Fold 4 Metrics: Loss = 0.2588, Accuracy = 0.9064, AUC = 0.8028\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.3823 - binary_accuracy: 0.6444 - loss: 2.6988 - val_auc: 0.7613 - val_binary_accuracy: 0.9044 - val_loss: 0.2801\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7563 - binary_accuracy: 0.9041 - loss: 0.2800 - val_auc: 0.7886 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9042 - loss: 0.2727 - val_auc: 0.7919 - val_binary_accuracy: 0.9057 - val_loss: 0.2651\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9053 - loss: 0.2699 - val_auc: 0.7942 - val_binary_accuracy: 0.9066 - val_loss: 0.2634\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9067 - loss: 0.2681 - val_auc: 0.7959 - val_binary_accuracy: 0.9079 - val_loss: 0.2619\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.7979 - val_binary_accuracy: 0.9088 - val_loss: 0.2607\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9086 - loss: 0.2658 - val_auc: 0.7985 - val_binary_accuracy: 0.9088 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9088 - loss: 0.2649 - val_auc: 0.7996 - val_binary_accuracy: 0.9098 - val_loss: 0.2583\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9089 - loss: 0.2642 - val_auc: 0.8003 - val_binary_accuracy: 0.9106 - val_loss: 0.2573\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9089 - loss: 0.2636 - val_auc: 0.8013 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8121 - binary_accuracy: 0.9093 - loss: 0.2559\n",
            "Fold 5 Metrics: Loss = 0.2564, Accuracy = 0.9107, AUC = 0.8013\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2597\n",
            "Average Accuracy: 0.9094\n",
            "Average AUC: 0.7988\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 2, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5850 - binary_accuracy: 0.7056 - loss: 3.5820 - val_auc: 0.7506 - val_binary_accuracy: 0.9032 - val_loss: 0.2870\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9062 - loss: 0.2728 - val_auc: 0.7654 - val_binary_accuracy: 0.9012 - val_loss: 0.2774\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9059 - loss: 0.2640 - val_auc: 0.7735 - val_binary_accuracy: 0.9051 - val_loss: 0.2695\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9073 - loss: 0.2599 - val_auc: 0.7791 - val_binary_accuracy: 0.9065 - val_loss: 0.2673\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9091 - loss: 0.2576 - val_auc: 0.7819 - val_binary_accuracy: 0.9076 - val_loss: 0.2669\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9104 - loss: 0.2560 - val_auc: 0.7850 - val_binary_accuracy: 0.9082 - val_loss: 0.2670\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9110 - loss: 0.2544 - val_auc: 0.7886 - val_binary_accuracy: 0.9081 - val_loss: 0.2660\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9113 - loss: 0.2538 - val_auc: 0.7912 - val_binary_accuracy: 0.9081 - val_loss: 0.2651\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8023 - binary_accuracy: 0.9117 - loss: 0.2529 - val_auc: 0.7917 - val_binary_accuracy: 0.9094 - val_loss: 0.2645\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8033 - binary_accuracy: 0.9117 - loss: 0.2523 - val_auc: 0.7925 - val_binary_accuracy: 0.9097 - val_loss: 0.2641\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7866 - binary_accuracy: 0.9138 - loss: 0.2563\n",
            "Fold 1 Metrics: Loss = 0.2641, Accuracy = 0.9097, AUC = 0.7925\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6988 - binary_accuracy: 0.8928 - loss: 0.3315 - val_auc: 0.8039 - val_binary_accuracy: 0.9093 - val_loss: 0.2594\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9051 - loss: 0.2747 - val_auc: 0.8084 - val_binary_accuracy: 0.9090 - val_loss: 0.2561\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9049 - loss: 0.2702 - val_auc: 0.8109 - val_binary_accuracy: 0.9088 - val_loss: 0.2545\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9062 - loss: 0.2671 - val_auc: 0.8095 - val_binary_accuracy: 0.9097 - val_loss: 0.2549\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9058 - loss: 0.2657 - val_auc: 0.8088 - val_binary_accuracy: 0.9102 - val_loss: 0.2549\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9070 - loss: 0.2641 - val_auc: 0.8103 - val_binary_accuracy: 0.9106 - val_loss: 0.2543\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9065 - loss: 0.2636 - val_auc: 0.8100 - val_binary_accuracy: 0.9096 - val_loss: 0.2549\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9065 - loss: 0.2628 - val_auc: 0.8152 - val_binary_accuracy: 0.9096 - val_loss: 0.2527\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9064 - loss: 0.2621 - val_auc: 0.8099 - val_binary_accuracy: 0.9088 - val_loss: 0.2554\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9065 - loss: 0.2616 - val_auc: 0.8157 - val_binary_accuracy: 0.9097 - val_loss: 0.2523\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8194 - binary_accuracy: 0.9133 - loss: 0.2432\n",
            "Fold 2 Metrics: Loss = 0.2523, Accuracy = 0.9097, AUC = 0.8157\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5993 - binary_accuracy: 0.6960 - loss: 4.3704 - val_auc: 0.7570 - val_binary_accuracy: 0.9032 - val_loss: 0.2827\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7523 - binary_accuracy: 0.9015 - loss: 0.2811 - val_auc: 0.7754 - val_binary_accuracy: 0.9037 - val_loss: 0.2753\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7638 - binary_accuracy: 0.9037 - loss: 0.2751 - val_auc: 0.7816 - val_binary_accuracy: 0.9062 - val_loss: 0.2684\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9043 - loss: 0.2722 - val_auc: 0.7873 - val_binary_accuracy: 0.9073 - val_loss: 0.2650\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9061 - loss: 0.2696 - val_auc: 0.7918 - val_binary_accuracy: 0.9081 - val_loss: 0.2634\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9074 - loss: 0.2678 - val_auc: 0.7946 - val_binary_accuracy: 0.9072 - val_loss: 0.2637\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9081 - loss: 0.2660 - val_auc: 0.7969 - val_binary_accuracy: 0.9079 - val_loss: 0.2639\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9087 - loss: 0.2645 - val_auc: 0.7983 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9084 - loss: 0.2638 - val_auc: 0.8001 - val_binary_accuracy: 0.9065 - val_loss: 0.2652\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8013 - val_binary_accuracy: 0.9071 - val_loss: 0.2658\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7952 - binary_accuracy: 0.9058 - loss: 0.2666\n",
            "Fold 3 Metrics: Loss = 0.2658, Accuracy = 0.9071, AUC = 0.8013\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6354 - binary_accuracy: 0.8301 - loss: 0.6190 - val_auc: 0.7861 - val_binary_accuracy: 0.9060 - val_loss: 0.2670\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9055 - loss: 0.2697 - val_auc: 0.7922 - val_binary_accuracy: 0.9066 - val_loss: 0.2635\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9058 - loss: 0.2663 - val_auc: 0.7966 - val_binary_accuracy: 0.9072 - val_loss: 0.2611\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9073 - loss: 0.2643 - val_auc: 0.8001 - val_binary_accuracy: 0.9072 - val_loss: 0.2598\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9078 - loss: 0.2634 - val_auc: 0.8021 - val_binary_accuracy: 0.9085 - val_loss: 0.2589\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9080 - loss: 0.2620 - val_auc: 0.8040 - val_binary_accuracy: 0.9064 - val_loss: 0.2586\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9085 - loss: 0.2612 - val_auc: 0.8061 - val_binary_accuracy: 0.9085 - val_loss: 0.2573\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9087 - loss: 0.2607 - val_auc: 0.8071 - val_binary_accuracy: 0.9081 - val_loss: 0.2568\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9095 - loss: 0.2599 - val_auc: 0.8083 - val_binary_accuracy: 0.9079 - val_loss: 0.2561\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9095 - loss: 0.2597 - val_auc: 0.8095 - val_binary_accuracy: 0.9084 - val_loss: 0.2556\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9072 - loss: 0.2619\n",
            "Fold 4 Metrics: Loss = 0.2556, Accuracy = 0.9084, AUC = 0.8095\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5681 - binary_accuracy: 0.8017 - loss: 1.5777 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7602 - binary_accuracy: 0.9040 - loss: 0.2780 - val_auc: 0.7966 - val_binary_accuracy: 0.9060 - val_loss: 0.2675\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9051 - loss: 0.2728 - val_auc: 0.8024 - val_binary_accuracy: 0.9063 - val_loss: 0.2599\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9068 - loss: 0.2695 - val_auc: 0.8041 - val_binary_accuracy: 0.9062 - val_loss: 0.2572\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.8061 - val_binary_accuracy: 0.9060 - val_loss: 0.2557\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9073 - loss: 0.2677 - val_auc: 0.8068 - val_binary_accuracy: 0.9057 - val_loss: 0.2553\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9074 - loss: 0.2674 - val_auc: 0.8077 - val_binary_accuracy: 0.9050 - val_loss: 0.2549\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9074 - loss: 0.2671 - val_auc: 0.8084 - val_binary_accuracy: 0.9076 - val_loss: 0.2534\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9075 - loss: 0.2661 - val_auc: 0.8089 - val_binary_accuracy: 0.9085 - val_loss: 0.2527\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7823 - binary_accuracy: 0.9077 - loss: 0.2656 - val_auc: 0.8085 - val_binary_accuracy: 0.9062 - val_loss: 0.2537\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8185 - binary_accuracy: 0.9057 - loss: 0.2510\n",
            "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9062, AUC = 0.8085\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2583\n",
            "Average Accuracy: 0.9082\n",
            "Average AUC: 0.8055\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 2, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7206 - binary_accuracy: 0.9015 - loss: 0.2951 - val_auc: 0.7831 - val_binary_accuracy: 0.9057 - val_loss: 0.2774\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9075 - loss: 0.2660 - val_auc: 0.7913 - val_binary_accuracy: 0.9082 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9103 - loss: 0.2602 - val_auc: 0.7923 - val_binary_accuracy: 0.9100 - val_loss: 0.2604\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9117 - loss: 0.2571 - val_auc: 0.7938 - val_binary_accuracy: 0.9093 - val_loss: 0.2603\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9121 - loss: 0.2553 - val_auc: 0.7942 - val_binary_accuracy: 0.9097 - val_loss: 0.2599\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9120 - loss: 0.2541 - val_auc: 0.7920 - val_binary_accuracy: 0.9090 - val_loss: 0.2725\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9104 - loss: 0.2563 - val_auc: 0.7953 - val_binary_accuracy: 0.9113 - val_loss: 0.2587\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9130 - loss: 0.2515 - val_auc: 0.7960 - val_binary_accuracy: 0.9113 - val_loss: 0.2612\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9125 - loss: 0.2512 - val_auc: 0.7964 - val_binary_accuracy: 0.9093 - val_loss: 0.2646\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9130 - loss: 0.2505 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2682\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9115 - loss: 0.2636\n",
            "Fold 1 Metrics: Loss = 0.2682, Accuracy = 0.9084, AUC = 0.7962\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6507 - binary_accuracy: 0.8843 - loss: 0.4740 - val_auc: 0.7976 - val_binary_accuracy: 0.8947 - val_loss: 0.3016\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7485 - binary_accuracy: 0.9023 - loss: 0.2852 - val_auc: 0.8083 - val_binary_accuracy: 0.9025 - val_loss: 0.2893\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9043 - loss: 0.2794 - val_auc: 0.8127 - val_binary_accuracy: 0.8916 - val_loss: 0.2959\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9051 - loss: 0.2766 - val_auc: 0.8112 - val_binary_accuracy: 0.8998 - val_loss: 0.2769\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9057 - loss: 0.2730 - val_auc: 0.8106 - val_binary_accuracy: 0.9073 - val_loss: 0.2647\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9065 - loss: 0.2696 - val_auc: 0.8122 - val_binary_accuracy: 0.9090 - val_loss: 0.2586\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9060 - loss: 0.2673 - val_auc: 0.8116 - val_binary_accuracy: 0.9078 - val_loss: 0.2565\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9058 - loss: 0.2656 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9065 - loss: 0.2643 - val_auc: 0.8129 - val_binary_accuracy: 0.9087 - val_loss: 0.2559\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9058 - loss: 0.2639 - val_auc: 0.8117 - val_binary_accuracy: 0.9084 - val_loss: 0.2563\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9129 - loss: 0.2466\n",
            "Fold 2 Metrics: Loss = 0.2563, Accuracy = 0.9084, AUC = 0.8117\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6639 - binary_accuracy: 0.8643 - loss: 0.6035 - val_auc: 0.7813 - val_binary_accuracy: 0.9066 - val_loss: 0.2673\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9042 - loss: 0.2733 - val_auc: 0.7930 - val_binary_accuracy: 0.9078 - val_loss: 0.2642\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9054 - loss: 0.2707 - val_auc: 0.7990 - val_binary_accuracy: 0.9073 - val_loss: 0.2617\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7723 - binary_accuracy: 0.9055 - loss: 0.2689 - val_auc: 0.8002 - val_binary_accuracy: 0.9088 - val_loss: 0.2587\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9066 - loss: 0.2686 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2568\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2682 - val_auc: 0.8021 - val_binary_accuracy: 0.9103 - val_loss: 0.2572\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9059 - loss: 0.2670 - val_auc: 0.8038 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9064 - loss: 0.2652 - val_auc: 0.8028 - val_binary_accuracy: 0.9102 - val_loss: 0.2566\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9071 - loss: 0.2647 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2565\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9075 - loss: 0.2614 - val_auc: 0.8046 - val_binary_accuracy: 0.9091 - val_loss: 0.2583\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7994 - binary_accuracy: 0.9108 - loss: 0.2583\n",
            "Fold 3 Metrics: Loss = 0.2583, Accuracy = 0.9091, AUC = 0.8046\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5694 - binary_accuracy: 0.8304 - loss: 1.5457 - val_auc: 0.7800 - val_binary_accuracy: 0.9056 - val_loss: 0.2700\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7628 - binary_accuracy: 0.9050 - loss: 0.2748 - val_auc: 0.7886 - val_binary_accuracy: 0.9076 - val_loss: 0.2643\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9077 - loss: 0.2698 - val_auc: 0.7945 - val_binary_accuracy: 0.9100 - val_loss: 0.2620\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9082 - loss: 0.2678 - val_auc: 0.7987 - val_binary_accuracy: 0.9101 - val_loss: 0.2602\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9079 - loss: 0.2668 - val_auc: 0.8028 - val_binary_accuracy: 0.9095 - val_loss: 0.2585\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9085 - loss: 0.2658 - val_auc: 0.8057 - val_binary_accuracy: 0.9093 - val_loss: 0.2578\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9085 - loss: 0.2653 - val_auc: 0.8074 - val_binary_accuracy: 0.9095 - val_loss: 0.2566\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.8083 - val_binary_accuracy: 0.9097 - val_loss: 0.2561\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9086 - loss: 0.2635 - val_auc: 0.8092 - val_binary_accuracy: 0.9098 - val_loss: 0.2557\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9086 - loss: 0.2629 - val_auc: 0.8098 - val_binary_accuracy: 0.9093 - val_loss: 0.2554\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7923 - binary_accuracy: 0.9090 - loss: 0.2623\n",
            "Fold 4 Metrics: Loss = 0.2554, Accuracy = 0.9093, AUC = 0.8098\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6531 - binary_accuracy: 0.8927 - loss: 0.4317 - val_auc: 0.7936 - val_binary_accuracy: 0.8969 - val_loss: 0.2813\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7395 - binary_accuracy: 0.9018 - loss: 0.2877 - val_auc: 0.8023 - val_binary_accuracy: 0.8939 - val_loss: 0.2877\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7499 - binary_accuracy: 0.9029 - loss: 0.2835 - val_auc: 0.8056 - val_binary_accuracy: 0.8904 - val_loss: 0.2915\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7577 - binary_accuracy: 0.9043 - loss: 0.2793 - val_auc: 0.8084 - val_binary_accuracy: 0.8942 - val_loss: 0.2893\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9052 - loss: 0.2770 - val_auc: 0.8088 - val_binary_accuracy: 0.8972 - val_loss: 0.2828\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9055 - loss: 0.2751 - val_auc: 0.8097 - val_binary_accuracy: 0.8977 - val_loss: 0.2783\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9063 - loss: 0.2732 - val_auc: 0.8101 - val_binary_accuracy: 0.8997 - val_loss: 0.2738\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9056 - loss: 0.2718 - val_auc: 0.8100 - val_binary_accuracy: 0.9005 - val_loss: 0.2708\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9055 - loss: 0.2708 - val_auc: 0.8100 - val_binary_accuracy: 0.9016 - val_loss: 0.2697\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.8098 - val_binary_accuracy: 0.9017 - val_loss: 0.2687\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8171 - binary_accuracy: 0.9044 - loss: 0.2660\n",
            "Fold 5 Metrics: Loss = 0.2687, Accuracy = 0.9017, AUC = 0.8098\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2614\n",
            "Average Accuracy: 0.9074\n",
            "Average AUC: 0.8064\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 2, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6751 - binary_accuracy: 0.8891 - loss: 0.4576 - val_auc: 0.7801 - val_binary_accuracy: 0.9048 - val_loss: 0.2903\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9071 - loss: 0.2705 - val_auc: 0.7893 - val_binary_accuracy: 0.9072 - val_loss: 0.2758\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9083 - loss: 0.2653 - val_auc: 0.7927 - val_binary_accuracy: 0.9068 - val_loss: 0.2953\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7971 - val_binary_accuracy: 0.9072 - val_loss: 0.2744\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9099 - loss: 0.2589 - val_auc: 0.7995 - val_binary_accuracy: 0.9100 - val_loss: 0.2568\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9128 - loss: 0.2536 - val_auc: 0.7993 - val_binary_accuracy: 0.9085 - val_loss: 0.2695\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9110 - loss: 0.2546 - val_auc: 0.7992 - val_binary_accuracy: 0.9104 - val_loss: 0.2565\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9133 - loss: 0.2506 - val_auc: 0.7986 - val_binary_accuracy: 0.9100 - val_loss: 0.2572\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9129 - loss: 0.2498 - val_auc: 0.7979 - val_binary_accuracy: 0.9109 - val_loss: 0.2608\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9135 - loss: 0.2497 - val_auc: 0.7989 - val_binary_accuracy: 0.9110 - val_loss: 0.2685\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7940 - binary_accuracy: 0.9147 - loss: 0.2639\n",
            "Fold 1 Metrics: Loss = 0.2685, Accuracy = 0.9110, AUC = 0.7989\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6523 - binary_accuracy: 0.8804 - loss: 0.4424 - val_auc: 0.8101 - val_binary_accuracy: 0.9072 - val_loss: 0.2617\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9016 - loss: 0.2777 - val_auc: 0.8124 - val_binary_accuracy: 0.9082 - val_loss: 0.2594\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7771 - binary_accuracy: 0.9039 - loss: 0.2722 - val_auc: 0.8119 - val_binary_accuracy: 0.9069 - val_loss: 0.2695\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7794 - binary_accuracy: 0.9050 - loss: 0.2712 - val_auc: 0.8135 - val_binary_accuracy: 0.9075 - val_loss: 0.2694\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9047 - loss: 0.2728 - val_auc: 0.8077 - val_binary_accuracy: 0.9032 - val_loss: 0.2869\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7746 - binary_accuracy: 0.9046 - loss: 0.2735 - val_auc: 0.8085 - val_binary_accuracy: 0.9062 - val_loss: 0.2697\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7793 - binary_accuracy: 0.9053 - loss: 0.2711 - val_auc: 0.8074 - val_binary_accuracy: 0.9085 - val_loss: 0.2583\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9061 - loss: 0.2668 - val_auc: 0.8010 - val_binary_accuracy: 0.9081 - val_loss: 0.2615\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9065 - loss: 0.2658 - val_auc: 0.8077 - val_binary_accuracy: 0.9097 - val_loss: 0.2575\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7954 - binary_accuracy: 0.9076 - loss: 0.2630 - val_auc: 0.8098 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8171 - binary_accuracy: 0.9121 - loss: 0.2472\n",
            "Fold 2 Metrics: Loss = 0.2560, Accuracy = 0.9090, AUC = 0.8098\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6354 - binary_accuracy: 0.8592 - loss: 1.1882 - val_auc: 0.7836 - val_binary_accuracy: 0.9063 - val_loss: 0.2833\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7343 - binary_accuracy: 0.9017 - loss: 0.2911 - val_auc: 0.7957 - val_binary_accuracy: 0.9054 - val_loss: 0.3158\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7497 - binary_accuracy: 0.9062 - loss: 0.2802 - val_auc: 0.7990 - val_binary_accuracy: 0.9063 - val_loss: 0.3010\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7469 - binary_accuracy: 0.9048 - loss: 0.2840 - val_auc: 0.8028 - val_binary_accuracy: 0.9103 - val_loss: 0.2643\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7557 - binary_accuracy: 0.9056 - loss: 0.2795 - val_auc: 0.8042 - val_binary_accuracy: 0.9079 - val_loss: 0.2603\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9059 - loss: 0.2735 - val_auc: 0.8053 - val_binary_accuracy: 0.9019 - val_loss: 0.2697\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9073 - loss: 0.2696 - val_auc: 0.8050 - val_binary_accuracy: 0.8979 - val_loss: 0.2764\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9063 - loss: 0.2675 - val_auc: 0.8050 - val_binary_accuracy: 0.9032 - val_loss: 0.2713\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9069 - loss: 0.2662 - val_auc: 0.8055 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9075 - loss: 0.2672 - val_auc: 0.8045 - val_binary_accuracy: 0.9106 - val_loss: 0.2564\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9113 - loss: 0.2574\n",
            "Fold 3 Metrics: Loss = 0.2564, Accuracy = 0.9106, AUC = 0.8045\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6163 - binary_accuracy: 0.8575 - loss: 1.0092 - val_auc: 0.7969 - val_binary_accuracy: 0.9069 - val_loss: 0.2687\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9063 - loss: 0.2717 - val_auc: 0.7996 - val_binary_accuracy: 0.9072 - val_loss: 0.2764\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9062 - loss: 0.2717 - val_auc: 0.8056 - val_binary_accuracy: 0.9084 - val_loss: 0.2722\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9072 - loss: 0.2693 - val_auc: 0.8056 - val_binary_accuracy: 0.9093 - val_loss: 0.2649\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9081 - loss: 0.2673 - val_auc: 0.8103 - val_binary_accuracy: 0.9088 - val_loss: 0.2744\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9080 - loss: 0.2664 - val_auc: 0.8102 - val_binary_accuracy: 0.9095 - val_loss: 0.2560\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9096 - loss: 0.2632 - val_auc: 0.8079 - val_binary_accuracy: 0.9090 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9099 - loss: 0.2632 - val_auc: 0.8097 - val_binary_accuracy: 0.9098 - val_loss: 0.2559\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2621 - val_auc: 0.8114 - val_binary_accuracy: 0.9091 - val_loss: 0.2548\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8106 - val_binary_accuracy: 0.9091 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9082 - loss: 0.2627\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9091, AUC = 0.8106\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6018 - binary_accuracy: 0.8659 - loss: 0.8248 - val_auc: 0.7914 - val_binary_accuracy: 0.8991 - val_loss: 0.2734\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7383 - binary_accuracy: 0.9010 - loss: 0.2886 - val_auc: 0.8022 - val_binary_accuracy: 0.8964 - val_loss: 0.2739\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7462 - binary_accuracy: 0.9019 - loss: 0.2855 - val_auc: 0.8053 - val_binary_accuracy: 0.8974 - val_loss: 0.2661\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7504 - binary_accuracy: 0.9025 - loss: 0.2836 - val_auc: 0.8068 - val_binary_accuracy: 0.8948 - val_loss: 0.2792\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7560 - binary_accuracy: 0.9043 - loss: 0.2796 - val_auc: 0.8080 - val_binary_accuracy: 0.8963 - val_loss: 0.2804\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9047 - loss: 0.2770 - val_auc: 0.8085 - val_binary_accuracy: 0.8954 - val_loss: 0.2792\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9050 - loss: 0.2745 - val_auc: 0.8091 - val_binary_accuracy: 0.8986 - val_loss: 0.2732\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9049 - loss: 0.2723 - val_auc: 0.8096 - val_binary_accuracy: 0.9004 - val_loss: 0.2684\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9050 - loss: 0.2709 - val_auc: 0.8097 - val_binary_accuracy: 0.9047 - val_loss: 0.2630\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9055 - loss: 0.2689 - val_auc: 0.8094 - val_binary_accuracy: 0.9036 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9055 - loss: 0.2615\n",
            "Fold 5 Metrics: Loss = 0.2635, Accuracy = 0.9036, AUC = 0.8094\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2599\n",
            "Average Accuracy: 0.9087\n",
            "Average AUC: 0.8066\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 2, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6504 - binary_accuracy: 0.8786 - loss: 0.5864 - val_auc: 0.7817 - val_binary_accuracy: 0.9090 - val_loss: 0.2642\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7497 - binary_accuracy: 0.9061 - loss: 0.2797 - val_auc: 0.7915 - val_binary_accuracy: 0.9097 - val_loss: 0.2596\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9094 - loss: 0.2658 - val_auc: 0.7916 - val_binary_accuracy: 0.9096 - val_loss: 0.2672\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9096 - loss: 0.2645 - val_auc: 0.7939 - val_binary_accuracy: 0.9072 - val_loss: 0.2882\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9106 - loss: 0.2604 - val_auc: 0.7954 - val_binary_accuracy: 0.9075 - val_loss: 0.2800\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9101 - loss: 0.2594 - val_auc: 0.7972 - val_binary_accuracy: 0.9106 - val_loss: 0.2575\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9119 - loss: 0.2534 - val_auc: 0.7982 - val_binary_accuracy: 0.9110 - val_loss: 0.2569\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9129 - loss: 0.2515 - val_auc: 0.7977 - val_binary_accuracy: 0.9118 - val_loss: 0.2590\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9126 - loss: 0.2512 - val_auc: 0.7983 - val_binary_accuracy: 0.9115 - val_loss: 0.2604\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9129 - loss: 0.2498 - val_auc: 0.7975 - val_binary_accuracy: 0.9100 - val_loss: 0.2641\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7943 - binary_accuracy: 0.9126 - loss: 0.2593\n",
            "Fold 1 Metrics: Loss = 0.2641, Accuracy = 0.9100, AUC = 0.7975\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6451 - binary_accuracy: 0.8699 - loss: 0.7414 - val_auc: 0.8049 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9026 - loss: 0.2829 - val_auc: 0.8066 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9054 - loss: 0.2741 - val_auc: 0.8084 - val_binary_accuracy: 0.9090 - val_loss: 0.2603\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9047 - loss: 0.2715 - val_auc: 0.8099 - val_binary_accuracy: 0.9093 - val_loss: 0.2710\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9046 - loss: 0.2708 - val_auc: 0.8078 - val_binary_accuracy: 0.9068 - val_loss: 0.2784\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.8036 - val_binary_accuracy: 0.9097 - val_loss: 0.2598\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9065 - loss: 0.2692 - val_auc: 0.8046 - val_binary_accuracy: 0.9094 - val_loss: 0.2610\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9070 - loss: 0.2643 - val_auc: 0.8036 - val_binary_accuracy: 0.9099 - val_loss: 0.2586\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9073 - loss: 0.2626 - val_auc: 0.8043 - val_binary_accuracy: 0.9099 - val_loss: 0.2599\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9074 - loss: 0.2612 - val_auc: 0.7874 - val_binary_accuracy: 0.9091 - val_loss: 0.2646\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7999 - binary_accuracy: 0.9126 - loss: 0.2546\n",
            "Fold 2 Metrics: Loss = 0.2646, Accuracy = 0.9091, AUC = 0.7874\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6312 - binary_accuracy: 0.8660 - loss: 1.1762 - val_auc: 0.7974 - val_binary_accuracy: 0.9044 - val_loss: 0.2904\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7125 - binary_accuracy: 0.8964 - loss: 0.3124 - val_auc: 0.8023 - val_binary_accuracy: 0.9088 - val_loss: 0.2753\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7300 - binary_accuracy: 0.9011 - loss: 0.2977 - val_auc: 0.8039 - val_binary_accuracy: 0.9102 - val_loss: 0.2717\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7544 - binary_accuracy: 0.9030 - loss: 0.2803 - val_auc: 0.8034 - val_binary_accuracy: 0.9109 - val_loss: 0.2582\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7682 - binary_accuracy: 0.9053 - loss: 0.2721 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2785\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9056 - loss: 0.2778 - val_auc: 0.8070 - val_binary_accuracy: 0.9029 - val_loss: 0.2728\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9071 - loss: 0.2688 - val_auc: 0.8083 - val_binary_accuracy: 0.9048 - val_loss: 0.2672\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9059 - loss: 0.2665 - val_auc: 0.8085 - val_binary_accuracy: 0.9102 - val_loss: 0.2558\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9066 - loss: 0.2673 - val_auc: 0.8046 - val_binary_accuracy: 0.9115 - val_loss: 0.2581\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9060 - loss: 0.2694 - val_auc: 0.8055 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7987 - binary_accuracy: 0.9127 - loss: 0.2570\n",
            "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9109, AUC = 0.8055\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6304 - binary_accuracy: 0.8679 - loss: 0.8913 - val_auc: 0.7991 - val_binary_accuracy: 0.9059 - val_loss: 0.2620\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7455 - binary_accuracy: 0.9030 - loss: 0.2861 - val_auc: 0.8030 - val_binary_accuracy: 0.8994 - val_loss: 0.2697\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7504 - binary_accuracy: 0.9039 - loss: 0.2830 - val_auc: 0.8068 - val_binary_accuracy: 0.9036 - val_loss: 0.2613\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7532 - binary_accuracy: 0.9046 - loss: 0.2829 - val_auc: 0.8096 - val_binary_accuracy: 0.9062 - val_loss: 0.2562\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9077 - loss: 0.2700 - val_auc: 0.8097 - val_binary_accuracy: 0.9097 - val_loss: 0.2577\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9083 - loss: 0.2682 - val_auc: 0.8111 - val_binary_accuracy: 0.9087 - val_loss: 0.2879\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9082 - loss: 0.2706 - val_auc: 0.8127 - val_binary_accuracy: 0.9098 - val_loss: 0.2601\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9086 - loss: 0.2642 - val_auc: 0.8118 - val_binary_accuracy: 0.9097 - val_loss: 0.2550\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9096 - loss: 0.2642 - val_auc: 0.8109 - val_binary_accuracy: 0.9079 - val_loss: 0.2547\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9090 - loss: 0.2631 - val_auc: 0.8117 - val_binary_accuracy: 0.9097 - val_loss: 0.2546\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7939 - binary_accuracy: 0.9087 - loss: 0.2618\n",
            "Fold 4 Metrics: Loss = 0.2546, Accuracy = 0.9097, AUC = 0.8117\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6253 - binary_accuracy: 0.8703 - loss: 0.8894 - val_auc: 0.7991 - val_binary_accuracy: 0.9020 - val_loss: 0.2607\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7261 - binary_accuracy: 0.8994 - loss: 0.2994 - val_auc: 0.8043 - val_binary_accuracy: 0.8976 - val_loss: 0.2687\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7441 - binary_accuracy: 0.9007 - loss: 0.2874 - val_auc: 0.8064 - val_binary_accuracy: 0.8941 - val_loss: 0.2824\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7505 - binary_accuracy: 0.9025 - loss: 0.2835 - val_auc: 0.8074 - val_binary_accuracy: 0.8932 - val_loss: 0.2816\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9044 - loss: 0.2779 - val_auc: 0.8087 - val_binary_accuracy: 0.8955 - val_loss: 0.2819\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7670 - binary_accuracy: 0.9047 - loss: 0.2749 - val_auc: 0.8082 - val_binary_accuracy: 0.8997 - val_loss: 0.2742\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9046 - loss: 0.2726 - val_auc: 0.8087 - val_binary_accuracy: 0.8982 - val_loss: 0.2733\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9045 - loss: 0.2717 - val_auc: 0.8086 - val_binary_accuracy: 0.9028 - val_loss: 0.2651\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9049 - loss: 0.2713 - val_auc: 0.8088 - val_binary_accuracy: 0.9091 - val_loss: 0.2544\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9082 - loss: 0.2678 - val_auc: 0.8098 - val_binary_accuracy: 0.9103 - val_loss: 0.2518\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9092 - loss: 0.2512\n",
            "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9103, AUC = 0.8098\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2584\n",
            "Average Accuracy: 0.9100\n",
            "Average AUC: 0.8024\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 3, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6665 - binary_accuracy: 0.8809 - loss: 0.3548 - val_auc: 0.7707 - val_binary_accuracy: 0.9053 - val_loss: 0.2720\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9099 - loss: 0.2599 - val_auc: 0.7797 - val_binary_accuracy: 0.9054 - val_loss: 0.2697\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9112 - loss: 0.2573 - val_auc: 0.7813 - val_binary_accuracy: 0.9088 - val_loss: 0.2655\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9124 - loss: 0.2552 - val_auc: 0.7835 - val_binary_accuracy: 0.9094 - val_loss: 0.2650\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9120 - loss: 0.2541 - val_auc: 0.7842 - val_binary_accuracy: 0.9097 - val_loss: 0.2642\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9124 - loss: 0.2531 - val_auc: 0.7844 - val_binary_accuracy: 0.9082 - val_loss: 0.2656\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9124 - loss: 0.2528 - val_auc: 0.7838 - val_binary_accuracy: 0.9084 - val_loss: 0.2655\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9131 - loss: 0.2516 - val_auc: 0.7850 - val_binary_accuracy: 0.9087 - val_loss: 0.2645\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9131 - loss: 0.2506 - val_auc: 0.7873 - val_binary_accuracy: 0.9084 - val_loss: 0.2631\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9137 - loss: 0.2498 - val_auc: 0.7884 - val_binary_accuracy: 0.9090 - val_loss: 0.2616\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7839 - binary_accuracy: 0.9112 - loss: 0.2553\n",
            "Fold 1 Metrics: Loss = 0.2616, Accuracy = 0.9090, AUC = 0.7884\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6155 - binary_accuracy: 0.6510 - loss: 4.1405 - val_auc: 0.7794 - val_binary_accuracy: 0.9062 - val_loss: 0.2693\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9053 - loss: 0.2719 - val_auc: 0.7858 - val_binary_accuracy: 0.9066 - val_loss: 0.2671\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9056 - loss: 0.2693 - val_auc: 0.7872 - val_binary_accuracy: 0.9069 - val_loss: 0.2670\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9059 - loss: 0.2673 - val_auc: 0.7906 - val_binary_accuracy: 0.9073 - val_loss: 0.2652\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9057 - loss: 0.2665 - val_auc: 0.7928 - val_binary_accuracy: 0.9071 - val_loss: 0.2647\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9060 - loss: 0.2655 - val_auc: 0.7938 - val_binary_accuracy: 0.9075 - val_loss: 0.2648\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9067 - loss: 0.2648 - val_auc: 0.7987 - val_binary_accuracy: 0.9082 - val_loss: 0.2628\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9065 - loss: 0.2640 - val_auc: 0.7981 - val_binary_accuracy: 0.9081 - val_loss: 0.2629\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9069 - loss: 0.2633 - val_auc: 0.7996 - val_binary_accuracy: 0.9082 - val_loss: 0.2611\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9071 - loss: 0.2624 - val_auc: 0.8021 - val_binary_accuracy: 0.9084 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8058 - binary_accuracy: 0.9120 - loss: 0.2503\n",
            "Fold 2 Metrics: Loss = 0.2599, Accuracy = 0.9084, AUC = 0.8021\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5921 - binary_accuracy: 0.8004 - loss: 0.7227 - val_auc: 0.7783 - val_binary_accuracy: 0.9045 - val_loss: 0.2729\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9058 - loss: 0.2708 - val_auc: 0.7856 - val_binary_accuracy: 0.9045 - val_loss: 0.2701\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.7903 - val_binary_accuracy: 0.9056 - val_loss: 0.2687\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9070 - loss: 0.2667 - val_auc: 0.7940 - val_binary_accuracy: 0.9059 - val_loss: 0.2657\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9072 - loss: 0.2661 - val_auc: 0.7964 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9076 - loss: 0.2651 - val_auc: 0.7981 - val_binary_accuracy: 0.9097 - val_loss: 0.2615\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9085 - loss: 0.2648 - val_auc: 0.7985 - val_binary_accuracy: 0.9104 - val_loss: 0.2605\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9091 - loss: 0.2640 - val_auc: 0.7985 - val_binary_accuracy: 0.9107 - val_loss: 0.2604\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.7994 - val_binary_accuracy: 0.9112 - val_loss: 0.2601\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9092 - loss: 0.2630 - val_auc: 0.7999 - val_binary_accuracy: 0.9118 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9134 - loss: 0.2596\n",
            "Fold 3 Metrics: Loss = 0.2599, Accuracy = 0.9118, AUC = 0.7999\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5840 - binary_accuracy: 0.9036 - loss: 0.6592 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2716\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9041 - loss: 0.2733 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9053 - loss: 0.2686 - val_auc: 0.7917 - val_binary_accuracy: 0.9047 - val_loss: 0.2635\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9066 - loss: 0.2660 - val_auc: 0.7953 - val_binary_accuracy: 0.9069 - val_loss: 0.2616\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.7974 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9084 - loss: 0.2631 - val_auc: 0.7989 - val_binary_accuracy: 0.9087 - val_loss: 0.2593\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9092 - loss: 0.2622 - val_auc: 0.8015 - val_binary_accuracy: 0.9098 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9099 - loss: 0.2614 - val_auc: 0.8030 - val_binary_accuracy: 0.9100 - val_loss: 0.2574\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.8052 - val_binary_accuracy: 0.9106 - val_loss: 0.2567\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9099 - loss: 0.2600 - val_auc: 0.8075 - val_binary_accuracy: 0.9101 - val_loss: 0.2560\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7887 - binary_accuracy: 0.9099 - loss: 0.2617\n",
            "Fold 4 Metrics: Loss = 0.2560, Accuracy = 0.9101, AUC = 0.8075\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6327 - binary_accuracy: 0.9013 - loss: 0.3295 - val_auc: 0.7975 - val_binary_accuracy: 0.9050 - val_loss: 0.2635\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9047 - loss: 0.2742 - val_auc: 0.8009 - val_binary_accuracy: 0.9054 - val_loss: 0.2606\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9044 - loss: 0.2713 - val_auc: 0.8029 - val_binary_accuracy: 0.9048 - val_loss: 0.2600\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9054 - loss: 0.2696 - val_auc: 0.8037 - val_binary_accuracy: 0.9060 - val_loss: 0.2603\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9063 - loss: 0.2679 - val_auc: 0.8051 - val_binary_accuracy: 0.9064 - val_loss: 0.2612\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9065 - loss: 0.2664 - val_auc: 0.8060 - val_binary_accuracy: 0.9070 - val_loss: 0.2612\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9067 - loss: 0.2652 - val_auc: 0.8068 - val_binary_accuracy: 0.9073 - val_loss: 0.2614\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9071 - loss: 0.2646 - val_auc: 0.8073 - val_binary_accuracy: 0.9060 - val_loss: 0.2625\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9074 - loss: 0.2641 - val_auc: 0.8077 - val_binary_accuracy: 0.9062 - val_loss: 0.2635\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8081 - val_binary_accuracy: 0.9056 - val_loss: 0.2646\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8173 - binary_accuracy: 0.9061 - loss: 0.2620\n",
            "Fold 5 Metrics: Loss = 0.2646, Accuracy = 0.9056, AUC = 0.8081\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2604\n",
            "Average Accuracy: 0.9090\n",
            "Average AUC: 0.8012\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 3, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - auc: 0.5937 - binary_accuracy: 0.8173 - loss: 0.9928 - val_auc: 0.7537 - val_binary_accuracy: 0.9044 - val_loss: 0.2783\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9072 - loss: 0.2688 - val_auc: 0.7666 - val_binary_accuracy: 0.9051 - val_loss: 0.2734\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9082 - loss: 0.2637 - val_auc: 0.7752 - val_binary_accuracy: 0.9060 - val_loss: 0.2701\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9094 - loss: 0.2592 - val_auc: 0.7817 - val_binary_accuracy: 0.9075 - val_loss: 0.2679\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9099 - loss: 0.2582 - val_auc: 0.7860 - val_binary_accuracy: 0.9063 - val_loss: 0.2665\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9105 - loss: 0.2556 - val_auc: 0.7906 - val_binary_accuracy: 0.9078 - val_loss: 0.2641\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9114 - loss: 0.2535 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2627\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9114 - loss: 0.2525 - val_auc: 0.7919 - val_binary_accuracy: 0.9099 - val_loss: 0.2621\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8050 - binary_accuracy: 0.9117 - loss: 0.2514 - val_auc: 0.7944 - val_binary_accuracy: 0.9096 - val_loss: 0.2622\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8067 - binary_accuracy: 0.9119 - loss: 0.2506 - val_auc: 0.7947 - val_binary_accuracy: 0.9096 - val_loss: 0.2614\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9130 - loss: 0.2529\n",
            "Fold 1 Metrics: Loss = 0.2614, Accuracy = 0.9096, AUC = 0.7947\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6341 - binary_accuracy: 0.8556 - loss: 0.5990 - val_auc: 0.7921 - val_binary_accuracy: 0.9081 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9058 - loss: 0.2726 - val_auc: 0.8011 - val_binary_accuracy: 0.9071 - val_loss: 0.2636\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9061 - loss: 0.2684 - val_auc: 0.8076 - val_binary_accuracy: 0.9081 - val_loss: 0.2601\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9073 - loss: 0.2658 - val_auc: 0.8074 - val_binary_accuracy: 0.9088 - val_loss: 0.2601\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9070 - loss: 0.2646 - val_auc: 0.7926 - val_binary_accuracy: 0.9088 - val_loss: 0.2640\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9066 - loss: 0.2638 - val_auc: 0.8001 - val_binary_accuracy: 0.9097 - val_loss: 0.2617\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7975 - binary_accuracy: 0.9074 - loss: 0.2621 - val_auc: 0.8042 - val_binary_accuracy: 0.9097 - val_loss: 0.2602\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9077 - loss: 0.2613 - val_auc: 0.7962 - val_binary_accuracy: 0.9100 - val_loss: 0.2620\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9077 - loss: 0.2617 - val_auc: 0.7965 - val_binary_accuracy: 0.9096 - val_loss: 0.2630\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9080 - loss: 0.2611 - val_auc: 0.8082 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8139 - binary_accuracy: 0.9123 - loss: 0.2519\n",
            "Fold 2 Metrics: Loss = 0.2608, Accuracy = 0.9078, AUC = 0.8082\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7358 - binary_accuracy: 0.9028 - loss: 0.2868 - val_auc: 0.7793 - val_binary_accuracy: 0.9050 - val_loss: 0.2715\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7651 - binary_accuracy: 0.9059 - loss: 0.2716 - val_auc: 0.7876 - val_binary_accuracy: 0.9065 - val_loss: 0.2706\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9080 - loss: 0.2672 - val_auc: 0.7938 - val_binary_accuracy: 0.9034 - val_loss: 0.2710\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9079 - loss: 0.2655 - val_auc: 0.7952 - val_binary_accuracy: 0.9066 - val_loss: 0.2670\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9085 - loss: 0.2657 - val_auc: 0.7968 - val_binary_accuracy: 0.9038 - val_loss: 0.2660\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9086 - loss: 0.2650 - val_auc: 0.7997 - val_binary_accuracy: 0.9056 - val_loss: 0.2631\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9088 - loss: 0.2656 - val_auc: 0.8009 - val_binary_accuracy: 0.9087 - val_loss: 0.2597\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9090 - loss: 0.2644 - val_auc: 0.8020 - val_binary_accuracy: 0.9047 - val_loss: 0.2618\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9090 - loss: 0.2648 - val_auc: 0.8026 - val_binary_accuracy: 0.9063 - val_loss: 0.2604\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9094 - loss: 0.2647 - val_auc: 0.8032 - val_binary_accuracy: 0.9094 - val_loss: 0.2573\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7966 - binary_accuracy: 0.9113 - loss: 0.2573\n",
            "Fold 3 Metrics: Loss = 0.2573, Accuracy = 0.9094, AUC = 0.8032\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6065 - binary_accuracy: 0.8294 - loss: 0.9768 - val_auc: 0.7830 - val_binary_accuracy: 0.9060 - val_loss: 0.2673\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9069 - loss: 0.2726 - val_auc: 0.7948 - val_binary_accuracy: 0.9094 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9085 - loss: 0.2673 - val_auc: 0.7999 - val_binary_accuracy: 0.9093 - val_loss: 0.2596\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9090 - loss: 0.2647 - val_auc: 0.8028 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9095 - loss: 0.2630 - val_auc: 0.8046 - val_binary_accuracy: 0.9091 - val_loss: 0.2571\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8064 - val_binary_accuracy: 0.9088 - val_loss: 0.2565\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9100 - loss: 0.2608 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2561\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9101 - loss: 0.2604 - val_auc: 0.8080 - val_binary_accuracy: 0.9078 - val_loss: 0.2560\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9098 - loss: 0.2601 - val_auc: 0.8078 - val_binary_accuracy: 0.9073 - val_loss: 0.2560\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9105 - loss: 0.2591 - val_auc: 0.8093 - val_binary_accuracy: 0.9067 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7920 - binary_accuracy: 0.9055 - loss: 0.2624\n",
            "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9067, AUC = 0.8093\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6545 - binary_accuracy: 0.8859 - loss: 0.3953 - val_auc: 0.7898 - val_binary_accuracy: 0.9073 - val_loss: 0.2651\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7587 - binary_accuracy: 0.9047 - loss: 0.2773 - val_auc: 0.7965 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7628 - binary_accuracy: 0.9048 - loss: 0.2751 - val_auc: 0.8017 - val_binary_accuracy: 0.9093 - val_loss: 0.2603\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7659 - binary_accuracy: 0.9043 - loss: 0.2730 - val_auc: 0.8038 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9056 - loss: 0.2703 - val_auc: 0.8052 - val_binary_accuracy: 0.9097 - val_loss: 0.2551\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9068 - loss: 0.2681 - val_auc: 0.8063 - val_binary_accuracy: 0.9094 - val_loss: 0.2535\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9077 - loss: 0.2662 - val_auc: 0.8072 - val_binary_accuracy: 0.9101 - val_loss: 0.2548\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9082 - loss: 0.2650 - val_auc: 0.8072 - val_binary_accuracy: 0.9066 - val_loss: 0.2581\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8079 - val_binary_accuracy: 0.9076 - val_loss: 0.2598\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.8072 - val_binary_accuracy: 0.9007 - val_loss: 0.2656\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8175 - binary_accuracy: 0.9040 - loss: 0.2620\n",
            "Fold 5 Metrics: Loss = 0.2656, Accuracy = 0.9007, AUC = 0.8072\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2602\n",
            "Average Accuracy: 0.9068\n",
            "Average AUC: 0.8045\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 3, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6956 - binary_accuracy: 0.8981 - loss: 0.3256 - val_auc: 0.7753 - val_binary_accuracy: 0.9066 - val_loss: 0.2714\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9109 - loss: 0.2643 - val_auc: 0.7793 - val_binary_accuracy: 0.9051 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9109 - loss: 0.2587 - val_auc: 0.7843 - val_binary_accuracy: 0.9053 - val_loss: 0.2744\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9102 - loss: 0.2562 - val_auc: 0.7861 - val_binary_accuracy: 0.9076 - val_loss: 0.2693\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9111 - loss: 0.2540 - val_auc: 0.7888 - val_binary_accuracy: 0.9091 - val_loss: 0.2610\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9134 - loss: 0.2522 - val_auc: 0.7873 - val_binary_accuracy: 0.9088 - val_loss: 0.2628\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9128 - loss: 0.2523 - val_auc: 0.7875 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9132 - loss: 0.2509 - val_auc: 0.7874 - val_binary_accuracy: 0.9081 - val_loss: 0.2658\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9125 - loss: 0.2510 - val_auc: 0.7905 - val_binary_accuracy: 0.9078 - val_loss: 0.2643\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9126 - loss: 0.2500 - val_auc: 0.7934 - val_binary_accuracy: 0.9087 - val_loss: 0.2630\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7922 - binary_accuracy: 0.9116 - loss: 0.2540\n",
            "Fold 1 Metrics: Loss = 0.2630, Accuracy = 0.9087, AUC = 0.7934\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6361 - binary_accuracy: 0.8670 - loss: 0.5392 - val_auc: 0.7902 - val_binary_accuracy: 0.9072 - val_loss: 0.2664\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9043 - loss: 0.2703 - val_auc: 0.7981 - val_binary_accuracy: 0.9079 - val_loss: 0.2626\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9057 - loss: 0.2677 - val_auc: 0.8008 - val_binary_accuracy: 0.9084 - val_loss: 0.2616\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9062 - loss: 0.2668 - val_auc: 0.7989 - val_binary_accuracy: 0.9099 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9065 - loss: 0.2667 - val_auc: 0.8062 - val_binary_accuracy: 0.9097 - val_loss: 0.2585\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9079 - loss: 0.2630 - val_auc: 0.8099 - val_binary_accuracy: 0.9097 - val_loss: 0.2600\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9078 - loss: 0.2615 - val_auc: 0.8086 - val_binary_accuracy: 0.9085 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9077 - loss: 0.2622 - val_auc: 0.8068 - val_binary_accuracy: 0.9099 - val_loss: 0.2579\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9086 - loss: 0.2605 - val_auc: 0.7886 - val_binary_accuracy: 0.9085 - val_loss: 0.2636\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9079 - loss: 0.2608 - val_auc: 0.8095 - val_binary_accuracy: 0.9084 - val_loss: 0.2578\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9133 - loss: 0.2487\n",
            "Fold 2 Metrics: Loss = 0.2578, Accuracy = 0.9084, AUC = 0.8095\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5923 - binary_accuracy: 0.8422 - loss: 1.5019 - val_auc: 0.7845 - val_binary_accuracy: 0.9094 - val_loss: 0.2713\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9060 - loss: 0.2708 - val_auc: 0.7917 - val_binary_accuracy: 0.9102 - val_loss: 0.2628\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9057 - loss: 0.2703 - val_auc: 0.7971 - val_binary_accuracy: 0.9103 - val_loss: 0.2601\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9060 - loss: 0.2695 - val_auc: 0.7996 - val_binary_accuracy: 0.9106 - val_loss: 0.2588\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9062 - loss: 0.2684 - val_auc: 0.8010 - val_binary_accuracy: 0.9107 - val_loss: 0.2581\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9062 - loss: 0.2660 - val_auc: 0.8041 - val_binary_accuracy: 0.9104 - val_loss: 0.2568\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9076 - loss: 0.2639 - val_auc: 0.8044 - val_binary_accuracy: 0.9107 - val_loss: 0.2583\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9084 - loss: 0.2621 - val_auc: 0.8048 - val_binary_accuracy: 0.9100 - val_loss: 0.2609\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.8040 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9087 - loss: 0.2611 - val_auc: 0.8040 - val_binary_accuracy: 0.9071 - val_loss: 0.2631\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7953 - binary_accuracy: 0.9070 - loss: 0.2647\n",
            "Fold 3 Metrics: Loss = 0.2631, Accuracy = 0.9071, AUC = 0.8040\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6367 - binary_accuracy: 0.8423 - loss: 0.8825 - val_auc: 0.7859 - val_binary_accuracy: 0.9056 - val_loss: 0.2670\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9066 - loss: 0.2724 - val_auc: 0.7916 - val_binary_accuracy: 0.9063 - val_loss: 0.2652\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9070 - loss: 0.2686 - val_auc: 0.7988 - val_binary_accuracy: 0.9063 - val_loss: 0.2617\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9069 - loss: 0.2664 - val_auc: 0.8009 - val_binary_accuracy: 0.9079 - val_loss: 0.2597\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9078 - loss: 0.2651 - val_auc: 0.8030 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9088 - loss: 0.2630 - val_auc: 0.8057 - val_binary_accuracy: 0.9067 - val_loss: 0.2583\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9096 - loss: 0.2612 - val_auc: 0.8065 - val_binary_accuracy: 0.9060 - val_loss: 0.2581\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9094 - loss: 0.2607 - val_auc: 0.8071 - val_binary_accuracy: 0.9054 - val_loss: 0.2576\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9095 - loss: 0.2596 - val_auc: 0.8063 - val_binary_accuracy: 0.9029 - val_loss: 0.2584\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9096 - loss: 0.2590 - val_auc: 0.8078 - val_binary_accuracy: 0.9045 - val_loss: 0.2571\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7888 - binary_accuracy: 0.9034 - loss: 0.2643\n",
            "Fold 4 Metrics: Loss = 0.2571, Accuracy = 0.9045, AUC = 0.8078\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6077 - binary_accuracy: 0.8418 - loss: 1.1925 - val_auc: 0.7915 - val_binary_accuracy: 0.9060 - val_loss: 0.2669\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9026 - loss: 0.2794 - val_auc: 0.7980 - val_binary_accuracy: 0.9013 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7592 - binary_accuracy: 0.9033 - loss: 0.2775 - val_auc: 0.8011 - val_binary_accuracy: 0.9022 - val_loss: 0.2667\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9039 - loss: 0.2756 - val_auc: 0.8030 - val_binary_accuracy: 0.9059 - val_loss: 0.2590\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9045 - loss: 0.2732 - val_auc: 0.8042 - val_binary_accuracy: 0.9073 - val_loss: 0.2569\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9055 - loss: 0.2711 - val_auc: 0.8046 - val_binary_accuracy: 0.9095 - val_loss: 0.2549\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9066 - loss: 0.2716 - val_auc: 0.8053 - val_binary_accuracy: 0.9082 - val_loss: 0.2546\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9071 - loss: 0.2672 - val_auc: 0.8060 - val_binary_accuracy: 0.9079 - val_loss: 0.2548\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9076 - loss: 0.2658 - val_auc: 0.8058 - val_binary_accuracy: 0.9101 - val_loss: 0.2537\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9083 - loss: 0.2641 - val_auc: 0.8068 - val_binary_accuracy: 0.9091 - val_loss: 0.2604\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9103 - loss: 0.2588\n",
            "Fold 5 Metrics: Loss = 0.2604, Accuracy = 0.9091, AUC = 0.8068\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2603\n",
            "Average Accuracy: 0.9075\n",
            "Average AUC: 0.8043\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 3, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6620 - binary_accuracy: 0.8833 - loss: 0.4496 - val_auc: 0.7799 - val_binary_accuracy: 0.9063 - val_loss: 0.2659\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9081 - loss: 0.2658 - val_auc: 0.7848 - val_binary_accuracy: 0.9094 - val_loss: 0.2648\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9113 - loss: 0.2585 - val_auc: 0.7904 - val_binary_accuracy: 0.9099 - val_loss: 0.2627\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9116 - loss: 0.2551 - val_auc: 0.7899 - val_binary_accuracy: 0.9099 - val_loss: 0.2674\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9122 - loss: 0.2547 - val_auc: 0.7905 - val_binary_accuracy: 0.9116 - val_loss: 0.2607\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9130 - loss: 0.2520 - val_auc: 0.7956 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9134 - loss: 0.2508 - val_auc: 0.7931 - val_binary_accuracy: 0.9091 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9132 - loss: 0.2502 - val_auc: 0.7965 - val_binary_accuracy: 0.9094 - val_loss: 0.2582\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9127 - loss: 0.2493 - val_auc: 0.7941 - val_binary_accuracy: 0.9084 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9126 - loss: 0.2507 - val_auc: 0.7925 - val_binary_accuracy: 0.9078 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2541\n",
            "Fold 1 Metrics: Loss = 0.2635, Accuracy = 0.9078, AUC = 0.7925\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6600 - binary_accuracy: 0.8773 - loss: 0.4980 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7620 - binary_accuracy: 0.9007 - loss: 0.2799 - val_auc: 0.8084 - val_binary_accuracy: 0.9075 - val_loss: 0.2741\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9035 - loss: 0.2776 - val_auc: 0.8099 - val_binary_accuracy: 0.9087 - val_loss: 0.2728\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9048 - loss: 0.2731 - val_auc: 0.8094 - val_binary_accuracy: 0.9090 - val_loss: 0.2603\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9072 - loss: 0.2662 - val_auc: 0.8081 - val_binary_accuracy: 0.9085 - val_loss: 0.2601\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9079 - loss: 0.2648 - val_auc: 0.8067 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9073 - loss: 0.2640 - val_auc: 0.8100 - val_binary_accuracy: 0.9093 - val_loss: 0.2604\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9082 - loss: 0.2621 - val_auc: 0.8084 - val_binary_accuracy: 0.9088 - val_loss: 0.2623\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9086 - loss: 0.2616 - val_auc: 0.8096 - val_binary_accuracy: 0.9091 - val_loss: 0.2619\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9087 - loss: 0.2606 - val_auc: 0.8117 - val_binary_accuracy: 0.9094 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9136 - loss: 0.2495\n",
            "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9094, AUC = 0.8117\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6791 - binary_accuracy: 0.8861 - loss: 0.3834 - val_auc: 0.7818 - val_binary_accuracy: 0.9048 - val_loss: 0.2699\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7358 - binary_accuracy: 0.9021 - loss: 0.2882 - val_auc: 0.7873 - val_binary_accuracy: 0.9094 - val_loss: 0.2638\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9046 - loss: 0.2724 - val_auc: 0.7951 - val_binary_accuracy: 0.9096 - val_loss: 0.2608\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9066 - loss: 0.2682 - val_auc: 0.7976 - val_binary_accuracy: 0.9082 - val_loss: 0.2660\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9086 - loss: 0.2634 - val_auc: 0.7979 - val_binary_accuracy: 0.9106 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9092 - loss: 0.2634 - val_auc: 0.7986 - val_binary_accuracy: 0.9090 - val_loss: 0.2644\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9092 - loss: 0.2627 - val_auc: 0.8002 - val_binary_accuracy: 0.9096 - val_loss: 0.2616\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8004 - val_binary_accuracy: 0.9109 - val_loss: 0.2614\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9106 - loss: 0.2622 - val_auc: 0.8011 - val_binary_accuracy: 0.9112 - val_loss: 0.2604\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9095 - loss: 0.2622 - val_auc: 0.8030 - val_binary_accuracy: 0.9112 - val_loss: 0.2607\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7959 - binary_accuracy: 0.9136 - loss: 0.2612\n",
            "Fold 3 Metrics: Loss = 0.2607, Accuracy = 0.9112, AUC = 0.8030\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6388 - binary_accuracy: 0.8631 - loss: 0.8942 - val_auc: 0.7867 - val_binary_accuracy: 0.9048 - val_loss: 0.2682\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9056 - loss: 0.2752 - val_auc: 0.7949 - val_binary_accuracy: 0.9082 - val_loss: 0.2619\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9076 - loss: 0.2698 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2594\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9079 - loss: 0.2675 - val_auc: 0.8062 - val_binary_accuracy: 0.9093 - val_loss: 0.2566\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9082 - loss: 0.2656 - val_auc: 0.8061 - val_binary_accuracy: 0.9094 - val_loss: 0.2567\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9089 - loss: 0.2627 - val_auc: 0.8084 - val_binary_accuracy: 0.9094 - val_loss: 0.2554\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9092 - loss: 0.2613 - val_auc: 0.8066 - val_binary_accuracy: 0.9081 - val_loss: 0.2564\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9097 - loss: 0.2597 - val_auc: 0.8074 - val_binary_accuracy: 0.9087 - val_loss: 0.2563\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9098 - loss: 0.2596 - val_auc: 0.8103 - val_binary_accuracy: 0.9082 - val_loss: 0.2549\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9098 - loss: 0.2587 - val_auc: 0.8091 - val_binary_accuracy: 0.9084 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7912 - binary_accuracy: 0.9070 - loss: 0.2622\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9084, AUC = 0.8091\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6449 - binary_accuracy: 0.8789 - loss: 0.6324 - val_auc: 0.7935 - val_binary_accuracy: 0.8997 - val_loss: 0.2774\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7408 - binary_accuracy: 0.9024 - loss: 0.2866 - val_auc: 0.7989 - val_binary_accuracy: 0.8995 - val_loss: 0.2754\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9037 - loss: 0.2780 - val_auc: 0.8015 - val_binary_accuracy: 0.8991 - val_loss: 0.2727\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9040 - loss: 0.2746 - val_auc: 0.8044 - val_binary_accuracy: 0.9035 - val_loss: 0.2653\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9039 - loss: 0.2743 - val_auc: 0.8053 - val_binary_accuracy: 0.9091 - val_loss: 0.2541\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9058 - loss: 0.2716 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2536\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9079 - loss: 0.2663 - val_auc: 0.8048 - val_binary_accuracy: 0.9078 - val_loss: 0.2582\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9072 - loss: 0.2669 - val_auc: 0.8068 - val_binary_accuracy: 0.9066 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9074 - loss: 0.2647 - val_auc: 0.8064 - val_binary_accuracy: 0.9059 - val_loss: 0.2610\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9076 - loss: 0.2646 - val_auc: 0.8082 - val_binary_accuracy: 0.9073 - val_loss: 0.2601\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8170 - binary_accuracy: 0.9088 - loss: 0.2586\n",
            "Fold 5 Metrics: Loss = 0.2601, Accuracy = 0.9073, AUC = 0.8082\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2596\n",
            "Average Accuracy: 0.9088\n",
            "Average AUC: 0.8049\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 3, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6388 - binary_accuracy: 0.8800 - loss: 0.6860 - val_auc: 0.7757 - val_binary_accuracy: 0.9048 - val_loss: 0.2865\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9083 - loss: 0.2669 - val_auc: 0.7827 - val_binary_accuracy: 0.9106 - val_loss: 0.2686\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9112 - loss: 0.2575 - val_auc: 0.7874 - val_binary_accuracy: 0.9103 - val_loss: 0.2672\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9115 - loss: 0.2548 - val_auc: 0.7905 - val_binary_accuracy: 0.9100 - val_loss: 0.2609\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9129 - loss: 0.2533 - val_auc: 0.7899 - val_binary_accuracy: 0.9112 - val_loss: 0.2639\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9118 - loss: 0.2521 - val_auc: 0.7929 - val_binary_accuracy: 0.9100 - val_loss: 0.2595\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9128 - loss: 0.2509 - val_auc: 0.7960 - val_binary_accuracy: 0.9084 - val_loss: 0.2597\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9123 - loss: 0.2501 - val_auc: 0.7964 - val_binary_accuracy: 0.9071 - val_loss: 0.2621\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9127 - loss: 0.2490 - val_auc: 0.7963 - val_binary_accuracy: 0.9072 - val_loss: 0.2632\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8086 - binary_accuracy: 0.9128 - loss: 0.2486 - val_auc: 0.7955 - val_binary_accuracy: 0.9076 - val_loss: 0.2637\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7939 - binary_accuracy: 0.9108 - loss: 0.2548\n",
            "Fold 1 Metrics: Loss = 0.2637, Accuracy = 0.9076, AUC = 0.7955\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6477 - binary_accuracy: 0.8743 - loss: 0.6347 - val_auc: 0.8025 - val_binary_accuracy: 0.9075 - val_loss: 0.2917\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9032 - loss: 0.2789 - val_auc: 0.8055 - val_binary_accuracy: 0.9063 - val_loss: 0.2628\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9052 - loss: 0.2677 - val_auc: 0.8072 - val_binary_accuracy: 0.9084 - val_loss: 0.2620\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9069 - loss: 0.2647 - val_auc: 0.7967 - val_binary_accuracy: 0.9073 - val_loss: 0.2640\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9070 - loss: 0.2656 - val_auc: 0.8046 - val_binary_accuracy: 0.9084 - val_loss: 0.2632\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.8033 - val_binary_accuracy: 0.9096 - val_loss: 0.2651\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8108 - val_binary_accuracy: 0.9093 - val_loss: 0.2593\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9081 - loss: 0.2610 - val_auc: 0.8091 - val_binary_accuracy: 0.9082 - val_loss: 0.2620\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9084 - loss: 0.2606 - val_auc: 0.8068 - val_binary_accuracy: 0.9100 - val_loss: 0.2622\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9091 - loss: 0.2605 - val_auc: 0.8080 - val_binary_accuracy: 0.9094 - val_loss: 0.2625\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9132 - loss: 0.2537\n",
            "Fold 2 Metrics: Loss = 0.2625, Accuracy = 0.9094, AUC = 0.8080\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6304 - binary_accuracy: 0.8858 - loss: 0.5479 - val_auc: 0.7825 - val_binary_accuracy: 0.9045 - val_loss: 0.2745\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9056 - loss: 0.2742 - val_auc: 0.7914 - val_binary_accuracy: 0.9096 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9059 - loss: 0.2710 - val_auc: 0.7938 - val_binary_accuracy: 0.9094 - val_loss: 0.2681\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9089 - loss: 0.2652 - val_auc: 0.7984 - val_binary_accuracy: 0.9099 - val_loss: 0.2606\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9084 - loss: 0.2637 - val_auc: 0.8018 - val_binary_accuracy: 0.9106 - val_loss: 0.2602\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9081 - loss: 0.2631 - val_auc: 0.8028 - val_binary_accuracy: 0.9104 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9091 - loss: 0.2626 - val_auc: 0.8040 - val_binary_accuracy: 0.9115 - val_loss: 0.2586\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8036 - val_binary_accuracy: 0.9113 - val_loss: 0.2588\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9094 - loss: 0.2616 - val_auc: 0.8056 - val_binary_accuracy: 0.9112 - val_loss: 0.2570\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9092 - loss: 0.2620 - val_auc: 0.8072 - val_binary_accuracy: 0.9113 - val_loss: 0.2564\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7995 - binary_accuracy: 0.9131 - loss: 0.2569\n",
            "Fold 3 Metrics: Loss = 0.2564, Accuracy = 0.9113, AUC = 0.8072\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6582 - binary_accuracy: 0.8837 - loss: 0.4978 - val_auc: 0.7885 - val_binary_accuracy: 0.9063 - val_loss: 0.2651\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7616 - binary_accuracy: 0.9074 - loss: 0.2732 - val_auc: 0.7977 - val_binary_accuracy: 0.9084 - val_loss: 0.2606\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9080 - loss: 0.2676 - val_auc: 0.7999 - val_binary_accuracy: 0.9063 - val_loss: 0.2605\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.8037 - val_binary_accuracy: 0.9073 - val_loss: 0.2583\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9086 - loss: 0.2626 - val_auc: 0.8056 - val_binary_accuracy: 0.9053 - val_loss: 0.2606\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8077 - val_binary_accuracy: 0.9073 - val_loss: 0.2570\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9099 - loss: 0.2607 - val_auc: 0.8077 - val_binary_accuracy: 0.9072 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9097 - loss: 0.2600 - val_auc: 0.8090 - val_binary_accuracy: 0.9095 - val_loss: 0.2550\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9100 - loss: 0.2594 - val_auc: 0.8111 - val_binary_accuracy: 0.9066 - val_loss: 0.2576\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9105 - loss: 0.2590 - val_auc: 0.8121 - val_binary_accuracy: 0.9094 - val_loss: 0.2541\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9083 - loss: 0.2626\n",
            "Fold 4 Metrics: Loss = 0.2541, Accuracy = 0.9094, AUC = 0.8121\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6539 - binary_accuracy: 0.8786 - loss: 0.5847 - val_auc: 0.7943 - val_binary_accuracy: 0.8989 - val_loss: 0.2791\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7515 - binary_accuracy: 0.9014 - loss: 0.2809 - val_auc: 0.7996 - val_binary_accuracy: 0.9003 - val_loss: 0.2678\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7562 - binary_accuracy: 0.9038 - loss: 0.2776 - val_auc: 0.8028 - val_binary_accuracy: 0.9098 - val_loss: 0.2559\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9069 - loss: 0.2694 - val_auc: 0.8029 - val_binary_accuracy: 0.9072 - val_loss: 0.2561\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9055 - loss: 0.2693 - val_auc: 0.8059 - val_binary_accuracy: 0.9064 - val_loss: 0.2601\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.8060 - val_binary_accuracy: 0.9064 - val_loss: 0.2627\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9074 - loss: 0.2652 - val_auc: 0.8074 - val_binary_accuracy: 0.9098 - val_loss: 0.2635\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9087 - loss: 0.2641 - val_auc: 0.8080 - val_binary_accuracy: 0.9107 - val_loss: 0.2613\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9091 - loss: 0.2633 - val_auc: 0.8089 - val_binary_accuracy: 0.9107 - val_loss: 0.2611\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8096 - val_binary_accuracy: 0.9119 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8174 - binary_accuracy: 0.9104 - loss: 0.2589\n",
            "Fold 5 Metrics: Loss = 0.2599, Accuracy = 0.9119, AUC = 0.8096\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2593\n",
            "Average Accuracy: 0.9099\n",
            "Average AUC: 0.8065\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 4, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6384 - binary_accuracy: 0.7253 - loss: 0.6739 - val_auc: 0.7654 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9078 - loss: 0.2624 - val_auc: 0.7704 - val_binary_accuracy: 0.9071 - val_loss: 0.2705\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9102 - loss: 0.2583 - val_auc: 0.7766 - val_binary_accuracy: 0.9076 - val_loss: 0.2668\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9113 - loss: 0.2560 - val_auc: 0.7785 - val_binary_accuracy: 0.9082 - val_loss: 0.2660\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9109 - loss: 0.2554 - val_auc: 0.7813 - val_binary_accuracy: 0.9088 - val_loss: 0.2646\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9116 - loss: 0.2536 - val_auc: 0.7830 - val_binary_accuracy: 0.9084 - val_loss: 0.2646\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9120 - loss: 0.2528 - val_auc: 0.7833 - val_binary_accuracy: 0.9084 - val_loss: 0.2649\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9120 - loss: 0.2531 - val_auc: 0.7844 - val_binary_accuracy: 0.9088 - val_loss: 0.2636\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9117 - loss: 0.2523 - val_auc: 0.7862 - val_binary_accuracy: 0.9088 - val_loss: 0.2633\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8023 - binary_accuracy: 0.9122 - loss: 0.2519 - val_auc: 0.7858 - val_binary_accuracy: 0.9084 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7829 - binary_accuracy: 0.9113 - loss: 0.2570\n",
            "Fold 1 Metrics: Loss = 0.2635, Accuracy = 0.9084, AUC = 0.7858\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7086 - binary_accuracy: 0.9021 - loss: 0.2949 - val_auc: 0.7871 - val_binary_accuracy: 0.9037 - val_loss: 0.2693\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9035 - loss: 0.2758 - val_auc: 0.7947 - val_binary_accuracy: 0.9045 - val_loss: 0.2644\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9039 - loss: 0.2725 - val_auc: 0.7982 - val_binary_accuracy: 0.9071 - val_loss: 0.2615\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9041 - loss: 0.2703 - val_auc: 0.7994 - val_binary_accuracy: 0.9069 - val_loss: 0.2612\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9053 - loss: 0.2685 - val_auc: 0.8018 - val_binary_accuracy: 0.9068 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9066 - loss: 0.2672 - val_auc: 0.8031 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9077 - loss: 0.2657 - val_auc: 0.8058 - val_binary_accuracy: 0.9081 - val_loss: 0.2574\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9080 - loss: 0.2645 - val_auc: 0.8058 - val_binary_accuracy: 0.9072 - val_loss: 0.2594\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9084 - loss: 0.2639 - val_auc: 0.8076 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9077 - loss: 0.2627 - val_auc: 0.8092 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8094 - binary_accuracy: 0.9120 - loss: 0.2474\n",
            "Fold 2 Metrics: Loss = 0.2549, Accuracy = 0.9091, AUC = 0.8092\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5823 - binary_accuracy: 0.8480 - loss: 0.3761 - val_auc: 0.7783 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7558 - binary_accuracy: 0.9051 - loss: 0.2762 - val_auc: 0.7873 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9054 - loss: 0.2711 - val_auc: 0.7906 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9059 - loss: 0.2684 - val_auc: 0.7936 - val_binary_accuracy: 0.9048 - val_loss: 0.2640\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9069 - loss: 0.2670 - val_auc: 0.7955 - val_binary_accuracy: 0.9071 - val_loss: 0.2631\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9076 - loss: 0.2658 - val_auc: 0.7965 - val_binary_accuracy: 0.9090 - val_loss: 0.2616\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9077 - loss: 0.2651 - val_auc: 0.7986 - val_binary_accuracy: 0.9090 - val_loss: 0.2609\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.8005 - val_binary_accuracy: 0.9096 - val_loss: 0.2598\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9089 - loss: 0.2628 - val_auc: 0.8015 - val_binary_accuracy: 0.9093 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9090 - loss: 0.2623 - val_auc: 0.8019 - val_binary_accuracy: 0.9100 - val_loss: 0.2583\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7959 - binary_accuracy: 0.9112 - loss: 0.2586\n",
            "Fold 3 Metrics: Loss = 0.2583, Accuracy = 0.9100, AUC = 0.8019\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5424 - binary_accuracy: 0.7829 - loss: 2.5380 - val_auc: 0.7417 - val_binary_accuracy: 0.9042 - val_loss: 0.2835\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7403 - binary_accuracy: 0.9047 - loss: 0.2825 - val_auc: 0.7766 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7654 - binary_accuracy: 0.9051 - loss: 0.2741 - val_auc: 0.7845 - val_binary_accuracy: 0.9060 - val_loss: 0.2684\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9057 - loss: 0.2713 - val_auc: 0.7886 - val_binary_accuracy: 0.9057 - val_loss: 0.2669\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9066 - loss: 0.2691 - val_auc: 0.7914 - val_binary_accuracy: 0.9067 - val_loss: 0.2646\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9073 - loss: 0.2670 - val_auc: 0.7940 - val_binary_accuracy: 0.9072 - val_loss: 0.2627\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9083 - loss: 0.2652 - val_auc: 0.7963 - val_binary_accuracy: 0.9078 - val_loss: 0.2610\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9085 - loss: 0.2642 - val_auc: 0.7988 - val_binary_accuracy: 0.9079 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.7999 - val_binary_accuracy: 0.9078 - val_loss: 0.2587\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.8012 - val_binary_accuracy: 0.9084 - val_loss: 0.2582\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7816 - binary_accuracy: 0.9074 - loss: 0.2649\n",
            "Fold 4 Metrics: Loss = 0.2582, Accuracy = 0.9084, AUC = 0.8012\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6275 - binary_accuracy: 0.7391 - loss: 0.8155 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9040 - loss: 0.2751 - val_auc: 0.7884 - val_binary_accuracy: 0.9047 - val_loss: 0.2655\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9050 - loss: 0.2705 - val_auc: 0.7919 - val_binary_accuracy: 0.9054 - val_loss: 0.2642\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9060 - loss: 0.2683 - val_auc: 0.7948 - val_binary_accuracy: 0.9064 - val_loss: 0.2613\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9070 - loss: 0.2670 - val_auc: 0.7955 - val_binary_accuracy: 0.9059 - val_loss: 0.2607\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9073 - loss: 0.2658 - val_auc: 0.7986 - val_binary_accuracy: 0.9062 - val_loss: 0.2584\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9080 - loss: 0.2647 - val_auc: 0.8002 - val_binary_accuracy: 0.9082 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9081 - loss: 0.2642 - val_auc: 0.8006 - val_binary_accuracy: 0.9098 - val_loss: 0.2568\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9085 - loss: 0.2635 - val_auc: 0.8030 - val_binary_accuracy: 0.9095 - val_loss: 0.2563\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9092 - loss: 0.2628 - val_auc: 0.8030 - val_binary_accuracy: 0.9101 - val_loss: 0.2553\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9084 - loss: 0.2544\n",
            "Fold 5 Metrics: Loss = 0.2553, Accuracy = 0.9101, AUC = 0.8030\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2580\n",
            "Average Accuracy: 0.9092\n",
            "Average AUC: 0.8002\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 4, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6757 - binary_accuracy: 0.8468 - loss: 0.5495 - val_auc: 0.7643 - val_binary_accuracy: 0.9044 - val_loss: 0.2779\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9066 - loss: 0.2666 - val_auc: 0.7750 - val_binary_accuracy: 0.9047 - val_loss: 0.2712\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9079 - loss: 0.2623 - val_auc: 0.7807 - val_binary_accuracy: 0.9056 - val_loss: 0.2686\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9093 - loss: 0.2587 - val_auc: 0.7848 - val_binary_accuracy: 0.9059 - val_loss: 0.2674\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9096 - loss: 0.2566 - val_auc: 0.7860 - val_binary_accuracy: 0.9066 - val_loss: 0.2668\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9096 - loss: 0.2544 - val_auc: 0.7871 - val_binary_accuracy: 0.9069 - val_loss: 0.2668\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8017 - binary_accuracy: 0.9107 - loss: 0.2529 - val_auc: 0.7890 - val_binary_accuracy: 0.9068 - val_loss: 0.2661\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9107 - loss: 0.2526 - val_auc: 0.7918 - val_binary_accuracy: 0.9075 - val_loss: 0.2652\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9111 - loss: 0.2512 - val_auc: 0.7935 - val_binary_accuracy: 0.9079 - val_loss: 0.2638\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8081 - binary_accuracy: 0.9116 - loss: 0.2500 - val_auc: 0.7935 - val_binary_accuracy: 0.9085 - val_loss: 0.2631\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9120 - loss: 0.2536\n",
            "Fold 1 Metrics: Loss = 0.2631, Accuracy = 0.9085, AUC = 0.7935\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6902 - binary_accuracy: 0.8972 - loss: 0.3136 - val_auc: 0.7918 - val_binary_accuracy: 0.9079 - val_loss: 0.2654\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9049 - loss: 0.2730 - val_auc: 0.7993 - val_binary_accuracy: 0.9096 - val_loss: 0.2639\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9067 - loss: 0.2697 - val_auc: 0.8037 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9065 - loss: 0.2693 - val_auc: 0.8056 - val_binary_accuracy: 0.9106 - val_loss: 0.2598\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9073 - loss: 0.2667 - val_auc: 0.8046 - val_binary_accuracy: 0.9072 - val_loss: 0.2676\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9075 - loss: 0.2645 - val_auc: 0.8046 - val_binary_accuracy: 0.9073 - val_loss: 0.2627\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9075 - loss: 0.2636 - val_auc: 0.8023 - val_binary_accuracy: 0.9090 - val_loss: 0.2621\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9084 - loss: 0.2623 - val_auc: 0.8102 - val_binary_accuracy: 0.9102 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8023 - val_binary_accuracy: 0.9090 - val_loss: 0.2625\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9083 - loss: 0.2611 - val_auc: 0.8094 - val_binary_accuracy: 0.9087 - val_loss: 0.2577\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.9118 - loss: 0.2485\n",
            "Fold 2 Metrics: Loss = 0.2577, Accuracy = 0.9087, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6536 - binary_accuracy: 0.8522 - loss: 0.7490 - val_auc: 0.7771 - val_binary_accuracy: 0.9056 - val_loss: 0.2699\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7580 - binary_accuracy: 0.9071 - loss: 0.2740 - val_auc: 0.7829 - val_binary_accuracy: 0.9075 - val_loss: 0.2692\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7664 - binary_accuracy: 0.9071 - loss: 0.2707 - val_auc: 0.7879 - val_binary_accuracy: 0.9084 - val_loss: 0.2675\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9067 - loss: 0.2691 - val_auc: 0.7899 - val_binary_accuracy: 0.9087 - val_loss: 0.2670\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.7923 - val_binary_accuracy: 0.9059 - val_loss: 0.2672\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9075 - loss: 0.2664 - val_auc: 0.7951 - val_binary_accuracy: 0.9097 - val_loss: 0.2641\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9078 - loss: 0.2666 - val_auc: 0.7944 - val_binary_accuracy: 0.9103 - val_loss: 0.2628\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9081 - loss: 0.2658 - val_auc: 0.7962 - val_binary_accuracy: 0.9079 - val_loss: 0.2634\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9081 - loss: 0.2657 - val_auc: 0.7973 - val_binary_accuracy: 0.9099 - val_loss: 0.2622\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9082 - loss: 0.2648 - val_auc: 0.7984 - val_binary_accuracy: 0.9102 - val_loss: 0.2601\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7943 - binary_accuracy: 0.9107 - loss: 0.2599\n",
            "Fold 3 Metrics: Loss = 0.2601, Accuracy = 0.9102, AUC = 0.7984\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - auc: 0.6610 - binary_accuracy: 0.9044 - loss: 0.3356 - val_auc: 0.7807 - val_binary_accuracy: 0.9048 - val_loss: 0.2690\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9063 - loss: 0.2737 - val_auc: 0.7888 - val_binary_accuracy: 0.9070 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9070 - loss: 0.2696 - val_auc: 0.7962 - val_binary_accuracy: 0.9053 - val_loss: 0.2630\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9063 - loss: 0.2666 - val_auc: 0.7984 - val_binary_accuracy: 0.9023 - val_loss: 0.2622\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2643 - val_auc: 0.8011 - val_binary_accuracy: 0.9062 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9076 - loss: 0.2632 - val_auc: 0.8021 - val_binary_accuracy: 0.9035 - val_loss: 0.2602\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9086 - loss: 0.2624 - val_auc: 0.8032 - val_binary_accuracy: 0.9032 - val_loss: 0.2599\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.8072 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9094 - loss: 0.2603 - val_auc: 0.8086 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8094 - val_binary_accuracy: 0.9090 - val_loss: 0.2546\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7896 - binary_accuracy: 0.9082 - loss: 0.2620\n",
            "Fold 4 Metrics: Loss = 0.2546, Accuracy = 0.9090, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5903 - binary_accuracy: 0.8426 - loss: 0.8164 - val_auc: 0.7801 - val_binary_accuracy: 0.9066 - val_loss: 0.2782\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7524 - binary_accuracy: 0.9046 - loss: 0.2796 - val_auc: 0.7909 - val_binary_accuracy: 0.9069 - val_loss: 0.2708\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9046 - loss: 0.2746 - val_auc: 0.7965 - val_binary_accuracy: 0.9073 - val_loss: 0.2656\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9044 - loss: 0.2720 - val_auc: 0.8004 - val_binary_accuracy: 0.9069 - val_loss: 0.2650\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9039 - loss: 0.2702 - val_auc: 0.8023 - val_binary_accuracy: 0.9059 - val_loss: 0.2651\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9054 - loss: 0.2685 - val_auc: 0.8046 - val_binary_accuracy: 0.9066 - val_loss: 0.2666\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9065 - loss: 0.2671 - val_auc: 0.8059 - val_binary_accuracy: 0.9075 - val_loss: 0.2641\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9071 - loss: 0.2656 - val_auc: 0.8055 - val_binary_accuracy: 0.9053 - val_loss: 0.2659\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.8081 - val_binary_accuracy: 0.9063 - val_loss: 0.2657\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8076 - val_binary_accuracy: 0.9066 - val_loss: 0.2638\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9092 - loss: 0.2615\n",
            "Fold 5 Metrics: Loss = 0.2638, Accuracy = 0.9066, AUC = 0.8076\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2599\n",
            "Average Accuracy: 0.9086\n",
            "Average AUC: 0.8037\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 4, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6601 - binary_accuracy: 0.8901 - loss: 0.3777 - val_auc: 0.7766 - val_binary_accuracy: 0.9072 - val_loss: 0.2873\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9085 - loss: 0.2657 - val_auc: 0.7797 - val_binary_accuracy: 0.9054 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9094 - loss: 0.2584 - val_auc: 0.7858 - val_binary_accuracy: 0.9071 - val_loss: 0.2628\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9100 - loss: 0.2566 - val_auc: 0.7885 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9112 - loss: 0.2537 - val_auc: 0.7880 - val_binary_accuracy: 0.9073 - val_loss: 0.2634\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9117 - loss: 0.2526 - val_auc: 0.7910 - val_binary_accuracy: 0.9082 - val_loss: 0.2622\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9122 - loss: 0.2506 - val_auc: 0.7872 - val_binary_accuracy: 0.9066 - val_loss: 0.2642\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9123 - loss: 0.2502 - val_auc: 0.7878 - val_binary_accuracy: 0.9082 - val_loss: 0.2619\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9120 - loss: 0.2493 - val_auc: 0.7917 - val_binary_accuracy: 0.9076 - val_loss: 0.2609\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9129 - loss: 0.2482 - val_auc: 0.7920 - val_binary_accuracy: 0.9079 - val_loss: 0.2604\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7921 - binary_accuracy: 0.9108 - loss: 0.2517\n",
            "Fold 1 Metrics: Loss = 0.2604, Accuracy = 0.9079, AUC = 0.7920\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6860 - binary_accuracy: 0.8952 - loss: 0.3456 - val_auc: 0.7974 - val_binary_accuracy: 0.9045 - val_loss: 0.2650\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9038 - loss: 0.2723 - val_auc: 0.7958 - val_binary_accuracy: 0.9047 - val_loss: 0.2685\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9048 - loss: 0.2687 - val_auc: 0.8071 - val_binary_accuracy: 0.9065 - val_loss: 0.2631\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9066 - loss: 0.2662 - val_auc: 0.8038 - val_binary_accuracy: 0.9069 - val_loss: 0.2612\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9052 - loss: 0.2657 - val_auc: 0.8051 - val_binary_accuracy: 0.9087 - val_loss: 0.2634\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9080 - loss: 0.2622 - val_auc: 0.8095 - val_binary_accuracy: 0.9091 - val_loss: 0.2595\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9083 - loss: 0.2616 - val_auc: 0.8078 - val_binary_accuracy: 0.9085 - val_loss: 0.2598\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9082 - loss: 0.2610 - val_auc: 0.8081 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9082 - loss: 0.2608 - val_auc: 0.8132 - val_binary_accuracy: 0.9088 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9089 - loss: 0.2603 - val_auc: 0.8115 - val_binary_accuracy: 0.9093 - val_loss: 0.2583\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9126 - loss: 0.2503\n",
            "Fold 2 Metrics: Loss = 0.2583, Accuracy = 0.9093, AUC = 0.8115\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6137 - binary_accuracy: 0.8627 - loss: 0.8741 - val_auc: 0.7711 - val_binary_accuracy: 0.9042 - val_loss: 0.2741\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7423 - binary_accuracy: 0.9036 - loss: 0.2834 - val_auc: 0.7781 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9035 - loss: 0.2775 - val_auc: 0.7866 - val_binary_accuracy: 0.9069 - val_loss: 0.2650\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9054 - loss: 0.2721 - val_auc: 0.7931 - val_binary_accuracy: 0.9094 - val_loss: 0.2615\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.7949 - val_binary_accuracy: 0.9093 - val_loss: 0.2676\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9082 - loss: 0.2646 - val_auc: 0.7980 - val_binary_accuracy: 0.9094 - val_loss: 0.2644\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9094 - loss: 0.2627 - val_auc: 0.7995 - val_binary_accuracy: 0.9075 - val_loss: 0.2640\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9092 - loss: 0.2619 - val_auc: 0.8025 - val_binary_accuracy: 0.9112 - val_loss: 0.2585\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9097 - loss: 0.2623 - val_auc: 0.8021 - val_binary_accuracy: 0.9091 - val_loss: 0.2627\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9099 - loss: 0.2620 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2578\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9121 - loss: 0.2586\n",
            "Fold 3 Metrics: Loss = 0.2578, Accuracy = 0.9107, AUC = 0.8026\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6741 - binary_accuracy: 0.8865 - loss: 0.3803 - val_auc: 0.7838 - val_binary_accuracy: 0.9053 - val_loss: 0.2682\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9059 - loss: 0.2740 - val_auc: 0.7923 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9071 - loss: 0.2697 - val_auc: 0.7957 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9076 - loss: 0.2674 - val_auc: 0.7989 - val_binary_accuracy: 0.9062 - val_loss: 0.2605\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9080 - loss: 0.2638 - val_auc: 0.8016 - val_binary_accuracy: 0.9084 - val_loss: 0.2594\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9081 - loss: 0.2630 - val_auc: 0.8025 - val_binary_accuracy: 0.9084 - val_loss: 0.2579\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.8034 - val_binary_accuracy: 0.9062 - val_loss: 0.2580\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9098 - loss: 0.2608 - val_auc: 0.8053 - val_binary_accuracy: 0.9073 - val_loss: 0.2575\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.8054 - val_binary_accuracy: 0.9082 - val_loss: 0.2572\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9096 - loss: 0.2602 - val_auc: 0.8062 - val_binary_accuracy: 0.9088 - val_loss: 0.2559\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7868 - binary_accuracy: 0.9074 - loss: 0.2634\n",
            "Fold 4 Metrics: Loss = 0.2559, Accuracy = 0.9088, AUC = 0.8062\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7049 - binary_accuracy: 0.9019 - loss: 0.3049 - val_auc: 0.7936 - val_binary_accuracy: 0.8948 - val_loss: 0.2847\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7451 - binary_accuracy: 0.9022 - loss: 0.2836 - val_auc: 0.7960 - val_binary_accuracy: 0.9064 - val_loss: 0.2609\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7600 - binary_accuracy: 0.9063 - loss: 0.2748 - val_auc: 0.7998 - val_binary_accuracy: 0.9091 - val_loss: 0.2580\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9075 - loss: 0.2697 - val_auc: 0.8023 - val_binary_accuracy: 0.9014 - val_loss: 0.2655\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9061 - loss: 0.2675 - val_auc: 0.8047 - val_binary_accuracy: 0.9063 - val_loss: 0.2620\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9078 - loss: 0.2658 - val_auc: 0.8059 - val_binary_accuracy: 0.9045 - val_loss: 0.2639\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9081 - loss: 0.2652 - val_auc: 0.8069 - val_binary_accuracy: 0.9064 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9090 - loss: 0.2639 - val_auc: 0.8075 - val_binary_accuracy: 0.9075 - val_loss: 0.2598\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8081 - val_binary_accuracy: 0.9078 - val_loss: 0.2599\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9095 - loss: 0.2635 - val_auc: 0.8076 - val_binary_accuracy: 0.9094 - val_loss: 0.2566\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9087 - loss: 0.2541\n",
            "Fold 5 Metrics: Loss = 0.2566, Accuracy = 0.9094, AUC = 0.8076\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2578\n",
            "Average Accuracy: 0.9092\n",
            "Average AUC: 0.8040\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 4, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6876 - binary_accuracy: 0.8980 - loss: 0.3569 - val_auc: 0.7743 - val_binary_accuracy: 0.9050 - val_loss: 0.2731\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9083 - loss: 0.2651 - val_auc: 0.7793 - val_binary_accuracy: 0.9094 - val_loss: 0.2753\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9097 - loss: 0.2597 - val_auc: 0.7853 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9115 - loss: 0.2556 - val_auc: 0.7903 - val_binary_accuracy: 0.9069 - val_loss: 0.2635\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9118 - loss: 0.2535 - val_auc: 0.7921 - val_binary_accuracy: 0.9088 - val_loss: 0.2603\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8005 - binary_accuracy: 0.9122 - loss: 0.2525 - val_auc: 0.7940 - val_binary_accuracy: 0.9096 - val_loss: 0.2593\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9118 - loss: 0.2508 - val_auc: 0.7942 - val_binary_accuracy: 0.9094 - val_loss: 0.2607\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9121 - loss: 0.2510 - val_auc: 0.7926 - val_binary_accuracy: 0.9075 - val_loss: 0.2641\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8068 - binary_accuracy: 0.9132 - loss: 0.2497 - val_auc: 0.7980 - val_binary_accuracy: 0.9081 - val_loss: 0.2589\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8098 - binary_accuracy: 0.9131 - loss: 0.2479 - val_auc: 0.7973 - val_binary_accuracy: 0.9076 - val_loss: 0.2613\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7942 - binary_accuracy: 0.9109 - loss: 0.2531\n",
            "Fold 1 Metrics: Loss = 0.2613, Accuracy = 0.9076, AUC = 0.7973\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6711 - binary_accuracy: 0.8797 - loss: 0.5018 - val_auc: 0.8015 - val_binary_accuracy: 0.9056 - val_loss: 0.2718\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9027 - loss: 0.2744 - val_auc: 0.7999 - val_binary_accuracy: 0.9076 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9057 - loss: 0.2688 - val_auc: 0.8042 - val_binary_accuracy: 0.9076 - val_loss: 0.2603\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9064 - loss: 0.2659 - val_auc: 0.8051 - val_binary_accuracy: 0.9072 - val_loss: 0.2614\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9075 - loss: 0.2641 - val_auc: 0.8066 - val_binary_accuracy: 0.9091 - val_loss: 0.2605\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.8084 - val_binary_accuracy: 0.9091 - val_loss: 0.2640\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9075 - loss: 0.2617 - val_auc: 0.8021 - val_binary_accuracy: 0.9091 - val_loss: 0.2644\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8089 - val_binary_accuracy: 0.9099 - val_loss: 0.2613\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9089 - loss: 0.2604 - val_auc: 0.8110 - val_binary_accuracy: 0.9094 - val_loss: 0.2597\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8002 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.8073 - val_binary_accuracy: 0.9091 - val_loss: 0.2639\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8134 - binary_accuracy: 0.9130 - loss: 0.2549\n",
            "Fold 2 Metrics: Loss = 0.2639, Accuracy = 0.9091, AUC = 0.8073\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7087 - binary_accuracy: 0.8943 - loss: 0.3278 - val_auc: 0.7834 - val_binary_accuracy: 0.9068 - val_loss: 0.2663\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7614 - binary_accuracy: 0.9058 - loss: 0.2729 - val_auc: 0.7872 - val_binary_accuracy: 0.9088 - val_loss: 0.2684\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9084 - loss: 0.2662 - val_auc: 0.7947 - val_binary_accuracy: 0.9094 - val_loss: 0.2662\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9085 - loss: 0.2653 - val_auc: 0.7956 - val_binary_accuracy: 0.9097 - val_loss: 0.2623\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9079 - loss: 0.2651 - val_auc: 0.7958 - val_binary_accuracy: 0.9104 - val_loss: 0.2619\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9075 - loss: 0.2632 - val_auc: 0.8008 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9079 - loss: 0.2642 - val_auc: 0.7996 - val_binary_accuracy: 0.9106 - val_loss: 0.2593\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9090 - loss: 0.2615 - val_auc: 0.8014 - val_binary_accuracy: 0.9104 - val_loss: 0.2591\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9094 - loss: 0.2607 - val_auc: 0.8003 - val_binary_accuracy: 0.9110 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2612 - val_auc: 0.8013 - val_binary_accuracy: 0.9115 - val_loss: 0.2585\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7944 - binary_accuracy: 0.9129 - loss: 0.2589\n",
            "Fold 3 Metrics: Loss = 0.2585, Accuracy = 0.9115, AUC = 0.8013\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6414 - binary_accuracy: 0.8837 - loss: 0.4603 - val_auc: 0.7865 - val_binary_accuracy: 0.9048 - val_loss: 0.2691\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9071 - loss: 0.2743 - val_auc: 0.7921 - val_binary_accuracy: 0.9079 - val_loss: 0.2627\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9080 - loss: 0.2686 - val_auc: 0.7938 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9084 - loss: 0.2649 - val_auc: 0.7994 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.8044 - val_binary_accuracy: 0.9051 - val_loss: 0.2585\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9092 - loss: 0.2629 - val_auc: 0.8044 - val_binary_accuracy: 0.9075 - val_loss: 0.2573\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9098 - loss: 0.2614 - val_auc: 0.8047 - val_binary_accuracy: 0.9078 - val_loss: 0.2575\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.8072 - val_binary_accuracy: 0.9078 - val_loss: 0.2569\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9102 - loss: 0.2600 - val_auc: 0.8093 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8093 - val_binary_accuracy: 0.9079 - val_loss: 0.2554\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7897 - binary_accuracy: 0.9071 - loss: 0.2634\n",
            "Fold 4 Metrics: Loss = 0.2554, Accuracy = 0.9079, AUC = 0.8093\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6406 - binary_accuracy: 0.8849 - loss: 0.5232 - val_auc: 0.7915 - val_binary_accuracy: 0.9003 - val_loss: 0.2699\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7510 - binary_accuracy: 0.9013 - loss: 0.2806 - val_auc: 0.7973 - val_binary_accuracy: 0.9063 - val_loss: 0.2584\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7659 - binary_accuracy: 0.9040 - loss: 0.2732 - val_auc: 0.7997 - val_binary_accuracy: 0.9057 - val_loss: 0.2617\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9050 - loss: 0.2706 - val_auc: 0.8024 - val_binary_accuracy: 0.9075 - val_loss: 0.2551\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9059 - loss: 0.2685 - val_auc: 0.8049 - val_binary_accuracy: 0.9103 - val_loss: 0.2586\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9077 - loss: 0.2651 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2591\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9088 - loss: 0.2643 - val_auc: 0.8056 - val_binary_accuracy: 0.9110 - val_loss: 0.2556\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9072 - loss: 0.2652 - val_auc: 0.8070 - val_binary_accuracy: 0.9110 - val_loss: 0.2575\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8089 - val_binary_accuracy: 0.9112 - val_loss: 0.2575\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9096 - loss: 0.2636 - val_auc: 0.8088 - val_binary_accuracy: 0.9110 - val_loss: 0.2563\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9095 - loss: 0.2553\n",
            "Fold 5 Metrics: Loss = 0.2563, Accuracy = 0.9110, AUC = 0.8088\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2591\n",
            "Average Accuracy: 0.9094\n",
            "Average AUC: 0.8048\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 4, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6483 - binary_accuracy: 0.8755 - loss: 0.5879 - val_auc: 0.7742 - val_binary_accuracy: 0.9085 - val_loss: 0.2753\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.7806 - val_binary_accuracy: 0.9102 - val_loss: 0.2640\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9105 - loss: 0.2580 - val_auc: 0.7864 - val_binary_accuracy: 0.9104 - val_loss: 0.2625\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9110 - loss: 0.2549 - val_auc: 0.7909 - val_binary_accuracy: 0.9113 - val_loss: 0.2664\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9119 - loss: 0.2535 - val_auc: 0.7925 - val_binary_accuracy: 0.9100 - val_loss: 0.2614\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9126 - loss: 0.2514 - val_auc: 0.7936 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9129 - loss: 0.2511 - val_auc: 0.7957 - val_binary_accuracy: 0.9090 - val_loss: 0.2599\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8064 - binary_accuracy: 0.9132 - loss: 0.2499 - val_auc: 0.7953 - val_binary_accuracy: 0.9099 - val_loss: 0.2581\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9126 - loss: 0.2502 - val_auc: 0.7961 - val_binary_accuracy: 0.9082 - val_loss: 0.2605\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8092 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7959 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9107 - loss: 0.2537\n",
            "Fold 1 Metrics: Loss = 0.2621, Accuracy = 0.9078, AUC = 0.7959\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6642 - binary_accuracy: 0.8735 - loss: 0.5663 - val_auc: 0.7947 - val_binary_accuracy: 0.9085 - val_loss: 0.2929\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9033 - loss: 0.2770 - val_auc: 0.8037 - val_binary_accuracy: 0.9054 - val_loss: 0.2659\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.8057 - val_binary_accuracy: 0.9063 - val_loss: 0.2629\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9059 - loss: 0.2669 - val_auc: 0.7991 - val_binary_accuracy: 0.9079 - val_loss: 0.2624\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9068 - loss: 0.2656 - val_auc: 0.8044 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9083 - loss: 0.2644 - val_auc: 0.8036 - val_binary_accuracy: 0.9076 - val_loss: 0.2645\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9085 - loss: 0.2627 - val_auc: 0.8062 - val_binary_accuracy: 0.9088 - val_loss: 0.2634\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9090 - loss: 0.2620 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2604\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9091 - loss: 0.2608 - val_auc: 0.8073 - val_binary_accuracy: 0.9097 - val_loss: 0.2639\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9085 - loss: 0.2611 - val_auc: 0.8074 - val_binary_accuracy: 0.9087 - val_loss: 0.2623\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8090 - binary_accuracy: 0.9128 - loss: 0.2549\n",
            "Fold 2 Metrics: Loss = 0.2623, Accuracy = 0.9087, AUC = 0.8074\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6402 - binary_accuracy: 0.8750 - loss: 0.6017 - val_auc: 0.7788 - val_binary_accuracy: 0.9072 - val_loss: 0.2750\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9053 - loss: 0.2736 - val_auc: 0.7840 - val_binary_accuracy: 0.9087 - val_loss: 0.2655\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9067 - loss: 0.2696 - val_auc: 0.7891 - val_binary_accuracy: 0.9093 - val_loss: 0.2649\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9084 - loss: 0.2669 - val_auc: 0.7925 - val_binary_accuracy: 0.9096 - val_loss: 0.2627\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9084 - loss: 0.2645 - val_auc: 0.7955 - val_binary_accuracy: 0.9104 - val_loss: 0.2603\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.7969 - val_binary_accuracy: 0.9106 - val_loss: 0.2606\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9087 - loss: 0.2636 - val_auc: 0.8000 - val_binary_accuracy: 0.9110 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9090 - loss: 0.2628 - val_auc: 0.8008 - val_binary_accuracy: 0.9107 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.8026 - val_binary_accuracy: 0.9112 - val_loss: 0.2593\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2581\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9112 - loss: 0.2587\n",
            "Fold 3 Metrics: Loss = 0.2581, Accuracy = 0.9107, AUC = 0.8026\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6449 - binary_accuracy: 0.8701 - loss: 0.8217 - val_auc: 0.7858 - val_binary_accuracy: 0.9053 - val_loss: 0.2684\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7600 - binary_accuracy: 0.9066 - loss: 0.2741 - val_auc: 0.7921 - val_binary_accuracy: 0.9082 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9084 - loss: 0.2681 - val_auc: 0.7965 - val_binary_accuracy: 0.9069 - val_loss: 0.2615\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9081 - loss: 0.2654 - val_auc: 0.8006 - val_binary_accuracy: 0.9088 - val_loss: 0.2594\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8035 - val_binary_accuracy: 0.9095 - val_loss: 0.2571\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9103 - loss: 0.2614 - val_auc: 0.8059 - val_binary_accuracy: 0.9098 - val_loss: 0.2557\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9104 - loss: 0.2604 - val_auc: 0.8073 - val_binary_accuracy: 0.9097 - val_loss: 0.2552\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9107 - loss: 0.2595 - val_auc: 0.8074 - val_binary_accuracy: 0.9100 - val_loss: 0.2550\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9104 - loss: 0.2598 - val_auc: 0.8083 - val_binary_accuracy: 0.9094 - val_loss: 0.2547\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9109 - loss: 0.2590 - val_auc: 0.8102 - val_binary_accuracy: 0.9095 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9089 - loss: 0.2623\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9095, AUC = 0.8102\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6608 - binary_accuracy: 0.8902 - loss: 0.4149 - val_auc: 0.7908 - val_binary_accuracy: 0.8977 - val_loss: 0.2746\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7512 - binary_accuracy: 0.9027 - loss: 0.2799 - val_auc: 0.7955 - val_binary_accuracy: 0.9032 - val_loss: 0.2625\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9039 - loss: 0.2754 - val_auc: 0.7993 - val_binary_accuracy: 0.9107 - val_loss: 0.2599\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7739 - binary_accuracy: 0.9060 - loss: 0.2696 - val_auc: 0.8012 - val_binary_accuracy: 0.9098 - val_loss: 0.2597\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9080 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2635\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9084 - loss: 0.2662 - val_auc: 0.8046 - val_binary_accuracy: 0.9084 - val_loss: 0.2644\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9076 - loss: 0.2654 - val_auc: 0.8065 - val_binary_accuracy: 0.9121 - val_loss: 0.2636\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9084 - loss: 0.2641 - val_auc: 0.8061 - val_binary_accuracy: 0.9106 - val_loss: 0.2647\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9086 - loss: 0.2640 - val_auc: 0.8081 - val_binary_accuracy: 0.9112 - val_loss: 0.2596\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9091 - loss: 0.2622 - val_auc: 0.8080 - val_binary_accuracy: 0.9116 - val_loss: 0.2602\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9115 - loss: 0.2588\n",
            "Fold 5 Metrics: Loss = 0.2602, Accuracy = 0.9116, AUC = 0.8080\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2596\n",
            "Average Accuracy: 0.9097\n",
            "Average AUC: 0.8048\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 5, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7407 - binary_accuracy: 0.9073 - loss: 0.2764 - val_auc: 0.7709 - val_binary_accuracy: 0.9047 - val_loss: 0.2712\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9094 - loss: 0.2598 - val_auc: 0.7768 - val_binary_accuracy: 0.9069 - val_loss: 0.2681\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9099 - loss: 0.2563 - val_auc: 0.7825 - val_binary_accuracy: 0.9065 - val_loss: 0.2662\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9106 - loss: 0.2545 - val_auc: 0.7853 - val_binary_accuracy: 0.9078 - val_loss: 0.2640\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9117 - loss: 0.2531 - val_auc: 0.7872 - val_binary_accuracy: 0.9088 - val_loss: 0.2630\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9120 - loss: 0.2518 - val_auc: 0.7887 - val_binary_accuracy: 0.9090 - val_loss: 0.2622\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7905 - val_binary_accuracy: 0.9094 - val_loss: 0.2618\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8069 - binary_accuracy: 0.9127 - loss: 0.2499 - val_auc: 0.7915 - val_binary_accuracy: 0.9099 - val_loss: 0.2613\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8082 - binary_accuracy: 0.9133 - loss: 0.2488 - val_auc: 0.7916 - val_binary_accuracy: 0.9093 - val_loss: 0.2611\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8092 - binary_accuracy: 0.9135 - loss: 0.2479 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2607\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9125 - loss: 0.2542\n",
            "Fold 1 Metrics: Loss = 0.2607, Accuracy = 0.9093, AUC = 0.7919\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5360 - binary_accuracy: 0.6777 - loss: 2.9505 - val_auc: 0.7771 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9029 - loss: 0.2784 - val_auc: 0.7787 - val_binary_accuracy: 0.9047 - val_loss: 0.2716\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9032 - loss: 0.2736 - val_auc: 0.7911 - val_binary_accuracy: 0.9056 - val_loss: 0.2646\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9049 - loss: 0.2709 - val_auc: 0.7938 - val_binary_accuracy: 0.9072 - val_loss: 0.2632\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9066 - loss: 0.2694 - val_auc: 0.7963 - val_binary_accuracy: 0.9078 - val_loss: 0.2622\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9065 - loss: 0.2683 - val_auc: 0.7986 - val_binary_accuracy: 0.9079 - val_loss: 0.2607\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9072 - loss: 0.2669 - val_auc: 0.8014 - val_binary_accuracy: 0.9078 - val_loss: 0.2594\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9078 - loss: 0.2658 - val_auc: 0.8025 - val_binary_accuracy: 0.9075 - val_loss: 0.2588\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9080 - loss: 0.2650 - val_auc: 0.8050 - val_binary_accuracy: 0.9073 - val_loss: 0.2586\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9082 - loss: 0.2644 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2574\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8085 - binary_accuracy: 0.9125 - loss: 0.2485\n",
            "Fold 2 Metrics: Loss = 0.2574, Accuracy = 0.9078, AUC = 0.8073\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4992 - binary_accuracy: 0.8095 - loss: 0.6973 - val_auc: 0.7599 - val_binary_accuracy: 0.9042 - val_loss: 0.2772\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9051 - loss: 0.2758 - val_auc: 0.7685 - val_binary_accuracy: 0.9042 - val_loss: 0.2740\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9054 - loss: 0.2724 - val_auc: 0.7766 - val_binary_accuracy: 0.9041 - val_loss: 0.2729\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9060 - loss: 0.2703 - val_auc: 0.7790 - val_binary_accuracy: 0.9045 - val_loss: 0.2711\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9061 - loss: 0.2688 - val_auc: 0.7822 - val_binary_accuracy: 0.9054 - val_loss: 0.2697\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.7842 - val_binary_accuracy: 0.9072 - val_loss: 0.2678\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9071 - loss: 0.2675 - val_auc: 0.7862 - val_binary_accuracy: 0.9087 - val_loss: 0.2669\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9073 - loss: 0.2668 - val_auc: 0.7873 - val_binary_accuracy: 0.9094 - val_loss: 0.2664\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9078 - loss: 0.2661 - val_auc: 0.7886 - val_binary_accuracy: 0.9102 - val_loss: 0.2654\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9082 - loss: 0.2655 - val_auc: 0.7896 - val_binary_accuracy: 0.9103 - val_loss: 0.2650\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7849 - binary_accuracy: 0.9110 - loss: 0.2645\n",
            "Fold 3 Metrics: Loss = 0.2650, Accuracy = 0.9103, AUC = 0.7896\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6278 - binary_accuracy: 0.8020 - loss: 0.4701 - val_auc: 0.7498 - val_binary_accuracy: 0.9044 - val_loss: 0.2810\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7508 - binary_accuracy: 0.9047 - loss: 0.2777 - val_auc: 0.7720 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9057 - loss: 0.2705 - val_auc: 0.7820 - val_binary_accuracy: 0.9060 - val_loss: 0.2687\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9083 - loss: 0.2678 - val_auc: 0.7870 - val_binary_accuracy: 0.9069 - val_loss: 0.2682\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9088 - loss: 0.2652 - val_auc: 0.7895 - val_binary_accuracy: 0.9069 - val_loss: 0.2663\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9094 - loss: 0.2636 - val_auc: 0.7913 - val_binary_accuracy: 0.9078 - val_loss: 0.2656\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9093 - loss: 0.2625 - val_auc: 0.7928 - val_binary_accuracy: 0.9078 - val_loss: 0.2651\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9094 - loss: 0.2617 - val_auc: 0.7946 - val_binary_accuracy: 0.9081 - val_loss: 0.2644\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2610 - val_auc: 0.7955 - val_binary_accuracy: 0.9081 - val_loss: 0.2647\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9096 - loss: 0.2601 - val_auc: 0.7969 - val_binary_accuracy: 0.9081 - val_loss: 0.2640\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7745 - binary_accuracy: 0.9073 - loss: 0.2713\n",
            "Fold 4 Metrics: Loss = 0.2640, Accuracy = 0.9081, AUC = 0.7969\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7206 - binary_accuracy: 0.9042 - loss: 0.2886 - val_auc: 0.7822 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7582 - binary_accuracy: 0.9044 - loss: 0.2772 - val_auc: 0.7893 - val_binary_accuracy: 0.9057 - val_loss: 0.2700\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9049 - loss: 0.2742 - val_auc: 0.7929 - val_binary_accuracy: 0.9062 - val_loss: 0.2663\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9060 - loss: 0.2720 - val_auc: 0.7953 - val_binary_accuracy: 0.9072 - val_loss: 0.2619\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9071 - loss: 0.2701 - val_auc: 0.7964 - val_binary_accuracy: 0.9076 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9072 - loss: 0.2692 - val_auc: 0.7965 - val_binary_accuracy: 0.9078 - val_loss: 0.2588\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9075 - loss: 0.2673 - val_auc: 0.7999 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9075 - loss: 0.2661 - val_auc: 0.8008 - val_binary_accuracy: 0.9098 - val_loss: 0.2570\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9086 - loss: 0.2659 - val_auc: 0.8012 - val_binary_accuracy: 0.9100 - val_loss: 0.2566\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9082 - loss: 0.2651 - val_auc: 0.8018 - val_binary_accuracy: 0.9109 - val_loss: 0.2557\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8119 - binary_accuracy: 0.9096 - loss: 0.2539\n",
            "Fold 5 Metrics: Loss = 0.2557, Accuracy = 0.9109, AUC = 0.8018\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2606\n",
            "Average Accuracy: 0.9093\n",
            "Average AUC: 0.7975\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 5, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6768 - binary_accuracy: 0.9012 - loss: 0.3083 - val_auc: 0.7721 - val_binary_accuracy: 0.9045 - val_loss: 0.2709\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9083 - loss: 0.2637 - val_auc: 0.7824 - val_binary_accuracy: 0.9053 - val_loss: 0.2659\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2583 - val_auc: 0.7853 - val_binary_accuracy: 0.9078 - val_loss: 0.2627\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9106 - loss: 0.2559 - val_auc: 0.7875 - val_binary_accuracy: 0.9087 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9118 - loss: 0.2540 - val_auc: 0.7889 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9116 - loss: 0.2527 - val_auc: 0.7904 - val_binary_accuracy: 0.9069 - val_loss: 0.2629\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9119 - loss: 0.2515 - val_auc: 0.7939 - val_binary_accuracy: 0.9088 - val_loss: 0.2604\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9119 - loss: 0.2500 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9123 - loss: 0.2497 - val_auc: 0.7948 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8091 - binary_accuracy: 0.9122 - loss: 0.2490 - val_auc: 0.7953 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9118 - loss: 0.2518\n",
            "Fold 1 Metrics: Loss = 0.2594, Accuracy = 0.9085, AUC = 0.7953\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7273 - binary_accuracy: 0.9029 - loss: 0.2894 - val_auc: 0.7957 - val_binary_accuracy: 0.9044 - val_loss: 0.2647\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9034 - loss: 0.2712 - val_auc: 0.8002 - val_binary_accuracy: 0.9071 - val_loss: 0.2608\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9047 - loss: 0.2676 - val_auc: 0.8050 - val_binary_accuracy: 0.9066 - val_loss: 0.2592\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7906 - binary_accuracy: 0.9060 - loss: 0.2656 - val_auc: 0.8074 - val_binary_accuracy: 0.9081 - val_loss: 0.2573\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9077 - loss: 0.2643 - val_auc: 0.8084 - val_binary_accuracy: 0.9088 - val_loss: 0.2566\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9084 - loss: 0.2630 - val_auc: 0.8108 - val_binary_accuracy: 0.9090 - val_loss: 0.2543\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8112 - val_binary_accuracy: 0.9099 - val_loss: 0.2539\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9082 - loss: 0.2605 - val_auc: 0.8111 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8006 - binary_accuracy: 0.9083 - loss: 0.2604 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2532\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9086 - loss: 0.2593 - val_auc: 0.8105 - val_binary_accuracy: 0.9099 - val_loss: 0.2544\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9137 - loss: 0.2452\n",
            "Fold 2 Metrics: Loss = 0.2544, Accuracy = 0.9099, AUC = 0.8105\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6220 - binary_accuracy: 0.8580 - loss: 0.4961 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7602 - binary_accuracy: 0.9052 - loss: 0.2745 - val_auc: 0.7819 - val_binary_accuracy: 0.9048 - val_loss: 0.2688\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7672 - binary_accuracy: 0.9063 - loss: 0.2710 - val_auc: 0.7895 - val_binary_accuracy: 0.9091 - val_loss: 0.2644\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9057 - loss: 0.2686 - val_auc: 0.7913 - val_binary_accuracy: 0.9085 - val_loss: 0.2633\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9065 - loss: 0.2667 - val_auc: 0.7919 - val_binary_accuracy: 0.9096 - val_loss: 0.2624\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9067 - loss: 0.2656 - val_auc: 0.7946 - val_binary_accuracy: 0.9097 - val_loss: 0.2612\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9080 - loss: 0.2635 - val_auc: 0.7939 - val_binary_accuracy: 0.9102 - val_loss: 0.2604\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9080 - loss: 0.2637 - val_auc: 0.7963 - val_binary_accuracy: 0.9103 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9082 - loss: 0.2612 - val_auc: 0.7947 - val_binary_accuracy: 0.9082 - val_loss: 0.2605\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9081 - loss: 0.2621 - val_auc: 0.7952 - val_binary_accuracy: 0.9097 - val_loss: 0.2594\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7884 - binary_accuracy: 0.9120 - loss: 0.2604\n",
            "Fold 3 Metrics: Loss = 0.2594, Accuracy = 0.9097, AUC = 0.7952\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6633 - binary_accuracy: 0.9040 - loss: 0.3229 - val_auc: 0.7850 - val_binary_accuracy: 0.9048 - val_loss: 0.2676\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9048 - loss: 0.2722 - val_auc: 0.7925 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9057 - loss: 0.2683 - val_auc: 0.7943 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7988 - val_binary_accuracy: 0.9051 - val_loss: 0.2609\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9077 - loss: 0.2638 - val_auc: 0.8002 - val_binary_accuracy: 0.9057 - val_loss: 0.2599\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2619 - val_auc: 0.8020 - val_binary_accuracy: 0.9011 - val_loss: 0.2632\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9082 - loss: 0.2624 - val_auc: 0.8046 - val_binary_accuracy: 0.9022 - val_loss: 0.2611\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9090 - loss: 0.2608 - val_auc: 0.8046 - val_binary_accuracy: 0.9070 - val_loss: 0.2576\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9103 - loss: 0.2591 - val_auc: 0.8067 - val_binary_accuracy: 0.9059 - val_loss: 0.2580\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8067 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7872 - binary_accuracy: 0.9074 - loss: 0.2640\n",
            "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9087, AUC = 0.8067\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6249 - binary_accuracy: 0.8291 - loss: 0.4671 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9043 - loss: 0.2747 - val_auc: 0.7917 - val_binary_accuracy: 0.9003 - val_loss: 0.2738\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9041 - loss: 0.2734 - val_auc: 0.7943 - val_binary_accuracy: 0.8995 - val_loss: 0.2674\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7991 - val_binary_accuracy: 0.9067 - val_loss: 0.2655\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9060 - loss: 0.2693 - val_auc: 0.8004 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9080 - loss: 0.2660 - val_auc: 0.8007 - val_binary_accuracy: 0.9067 - val_loss: 0.2611\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9074 - loss: 0.2656 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2577\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9088 - loss: 0.2633 - val_auc: 0.8051 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8058 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9088 - loss: 0.2624 - val_auc: 0.8067 - val_binary_accuracy: 0.9103 - val_loss: 0.2563\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9101 - loss: 0.2536\n",
            "Fold 5 Metrics: Loss = 0.2563, Accuracy = 0.9103, AUC = 0.8067\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2571\n",
            "Average Accuracy: 0.9094\n",
            "Average AUC: 0.8029\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 5, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7065 - binary_accuracy: 0.9066 - loss: 0.2945 - val_auc: 0.7741 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9077 - loss: 0.2617 - val_auc: 0.7815 - val_binary_accuracy: 0.9050 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9095 - loss: 0.2581 - val_auc: 0.7843 - val_binary_accuracy: 0.9072 - val_loss: 0.2643\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9112 - loss: 0.2549 - val_auc: 0.7880 - val_binary_accuracy: 0.9072 - val_loss: 0.2635\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9112 - loss: 0.2535 - val_auc: 0.7885 - val_binary_accuracy: 0.9069 - val_loss: 0.2627\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9110 - loss: 0.2514 - val_auc: 0.7901 - val_binary_accuracy: 0.9094 - val_loss: 0.2613\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9117 - loss: 0.2508 - val_auc: 0.7918 - val_binary_accuracy: 0.9088 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9120 - loss: 0.2498 - val_auc: 0.7914 - val_binary_accuracy: 0.9081 - val_loss: 0.2612\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8099 - binary_accuracy: 0.9129 - loss: 0.2480 - val_auc: 0.7918 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8098 - binary_accuracy: 0.9131 - loss: 0.2480 - val_auc: 0.7914 - val_binary_accuracy: 0.9072 - val_loss: 0.2619\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7918 - binary_accuracy: 0.9114 - loss: 0.2528\n",
            "Fold 1 Metrics: Loss = 0.2619, Accuracy = 0.9072, AUC = 0.7914\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - auc: 0.6525 - binary_accuracy: 0.8688 - loss: 0.5184 - val_auc: 0.7926 - val_binary_accuracy: 0.9040 - val_loss: 0.2703\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9032 - loss: 0.2726 - val_auc: 0.7990 - val_binary_accuracy: 0.9047 - val_loss: 0.2685\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9047 - loss: 0.2679 - val_auc: 0.8014 - val_binary_accuracy: 0.9068 - val_loss: 0.2666\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9075 - loss: 0.2670 - val_auc: 0.8016 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9071 - loss: 0.2652 - val_auc: 0.8024 - val_binary_accuracy: 0.9069 - val_loss: 0.2633\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9076 - loss: 0.2636 - val_auc: 0.8017 - val_binary_accuracy: 0.9088 - val_loss: 0.2628\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9071 - loss: 0.2625 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2598\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9081 - loss: 0.2615 - val_auc: 0.8113 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9085 - loss: 0.2608 - val_auc: 0.8099 - val_binary_accuracy: 0.9093 - val_loss: 0.2587\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9091 - loss: 0.2603 - val_auc: 0.8159 - val_binary_accuracy: 0.9087 - val_loss: 0.2553\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8209 - binary_accuracy: 0.9127 - loss: 0.2465\n",
            "Fold 2 Metrics: Loss = 0.2553, Accuracy = 0.9087, AUC = 0.8159\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6395 - binary_accuracy: 0.8448 - loss: 0.8657 - val_auc: 0.7829 - val_binary_accuracy: 0.9059 - val_loss: 0.2744\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9073 - loss: 0.2715 - val_auc: 0.7891 - val_binary_accuracy: 0.9081 - val_loss: 0.2712\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9073 - loss: 0.2683 - val_auc: 0.7922 - val_binary_accuracy: 0.9050 - val_loss: 0.2667\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9076 - loss: 0.2681 - val_auc: 0.7940 - val_binary_accuracy: 0.9085 - val_loss: 0.2638\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9079 - loss: 0.2663 - val_auc: 0.7974 - val_binary_accuracy: 0.9084 - val_loss: 0.2618\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9078 - loss: 0.2643 - val_auc: 0.7991 - val_binary_accuracy: 0.9091 - val_loss: 0.2622\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9082 - loss: 0.2631 - val_auc: 0.8007 - val_binary_accuracy: 0.9090 - val_loss: 0.2607\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9089 - loss: 0.2625 - val_auc: 0.8027 - val_binary_accuracy: 0.9090 - val_loss: 0.2601\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9088 - loss: 0.2617 - val_auc: 0.8039 - val_binary_accuracy: 0.9073 - val_loss: 0.2604\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9095 - loss: 0.2615 - val_auc: 0.8035 - val_binary_accuracy: 0.9096 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7963 - binary_accuracy: 0.9118 - loss: 0.2593\n",
            "Fold 3 Metrics: Loss = 0.2587, Accuracy = 0.9096, AUC = 0.8035\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7178 - binary_accuracy: 0.9054 - loss: 0.2938 - val_auc: 0.7950 - val_binary_accuracy: 0.9076 - val_loss: 0.2615\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9079 - loss: 0.2668 - val_auc: 0.7960 - val_binary_accuracy: 0.9064 - val_loss: 0.2606\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9075 - loss: 0.2651 - val_auc: 0.7994 - val_binary_accuracy: 0.9053 - val_loss: 0.2609\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8033 - val_binary_accuracy: 0.9067 - val_loss: 0.2581\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9089 - loss: 0.2615 - val_auc: 0.8032 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9096 - loss: 0.2606 - val_auc: 0.7999 - val_binary_accuracy: 0.9088 - val_loss: 0.2583\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9105 - loss: 0.2601 - val_auc: 0.8074 - val_binary_accuracy: 0.9094 - val_loss: 0.2552\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8089 - val_binary_accuracy: 0.9087 - val_loss: 0.2560\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9107 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9107 - loss: 0.2571 - val_auc: 0.8107 - val_binary_accuracy: 0.9093 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7915 - binary_accuracy: 0.9094 - loss: 0.2624\n",
            "Fold 4 Metrics: Loss = 0.2551, Accuracy = 0.9093, AUC = 0.8107\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6953 - binary_accuracy: 0.9039 - loss: 0.2980 - val_auc: 0.7916 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9037 - loss: 0.2771 - val_auc: 0.7958 - val_binary_accuracy: 0.9053 - val_loss: 0.2638\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9051 - loss: 0.2717 - val_auc: 0.8012 - val_binary_accuracy: 0.9093 - val_loss: 0.2614\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.8033 - val_binary_accuracy: 0.9093 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9081 - loss: 0.2666 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2614\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9084 - loss: 0.2659 - val_auc: 0.8059 - val_binary_accuracy: 0.9093 - val_loss: 0.2613\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9076 - loss: 0.2644 - val_auc: 0.8071 - val_binary_accuracy: 0.9101 - val_loss: 0.2575\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.8085 - val_binary_accuracy: 0.9103 - val_loss: 0.2564\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9099 - loss: 0.2622 - val_auc: 0.8092 - val_binary_accuracy: 0.9107 - val_loss: 0.2549\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9100 - loss: 0.2624 - val_auc: 0.8099 - val_binary_accuracy: 0.9098 - val_loss: 0.2529\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9086 - loss: 0.2514\n",
            "Fold 5 Metrics: Loss = 0.2529, Accuracy = 0.9098, AUC = 0.8099\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2568\n",
            "Average Accuracy: 0.9089\n",
            "Average AUC: 0.8063\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 5, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6974 - binary_accuracy: 0.9006 - loss: 0.3307 - val_auc: 0.7742 - val_binary_accuracy: 0.9084 - val_loss: 0.2769\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.7827 - val_binary_accuracy: 0.9085 - val_loss: 0.2661\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9103 - loss: 0.2595 - val_auc: 0.7857 - val_binary_accuracy: 0.9091 - val_loss: 0.2629\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9110 - loss: 0.2545 - val_auc: 0.7854 - val_binary_accuracy: 0.9115 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9113 - loss: 0.2533 - val_auc: 0.7902 - val_binary_accuracy: 0.9088 - val_loss: 0.2597\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7908 - val_binary_accuracy: 0.9079 - val_loss: 0.2609\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9125 - loss: 0.2505 - val_auc: 0.7908 - val_binary_accuracy: 0.9084 - val_loss: 0.2633\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9130 - loss: 0.2494 - val_auc: 0.7945 - val_binary_accuracy: 0.9063 - val_loss: 0.2647\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9125 - loss: 0.2491 - val_auc: 0.7944 - val_binary_accuracy: 0.9072 - val_loss: 0.2648\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9126 - loss: 0.2485 - val_auc: 0.7941 - val_binary_accuracy: 0.9073 - val_loss: 0.2626\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7940 - binary_accuracy: 0.9106 - loss: 0.2539\n",
            "Fold 1 Metrics: Loss = 0.2626, Accuracy = 0.9073, AUC = 0.7941\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6998 - binary_accuracy: 0.8838 - loss: 0.3609 - val_auc: 0.7953 - val_binary_accuracy: 0.9045 - val_loss: 0.2826\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7627 - binary_accuracy: 0.9035 - loss: 0.2775 - val_auc: 0.7992 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9049 - loss: 0.2698 - val_auc: 0.8042 - val_binary_accuracy: 0.9066 - val_loss: 0.2631\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9058 - loss: 0.2670 - val_auc: 0.8063 - val_binary_accuracy: 0.9081 - val_loss: 0.2642\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9070 - loss: 0.2663 - val_auc: 0.8062 - val_binary_accuracy: 0.9073 - val_loss: 0.2653\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9077 - loss: 0.2641 - val_auc: 0.8034 - val_binary_accuracy: 0.9075 - val_loss: 0.2677\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8074 - val_binary_accuracy: 0.9093 - val_loss: 0.2652\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9081 - loss: 0.2617 - val_auc: 0.8063 - val_binary_accuracy: 0.9085 - val_loss: 0.2641\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9086 - loss: 0.2614 - val_auc: 0.8058 - val_binary_accuracy: 0.9091 - val_loss: 0.2637\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9082 - loss: 0.2606 - val_auc: 0.8082 - val_binary_accuracy: 0.9079 - val_loss: 0.2628\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8096 - binary_accuracy: 0.9121 - loss: 0.2547\n",
            "Fold 2 Metrics: Loss = 0.2628, Accuracy = 0.9079, AUC = 0.8082\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6591 - binary_accuracy: 0.8839 - loss: 0.5042 - val_auc: 0.7756 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7546 - binary_accuracy: 0.9049 - loss: 0.2768 - val_auc: 0.7852 - val_binary_accuracy: 0.9096 - val_loss: 0.2672\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9076 - loss: 0.2673 - val_auc: 0.7930 - val_binary_accuracy: 0.9103 - val_loss: 0.2622\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9080 - loss: 0.2657 - val_auc: 0.7946 - val_binary_accuracy: 0.9081 - val_loss: 0.2625\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9087 - loss: 0.2637 - val_auc: 0.7972 - val_binary_accuracy: 0.9102 - val_loss: 0.2609\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9084 - loss: 0.2633 - val_auc: 0.7994 - val_binary_accuracy: 0.9103 - val_loss: 0.2604\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9089 - loss: 0.2623 - val_auc: 0.8015 - val_binary_accuracy: 0.9110 - val_loss: 0.2616\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.8018 - val_binary_accuracy: 0.9107 - val_loss: 0.2612\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9088 - loss: 0.2616 - val_auc: 0.8027 - val_binary_accuracy: 0.9112 - val_loss: 0.2596\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8039 - val_binary_accuracy: 0.9109 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7971 - binary_accuracy: 0.9118 - loss: 0.2592\n",
            "Fold 3 Metrics: Loss = 0.2586, Accuracy = 0.9109, AUC = 0.8039\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6802 - binary_accuracy: 0.8869 - loss: 0.3484 - val_auc: 0.7851 - val_binary_accuracy: 0.9075 - val_loss: 0.2662\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9065 - loss: 0.2705 - val_auc: 0.7932 - val_binary_accuracy: 0.9038 - val_loss: 0.2647\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9072 - loss: 0.2670 - val_auc: 0.7967 - val_binary_accuracy: 0.9076 - val_loss: 0.2605\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.8005 - val_binary_accuracy: 0.9085 - val_loss: 0.2580\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9089 - loss: 0.2626 - val_auc: 0.8009 - val_binary_accuracy: 0.9098 - val_loss: 0.2574\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8040 - val_binary_accuracy: 0.9094 - val_loss: 0.2563\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9102 - loss: 0.2614 - val_auc: 0.8055 - val_binary_accuracy: 0.9097 - val_loss: 0.2563\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9101 - loss: 0.2600 - val_auc: 0.8064 - val_binary_accuracy: 0.9095 - val_loss: 0.2564\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9100 - loss: 0.2593 - val_auc: 0.8075 - val_binary_accuracy: 0.9098 - val_loss: 0.2562\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9106 - loss: 0.2585 - val_auc: 0.8080 - val_binary_accuracy: 0.9093 - val_loss: 0.2556\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9082 - loss: 0.2633\n",
            "Fold 4 Metrics: Loss = 0.2556, Accuracy = 0.9093, AUC = 0.8080\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6713 - binary_accuracy: 0.8885 - loss: 0.3562 - val_auc: 0.7881 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7560 - binary_accuracy: 0.9039 - loss: 0.2776 - val_auc: 0.7947 - val_binary_accuracy: 0.9079 - val_loss: 0.2627\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9065 - loss: 0.2729 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9060 - loss: 0.2705 - val_auc: 0.8007 - val_binary_accuracy: 0.9112 - val_loss: 0.2633\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9067 - loss: 0.2687 - val_auc: 0.8021 - val_binary_accuracy: 0.9104 - val_loss: 0.2590\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9071 - loss: 0.2674 - val_auc: 0.8048 - val_binary_accuracy: 0.9104 - val_loss: 0.2580\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.8060 - val_binary_accuracy: 0.9104 - val_loss: 0.2581\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2634 - val_auc: 0.8072 - val_binary_accuracy: 0.9113 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9094 - loss: 0.2623 - val_auc: 0.8063 - val_binary_accuracy: 0.9110 - val_loss: 0.2551\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9087 - loss: 0.2620 - val_auc: 0.8075 - val_binary_accuracy: 0.9113 - val_loss: 0.2542\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8159 - binary_accuracy: 0.9098 - loss: 0.2532\n",
            "Fold 5 Metrics: Loss = 0.2542, Accuracy = 0.9113, AUC = 0.8075\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2588\n",
            "Average Accuracy: 0.9093\n",
            "Average AUC: 0.8043\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 5, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6604 - binary_accuracy: 0.8799 - loss: 0.4752 - val_auc: 0.7722 - val_binary_accuracy: 0.9071 - val_loss: 0.2713\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9091 - loss: 0.2630 - val_auc: 0.7802 - val_binary_accuracy: 0.9078 - val_loss: 0.2715\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2572 - val_auc: 0.7870 - val_binary_accuracy: 0.9093 - val_loss: 0.2636\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9117 - loss: 0.2553 - val_auc: 0.7902 - val_binary_accuracy: 0.9099 - val_loss: 0.2630\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9121 - loss: 0.2537 - val_auc: 0.7928 - val_binary_accuracy: 0.9090 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9131 - loss: 0.2514 - val_auc: 0.7936 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9127 - loss: 0.2506 - val_auc: 0.7947 - val_binary_accuracy: 0.9088 - val_loss: 0.2592\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9133 - loss: 0.2493 - val_auc: 0.7947 - val_binary_accuracy: 0.9087 - val_loss: 0.2591\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8062 - binary_accuracy: 0.9130 - loss: 0.2492 - val_auc: 0.7944 - val_binary_accuracy: 0.9075 - val_loss: 0.2643\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9130 - loss: 0.2478 - val_auc: 0.7967 - val_binary_accuracy: 0.9075 - val_loss: 0.2624\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9105 - loss: 0.2539\n",
            "Fold 1 Metrics: Loss = 0.2624, Accuracy = 0.9075, AUC = 0.7967\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6583 - binary_accuracy: 0.8823 - loss: 0.5256 - val_auc: 0.7975 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9035 - loss: 0.2733 - val_auc: 0.8036 - val_binary_accuracy: 0.9063 - val_loss: 0.2675\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9057 - loss: 0.2684 - val_auc: 0.8062 - val_binary_accuracy: 0.9081 - val_loss: 0.2629\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9063 - loss: 0.2668 - val_auc: 0.8093 - val_binary_accuracy: 0.9062 - val_loss: 0.2619\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9068 - loss: 0.2650 - val_auc: 0.8026 - val_binary_accuracy: 0.9073 - val_loss: 0.2651\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9079 - loss: 0.2645 - val_auc: 0.8084 - val_binary_accuracy: 0.9071 - val_loss: 0.2659\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9067 - loss: 0.2632 - val_auc: 0.8118 - val_binary_accuracy: 0.9071 - val_loss: 0.2634\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9079 - loss: 0.2620 - val_auc: 0.8119 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9078 - loss: 0.2617 - val_auc: 0.8081 - val_binary_accuracy: 0.9082 - val_loss: 0.2628\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9088 - loss: 0.2612 - val_auc: 0.8066 - val_binary_accuracy: 0.9082 - val_loss: 0.2651\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8135 - binary_accuracy: 0.9126 - loss: 0.2562\n",
            "Fold 2 Metrics: Loss = 0.2651, Accuracy = 0.9082, AUC = 0.8066\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6539 - binary_accuracy: 0.8703 - loss: 0.4389 - val_auc: 0.7834 - val_binary_accuracy: 0.9063 - val_loss: 0.2737\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9068 - loss: 0.2708 - val_auc: 0.7899 - val_binary_accuracy: 0.9051 - val_loss: 0.2677\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9077 - loss: 0.2666 - val_auc: 0.7933 - val_binary_accuracy: 0.9053 - val_loss: 0.2636\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9085 - loss: 0.2650 - val_auc: 0.7966 - val_binary_accuracy: 0.9071 - val_loss: 0.2616\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9083 - loss: 0.2644 - val_auc: 0.7991 - val_binary_accuracy: 0.9054 - val_loss: 0.2626\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9095 - loss: 0.2624 - val_auc: 0.8015 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8019 - val_binary_accuracy: 0.9102 - val_loss: 0.2598\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8035 - val_binary_accuracy: 0.9109 - val_loss: 0.2575\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9096 - loss: 0.2620 - val_auc: 0.8041 - val_binary_accuracy: 0.9071 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9093 - loss: 0.2600 - val_auc: 0.8056 - val_binary_accuracy: 0.9097 - val_loss: 0.2588\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7988 - binary_accuracy: 0.9097 - loss: 0.2595\n",
            "Fold 3 Metrics: Loss = 0.2588, Accuracy = 0.9097, AUC = 0.8056\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6627 - binary_accuracy: 0.8852 - loss: 0.4744 - val_auc: 0.7887 - val_binary_accuracy: 0.9050 - val_loss: 0.2751\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9071 - loss: 0.2727 - val_auc: 0.7961 - val_binary_accuracy: 0.9069 - val_loss: 0.2627\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.8004 - val_binary_accuracy: 0.9081 - val_loss: 0.2597\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8025 - val_binary_accuracy: 0.9079 - val_loss: 0.2594\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9091 - loss: 0.2633 - val_auc: 0.8055 - val_binary_accuracy: 0.9093 - val_loss: 0.2563\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9095 - loss: 0.2620 - val_auc: 0.8067 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9103 - loss: 0.2612 - val_auc: 0.8094 - val_binary_accuracy: 0.9104 - val_loss: 0.2542\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9103 - loss: 0.2606 - val_auc: 0.8108 - val_binary_accuracy: 0.9097 - val_loss: 0.2539\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9103 - loss: 0.2600 - val_auc: 0.8101 - val_binary_accuracy: 0.9095 - val_loss: 0.2542\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9105 - loss: 0.2591 - val_auc: 0.8119 - val_binary_accuracy: 0.9097 - val_loss: 0.2532\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7929 - binary_accuracy: 0.9092 - loss: 0.2601\n",
            "Fold 4 Metrics: Loss = 0.2532, Accuracy = 0.9097, AUC = 0.8119\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6627 - binary_accuracy: 0.8900 - loss: 0.3801 - val_auc: 0.7908 - val_binary_accuracy: 0.9064 - val_loss: 0.2643\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9036 - loss: 0.2766 - val_auc: 0.7966 - val_binary_accuracy: 0.9022 - val_loss: 0.2604\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9040 - loss: 0.2731 - val_auc: 0.8000 - val_binary_accuracy: 0.9026 - val_loss: 0.2655\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9050 - loss: 0.2698 - val_auc: 0.8031 - val_binary_accuracy: 0.9098 - val_loss: 0.2657\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9076 - loss: 0.2673 - val_auc: 0.8038 - val_binary_accuracy: 0.9103 - val_loss: 0.2662\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9067 - loss: 0.2667 - val_auc: 0.8061 - val_binary_accuracy: 0.9101 - val_loss: 0.2626\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8078 - val_binary_accuracy: 0.9109 - val_loss: 0.2629\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9085 - loss: 0.2637 - val_auc: 0.8088 - val_binary_accuracy: 0.9113 - val_loss: 0.2612\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8093 - val_binary_accuracy: 0.9112 - val_loss: 0.2606\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9089 - loss: 0.2621 - val_auc: 0.8105 - val_binary_accuracy: 0.9110 - val_loss: 0.2592\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8180 - binary_accuracy: 0.9095 - loss: 0.2583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|      | 1/3 [27:29<54:58, 1649.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 Metrics: Loss = 0.2592, Accuracy = 0.9110, AUC = 0.8105\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2597\n",
            "Average Accuracy: 0.9092\n",
            "Average AUC: 0.8063\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 1, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5407 - binary_accuracy: 0.8881 - loss: 0.4453 - val_auc: 0.7252 - val_binary_accuracy: 0.9044 - val_loss: 0.2942\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7504 - binary_accuracy: 0.9069 - loss: 0.2838 - val_auc: 0.7611 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9069 - loss: 0.2731 - val_auc: 0.7639 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9069 - loss: 0.2694 - val_auc: 0.7680 - val_binary_accuracy: 0.9044 - val_loss: 0.2769\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.7680 - val_binary_accuracy: 0.9044 - val_loss: 0.2740\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9069 - loss: 0.2637 - val_auc: 0.7704 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7703 - val_binary_accuracy: 0.9044 - val_loss: 0.2711\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9069 - loss: 0.2606 - val_auc: 0.7728 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2597 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9069 - loss: 0.2591 - val_auc: 0.7754 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7695 - binary_accuracy: 0.9084 - loss: 0.2623\n",
            "Fold 1 Metrics: Loss = 0.2693, Accuracy = 0.9044, AUC = 0.7754\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5431 - binary_accuracy: 0.6690 - loss: 0.5823 - val_auc: 0.7283 - val_binary_accuracy: 0.9042 - val_loss: 0.2975\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7313 - binary_accuracy: 0.9029 - loss: 0.2964 - val_auc: 0.7698 - val_binary_accuracy: 0.9042 - val_loss: 0.2864\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7585 - binary_accuracy: 0.9029 - loss: 0.2881 - val_auc: 0.7775 - val_binary_accuracy: 0.9042 - val_loss: 0.2786\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9029 - loss: 0.2803 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2724\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2756 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9029 - loss: 0.2730 - val_auc: 0.7930 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9029 - loss: 0.2714 - val_auc: 0.7936 - val_binary_accuracy: 0.9042 - val_loss: 0.2647\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9029 - loss: 0.2702 - val_auc: 0.7938 - val_binary_accuracy: 0.9042 - val_loss: 0.2635\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9029 - loss: 0.2692 - val_auc: 0.7980 - val_binary_accuracy: 0.9042 - val_loss: 0.2621\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9029 - loss: 0.2683 - val_auc: 0.7988 - val_binary_accuracy: 0.9042 - val_loss: 0.2610\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7984 - binary_accuracy: 0.9092 - loss: 0.2522\n",
            "Fold 2 Metrics: Loss = 0.2610, Accuracy = 0.9042, AUC = 0.7988\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5566 - binary_accuracy: 0.8404 - loss: 0.4183 - val_auc: 0.7434 - val_binary_accuracy: 0.9042 - val_loss: 0.2893\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7448 - binary_accuracy: 0.9051 - loss: 0.2850 - val_auc: 0.7576 - val_binary_accuracy: 0.9042 - val_loss: 0.2785\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9051 - loss: 0.2765 - val_auc: 0.7733 - val_binary_accuracy: 0.9042 - val_loss: 0.2735\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9051 - loss: 0.2715 - val_auc: 0.7771 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9051 - loss: 0.2685 - val_auc: 0.7793 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7828 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9051 - loss: 0.2654 - val_auc: 0.7842 - val_binary_accuracy: 0.9042 - val_loss: 0.2678\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9051 - loss: 0.2646 - val_auc: 0.7856 - val_binary_accuracy: 0.9042 - val_loss: 0.2673\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9051 - loss: 0.2636 - val_auc: 0.7896 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7821 - binary_accuracy: 0.9046 - loss: 0.2672\n",
            "Fold 3 Metrics: Loss = 0.2663, Accuracy = 0.9042, AUC = 0.7896\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5240 - binary_accuracy: 0.7788 - loss: 0.5157 - val_auc: 0.7256 - val_binary_accuracy: 0.9044 - val_loss: 0.3122\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7287 - binary_accuracy: 0.9047 - loss: 0.3036 - val_auc: 0.7630 - val_binary_accuracy: 0.9044 - val_loss: 0.2779\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7619 - binary_accuracy: 0.9047 - loss: 0.2764 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9047 - loss: 0.2717 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7742 - binary_accuracy: 0.9047 - loss: 0.2695 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9047 - loss: 0.2683 - val_auc: 0.7825 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9047 - loss: 0.2676 - val_auc: 0.7815 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9047 - loss: 0.2670 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9047 - loss: 0.2665 - val_auc: 0.7827 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9047 - loss: 0.2660 - val_auc: 0.7825 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7576 - binary_accuracy: 0.9049 - loss: 0.2724\n",
            "Fold 4 Metrics: Loss = 0.2665, Accuracy = 0.9044, AUC = 0.7825\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5757 - binary_accuracy: 0.8772 - loss: 0.3729 - val_auc: 0.7388 - val_binary_accuracy: 0.9044 - val_loss: 0.2870\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7411 - binary_accuracy: 0.9040 - loss: 0.2862 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7650 - binary_accuracy: 0.9040 - loss: 0.2755 - val_auc: 0.7852 - val_binary_accuracy: 0.9044 - val_loss: 0.2646\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7720 - binary_accuracy: 0.9049 - loss: 0.2702 - val_auc: 0.7873 - val_binary_accuracy: 0.9067 - val_loss: 0.2615\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9062 - loss: 0.2676 - val_auc: 0.7915 - val_binary_accuracy: 0.9076 - val_loss: 0.2600\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9077 - loss: 0.2660 - val_auc: 0.7935 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7824 - binary_accuracy: 0.9084 - loss: 0.2650 - val_auc: 0.7944 - val_binary_accuracy: 0.9097 - val_loss: 0.2582\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9085 - loss: 0.2643 - val_auc: 0.7955 - val_binary_accuracy: 0.9100 - val_loss: 0.2578\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9086 - loss: 0.2637 - val_auc: 0.7962 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7852 - binary_accuracy: 0.9084 - loss: 0.2633 - val_auc: 0.7966 - val_binary_accuracy: 0.9100 - val_loss: 0.2568\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8049 - binary_accuracy: 0.9085 - loss: 0.2565\n",
            "Fold 5 Metrics: Loss = 0.2568, Accuracy = 0.9100, AUC = 0.7966\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2640\n",
            "Average Accuracy: 0.9055\n",
            "Average AUC: 0.7886\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 1, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5814 - binary_accuracy: 0.6433 - loss: 0.6112 - val_auc: 0.7338 - val_binary_accuracy: 0.9044 - val_loss: 0.2928\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7551 - binary_accuracy: 0.9069 - loss: 0.2785 - val_auc: 0.7602 - val_binary_accuracy: 0.9044 - val_loss: 0.2753\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9069 - loss: 0.2657 - val_auc: 0.7694 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7941 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7769 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7977 - binary_accuracy: 0.9069 - loss: 0.2567 - val_auc: 0.7788 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7992 - binary_accuracy: 0.9070 - loss: 0.2558 - val_auc: 0.7803 - val_binary_accuracy: 0.9060 - val_loss: 0.2648\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8003 - binary_accuracy: 0.9084 - loss: 0.2548 - val_auc: 0.7815 - val_binary_accuracy: 0.9071 - val_loss: 0.2641\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8019 - binary_accuracy: 0.9096 - loss: 0.2540 - val_auc: 0.7836 - val_binary_accuracy: 0.9076 - val_loss: 0.2635\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8027 - binary_accuracy: 0.9106 - loss: 0.2534 - val_auc: 0.7855 - val_binary_accuracy: 0.9088 - val_loss: 0.2629\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7808 - binary_accuracy: 0.9122 - loss: 0.2566\n",
            "Fold 1 Metrics: Loss = 0.2629, Accuracy = 0.9088, AUC = 0.7855\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5741 - binary_accuracy: 0.7016 - loss: 0.5321 - val_auc: 0.7599 - val_binary_accuracy: 0.9042 - val_loss: 0.2855\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7551 - binary_accuracy: 0.9029 - loss: 0.2834 - val_auc: 0.7829 - val_binary_accuracy: 0.9042 - val_loss: 0.2736\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9029 - loss: 0.2756 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7805 - binary_accuracy: 0.9029 - loss: 0.2717 - val_auc: 0.7976 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9029 - loss: 0.2694 - val_auc: 0.8017 - val_binary_accuracy: 0.9042 - val_loss: 0.2658\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9029 - loss: 0.2679 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2636\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9045 - loss: 0.2666 - val_auc: 0.8037 - val_binary_accuracy: 0.9048 - val_loss: 0.2610\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9054 - loss: 0.2651 - val_auc: 0.8046 - val_binary_accuracy: 0.9057 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9065 - loss: 0.2641 - val_auc: 0.8073 - val_binary_accuracy: 0.9066 - val_loss: 0.2590\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9070 - loss: 0.2632 - val_auc: 0.8092 - val_binary_accuracy: 0.9069 - val_loss: 0.2584\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8106 - binary_accuracy: 0.9109 - loss: 0.2493\n",
            "Fold 2 Metrics: Loss = 0.2584, Accuracy = 0.9069, AUC = 0.8092\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6599 - binary_accuracy: 0.9042 - loss: 0.3330 - val_auc: 0.7664 - val_binary_accuracy: 0.9042 - val_loss: 0.2731\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9051 - loss: 0.2704 - val_auc: 0.7746 - val_binary_accuracy: 0.9042 - val_loss: 0.2704\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9051 - loss: 0.2674 - val_auc: 0.7760 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9051 - loss: 0.2659 - val_auc: 0.7795 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7805 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2641 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2665\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9053 - loss: 0.2633 - val_auc: 0.7856 - val_binary_accuracy: 0.9057 - val_loss: 0.2654\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7857 - binary_accuracy: 0.9065 - loss: 0.2623 - val_auc: 0.7881 - val_binary_accuracy: 0.9069 - val_loss: 0.2643\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7871 - binary_accuracy: 0.9072 - loss: 0.2613 - val_auc: 0.7913 - val_binary_accuracy: 0.9090 - val_loss: 0.2630\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9075 - loss: 0.2604 - val_auc: 0.7932 - val_binary_accuracy: 0.9093 - val_loss: 0.2620\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7855 - binary_accuracy: 0.9099 - loss: 0.2633\n",
            "Fold 3 Metrics: Loss = 0.2620, Accuracy = 0.9093, AUC = 0.7932\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5827 - binary_accuracy: 0.6991 - loss: 0.5044 - val_auc: 0.7478 - val_binary_accuracy: 0.9044 - val_loss: 0.2858\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7446 - binary_accuracy: 0.9047 - loss: 0.2826 - val_auc: 0.7729 - val_binary_accuracy: 0.9044 - val_loss: 0.2749\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9047 - loss: 0.2730 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9047 - loss: 0.2686 - val_auc: 0.7858 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9047 - loss: 0.2663 - val_auc: 0.7884 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9048 - loss: 0.2643 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7868 - binary_accuracy: 0.9052 - loss: 0.2632 - val_auc: 0.7899 - val_binary_accuracy: 0.9047 - val_loss: 0.2660\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9070 - loss: 0.2623 - val_auc: 0.7910 - val_binary_accuracy: 0.9056 - val_loss: 0.2654\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9087 - loss: 0.2615 - val_auc: 0.7925 - val_binary_accuracy: 0.9070 - val_loss: 0.2648\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9089 - loss: 0.2606 - val_auc: 0.7934 - val_binary_accuracy: 0.9076 - val_loss: 0.2642\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7696 - binary_accuracy: 0.9062 - loss: 0.2695\n",
            "Fold 4 Metrics: Loss = 0.2642, Accuracy = 0.9076, AUC = 0.7934\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6358 - binary_accuracy: 0.9040 - loss: 0.3280 - val_auc: 0.7817 - val_binary_accuracy: 0.9044 - val_loss: 0.2685\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9040 - loss: 0.2742 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7746 - binary_accuracy: 0.9040 - loss: 0.2710 - val_auc: 0.7913 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.7956 - val_binary_accuracy: 0.9044 - val_loss: 0.2601\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7818 - binary_accuracy: 0.9040 - loss: 0.2679 - val_auc: 0.7975 - val_binary_accuracy: 0.9044 - val_loss: 0.2589\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9042 - loss: 0.2666 - val_auc: 0.7992 - val_binary_accuracy: 0.9048 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7997 - val_binary_accuracy: 0.9053 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9065 - loss: 0.2647 - val_auc: 0.8003 - val_binary_accuracy: 0.9073 - val_loss: 0.2565\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9070 - loss: 0.2638 - val_auc: 0.8006 - val_binary_accuracy: 0.9085 - val_loss: 0.2558\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9080 - loss: 0.2630 - val_auc: 0.8014 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8118 - binary_accuracy: 0.9068 - loss: 0.2537\n",
            "Fold 5 Metrics: Loss = 0.2550, Accuracy = 0.9090, AUC = 0.8014\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2605\n",
            "Average Accuracy: 0.9083\n",
            "Average AUC: 0.7965\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 1, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6186 - binary_accuracy: 0.8966 - loss: 0.3419 - val_auc: 0.7591 - val_binary_accuracy: 0.9044 - val_loss: 0.2778\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9069 - loss: 0.2665 - val_auc: 0.7716 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9070 - loss: 0.2587 - val_auc: 0.7766 - val_binary_accuracy: 0.9060 - val_loss: 0.2672\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9098 - loss: 0.2561 - val_auc: 0.7801 - val_binary_accuracy: 0.9073 - val_loss: 0.2654\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9113 - loss: 0.2543 - val_auc: 0.7829 - val_binary_accuracy: 0.9088 - val_loss: 0.2639\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9120 - loss: 0.2527 - val_auc: 0.7854 - val_binary_accuracy: 0.9099 - val_loss: 0.2624\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9123 - loss: 0.2513 - val_auc: 0.7874 - val_binary_accuracy: 0.9094 - val_loss: 0.2613\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9123 - loss: 0.2503 - val_auc: 0.7893 - val_binary_accuracy: 0.9093 - val_loss: 0.2608\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8094 - binary_accuracy: 0.9129 - loss: 0.2494 - val_auc: 0.7898 - val_binary_accuracy: 0.9091 - val_loss: 0.2603\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9128 - loss: 0.2486 - val_auc: 0.7912 - val_binary_accuracy: 0.9096 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7863 - binary_accuracy: 0.9139 - loss: 0.2541\n",
            "Fold 1 Metrics: Loss = 0.2599, Accuracy = 0.9096, AUC = 0.7912\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6473 - binary_accuracy: 0.9029 - loss: 0.3159 - val_auc: 0.7858 - val_binary_accuracy: 0.9042 - val_loss: 0.2720\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9029 - loss: 0.2745 - val_auc: 0.7967 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.7998 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9031 - loss: 0.2680 - val_auc: 0.8024 - val_binary_accuracy: 0.9044 - val_loss: 0.2627\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9045 - loss: 0.2662 - val_auc: 0.8050 - val_binary_accuracy: 0.9057 - val_loss: 0.2602\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9060 - loss: 0.2646 - val_auc: 0.8058 - val_binary_accuracy: 0.9060 - val_loss: 0.2592\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9070 - loss: 0.2627 - val_auc: 0.8070 - val_binary_accuracy: 0.9062 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9073 - loss: 0.2615 - val_auc: 0.8076 - val_binary_accuracy: 0.9071 - val_loss: 0.2590\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9080 - loss: 0.2604 - val_auc: 0.8090 - val_binary_accuracy: 0.9078 - val_loss: 0.2587\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8017 - binary_accuracy: 0.9078 - loss: 0.2596 - val_auc: 0.8100 - val_binary_accuracy: 0.9081 - val_loss: 0.2583\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8147 - binary_accuracy: 0.9118 - loss: 0.2477\n",
            "Fold 2 Metrics: Loss = 0.2583, Accuracy = 0.9081, AUC = 0.8100\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7156 - binary_accuracy: 0.9051 - loss: 0.2877 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7728 - binary_accuracy: 0.9051 - loss: 0.2691 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7798 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7847 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9053 - loss: 0.2639 - val_auc: 0.7893 - val_binary_accuracy: 0.9048 - val_loss: 0.2648\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7860 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.7926 - val_binary_accuracy: 0.9076 - val_loss: 0.2628\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9076 - loss: 0.2611 - val_auc: 0.7957 - val_binary_accuracy: 0.9094 - val_loss: 0.2615\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7907 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.7979 - val_binary_accuracy: 0.9100 - val_loss: 0.2604\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7916 - binary_accuracy: 0.9094 - loss: 0.2593 - val_auc: 0.7993 - val_binary_accuracy: 0.9102 - val_loss: 0.2594\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7931 - binary_accuracy: 0.9095 - loss: 0.2587 - val_auc: 0.8006 - val_binary_accuracy: 0.9103 - val_loss: 0.2587\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7939 - binary_accuracy: 0.9098 - loss: 0.2582 - val_auc: 0.8025 - val_binary_accuracy: 0.9104 - val_loss: 0.2580\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9120 - loss: 0.2587\n",
            "Fold 3 Metrics: Loss = 0.2580, Accuracy = 0.9104, AUC = 0.8025\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5983 - binary_accuracy: 0.7126 - loss: 0.5437 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2777\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7606 - binary_accuracy: 0.9047 - loss: 0.2754 - val_auc: 0.7823 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9047 - loss: 0.2678 - val_auc: 0.7875 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7826 - binary_accuracy: 0.9050 - loss: 0.2653 - val_auc: 0.7899 - val_binary_accuracy: 0.9045 - val_loss: 0.2673\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9062 - loss: 0.2637 - val_auc: 0.7929 - val_binary_accuracy: 0.9057 - val_loss: 0.2662\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9083 - loss: 0.2622 - val_auc: 0.7957 - val_binary_accuracy: 0.9070 - val_loss: 0.2653\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.7975 - val_binary_accuracy: 0.9079 - val_loss: 0.2640\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9091 - loss: 0.2601 - val_auc: 0.7994 - val_binary_accuracy: 0.9085 - val_loss: 0.2632\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9096 - loss: 0.2593 - val_auc: 0.8001 - val_binary_accuracy: 0.9091 - val_loss: 0.2626\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9100 - loss: 0.2586 - val_auc: 0.8017 - val_binary_accuracy: 0.9094 - val_loss: 0.2622\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7809 - binary_accuracy: 0.9092 - loss: 0.2677\n",
            "Fold 4 Metrics: Loss = 0.2622, Accuracy = 0.9094, AUC = 0.8017\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6977 - binary_accuracy: 0.9040 - loss: 0.2969 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9040 - loss: 0.2689 - val_auc: 0.7955 - val_binary_accuracy: 0.9047 - val_loss: 0.2596\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9045 - loss: 0.2668 - val_auc: 0.7981 - val_binary_accuracy: 0.9060 - val_loss: 0.2578\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9057 - loss: 0.2653 - val_auc: 0.8018 - val_binary_accuracy: 0.9087 - val_loss: 0.2560\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.8029 - val_binary_accuracy: 0.9087 - val_loss: 0.2553\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9084 - loss: 0.2627 - val_auc: 0.8040 - val_binary_accuracy: 0.9093 - val_loss: 0.2545\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9087 - loss: 0.2618 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2537\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9094 - loss: 0.2611 - val_auc: 0.8062 - val_binary_accuracy: 0.9104 - val_loss: 0.2530\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9100 - loss: 0.2602 - val_auc: 0.8068 - val_binary_accuracy: 0.9104 - val_loss: 0.2525\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9084 - loss: 0.2513\n",
            "Fold 5 Metrics: Loss = 0.2525, Accuracy = 0.9104, AUC = 0.8068\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2582\n",
            "Average Accuracy: 0.9096\n",
            "Average AUC: 0.8025\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 1, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6868 - binary_accuracy: 0.9069 - loss: 0.2956 - val_auc: 0.7720 - val_binary_accuracy: 0.9044 - val_loss: 0.2714\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9075 - loss: 0.2586 - val_auc: 0.7812 - val_binary_accuracy: 0.9069 - val_loss: 0.2663\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9093 - loss: 0.2549 - val_auc: 0.7856 - val_binary_accuracy: 0.9082 - val_loss: 0.2640\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9118 - loss: 0.2526 - val_auc: 0.7884 - val_binary_accuracy: 0.9079 - val_loss: 0.2622\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9130 - loss: 0.2509 - val_auc: 0.7903 - val_binary_accuracy: 0.9085 - val_loss: 0.2610\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9129 - loss: 0.2493 - val_auc: 0.7918 - val_binary_accuracy: 0.9085 - val_loss: 0.2604\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9128 - loss: 0.2484 - val_auc: 0.7930 - val_binary_accuracy: 0.9085 - val_loss: 0.2600\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9127 - loss: 0.2475 - val_auc: 0.7938 - val_binary_accuracy: 0.9087 - val_loss: 0.2597\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8133 - binary_accuracy: 0.9127 - loss: 0.2469 - val_auc: 0.7941 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9126 - loss: 0.2463 - val_auc: 0.7949 - val_binary_accuracy: 0.9090 - val_loss: 0.2591\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7946 - binary_accuracy: 0.9128 - loss: 0.2521\n",
            "Fold 1 Metrics: Loss = 0.2591, Accuracy = 0.9090, AUC = 0.7949\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6517 - binary_accuracy: 0.8179 - loss: 0.3826 - val_auc: 0.7930 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8002 - val_binary_accuracy: 0.9042 - val_loss: 0.2628\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9042 - loss: 0.2661 - val_auc: 0.8058 - val_binary_accuracy: 0.9048 - val_loss: 0.2597\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9064 - loss: 0.2636 - val_auc: 0.8082 - val_binary_accuracy: 0.9060 - val_loss: 0.2586\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9069 - loss: 0.2619 - val_auc: 0.8095 - val_binary_accuracy: 0.9062 - val_loss: 0.2579\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.8110 - val_binary_accuracy: 0.9072 - val_loss: 0.2570\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9081 - loss: 0.2598 - val_auc: 0.8115 - val_binary_accuracy: 0.9073 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9080 - loss: 0.2591 - val_auc: 0.8116 - val_binary_accuracy: 0.9076 - val_loss: 0.2568\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9079 - loss: 0.2584 - val_auc: 0.8129 - val_binary_accuracy: 0.9082 - val_loss: 0.2565\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9083 - loss: 0.2578 - val_auc: 0.8133 - val_binary_accuracy: 0.9084 - val_loss: 0.2565\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8198 - binary_accuracy: 0.9127 - loss: 0.2454\n",
            "Fold 2 Metrics: Loss = 0.2565, Accuracy = 0.9084, AUC = 0.8133\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6423 - binary_accuracy: 0.8182 - loss: 0.3870 - val_auc: 0.7731 - val_binary_accuracy: 0.9042 - val_loss: 0.2711\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9052 - loss: 0.2688 - val_auc: 0.7804 - val_binary_accuracy: 0.9045 - val_loss: 0.2677\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9071 - loss: 0.2651 - val_auc: 0.7852 - val_binary_accuracy: 0.9079 - val_loss: 0.2652\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9081 - loss: 0.2633 - val_auc: 0.7890 - val_binary_accuracy: 0.9102 - val_loss: 0.2631\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9090 - loss: 0.2618 - val_auc: 0.7941 - val_binary_accuracy: 0.9099 - val_loss: 0.2611\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9095 - loss: 0.2605 - val_auc: 0.7981 - val_binary_accuracy: 0.9103 - val_loss: 0.2593\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9094 - loss: 0.2595 - val_auc: 0.8009 - val_binary_accuracy: 0.9113 - val_loss: 0.2581\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9096 - loss: 0.2587 - val_auc: 0.8031 - val_binary_accuracy: 0.9113 - val_loss: 0.2570\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9094 - loss: 0.2581 - val_auc: 0.8049 - val_binary_accuracy: 0.9115 - val_loss: 0.2562\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9096 - loss: 0.2576 - val_auc: 0.8059 - val_binary_accuracy: 0.9113 - val_loss: 0.2557\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9125 - loss: 0.2569\n",
            "Fold 3 Metrics: Loss = 0.2557, Accuracy = 0.9113, AUC = 0.8059\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6984 - binary_accuracy: 0.9049 - loss: 0.2910 - val_auc: 0.7864 - val_binary_accuracy: 0.9051 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7942 - val_binary_accuracy: 0.9066 - val_loss: 0.2623\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.7989 - val_binary_accuracy: 0.9078 - val_loss: 0.2601\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9095 - loss: 0.2601 - val_auc: 0.8015 - val_binary_accuracy: 0.9084 - val_loss: 0.2583\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9104 - loss: 0.2586 - val_auc: 0.8059 - val_binary_accuracy: 0.9087 - val_loss: 0.2570\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9109 - loss: 0.2575 - val_auc: 0.8062 - val_binary_accuracy: 0.9093 - val_loss: 0.2563\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9107 - loss: 0.2567 - val_auc: 0.8087 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7990 - binary_accuracy: 0.9108 - loss: 0.2559 - val_auc: 0.8093 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9110 - loss: 0.2555 - val_auc: 0.8103 - val_binary_accuracy: 0.9095 - val_loss: 0.2552\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9113 - loss: 0.2550 - val_auc: 0.8101 - val_binary_accuracy: 0.9095 - val_loss: 0.2549\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7899 - binary_accuracy: 0.9090 - loss: 0.2617\n",
            "Fold 4 Metrics: Loss = 0.2549, Accuracy = 0.9095, AUC = 0.8101\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6479 - binary_accuracy: 0.8353 - loss: 0.3740 - val_auc: 0.7840 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9040 - loss: 0.2720 - val_auc: 0.7910 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9044 - loss: 0.2683 - val_auc: 0.7960 - val_binary_accuracy: 0.9067 - val_loss: 0.2589\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9064 - loss: 0.2662 - val_auc: 0.7995 - val_binary_accuracy: 0.9079 - val_loss: 0.2572\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7868 - binary_accuracy: 0.9084 - loss: 0.2645 - val_auc: 0.8025 - val_binary_accuracy: 0.9095 - val_loss: 0.2556\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7902 - binary_accuracy: 0.9086 - loss: 0.2630 - val_auc: 0.8039 - val_binary_accuracy: 0.9100 - val_loss: 0.2545\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7913 - binary_accuracy: 0.9089 - loss: 0.2617 - val_auc: 0.8054 - val_binary_accuracy: 0.9101 - val_loss: 0.2537\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7936 - binary_accuracy: 0.9093 - loss: 0.2608 - val_auc: 0.8058 - val_binary_accuracy: 0.9107 - val_loss: 0.2531\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9098 - loss: 0.2600 - val_auc: 0.8060 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9102 - loss: 0.2594 - val_auc: 0.8069 - val_binary_accuracy: 0.9107 - val_loss: 0.2522\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8153 - binary_accuracy: 0.9089 - loss: 0.2510\n",
            "Fold 5 Metrics: Loss = 0.2522, Accuracy = 0.9107, AUC = 0.8069\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2557\n",
            "Average Accuracy: 0.9098\n",
            "Average AUC: 0.8062\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 1, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6850 - binary_accuracy: 0.8710 - loss: 0.3234 - val_auc: 0.7733 - val_binary_accuracy: 0.9051 - val_loss: 0.2710\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.7813 - val_binary_accuracy: 0.9076 - val_loss: 0.2667\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9107 - loss: 0.2548 - val_auc: 0.7862 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7903 - val_binary_accuracy: 0.9088 - val_loss: 0.2613\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9128 - loss: 0.2501 - val_auc: 0.7922 - val_binary_accuracy: 0.9087 - val_loss: 0.2602\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8095 - binary_accuracy: 0.9126 - loss: 0.2488 - val_auc: 0.7933 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9127 - loss: 0.2477 - val_auc: 0.7948 - val_binary_accuracy: 0.9088 - val_loss: 0.2590\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8135 - binary_accuracy: 0.9127 - loss: 0.2469 - val_auc: 0.7953 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8146 - binary_accuracy: 0.9128 - loss: 0.2462 - val_auc: 0.7952 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8154 - binary_accuracy: 0.9127 - loss: 0.2457 - val_auc: 0.7962 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7961 - binary_accuracy: 0.9129 - loss: 0.2514\n",
            "Fold 1 Metrics: Loss = 0.2586, Accuracy = 0.9088, AUC = 0.7962\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6677 - binary_accuracy: 0.8441 - loss: 0.3601 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2654\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9036 - loss: 0.2691 - val_auc: 0.8037 - val_binary_accuracy: 0.9054 - val_loss: 0.2597\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9055 - loss: 0.2651 - val_auc: 0.8071 - val_binary_accuracy: 0.9068 - val_loss: 0.2577\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9074 - loss: 0.2630 - val_auc: 0.8099 - val_binary_accuracy: 0.9073 - val_loss: 0.2569\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9077 - loss: 0.2616 - val_auc: 0.8116 - val_binary_accuracy: 0.9078 - val_loss: 0.2558\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9078 - loss: 0.2605 - val_auc: 0.8123 - val_binary_accuracy: 0.9079 - val_loss: 0.2555\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9085 - loss: 0.2597 - val_auc: 0.8131 - val_binary_accuracy: 0.9081 - val_loss: 0.2549\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9084 - loss: 0.2589 - val_auc: 0.8136 - val_binary_accuracy: 0.9084 - val_loss: 0.2546\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9085 - loss: 0.2582 - val_auc: 0.8140 - val_binary_accuracy: 0.9090 - val_loss: 0.2543\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9084 - loss: 0.2576 - val_auc: 0.8145 - val_binary_accuracy: 0.9088 - val_loss: 0.2541\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8208 - binary_accuracy: 0.9133 - loss: 0.2435\n",
            "Fold 2 Metrics: Loss = 0.2541, Accuracy = 0.9088, AUC = 0.8145\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6643 - binary_accuracy: 0.8778 - loss: 0.3242 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9067 - loss: 0.2680 - val_auc: 0.7863 - val_binary_accuracy: 0.9075 - val_loss: 0.2657\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9081 - loss: 0.2653 - val_auc: 0.7920 - val_binary_accuracy: 0.9097 - val_loss: 0.2632\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9085 - loss: 0.2632 - val_auc: 0.7953 - val_binary_accuracy: 0.9100 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9092 - loss: 0.2618 - val_auc: 0.7988 - val_binary_accuracy: 0.9107 - val_loss: 0.2594\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9092 - loss: 0.2609 - val_auc: 0.8003 - val_binary_accuracy: 0.9110 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9096 - loss: 0.2600 - val_auc: 0.8029 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9099 - loss: 0.2594 - val_auc: 0.8035 - val_binary_accuracy: 0.9112 - val_loss: 0.2564\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9098 - loss: 0.2589 - val_auc: 0.8053 - val_binary_accuracy: 0.9110 - val_loss: 0.2557\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7922 - binary_accuracy: 0.9098 - loss: 0.2585 - val_auc: 0.8063 - val_binary_accuracy: 0.9109 - val_loss: 0.2553\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9118 - loss: 0.2562\n",
            "Fold 3 Metrics: Loss = 0.2553, Accuracy = 0.9109, AUC = 0.8063\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7242 - binary_accuracy: 0.9052 - loss: 0.2848 - val_auc: 0.7915 - val_binary_accuracy: 0.9070 - val_loss: 0.2633\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9078 - loss: 0.2645 - val_auc: 0.7983 - val_binary_accuracy: 0.9081 - val_loss: 0.2597\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9098 - loss: 0.2612 - val_auc: 0.8017 - val_binary_accuracy: 0.9094 - val_loss: 0.2577\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9100 - loss: 0.2594 - val_auc: 0.8051 - val_binary_accuracy: 0.9098 - val_loss: 0.2564\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9106 - loss: 0.2580 - val_auc: 0.8077 - val_binary_accuracy: 0.9097 - val_loss: 0.2554\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9111 - loss: 0.2572 - val_auc: 0.8084 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9109 - loss: 0.2566 - val_auc: 0.8094 - val_binary_accuracy: 0.9091 - val_loss: 0.2543\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9109 - loss: 0.2561 - val_auc: 0.8105 - val_binary_accuracy: 0.9093 - val_loss: 0.2539\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9111 - loss: 0.2557 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2536\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9110 - loss: 0.2553 - val_auc: 0.8117 - val_binary_accuracy: 0.9093 - val_loss: 0.2535\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7926 - binary_accuracy: 0.9089 - loss: 0.2605\n",
            "Fold 4 Metrics: Loss = 0.2535, Accuracy = 0.9093, AUC = 0.8117\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6878 - binary_accuracy: 0.8724 - loss: 0.3236 - val_auc: 0.7872 - val_binary_accuracy: 0.9045 - val_loss: 0.2643\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9059 - loss: 0.2700 - val_auc: 0.7952 - val_binary_accuracy: 0.9081 - val_loss: 0.2600\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9086 - loss: 0.2667 - val_auc: 0.7990 - val_binary_accuracy: 0.9090 - val_loss: 0.2569\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9090 - loss: 0.2644 - val_auc: 0.8026 - val_binary_accuracy: 0.9098 - val_loss: 0.2549\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9092 - loss: 0.2627 - val_auc: 0.8057 - val_binary_accuracy: 0.9103 - val_loss: 0.2531\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9095 - loss: 0.2615 - val_auc: 0.8067 - val_binary_accuracy: 0.9106 - val_loss: 0.2527\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9097 - loss: 0.2605 - val_auc: 0.8076 - val_binary_accuracy: 0.9109 - val_loss: 0.2521\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9102 - loss: 0.2598 - val_auc: 0.8080 - val_binary_accuracy: 0.9109 - val_loss: 0.2519\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9105 - loss: 0.2593 - val_auc: 0.8081 - val_binary_accuracy: 0.9112 - val_loss: 0.2518\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9105 - loss: 0.2589 - val_auc: 0.8085 - val_binary_accuracy: 0.9112 - val_loss: 0.2518\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9094 - loss: 0.2510\n",
            "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9112, AUC = 0.8085\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2547\n",
            "Average Accuracy: 0.9098\n",
            "Average AUC: 0.8074\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 2, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5174 - binary_accuracy: 0.5824 - loss: 0.6365 - val_auc: 0.7352 - val_binary_accuracy: 0.9044 - val_loss: 0.3114\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7387 - binary_accuracy: 0.9069 - loss: 0.2987 - val_auc: 0.7471 - val_binary_accuracy: 0.9044 - val_loss: 0.2900\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9069 - loss: 0.2792 - val_auc: 0.7612 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9069 - loss: 0.2687 - val_auc: 0.7653 - val_binary_accuracy: 0.9044 - val_loss: 0.2737\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.7718 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9069 - loss: 0.2593 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9069 - loss: 0.2575 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9069 - loss: 0.2563 - val_auc: 0.7763 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9069 - loss: 0.2556 - val_auc: 0.7774 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9070 - loss: 0.2550 - val_auc: 0.7796 - val_binary_accuracy: 0.9045 - val_loss: 0.2656\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7781 - binary_accuracy: 0.9086 - loss: 0.2584\n",
            "Fold 1 Metrics: Loss = 0.2656, Accuracy = 0.9045, AUC = 0.7796\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.4830 - binary_accuracy: 0.8103 - loss: 0.4890 - val_auc: 0.6652 - val_binary_accuracy: 0.9042 - val_loss: 0.3137\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.6821 - binary_accuracy: 0.9029 - loss: 0.3148 - val_auc: 0.7370 - val_binary_accuracy: 0.9042 - val_loss: 0.3088\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7247 - binary_accuracy: 0.9029 - loss: 0.3110 - val_auc: 0.7555 - val_binary_accuracy: 0.9042 - val_loss: 0.3041\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7427 - binary_accuracy: 0.9029 - loss: 0.3017 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2867\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9029 - loss: 0.2871 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2750\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9029 - loss: 0.2775 - val_auc: 0.7827 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9029 - loss: 0.2730 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2709 - val_auc: 0.7922 - val_binary_accuracy: 0.9042 - val_loss: 0.2637\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9029 - loss: 0.2699 - val_auc: 0.7948 - val_binary_accuracy: 0.9042 - val_loss: 0.2627\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9029 - loss: 0.2693 - val_auc: 0.8002 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7975 - binary_accuracy: 0.9092 - loss: 0.2542\n",
            "Fold 2 Metrics: Loss = 0.2623, Accuracy = 0.9042, AUC = 0.8002\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5581 - binary_accuracy: 0.6994 - loss: 0.5267 - val_auc: 0.7585 - val_binary_accuracy: 0.9042 - val_loss: 0.2914\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7546 - binary_accuracy: 0.9051 - loss: 0.2867 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2786\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9051 - loss: 0.2750 - val_auc: 0.7714 - val_binary_accuracy: 0.9042 - val_loss: 0.2728\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9051 - loss: 0.2698 - val_auc: 0.7789 - val_binary_accuracy: 0.9042 - val_loss: 0.2709\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7759 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9051 - loss: 0.2662 - val_auc: 0.7798 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9051 - loss: 0.2650 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7838 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9051 - loss: 0.2629 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9051 - loss: 0.2620 - val_auc: 0.7877 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7815 - binary_accuracy: 0.9046 - loss: 0.2655\n",
            "Fold 3 Metrics: Loss = 0.2652, Accuracy = 0.9042, AUC = 0.7877\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5508 - binary_accuracy: 0.8437 - loss: 0.4380 - val_auc: 0.7529 - val_binary_accuracy: 0.9044 - val_loss: 0.2950\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7393 - binary_accuracy: 0.9047 - loss: 0.2905 - val_auc: 0.7674 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9047 - loss: 0.2774 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2739\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9047 - loss: 0.2707 - val_auc: 0.7860 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9047 - loss: 0.2674 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9047 - loss: 0.2660 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9047 - loss: 0.2650 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9047 - loss: 0.2643 - val_auc: 0.7931 - val_binary_accuracy: 0.9044 - val_loss: 0.2653\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9047 - loss: 0.2636 - val_auc: 0.7944 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9047 - loss: 0.2630 - val_auc: 0.7947 - val_binary_accuracy: 0.9044 - val_loss: 0.2644\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7729 - binary_accuracy: 0.9049 - loss: 0.2691\n",
            "Fold 4 Metrics: Loss = 0.2644, Accuracy = 0.9044, AUC = 0.7947\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5074 - binary_accuracy: 0.7590 - loss: 0.4816 - val_auc: 0.7335 - val_binary_accuracy: 0.9044 - val_loss: 0.3036\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7281 - binary_accuracy: 0.9040 - loss: 0.3030 - val_auc: 0.7601 - val_binary_accuracy: 0.9044 - val_loss: 0.2946\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7483 - binary_accuracy: 0.9040 - loss: 0.2945 - val_auc: 0.7685 - val_binary_accuracy: 0.9044 - val_loss: 0.2823\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9040 - loss: 0.2834 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2738\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9040 - loss: 0.2769 - val_auc: 0.7779 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9040 - loss: 0.2725 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9040 - loss: 0.2719 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7885 - val_binary_accuracy: 0.9044 - val_loss: 0.2632\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9040 - loss: 0.2711 - val_auc: 0.7895 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7987 - binary_accuracy: 0.9013 - loss: 0.2630\n",
            "Fold 5 Metrics: Loss = 0.2626, Accuracy = 0.9044, AUC = 0.7895\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2640\n",
            "Average Accuracy: 0.9044\n",
            "Average AUC: 0.7904\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 2, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - auc: 0.5151 - binary_accuracy: 0.6644 - loss: 0.5768 - val_auc: 0.7096 - val_binary_accuracy: 0.9044 - val_loss: 0.3085\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7242 - binary_accuracy: 0.9069 - loss: 0.2999 - val_auc: 0.7472 - val_binary_accuracy: 0.9044 - val_loss: 0.2943\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9069 - loss: 0.2826 - val_auc: 0.7603 - val_binary_accuracy: 0.9044 - val_loss: 0.2804\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9069 - loss: 0.2683 - val_auc: 0.7607 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9069 - loss: 0.2616 - val_auc: 0.7689 - val_binary_accuracy: 0.9044 - val_loss: 0.2704\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2596 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2696\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9069 - loss: 0.2587 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9069 - loss: 0.2581 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9069 - loss: 0.2576 - val_auc: 0.7752 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9069 - loss: 0.2571 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7735 - binary_accuracy: 0.9084 - loss: 0.2604\n",
            "Fold 1 Metrics: Loss = 0.2680, Accuracy = 0.9044, AUC = 0.7751\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5828 - binary_accuracy: 0.9020 - loss: 0.3681 - val_auc: 0.7650 - val_binary_accuracy: 0.9042 - val_loss: 0.2861\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9029 - loss: 0.2832 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2711 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2650\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9029 - loss: 0.2675 - val_auc: 0.8000 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9048 - loss: 0.2648 - val_auc: 0.8026 - val_binary_accuracy: 0.9047 - val_loss: 0.2616\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9063 - loss: 0.2628 - val_auc: 0.8053 - val_binary_accuracy: 0.9062 - val_loss: 0.2609\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.8073 - val_binary_accuracy: 0.9069 - val_loss: 0.2602\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9075 - loss: 0.2603 - val_auc: 0.8085 - val_binary_accuracy: 0.9075 - val_loss: 0.2595\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9078 - loss: 0.2594 - val_auc: 0.8092 - val_binary_accuracy: 0.9079 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.8113 - val_binary_accuracy: 0.9082 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8159 - binary_accuracy: 0.9121 - loss: 0.2488\n",
            "Fold 2 Metrics: Loss = 0.2587, Accuracy = 0.9082, AUC = 0.8113\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5187 - binary_accuracy: 0.7906 - loss: 0.4414 - val_auc: 0.7587 - val_binary_accuracy: 0.9042 - val_loss: 0.2873\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9051 - loss: 0.2828 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7817 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9051 - loss: 0.2665 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2673\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9051 - loss: 0.2635 - val_auc: 0.7881 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9051 - loss: 0.2629 - val_auc: 0.7891 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9051 - loss: 0.2624 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2649\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9058 - loss: 0.2616 - val_auc: 0.7917 - val_binary_accuracy: 0.9079 - val_loss: 0.2639\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9074 - loss: 0.2644\n",
            "Fold 3 Metrics: Loss = 0.2639, Accuracy = 0.9079, AUC = 0.7917\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5575 - binary_accuracy: 0.9047 - loss: 0.3670 - val_auc: 0.7704 - val_binary_accuracy: 0.9044 - val_loss: 0.2877\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7604 - binary_accuracy: 0.9047 - loss: 0.2814 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9047 - loss: 0.2677 - val_auc: 0.7826 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9047 - loss: 0.2653 - val_auc: 0.7867 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9050 - loss: 0.2641 - val_auc: 0.7887 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9066 - loss: 0.2633 - val_auc: 0.7932 - val_binary_accuracy: 0.9053 - val_loss: 0.2648\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9083 - loss: 0.2622 - val_auc: 0.7934 - val_binary_accuracy: 0.9067 - val_loss: 0.2640\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9091 - loss: 0.2612 - val_auc: 0.7963 - val_binary_accuracy: 0.9070 - val_loss: 0.2631\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9094 - loss: 0.2602 - val_auc: 0.7984 - val_binary_accuracy: 0.9078 - val_loss: 0.2622\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9097 - loss: 0.2593 - val_auc: 0.8003 - val_binary_accuracy: 0.9088 - val_loss: 0.2612\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7793 - binary_accuracy: 0.9080 - loss: 0.2669\n",
            "Fold 4 Metrics: Loss = 0.2612, Accuracy = 0.9088, AUC = 0.8003\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5635 - binary_accuracy: 0.8763 - loss: 0.3911 - val_auc: 0.7609 - val_binary_accuracy: 0.9044 - val_loss: 0.2932\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7480 - binary_accuracy: 0.9040 - loss: 0.2910 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2742\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9040 - loss: 0.2766 - val_auc: 0.7842 - val_binary_accuracy: 0.9044 - val_loss: 0.2644\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9040 - loss: 0.2706 - val_auc: 0.7881 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9040 - loss: 0.2687 - val_auc: 0.7936 - val_binary_accuracy: 0.9044 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9040 - loss: 0.2671 - val_auc: 0.7967 - val_binary_accuracy: 0.9060 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9058 - loss: 0.2654 - val_auc: 0.7970 - val_binary_accuracy: 0.9084 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9079 - loss: 0.2640 - val_auc: 0.7987 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9083 - loss: 0.2627 - val_auc: 0.7978 - val_binary_accuracy: 0.9097 - val_loss: 0.2558\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9090 - loss: 0.2615 - val_auc: 0.7997 - val_binary_accuracy: 0.9101 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8093 - binary_accuracy: 0.9079 - loss: 0.2532\n",
            "Fold 5 Metrics: Loss = 0.2552, Accuracy = 0.9101, AUC = 0.7997\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2614\n",
            "Average Accuracy: 0.9079\n",
            "Average AUC: 0.7956\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 2, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6283 - binary_accuracy: 0.9033 - loss: 0.3333 - val_auc: 0.7664 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9069 - loss: 0.2620 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9069 - loss: 0.2575 - val_auc: 0.7791 - val_binary_accuracy: 0.9041 - val_loss: 0.2672\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9072 - loss: 0.2550 - val_auc: 0.7825 - val_binary_accuracy: 0.9065 - val_loss: 0.2653\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9093 - loss: 0.2530 - val_auc: 0.7846 - val_binary_accuracy: 0.9079 - val_loss: 0.2638\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9110 - loss: 0.2512 - val_auc: 0.7873 - val_binary_accuracy: 0.9088 - val_loss: 0.2625\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9120 - loss: 0.2498 - val_auc: 0.7885 - val_binary_accuracy: 0.9084 - val_loss: 0.2616\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9123 - loss: 0.2487 - val_auc: 0.7895 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8114 - binary_accuracy: 0.9124 - loss: 0.2480 - val_auc: 0.7895 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8123 - binary_accuracy: 0.9124 - loss: 0.2473 - val_auc: 0.7904 - val_binary_accuracy: 0.9085 - val_loss: 0.2603\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7897 - binary_accuracy: 0.9113 - loss: 0.2530\n",
            "Fold 1 Metrics: Loss = 0.2603, Accuracy = 0.9085, AUC = 0.7904\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6523 - binary_accuracy: 0.9029 - loss: 0.3193 - val_auc: 0.7889 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9029 - loss: 0.2714 - val_auc: 0.7968 - val_binary_accuracy: 0.9042 - val_loss: 0.2625\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9038 - loss: 0.2674 - val_auc: 0.8027 - val_binary_accuracy: 0.9045 - val_loss: 0.2602\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9052 - loss: 0.2644 - val_auc: 0.8057 - val_binary_accuracy: 0.9065 - val_loss: 0.2578\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9068 - loss: 0.2623 - val_auc: 0.8072 - val_binary_accuracy: 0.9071 - val_loss: 0.2577\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9074 - loss: 0.2611 - val_auc: 0.8076 - val_binary_accuracy: 0.9078 - val_loss: 0.2574\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9079 - loss: 0.2602 - val_auc: 0.8087 - val_binary_accuracy: 0.9078 - val_loss: 0.2569\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9081 - loss: 0.2595 - val_auc: 0.8086 - val_binary_accuracy: 0.9084 - val_loss: 0.2570\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9087 - loss: 0.2589 - val_auc: 0.8100 - val_binary_accuracy: 0.9082 - val_loss: 0.2566\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9088 - loss: 0.2582 - val_auc: 0.8098 - val_binary_accuracy: 0.9087 - val_loss: 0.2568\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8164 - binary_accuracy: 0.9116 - loss: 0.2460\n",
            "Fold 2 Metrics: Loss = 0.2568, Accuracy = 0.9087, AUC = 0.8098\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6286 - binary_accuracy: 0.8816 - loss: 0.3469 - val_auc: 0.7731 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9051 - loss: 0.2696 - val_auc: 0.7800 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9059 - loss: 0.2659 - val_auc: 0.7851 - val_binary_accuracy: 0.9072 - val_loss: 0.2658\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9076 - loss: 0.2641 - val_auc: 0.7897 - val_binary_accuracy: 0.9093 - val_loss: 0.2637\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9081 - loss: 0.2629 - val_auc: 0.7945 - val_binary_accuracy: 0.9100 - val_loss: 0.2616\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.7986 - val_binary_accuracy: 0.9109 - val_loss: 0.2597\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9091 - loss: 0.2604 - val_auc: 0.8017 - val_binary_accuracy: 0.9109 - val_loss: 0.2583\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9094 - loss: 0.2597 - val_auc: 0.8042 - val_binary_accuracy: 0.9113 - val_loss: 0.2573\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9094 - loss: 0.2591 - val_auc: 0.8054 - val_binary_accuracy: 0.9113 - val_loss: 0.2566\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9099 - loss: 0.2587 - val_auc: 0.8057 - val_binary_accuracy: 0.9113 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7978 - binary_accuracy: 0.9127 - loss: 0.2572\n",
            "Fold 3 Metrics: Loss = 0.2561, Accuracy = 0.9113, AUC = 0.8057\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6091 - binary_accuracy: 0.8293 - loss: 0.3819 - val_auc: 0.7752 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9047 - loss: 0.2691 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9050 - loss: 0.2652 - val_auc: 0.7943 - val_binary_accuracy: 0.9047 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9079 - loss: 0.2629 - val_auc: 0.7995 - val_binary_accuracy: 0.9070 - val_loss: 0.2615\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9097 - loss: 0.2606 - val_auc: 0.8024 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9105 - loss: 0.2594 - val_auc: 0.8044 - val_binary_accuracy: 0.9082 - val_loss: 0.2582\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9111 - loss: 0.2584 - val_auc: 0.8060 - val_binary_accuracy: 0.9084 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9114 - loss: 0.2575 - val_auc: 0.8074 - val_binary_accuracy: 0.9084 - val_loss: 0.2569\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9113 - loss: 0.2567 - val_auc: 0.8085 - val_binary_accuracy: 0.9081 - val_loss: 0.2567\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9112 - loss: 0.2562 - val_auc: 0.8098 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9084 - loss: 0.2616\n",
            "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9087, AUC = 0.8098\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6192 - binary_accuracy: 0.9038 - loss: 0.3399 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9040 - loss: 0.2737 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2611\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9048 - loss: 0.2690 - val_auc: 0.7961 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7984 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9087 - loss: 0.2644 - val_auc: 0.8018 - val_binary_accuracy: 0.9101 - val_loss: 0.2547\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9089 - loss: 0.2628 - val_auc: 0.8031 - val_binary_accuracy: 0.9107 - val_loss: 0.2539\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8042 - val_binary_accuracy: 0.9107 - val_loss: 0.2533\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9094 - loss: 0.2609 - val_auc: 0.8044 - val_binary_accuracy: 0.9106 - val_loss: 0.2532\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8049 - val_binary_accuracy: 0.9109 - val_loss: 0.2530\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8049 - val_binary_accuracy: 0.9110 - val_loss: 0.2528\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8138 - binary_accuracy: 0.9091 - loss: 0.2512\n",
            "Fold 5 Metrics: Loss = 0.2528, Accuracy = 0.9110, AUC = 0.8049\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2564\n",
            "Average Accuracy: 0.9096\n",
            "Average AUC: 0.8041\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 2, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6988 - binary_accuracy: 0.9069 - loss: 0.2914 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9072 - loss: 0.2590 - val_auc: 0.7819 - val_binary_accuracy: 0.9048 - val_loss: 0.2660\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9094 - loss: 0.2551 - val_auc: 0.7877 - val_binary_accuracy: 0.9060 - val_loss: 0.2628\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8045 - binary_accuracy: 0.9112 - loss: 0.2520 - val_auc: 0.7907 - val_binary_accuracy: 0.9076 - val_loss: 0.2610\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9123 - loss: 0.2499 - val_auc: 0.7921 - val_binary_accuracy: 0.9078 - val_loss: 0.2601\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9125 - loss: 0.2485 - val_auc: 0.7936 - val_binary_accuracy: 0.9087 - val_loss: 0.2592\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8116 - binary_accuracy: 0.9124 - loss: 0.2475 - val_auc: 0.7944 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8131 - binary_accuracy: 0.9128 - loss: 0.2468 - val_auc: 0.7945 - val_binary_accuracy: 0.9091 - val_loss: 0.2586\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9129 - loss: 0.2462 - val_auc: 0.7945 - val_binary_accuracy: 0.9093 - val_loss: 0.2586\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8148 - binary_accuracy: 0.9125 - loss: 0.2457 - val_auc: 0.7951 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7937 - binary_accuracy: 0.9128 - loss: 0.2518\n",
            "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9091, AUC = 0.7951\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6524 - binary_accuracy: 0.8633 - loss: 0.3412 - val_auc: 0.7960 - val_binary_accuracy: 0.9042 - val_loss: 0.2636\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9040 - loss: 0.2687 - val_auc: 0.8037 - val_binary_accuracy: 0.9056 - val_loss: 0.2591\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9053 - loss: 0.2643 - val_auc: 0.8077 - val_binary_accuracy: 0.9068 - val_loss: 0.2571\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9072 - loss: 0.2621 - val_auc: 0.8092 - val_binary_accuracy: 0.9076 - val_loss: 0.2560\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9077 - loss: 0.2607 - val_auc: 0.8105 - val_binary_accuracy: 0.9079 - val_loss: 0.2554\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8005 - binary_accuracy: 0.9079 - loss: 0.2598 - val_auc: 0.8100 - val_binary_accuracy: 0.9085 - val_loss: 0.2552\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8020 - binary_accuracy: 0.9083 - loss: 0.2592 - val_auc: 0.8104 - val_binary_accuracy: 0.9085 - val_loss: 0.2550\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9081 - loss: 0.2587 - val_auc: 0.8103 - val_binary_accuracy: 0.9085 - val_loss: 0.2549\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9080 - loss: 0.2581 - val_auc: 0.8106 - val_binary_accuracy: 0.9087 - val_loss: 0.2548\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9083 - loss: 0.2576 - val_auc: 0.8106 - val_binary_accuracy: 0.9085 - val_loss: 0.2550\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9121 - loss: 0.2445\n",
            "Fold 2 Metrics: Loss = 0.2550, Accuracy = 0.9085, AUC = 0.8106\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6260 - binary_accuracy: 0.8325 - loss: 0.3854 - val_auc: 0.7763 - val_binary_accuracy: 0.9042 - val_loss: 0.2705\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9055 - loss: 0.2685 - val_auc: 0.7850 - val_binary_accuracy: 0.9053 - val_loss: 0.2663\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9072 - loss: 0.2656 - val_auc: 0.7905 - val_binary_accuracy: 0.9087 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9079 - loss: 0.2643 - val_auc: 0.7946 - val_binary_accuracy: 0.9106 - val_loss: 0.2615\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.7972 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9094 - loss: 0.2625 - val_auc: 0.7997 - val_binary_accuracy: 0.9110 - val_loss: 0.2584\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9096 - loss: 0.2619 - val_auc: 0.8014 - val_binary_accuracy: 0.9113 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9101 - loss: 0.2614 - val_auc: 0.8029 - val_binary_accuracy: 0.9116 - val_loss: 0.2568\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9103 - loss: 0.2609 - val_auc: 0.8046 - val_binary_accuracy: 0.9116 - val_loss: 0.2563\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9103 - loss: 0.2603 - val_auc: 0.8062 - val_binary_accuracy: 0.9115 - val_loss: 0.2559\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7977 - binary_accuracy: 0.9130 - loss: 0.2568\n",
            "Fold 3 Metrics: Loss = 0.2559, Accuracy = 0.9115, AUC = 0.8062\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6158 - binary_accuracy: 0.8419 - loss: 0.3678 - val_auc: 0.7857 - val_binary_accuracy: 0.9048 - val_loss: 0.2655\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9065 - loss: 0.2662 - val_auc: 0.7949 - val_binary_accuracy: 0.9087 - val_loss: 0.2609\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9083 - loss: 0.2627 - val_auc: 0.8004 - val_binary_accuracy: 0.9088 - val_loss: 0.2583\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9098 - loss: 0.2606 - val_auc: 0.8030 - val_binary_accuracy: 0.9095 - val_loss: 0.2569\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9103 - loss: 0.2594 - val_auc: 0.8044 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7929 - binary_accuracy: 0.9106 - loss: 0.2585 - val_auc: 0.8063 - val_binary_accuracy: 0.9093 - val_loss: 0.2554\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9112 - loss: 0.2577 - val_auc: 0.8084 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9118 - loss: 0.2571 - val_auc: 0.8090 - val_binary_accuracy: 0.9097 - val_loss: 0.2542\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9117 - loss: 0.2568 - val_auc: 0.8098 - val_binary_accuracy: 0.9097 - val_loss: 0.2539\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9119 - loss: 0.2564 - val_auc: 0.8104 - val_binary_accuracy: 0.9097 - val_loss: 0.2537\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7914 - binary_accuracy: 0.9099 - loss: 0.2603\n",
            "Fold 4 Metrics: Loss = 0.2537, Accuracy = 0.9097, AUC = 0.8104\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6509 - binary_accuracy: 0.8786 - loss: 0.3291 - val_auc: 0.7903 - val_binary_accuracy: 0.9045 - val_loss: 0.2618\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.7960 - val_binary_accuracy: 0.9082 - val_loss: 0.2584\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9070 - loss: 0.2680 - val_auc: 0.7986 - val_binary_accuracy: 0.9084 - val_loss: 0.2561\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9087 - loss: 0.2659 - val_auc: 0.8028 - val_binary_accuracy: 0.9094 - val_loss: 0.2543\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9091 - loss: 0.2642 - val_auc: 0.8048 - val_binary_accuracy: 0.9101 - val_loss: 0.2530\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9091 - loss: 0.2629 - val_auc: 0.8060 - val_binary_accuracy: 0.9109 - val_loss: 0.2522\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8063 - val_binary_accuracy: 0.9109 - val_loss: 0.2517\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9098 - loss: 0.2611 - val_auc: 0.8072 - val_binary_accuracy: 0.9110 - val_loss: 0.2515\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9103 - loss: 0.2605 - val_auc: 0.8070 - val_binary_accuracy: 0.9112 - val_loss: 0.2513\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9100 - loss: 0.2600 - val_auc: 0.8078 - val_binary_accuracy: 0.9110 - val_loss: 0.2511\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9094 - loss: 0.2501\n",
            "Fold 5 Metrics: Loss = 0.2511, Accuracy = 0.9110, AUC = 0.8078\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2549\n",
            "Average Accuracy: 0.9100\n",
            "Average AUC: 0.8060\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 2, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7176 - binary_accuracy: 0.9069 - loss: 0.2854 - val_auc: 0.7773 - val_binary_accuracy: 0.9048 - val_loss: 0.2695\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9097 - loss: 0.2587 - val_auc: 0.7868 - val_binary_accuracy: 0.9066 - val_loss: 0.2653\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9119 - loss: 0.2544 - val_auc: 0.7917 - val_binary_accuracy: 0.9078 - val_loss: 0.2632\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9115 - loss: 0.2520 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2631\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9121 - loss: 0.2503 - val_auc: 0.7946 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8084 - binary_accuracy: 0.9123 - loss: 0.2491 - val_auc: 0.7955 - val_binary_accuracy: 0.9078 - val_loss: 0.2616\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8101 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7961 - val_binary_accuracy: 0.9082 - val_loss: 0.2606\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9127 - loss: 0.2474 - val_auc: 0.7959 - val_binary_accuracy: 0.9082 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8131 - binary_accuracy: 0.9123 - loss: 0.2468 - val_auc: 0.7962 - val_binary_accuracy: 0.9082 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8138 - binary_accuracy: 0.9127 - loss: 0.2464 - val_auc: 0.7964 - val_binary_accuracy: 0.9082 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7964 - binary_accuracy: 0.9118 - loss: 0.2504\n",
            "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9082, AUC = 0.7964\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6800 - binary_accuracy: 0.8850 - loss: 0.3162 - val_auc: 0.7986 - val_binary_accuracy: 0.9047 - val_loss: 0.2627\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9045 - loss: 0.2695 - val_auc: 0.8064 - val_binary_accuracy: 0.9060 - val_loss: 0.2596\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9060 - loss: 0.2654 - val_auc: 0.8089 - val_binary_accuracy: 0.9082 - val_loss: 0.2580\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9076 - loss: 0.2627 - val_auc: 0.8092 - val_binary_accuracy: 0.9096 - val_loss: 0.2566\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9085 - loss: 0.2609 - val_auc: 0.8099 - val_binary_accuracy: 0.9103 - val_loss: 0.2556\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9087 - loss: 0.2600 - val_auc: 0.8100 - val_binary_accuracy: 0.9099 - val_loss: 0.2546\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9081 - loss: 0.2592 - val_auc: 0.8112 - val_binary_accuracy: 0.9103 - val_loss: 0.2539\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9078 - loss: 0.2586 - val_auc: 0.8109 - val_binary_accuracy: 0.9102 - val_loss: 0.2535\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9079 - loss: 0.2581 - val_auc: 0.8131 - val_binary_accuracy: 0.9103 - val_loss: 0.2529\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8050 - binary_accuracy: 0.9078 - loss: 0.2577 - val_auc: 0.8121 - val_binary_accuracy: 0.9100 - val_loss: 0.2533\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8181 - binary_accuracy: 0.9130 - loss: 0.2431\n",
            "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9100, AUC = 0.8121\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6425 - binary_accuracy: 0.8758 - loss: 0.3350 - val_auc: 0.7791 - val_binary_accuracy: 0.9051 - val_loss: 0.2682\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7620 - binary_accuracy: 0.9071 - loss: 0.2725 - val_auc: 0.7861 - val_binary_accuracy: 0.9082 - val_loss: 0.2651\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7685 - binary_accuracy: 0.9073 - loss: 0.2692 - val_auc: 0.7920 - val_binary_accuracy: 0.9102 - val_loss: 0.2624\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9085 - loss: 0.2666 - val_auc: 0.7964 - val_binary_accuracy: 0.9104 - val_loss: 0.2602\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9090 - loss: 0.2646 - val_auc: 0.7996 - val_binary_accuracy: 0.9112 - val_loss: 0.2583\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9096 - loss: 0.2639 - val_auc: 0.8011 - val_binary_accuracy: 0.9115 - val_loss: 0.2571\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9097 - loss: 0.2631 - val_auc: 0.8029 - val_binary_accuracy: 0.9116 - val_loss: 0.2562\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9100 - loss: 0.2625 - val_auc: 0.8047 - val_binary_accuracy: 0.9115 - val_loss: 0.2556\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9110 - loss: 0.2618 - val_auc: 0.8052 - val_binary_accuracy: 0.9116 - val_loss: 0.2553\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9108 - loss: 0.2612 - val_auc: 0.8055 - val_binary_accuracy: 0.9116 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7976 - binary_accuracy: 0.9134 - loss: 0.2556\n",
            "Fold 3 Metrics: Loss = 0.2551, Accuracy = 0.9116, AUC = 0.8055\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6487 - binary_accuracy: 0.8869 - loss: 0.3241 - val_auc: 0.7897 - val_binary_accuracy: 0.9063 - val_loss: 0.2639\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9071 - loss: 0.2666 - val_auc: 0.7988 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9088 - loss: 0.2630 - val_auc: 0.8036 - val_binary_accuracy: 0.9087 - val_loss: 0.2572\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9097 - loss: 0.2610 - val_auc: 0.8060 - val_binary_accuracy: 0.9081 - val_loss: 0.2559\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9102 - loss: 0.2597 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2552\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9106 - loss: 0.2588 - val_auc: 0.8088 - val_binary_accuracy: 0.9091 - val_loss: 0.2546\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9107 - loss: 0.2581 - val_auc: 0.8095 - val_binary_accuracy: 0.9093 - val_loss: 0.2543\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9109 - loss: 0.2575 - val_auc: 0.8100 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9110 - loss: 0.2570 - val_auc: 0.8105 - val_binary_accuracy: 0.9094 - val_loss: 0.2539\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9113 - loss: 0.2566 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2538\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9083 - loss: 0.2609\n",
            "Fold 4 Metrics: Loss = 0.2538, Accuracy = 0.9091, AUC = 0.8113\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6596 - binary_accuracy: 0.8855 - loss: 0.3214 - val_auc: 0.7902 - val_binary_accuracy: 0.9041 - val_loss: 0.2671\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9043 - loss: 0.2730 - val_auc: 0.7974 - val_binary_accuracy: 0.9053 - val_loss: 0.2647\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9062 - loss: 0.2696 - val_auc: 0.8024 - val_binary_accuracy: 0.9090 - val_loss: 0.2619\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9069 - loss: 0.2669 - val_auc: 0.8047 - val_binary_accuracy: 0.9094 - val_loss: 0.2594\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8062 - val_binary_accuracy: 0.9107 - val_loss: 0.2573\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9083 - loss: 0.2640 - val_auc: 0.8075 - val_binary_accuracy: 0.9116 - val_loss: 0.2554\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2630 - val_auc: 0.8076 - val_binary_accuracy: 0.9115 - val_loss: 0.2539\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8082 - val_binary_accuracy: 0.9113 - val_loss: 0.2529\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8086 - val_binary_accuracy: 0.9115 - val_loss: 0.2519\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9093 - loss: 0.2607 - val_auc: 0.8095 - val_binary_accuracy: 0.9118 - val_loss: 0.2515\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9096 - loss: 0.2499\n",
            "Fold 5 Metrics: Loss = 0.2515, Accuracy = 0.9118, AUC = 0.8095\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2545\n",
            "Average Accuracy: 0.9101\n",
            "Average AUC: 0.8070\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 3, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5016 - binary_accuracy: 0.6917 - loss: 0.5461 - val_auc: 0.7261 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6942 - binary_accuracy: 0.9069 - loss: 0.3066 - val_auc: 0.7271 - val_binary_accuracy: 0.9044 - val_loss: 0.3083\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9069 - loss: 0.3004 - val_auc: 0.7529 - val_binary_accuracy: 0.9044 - val_loss: 0.2989\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9069 - loss: 0.2879 - val_auc: 0.7558 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9069 - loss: 0.2709 - val_auc: 0.7661 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7747 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9069 - loss: 0.2585 - val_auc: 0.7771 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9069 - loss: 0.2570 - val_auc: 0.7775 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9069 - loss: 0.2563 - val_auc: 0.7803 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9069 - loss: 0.2557 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7775 - binary_accuracy: 0.9084 - loss: 0.2589\n",
            "Fold 1 Metrics: Loss = 0.2662, Accuracy = 0.9044, AUC = 0.7814\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5037 - binary_accuracy: 0.5797 - loss: 0.6377 - val_auc: 0.6403 - val_binary_accuracy: 0.9042 - val_loss: 0.3163\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6298 - binary_accuracy: 0.9029 - loss: 0.3170 - val_auc: 0.7354 - val_binary_accuracy: 0.9042 - val_loss: 0.3102\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7345 - binary_accuracy: 0.9029 - loss: 0.3117 - val_auc: 0.7564 - val_binary_accuracy: 0.9042 - val_loss: 0.3024\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7552 - binary_accuracy: 0.9029 - loss: 0.3026 - val_auc: 0.7788 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9029 - loss: 0.2889 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2743\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9029 - loss: 0.2769 - val_auc: 0.7942 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2729 - val_auc: 0.7966 - val_binary_accuracy: 0.9042 - val_loss: 0.2640\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9029 - loss: 0.2695 - val_auc: 0.7981 - val_binary_accuracy: 0.9042 - val_loss: 0.2620\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9029 - loss: 0.2679 - val_auc: 0.8014 - val_binary_accuracy: 0.9042 - val_loss: 0.2612\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9029 - loss: 0.2666 - val_auc: 0.8023 - val_binary_accuracy: 0.9042 - val_loss: 0.2609\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8054 - binary_accuracy: 0.9092 - loss: 0.2511\n",
            "Fold 2 Metrics: Loss = 0.2609, Accuracy = 0.9042, AUC = 0.8023\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5094 - binary_accuracy: 0.9051 - loss: 0.4287 - val_auc: 0.7078 - val_binary_accuracy: 0.9042 - val_loss: 0.3112\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7050 - binary_accuracy: 0.9051 - loss: 0.3059 - val_auc: 0.7609 - val_binary_accuracy: 0.9042 - val_loss: 0.2882\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7575 - binary_accuracy: 0.9051 - loss: 0.2824 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2735\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9051 - loss: 0.2706 - val_auc: 0.7745 - val_binary_accuracy: 0.9042 - val_loss: 0.2705\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9051 - loss: 0.2681 - val_auc: 0.7803 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9051 - loss: 0.2664 - val_auc: 0.7845 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7839 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9051 - loss: 0.2650 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2670\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9051 - loss: 0.2643 - val_auc: 0.7866 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9051 - loss: 0.2635 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7821 - binary_accuracy: 0.9046 - loss: 0.2655\n",
            "Fold 3 Metrics: Loss = 0.2657, Accuracy = 0.9042, AUC = 0.7876\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5206 - binary_accuracy: 0.9047 - loss: 0.3544 - val_auc: 0.7491 - val_binary_accuracy: 0.9044 - val_loss: 0.3113\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7073 - binary_accuracy: 0.9047 - loss: 0.3089 - val_auc: 0.7533 - val_binary_accuracy: 0.9044 - val_loss: 0.3009\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7386 - binary_accuracy: 0.9047 - loss: 0.2960 - val_auc: 0.7657 - val_binary_accuracy: 0.9044 - val_loss: 0.2825\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9047 - loss: 0.2777 - val_auc: 0.7776 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9047 - loss: 0.2692 - val_auc: 0.7773 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9047 - loss: 0.2675 - val_auc: 0.7821 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9047 - loss: 0.2670 - val_auc: 0.7812 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9047 - loss: 0.2666 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9047 - loss: 0.2659 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7650 - binary_accuracy: 0.9049 - loss: 0.2728\n",
            "Fold 4 Metrics: Loss = 0.2692, Accuracy = 0.9044, AUC = 0.7828\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5026 - binary_accuracy: 0.6269 - loss: 0.5922 - val_auc: 0.7004 - val_binary_accuracy: 0.9044 - val_loss: 0.3140\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6943 - binary_accuracy: 0.9040 - loss: 0.3128 - val_auc: 0.7520 - val_binary_accuracy: 0.9044 - val_loss: 0.3028\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7483 - binary_accuracy: 0.9040 - loss: 0.3011 - val_auc: 0.7717 - val_binary_accuracy: 0.9044 - val_loss: 0.2867\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7598 - binary_accuracy: 0.9040 - loss: 0.2865 - val_auc: 0.7743 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2758 - val_auc: 0.7890 - val_binary_accuracy: 0.9044 - val_loss: 0.2651\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7925 - val_binary_accuracy: 0.9044 - val_loss: 0.2629\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9040 - loss: 0.2702 - val_auc: 0.7928 - val_binary_accuracy: 0.9044 - val_loss: 0.2619\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9040 - loss: 0.2694 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2612\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9040 - loss: 0.2688 - val_auc: 0.7941 - val_binary_accuracy: 0.9044 - val_loss: 0.2605\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9040 - loss: 0.2681 - val_auc: 0.7955 - val_binary_accuracy: 0.9044 - val_loss: 0.2600\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8072 - binary_accuracy: 0.9013 - loss: 0.2585\n",
            "Fold 5 Metrics: Loss = 0.2600, Accuracy = 0.9044, AUC = 0.7955\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2644\n",
            "Average Accuracy: 0.9043\n",
            "Average AUC: 0.7899\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 3, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5001 - binary_accuracy: 0.6835 - loss: 0.5494 - val_auc: 0.6707 - val_binary_accuracy: 0.9044 - val_loss: 0.3132\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6898 - binary_accuracy: 0.9069 - loss: 0.3056 - val_auc: 0.7449 - val_binary_accuracy: 0.9044 - val_loss: 0.3041\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7515 - binary_accuracy: 0.9069 - loss: 0.2922 - val_auc: 0.7589 - val_binary_accuracy: 0.9044 - val_loss: 0.2818\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9069 - loss: 0.2695 - val_auc: 0.7672 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9069 - loss: 0.2617 - val_auc: 0.7753 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9069 - loss: 0.2589 - val_auc: 0.7799 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9069 - loss: 0.2572 - val_auc: 0.7831 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9069 - loss: 0.2562 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2648\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9069 - loss: 0.2551 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8045 - binary_accuracy: 0.9069 - loss: 0.2539 - val_auc: 0.7895 - val_binary_accuracy: 0.9044 - val_loss: 0.2628\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9084 - loss: 0.2555\n",
            "Fold 1 Metrics: Loss = 0.2628, Accuracy = 0.9044, AUC = 0.7895\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5494 - binary_accuracy: 0.8115 - loss: 0.4208 - val_auc: 0.7633 - val_binary_accuracy: 0.9042 - val_loss: 0.2972\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7539 - binary_accuracy: 0.9029 - loss: 0.2931 - val_auc: 0.7887 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9029 - loss: 0.2732 - val_auc: 0.7956 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8009 - val_binary_accuracy: 0.9042 - val_loss: 0.2638\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9029 - loss: 0.2683 - val_auc: 0.8026 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9029 - loss: 0.2668 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9036 - loss: 0.2652 - val_auc: 0.8050 - val_binary_accuracy: 0.9042 - val_loss: 0.2616\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9052 - loss: 0.2638 - val_auc: 0.8064 - val_binary_accuracy: 0.9051 - val_loss: 0.2616\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9063 - loss: 0.2625 - val_auc: 0.8069 - val_binary_accuracy: 0.9059 - val_loss: 0.2612\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9075 - loss: 0.2614 - val_auc: 0.8078 - val_binary_accuracy: 0.9068 - val_loss: 0.2607\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8112 - binary_accuracy: 0.9104 - loss: 0.2513\n",
            "Fold 2 Metrics: Loss = 0.2607, Accuracy = 0.9068, AUC = 0.8078\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5586 - binary_accuracy: 0.9051 - loss: 0.3586 - val_auc: 0.7628 - val_binary_accuracy: 0.9042 - val_loss: 0.2854\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7576 - binary_accuracy: 0.9051 - loss: 0.2787 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9051 - loss: 0.2676 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9051 - loss: 0.2660 - val_auc: 0.7837 - val_binary_accuracy: 0.9042 - val_loss: 0.2676\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9051 - loss: 0.2648 - val_auc: 0.7870 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9051 - loss: 0.2636 - val_auc: 0.7890 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9053 - loss: 0.2624 - val_auc: 0.7912 - val_binary_accuracy: 0.9042 - val_loss: 0.2644\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9070 - loss: 0.2615 - val_auc: 0.7935 - val_binary_accuracy: 0.9090 - val_loss: 0.2633\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9086 - loss: 0.2608 - val_auc: 0.7945 - val_binary_accuracy: 0.9093 - val_loss: 0.2621\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9095 - loss: 0.2600 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2609\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2619\n",
            "Fold 3 Metrics: Loss = 0.2609, Accuracy = 0.9094, AUC = 0.7978\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5424 - binary_accuracy: 0.9047 - loss: 0.3808 - val_auc: 0.7546 - val_binary_accuracy: 0.9044 - val_loss: 0.2978\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7434 - binary_accuracy: 0.9047 - loss: 0.2896 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9047 - loss: 0.2698 - val_auc: 0.7893 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9047 - loss: 0.2653 - val_auc: 0.7930 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9047 - loss: 0.2639 - val_auc: 0.7951 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9048 - loss: 0.2629 - val_auc: 0.7961 - val_binary_accuracy: 0.9044 - val_loss: 0.2652\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9059 - loss: 0.2616 - val_auc: 0.7985 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9086 - loss: 0.2603 - val_auc: 0.8002 - val_binary_accuracy: 0.9060 - val_loss: 0.2621\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9100 - loss: 0.2592 - val_auc: 0.8014 - val_binary_accuracy: 0.9081 - val_loss: 0.2608\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9101 - loss: 0.2583 - val_auc: 0.8034 - val_binary_accuracy: 0.9088 - val_loss: 0.2598\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7852 - binary_accuracy: 0.9078 - loss: 0.2646\n",
            "Fold 4 Metrics: Loss = 0.2598, Accuracy = 0.9088, AUC = 0.8034\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5186 - binary_accuracy: 0.6762 - loss: 0.5585 - val_auc: 0.7575 - val_binary_accuracy: 0.9044 - val_loss: 0.3071\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7405 - binary_accuracy: 0.9040 - loss: 0.3036 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2812\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9040 - loss: 0.2809 - val_auc: 0.7861 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9040 - loss: 0.2711 - val_auc: 0.7940 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9040 - loss: 0.2684 - val_auc: 0.7970 - val_binary_accuracy: 0.9044 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9040 - loss: 0.2667 - val_auc: 0.7980 - val_binary_accuracy: 0.9044 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9043 - loss: 0.2650 - val_auc: 0.7993 - val_binary_accuracy: 0.9084 - val_loss: 0.2575\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9073 - loss: 0.2638 - val_auc: 0.8002 - val_binary_accuracy: 0.9100 - val_loss: 0.2566\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8002 - val_binary_accuracy: 0.9101 - val_loss: 0.2559\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9088 - loss: 0.2622 - val_auc: 0.8009 - val_binary_accuracy: 0.9094 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8121 - binary_accuracy: 0.9078 - loss: 0.2525\n",
            "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9094, AUC = 0.8009\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2598\n",
            "Average Accuracy: 0.9078\n",
            "Average AUC: 0.7999\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 3, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6031 - binary_accuracy: 0.9069 - loss: 0.3197 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2756\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9069 - loss: 0.2629 - val_auc: 0.7730 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9070 - loss: 0.2584 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9072 - loss: 0.2563 - val_auc: 0.7797 - val_binary_accuracy: 0.9062 - val_loss: 0.2662\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9104 - loss: 0.2543 - val_auc: 0.7826 - val_binary_accuracy: 0.9075 - val_loss: 0.2648\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9123 - loss: 0.2523 - val_auc: 0.7852 - val_binary_accuracy: 0.9078 - val_loss: 0.2636\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7873 - val_binary_accuracy: 0.9087 - val_loss: 0.2624\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9124 - loss: 0.2491 - val_auc: 0.7896 - val_binary_accuracy: 0.9085 - val_loss: 0.2614\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8104 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7899 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8115 - binary_accuracy: 0.9130 - loss: 0.2474 - val_auc: 0.7907 - val_binary_accuracy: 0.9088 - val_loss: 0.2606\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9132 - loss: 0.2533\n",
            "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9088, AUC = 0.7907\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5975 - binary_accuracy: 0.8692 - loss: 0.3589 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9029 - loss: 0.2736 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9030 - loss: 0.2682 - val_auc: 0.8016 - val_binary_accuracy: 0.9042 - val_loss: 0.2607\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9038 - loss: 0.2656 - val_auc: 0.8044 - val_binary_accuracy: 0.9050 - val_loss: 0.2588\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9063 - loss: 0.2629 - val_auc: 0.8071 - val_binary_accuracy: 0.9066 - val_loss: 0.2583\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9070 - loss: 0.2611 - val_auc: 0.8083 - val_binary_accuracy: 0.9073 - val_loss: 0.2578\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9075 - loss: 0.2599 - val_auc: 0.8082 - val_binary_accuracy: 0.9078 - val_loss: 0.2577\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9077 - loss: 0.2591 - val_auc: 0.8086 - val_binary_accuracy: 0.9078 - val_loss: 0.2578\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9079 - loss: 0.2585 - val_auc: 0.8084 - val_binary_accuracy: 0.9085 - val_loss: 0.2580\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9078 - loss: 0.2579 - val_auc: 0.8094 - val_binary_accuracy: 0.9087 - val_loss: 0.2580\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8141 - binary_accuracy: 0.9121 - loss: 0.2476\n",
            "Fold 2 Metrics: Loss = 0.2580, Accuracy = 0.9087, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5699 - binary_accuracy: 0.8448 - loss: 0.3757 - val_auc: 0.7576 - val_binary_accuracy: 0.9042 - val_loss: 0.2835\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9051 - loss: 0.2760 - val_auc: 0.7803 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9052 - loss: 0.2670 - val_auc: 0.7852 - val_binary_accuracy: 0.9048 - val_loss: 0.2661\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9068 - loss: 0.2648 - val_auc: 0.7893 - val_binary_accuracy: 0.9088 - val_loss: 0.2642\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.7928 - val_binary_accuracy: 0.9099 - val_loss: 0.2626\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9090 - loss: 0.2623 - val_auc: 0.7958 - val_binary_accuracy: 0.9104 - val_loss: 0.2610\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9095 - loss: 0.2614 - val_auc: 0.7977 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9092 - loss: 0.2607 - val_auc: 0.7994 - val_binary_accuracy: 0.9109 - val_loss: 0.2586\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9094 - loss: 0.2600 - val_auc: 0.8016 - val_binary_accuracy: 0.9110 - val_loss: 0.2575\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9095 - loss: 0.2595 - val_auc: 0.8036 - val_binary_accuracy: 0.9112 - val_loss: 0.2567\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7953 - binary_accuracy: 0.9127 - loss: 0.2575\n",
            "Fold 3 Metrics: Loss = 0.2567, Accuracy = 0.9112, AUC = 0.8036\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5847 - binary_accuracy: 0.8714 - loss: 0.3584 - val_auc: 0.7733 - val_binary_accuracy: 0.9044 - val_loss: 0.2755\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9047 - loss: 0.2713 - val_auc: 0.7870 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9049 - loss: 0.2652 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9068 - loss: 0.2631 - val_auc: 0.7971 - val_binary_accuracy: 0.9056 - val_loss: 0.2607\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9090 - loss: 0.2613 - val_auc: 0.8003 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9090 - loss: 0.2599 - val_auc: 0.8023 - val_binary_accuracy: 0.9082 - val_loss: 0.2579\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9096 - loss: 0.2589 - val_auc: 0.8048 - val_binary_accuracy: 0.9087 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9100 - loss: 0.2583 - val_auc: 0.8058 - val_binary_accuracy: 0.9094 - val_loss: 0.2569\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7958 - binary_accuracy: 0.9097 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9100 - loss: 0.2572 - val_auc: 0.8083 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7889 - binary_accuracy: 0.9088 - loss: 0.2624\n",
            "Fold 4 Metrics: Loss = 0.2562, Accuracy = 0.9093, AUC = 0.8083\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6027 - binary_accuracy: 0.8854 - loss: 0.3512 - val_auc: 0.7779 - val_binary_accuracy: 0.9044 - val_loss: 0.2725\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9040 - loss: 0.2747 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9040 - loss: 0.2703 - val_auc: 0.7929 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9040 - loss: 0.2686 - val_auc: 0.7954 - val_binary_accuracy: 0.9044 - val_loss: 0.2588\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9047 - loss: 0.2667 - val_auc: 0.7974 - val_binary_accuracy: 0.9085 - val_loss: 0.2572\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9078 - loss: 0.2652 - val_auc: 0.8014 - val_binary_accuracy: 0.9093 - val_loss: 0.2560\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8041 - val_binary_accuracy: 0.9093 - val_loss: 0.2548\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9094 - loss: 0.2625 - val_auc: 0.8067 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9094 - loss: 0.2615 - val_auc: 0.8085 - val_binary_accuracy: 0.9100 - val_loss: 0.2525\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9096 - loss: 0.2606 - val_auc: 0.8098 - val_binary_accuracy: 0.9103 - val_loss: 0.2516\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8184 - binary_accuracy: 0.9086 - loss: 0.2501\n",
            "Fold 5 Metrics: Loss = 0.2516, Accuracy = 0.9103, AUC = 0.8098\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2566\n",
            "Average Accuracy: 0.9096\n",
            "Average AUC: 0.8044\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 3, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6540 - binary_accuracy: 0.9069 - loss: 0.3076 - val_auc: 0.7724 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9071 - loss: 0.2598 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9089 - loss: 0.2558 - val_auc: 0.7864 - val_binary_accuracy: 0.9051 - val_loss: 0.2639\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9105 - loss: 0.2528 - val_auc: 0.7896 - val_binary_accuracy: 0.9068 - val_loss: 0.2623\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9116 - loss: 0.2507 - val_auc: 0.7923 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9119 - loss: 0.2493 - val_auc: 0.7935 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9126 - loss: 0.2482 - val_auc: 0.7942 - val_binary_accuracy: 0.9084 - val_loss: 0.2594\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9125 - loss: 0.2474 - val_auc: 0.7944 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8133 - binary_accuracy: 0.9127 - loss: 0.2466 - val_auc: 0.7948 - val_binary_accuracy: 0.9088 - val_loss: 0.2588\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8141 - binary_accuracy: 0.9129 - loss: 0.2461 - val_auc: 0.7951 - val_binary_accuracy: 0.9085 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7937 - binary_accuracy: 0.9122 - loss: 0.2515\n",
            "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9085, AUC = 0.7951\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6455 - binary_accuracy: 0.9029 - loss: 0.3099 - val_auc: 0.7958 - val_binary_accuracy: 0.9042 - val_loss: 0.2653\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9040 - loss: 0.2706 - val_auc: 0.8024 - val_binary_accuracy: 0.9053 - val_loss: 0.2601\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9055 - loss: 0.2660 - val_auc: 0.8055 - val_binary_accuracy: 0.9065 - val_loss: 0.2584\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9069 - loss: 0.2634 - val_auc: 0.8074 - val_binary_accuracy: 0.9072 - val_loss: 0.2561\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8087 - val_binary_accuracy: 0.9087 - val_loss: 0.2550\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9082 - loss: 0.2602 - val_auc: 0.8090 - val_binary_accuracy: 0.9088 - val_loss: 0.2547\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9082 - loss: 0.2594 - val_auc: 0.8096 - val_binary_accuracy: 0.9088 - val_loss: 0.2548\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9085 - loss: 0.2587 - val_auc: 0.8089 - val_binary_accuracy: 0.9087 - val_loss: 0.2550\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9085 - loss: 0.2582 - val_auc: 0.8093 - val_binary_accuracy: 0.9087 - val_loss: 0.2549\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9087 - loss: 0.2578 - val_auc: 0.8095 - val_binary_accuracy: 0.9088 - val_loss: 0.2548\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8161 - binary_accuracy: 0.9127 - loss: 0.2442\n",
            "Fold 2 Metrics: Loss = 0.2548, Accuracy = 0.9088, AUC = 0.8095\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6080 - binary_accuracy: 0.8568 - loss: 0.3631 - val_auc: 0.7791 - val_binary_accuracy: 0.9042 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9053 - loss: 0.2690 - val_auc: 0.7862 - val_binary_accuracy: 0.9050 - val_loss: 0.2660\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9073 - loss: 0.2666 - val_auc: 0.7899 - val_binary_accuracy: 0.9088 - val_loss: 0.2636\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9081 - loss: 0.2650 - val_auc: 0.7936 - val_binary_accuracy: 0.9096 - val_loss: 0.2615\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.7955 - val_binary_accuracy: 0.9103 - val_loss: 0.2599\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9090 - loss: 0.2633 - val_auc: 0.7979 - val_binary_accuracy: 0.9107 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9094 - loss: 0.2626 - val_auc: 0.7990 - val_binary_accuracy: 0.9109 - val_loss: 0.2578\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9095 - loss: 0.2619 - val_auc: 0.8009 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9096 - loss: 0.2613 - val_auc: 0.8020 - val_binary_accuracy: 0.9115 - val_loss: 0.2565\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.8031 - val_binary_accuracy: 0.9115 - val_loss: 0.2560\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9134 - loss: 0.2566\n",
            "Fold 3 Metrics: Loss = 0.2560, Accuracy = 0.9115, AUC = 0.8031\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5836 - binary_accuracy: 0.8179 - loss: 0.4140 - val_auc: 0.7830 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9047 - loss: 0.2675 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9065 - loss: 0.2640 - val_auc: 0.7958 - val_binary_accuracy: 0.9064 - val_loss: 0.2612\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2618 - val_auc: 0.7993 - val_binary_accuracy: 0.9088 - val_loss: 0.2591\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9094 - loss: 0.2601 - val_auc: 0.8026 - val_binary_accuracy: 0.9091 - val_loss: 0.2571\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9103 - loss: 0.2588 - val_auc: 0.8045 - val_binary_accuracy: 0.9095 - val_loss: 0.2560\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9107 - loss: 0.2580 - val_auc: 0.8057 - val_binary_accuracy: 0.9094 - val_loss: 0.2554\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9108 - loss: 0.2573 - val_auc: 0.8067 - val_binary_accuracy: 0.9098 - val_loss: 0.2551\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.8079 - val_binary_accuracy: 0.9097 - val_loss: 0.2547\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9115 - loss: 0.2564 - val_auc: 0.8084 - val_binary_accuracy: 0.9095 - val_loss: 0.2544\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7896 - binary_accuracy: 0.9085 - loss: 0.2608\n",
            "Fold 4 Metrics: Loss = 0.2544, Accuracy = 0.9095, AUC = 0.8084\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6257 - binary_accuracy: 0.9040 - loss: 0.3208 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9043 - loss: 0.2727 - val_auc: 0.7930 - val_binary_accuracy: 0.9079 - val_loss: 0.2598\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9061 - loss: 0.2698 - val_auc: 0.7960 - val_binary_accuracy: 0.9081 - val_loss: 0.2577\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9084 - loss: 0.2675 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2560\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9086 - loss: 0.2656 - val_auc: 0.8022 - val_binary_accuracy: 0.9094 - val_loss: 0.2547\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9092 - loss: 0.2641 - val_auc: 0.8050 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9092 - loss: 0.2628 - val_auc: 0.8059 - val_binary_accuracy: 0.9106 - val_loss: 0.2528\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9094 - loss: 0.2619 - val_auc: 0.8069 - val_binary_accuracy: 0.9107 - val_loss: 0.2521\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9095 - loss: 0.2611 - val_auc: 0.8078 - val_binary_accuracy: 0.9113 - val_loss: 0.2516\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8084 - val_binary_accuracy: 0.9115 - val_loss: 0.2513\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9096 - loss: 0.2489\n",
            "Fold 5 Metrics: Loss = 0.2513, Accuracy = 0.9115, AUC = 0.8084\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2551\n",
            "Average Accuracy: 0.9100\n",
            "Average AUC: 0.8049\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 3, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6561 - binary_accuracy: 0.8901 - loss: 0.3053 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9076 - loss: 0.2608 - val_auc: 0.7809 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9097 - loss: 0.2570 - val_auc: 0.7871 - val_binary_accuracy: 0.9054 - val_loss: 0.2666\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9108 - loss: 0.2539 - val_auc: 0.7910 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8040 - binary_accuracy: 0.9117 - loss: 0.2515 - val_auc: 0.7933 - val_binary_accuracy: 0.9075 - val_loss: 0.2631\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9119 - loss: 0.2498 - val_auc: 0.7942 - val_binary_accuracy: 0.9081 - val_loss: 0.2620\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8095 - binary_accuracy: 0.9125 - loss: 0.2486 - val_auc: 0.7946 - val_binary_accuracy: 0.9087 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8115 - binary_accuracy: 0.9128 - loss: 0.2476 - val_auc: 0.7958 - val_binary_accuracy: 0.9087 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8130 - binary_accuracy: 0.9132 - loss: 0.2468 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2593\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8140 - binary_accuracy: 0.9131 - loss: 0.2462 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2589\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9118 - loss: 0.2508\n",
            "Fold 1 Metrics: Loss = 0.2589, Accuracy = 0.9084, AUC = 0.7962\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6743 - binary_accuracy: 0.9031 - loss: 0.3031 - val_auc: 0.7991 - val_binary_accuracy: 0.9042 - val_loss: 0.2653\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9043 - loss: 0.2697 - val_auc: 0.8052 - val_binary_accuracy: 0.9060 - val_loss: 0.2627\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9065 - loss: 0.2656 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2609\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9079 - loss: 0.2630 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2599\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8083 - val_binary_accuracy: 0.9090 - val_loss: 0.2589\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7987 - binary_accuracy: 0.9082 - loss: 0.2606 - val_auc: 0.8086 - val_binary_accuracy: 0.9093 - val_loss: 0.2580\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8008 - binary_accuracy: 0.9084 - loss: 0.2599 - val_auc: 0.8092 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9083 - loss: 0.2593 - val_auc: 0.8100 - val_binary_accuracy: 0.9094 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9083 - loss: 0.2587 - val_auc: 0.8103 - val_binary_accuracy: 0.9093 - val_loss: 0.2555\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9083 - loss: 0.2583 - val_auc: 0.8105 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9124 - loss: 0.2453\n",
            "Fold 2 Metrics: Loss = 0.2550, Accuracy = 0.9093, AUC = 0.8105\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6393 - binary_accuracy: 0.8865 - loss: 0.3228 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7624 - binary_accuracy: 0.9060 - loss: 0.2722 - val_auc: 0.7872 - val_binary_accuracy: 0.9073 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9076 - loss: 0.2690 - val_auc: 0.7918 - val_binary_accuracy: 0.9102 - val_loss: 0.2628\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9085 - loss: 0.2667 - val_auc: 0.7959 - val_binary_accuracy: 0.9110 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9090 - loss: 0.2650 - val_auc: 0.7991 - val_binary_accuracy: 0.9113 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9093 - loss: 0.2638 - val_auc: 0.8011 - val_binary_accuracy: 0.9113 - val_loss: 0.2582\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9094 - loss: 0.2629 - val_auc: 0.8033 - val_binary_accuracy: 0.9113 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9099 - loss: 0.2621 - val_auc: 0.8050 - val_binary_accuracy: 0.9115 - val_loss: 0.2563\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9100 - loss: 0.2615 - val_auc: 0.8059 - val_binary_accuracy: 0.9118 - val_loss: 0.2557\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9098 - loss: 0.2609 - val_auc: 0.8069 - val_binary_accuracy: 0.9115 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7990 - binary_accuracy: 0.9130 - loss: 0.2559\n",
            "Fold 3 Metrics: Loss = 0.2552, Accuracy = 0.9115, AUC = 0.8069\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6251 - binary_accuracy: 0.8866 - loss: 0.3383 - val_auc: 0.7882 - val_binary_accuracy: 0.9051 - val_loss: 0.2648\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9059 - loss: 0.2676 - val_auc: 0.7959 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9081 - loss: 0.2646 - val_auc: 0.8012 - val_binary_accuracy: 0.9085 - val_loss: 0.2582\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9090 - loss: 0.2622 - val_auc: 0.8046 - val_binary_accuracy: 0.9085 - val_loss: 0.2566\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9100 - loss: 0.2605 - val_auc: 0.8065 - val_binary_accuracy: 0.9087 - val_loss: 0.2557\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9100 - loss: 0.2595 - val_auc: 0.8072 - val_binary_accuracy: 0.9085 - val_loss: 0.2551\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8085 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9107 - loss: 0.2580 - val_auc: 0.8092 - val_binary_accuracy: 0.9093 - val_loss: 0.2544\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9107 - loss: 0.2575 - val_auc: 0.8100 - val_binary_accuracy: 0.9091 - val_loss: 0.2542\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9109 - loss: 0.2571 - val_auc: 0.8101 - val_binary_accuracy: 0.9093 - val_loss: 0.2540\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7920 - binary_accuracy: 0.9086 - loss: 0.2607\n",
            "Fold 4 Metrics: Loss = 0.2540, Accuracy = 0.9093, AUC = 0.8101\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6250 - binary_accuracy: 0.8698 - loss: 0.3534 - val_auc: 0.7891 - val_binary_accuracy: 0.9075 - val_loss: 0.2658\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9045 - loss: 0.2732 - val_auc: 0.7945 - val_binary_accuracy: 0.9082 - val_loss: 0.2639\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9057 - loss: 0.2704 - val_auc: 0.7990 - val_binary_accuracy: 0.9081 - val_loss: 0.2625\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9074 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9085 - val_loss: 0.2616\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9082 - loss: 0.2662 - val_auc: 0.8042 - val_binary_accuracy: 0.9087 - val_loss: 0.2600\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9085 - loss: 0.2648 - val_auc: 0.8050 - val_binary_accuracy: 0.9101 - val_loss: 0.2582\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9087 - loss: 0.2638 - val_auc: 0.8062 - val_binary_accuracy: 0.9103 - val_loss: 0.2564\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9092 - loss: 0.2630 - val_auc: 0.8072 - val_binary_accuracy: 0.9115 - val_loss: 0.2547\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9092 - loss: 0.2622 - val_auc: 0.8072 - val_binary_accuracy: 0.9121 - val_loss: 0.2537\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9096 - loss: 0.2615 - val_auc: 0.8083 - val_binary_accuracy: 0.9116 - val_loss: 0.2527\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9095 - loss: 0.2509\n",
            "Fold 5 Metrics: Loss = 0.2527, Accuracy = 0.9116, AUC = 0.8083\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2552\n",
            "Average Accuracy: 0.9100\n",
            "Average AUC: 0.8064\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 4, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4969 - binary_accuracy: 0.3356 - loss: 1.0198 - val_auc: 0.4997 - val_binary_accuracy: 0.9044 - val_loss: 0.3583\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4961 - binary_accuracy: 0.9069 - loss: 0.3372 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3189\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5076 - binary_accuracy: 0.9069 - loss: 0.3124 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3155\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5098 - binary_accuracy: 0.9069 - loss: 0.3099 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3151\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5093 - binary_accuracy: 0.9069 - loss: 0.3095 - val_auc: 0.4999 - val_binary_accuracy: 0.9044 - val_loss: 0.3150\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5691 - binary_accuracy: 0.9069 - loss: 0.3093 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5973 - binary_accuracy: 0.9069 - loss: 0.3088 - val_auc: 0.7049 - val_binary_accuracy: 0.9044 - val_loss: 0.3133\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7355 - binary_accuracy: 0.9069 - loss: 0.3064 - val_auc: 0.7475 - val_binary_accuracy: 0.9044 - val_loss: 0.3039\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9069 - loss: 0.2901 - val_auc: 0.7627 - val_binary_accuracy: 0.9044 - val_loss: 0.2786\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7697 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7680 - binary_accuracy: 0.9084 - loss: 0.2622\n",
            "Fold 1 Metrics: Loss = 0.2700, Accuracy = 0.9044, AUC = 0.7697\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5046 - binary_accuracy: 0.9029 - loss: 0.3812 - val_auc: 0.6797 - val_binary_accuracy: 0.9042 - val_loss: 0.3142\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6695 - binary_accuracy: 0.9029 - loss: 0.3158 - val_auc: 0.7519 - val_binary_accuracy: 0.9042 - val_loss: 0.3039\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7421 - binary_accuracy: 0.9029 - loss: 0.2995 - val_auc: 0.7911 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2751 - val_auc: 0.7948 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9029 - loss: 0.2696 - val_auc: 0.8021 - val_binary_accuracy: 0.9042 - val_loss: 0.2644\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9029 - loss: 0.2673 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2635\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9029 - loss: 0.2657 - val_auc: 0.8057 - val_binary_accuracy: 0.9042 - val_loss: 0.2629\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9030 - loss: 0.2643 - val_auc: 0.8063 - val_binary_accuracy: 0.9042 - val_loss: 0.2622\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7975 - binary_accuracy: 0.9047 - loss: 0.2632 - val_auc: 0.8064 - val_binary_accuracy: 0.9051 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9061 - loss: 0.2622 - val_auc: 0.8080 - val_binary_accuracy: 0.9056 - val_loss: 0.2609\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8113 - binary_accuracy: 0.9099 - loss: 0.2505\n",
            "Fold 2 Metrics: Loss = 0.2609, Accuracy = 0.9056, AUC = 0.8080\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5037 - binary_accuracy: 0.8728 - loss: 0.4521 - val_auc: 0.6925 - val_binary_accuracy: 0.9042 - val_loss: 0.3140\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6814 - binary_accuracy: 0.9051 - loss: 0.3107 - val_auc: 0.7450 - val_binary_accuracy: 0.9042 - val_loss: 0.3009\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7463 - binary_accuracy: 0.9051 - loss: 0.2936 - val_auc: 0.7699 - val_binary_accuracy: 0.9042 - val_loss: 0.2784\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9051 - loss: 0.2740 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9051 - loss: 0.2682 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7799 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7802 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9051 - loss: 0.2645 - val_auc: 0.7831 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9051 - loss: 0.2639 - val_auc: 0.7844 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7804 - binary_accuracy: 0.9046 - loss: 0.2672\n",
            "Fold 3 Metrics: Loss = 0.2674, Accuracy = 0.9042, AUC = 0.7844\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - auc: 0.4974 - binary_accuracy: 0.6128 - loss: 0.6017 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3166\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4971 - binary_accuracy: 0.9047 - loss: 0.3151 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3153\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5004 - binary_accuracy: 0.9047 - loss: 0.3146 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3152\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5160 - binary_accuracy: 0.9047 - loss: 0.3144 - val_auc: 0.6853 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6210 - binary_accuracy: 0.9047 - loss: 0.3129 - val_auc: 0.7450 - val_binary_accuracy: 0.9044 - val_loss: 0.3091\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7349 - binary_accuracy: 0.9047 - loss: 0.3057 - val_auc: 0.7712 - val_binary_accuracy: 0.9044 - val_loss: 0.2949\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7509 - binary_accuracy: 0.9047 - loss: 0.2897 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2800\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7627 - binary_accuracy: 0.9047 - loss: 0.2754 - val_auc: 0.7768 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9047 - loss: 0.2701 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2726\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9047 - loss: 0.2681 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7635 - binary_accuracy: 0.9049 - loss: 0.2743\n",
            "Fold 4 Metrics: Loss = 0.2712, Accuracy = 0.9044, AUC = 0.7828\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5041 - binary_accuracy: 0.7764 - loss: 0.4915 - val_auc: 0.6729 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5882 - binary_accuracy: 0.9040 - loss: 0.3149 - val_auc: 0.7296 - val_binary_accuracy: 0.9044 - val_loss: 0.3122\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7166 - binary_accuracy: 0.9040 - loss: 0.3122 - val_auc: 0.7463 - val_binary_accuracy: 0.9044 - val_loss: 0.3044\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7387 - binary_accuracy: 0.9040 - loss: 0.3013 - val_auc: 0.7674 - val_binary_accuracy: 0.9044 - val_loss: 0.2817\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7552 - binary_accuracy: 0.9040 - loss: 0.2832 - val_auc: 0.7707 - val_binary_accuracy: 0.9044 - val_loss: 0.2714\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7643 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9040 - loss: 0.2729 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2655\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9040 - loss: 0.2717 - val_auc: 0.7822 - val_binary_accuracy: 0.9044 - val_loss: 0.2646\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9040 - loss: 0.2710 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2640\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9040 - loss: 0.2705 - val_auc: 0.7897 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8000 - binary_accuracy: 0.9013 - loss: 0.2621\n",
            "Fold 5 Metrics: Loss = 0.2635, Accuracy = 0.9044, AUC = 0.7897\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2666\n",
            "Average Accuracy: 0.9046\n",
            "Average AUC: 0.7869\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 4, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4990 - binary_accuracy: 0.7259 - loss: 0.4959 - val_auc: 0.6752 - val_binary_accuracy: 0.9044 - val_loss: 0.3144\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6313 - binary_accuracy: 0.9069 - loss: 0.3070 - val_auc: 0.7469 - val_binary_accuracy: 0.9044 - val_loss: 0.2975\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9069 - loss: 0.2813 - val_auc: 0.7646 - val_binary_accuracy: 0.9044 - val_loss: 0.2733\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9069 - loss: 0.2623 - val_auc: 0.7768 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9069 - loss: 0.2584 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9069 - loss: 0.2567 - val_auc: 0.7826 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7997 - binary_accuracy: 0.9069 - loss: 0.2556 - val_auc: 0.7866 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9069 - loss: 0.2546 - val_auc: 0.7901 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9070 - loss: 0.2536 - val_auc: 0.7907 - val_binary_accuracy: 0.9044 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9078 - loss: 0.2525 - val_auc: 0.7926 - val_binary_accuracy: 0.9069 - val_loss: 0.2607\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7934 - binary_accuracy: 0.9111 - loss: 0.2528\n",
            "Fold 1 Metrics: Loss = 0.2607, Accuracy = 0.9069, AUC = 0.7926\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5150 - binary_accuracy: 0.9029 - loss: 0.3443 - val_auc: 0.7261 - val_binary_accuracy: 0.9042 - val_loss: 0.3104\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7228 - binary_accuracy: 0.9029 - loss: 0.3022 - val_auc: 0.7919 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9029 - loss: 0.2716 - val_auc: 0.8001 - val_binary_accuracy: 0.9042 - val_loss: 0.2641\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9029 - loss: 0.2686 - val_auc: 0.8026 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9037 - loss: 0.2671 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9046 - loss: 0.2655 - val_auc: 0.8045 - val_binary_accuracy: 0.9056 - val_loss: 0.2614\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9066 - loss: 0.2639 - val_auc: 0.8050 - val_binary_accuracy: 0.9063 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.8069 - val_binary_accuracy: 0.9069 - val_loss: 0.2594\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9075 - loss: 0.2612 - val_auc: 0.8076 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9078 - loss: 0.2604 - val_auc: 0.8076 - val_binary_accuracy: 0.9082 - val_loss: 0.2588\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8108 - binary_accuracy: 0.9118 - loss: 0.2494\n",
            "Fold 2 Metrics: Loss = 0.2588, Accuracy = 0.9082, AUC = 0.8076\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5068 - binary_accuracy: 0.8865 - loss: 0.3881 - val_auc: 0.7022 - val_binary_accuracy: 0.9042 - val_loss: 0.3133\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6946 - binary_accuracy: 0.9051 - loss: 0.3082 - val_auc: 0.7682 - val_binary_accuracy: 0.9042 - val_loss: 0.2854\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7616 - binary_accuracy: 0.9051 - loss: 0.2770 - val_auc: 0.7730 - val_binary_accuracy: 0.9042 - val_loss: 0.2713\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9051 - loss: 0.2686 - val_auc: 0.7775 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7823 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9051 - loss: 0.2659 - val_auc: 0.7843 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9059 - loss: 0.2647 - val_auc: 0.7862 - val_binary_accuracy: 0.9082 - val_loss: 0.2654\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9079 - loss: 0.2636 - val_auc: 0.7873 - val_binary_accuracy: 0.9097 - val_loss: 0.2646\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9084 - loss: 0.2631 - val_auc: 0.7884 - val_binary_accuracy: 0.9102 - val_loss: 0.2638\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.7900 - val_binary_accuracy: 0.9103 - val_loss: 0.2632\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7847 - binary_accuracy: 0.9115 - loss: 0.2633\n",
            "Fold 3 Metrics: Loss = 0.2632, Accuracy = 0.9103, AUC = 0.7900\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5048 - binary_accuracy: 0.6734 - loss: 0.5628 - val_auc: 0.7008 - val_binary_accuracy: 0.9044 - val_loss: 0.3131\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6866 - binary_accuracy: 0.9047 - loss: 0.3106 - val_auc: 0.7548 - val_binary_accuracy: 0.9044 - val_loss: 0.2990\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7447 - binary_accuracy: 0.9047 - loss: 0.2920 - val_auc: 0.7681 - val_binary_accuracy: 0.9044 - val_loss: 0.2774\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9047 - loss: 0.2733 - val_auc: 0.7790 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9047 - loss: 0.2688 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2734\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9047 - loss: 0.2679 - val_auc: 0.7866 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9047 - loss: 0.2674 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9047 - loss: 0.2665 - val_auc: 0.7878 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9047 - loss: 0.2658 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9047 - loss: 0.2650 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7716 - binary_accuracy: 0.9049 - loss: 0.2734\n",
            "Fold 4 Metrics: Loss = 0.2680, Accuracy = 0.9044, AUC = 0.7924\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5250 - binary_accuracy: 0.9040 - loss: 0.3465 - val_auc: 0.7361 - val_binary_accuracy: 0.9044 - val_loss: 0.3061\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7318 - binary_accuracy: 0.9040 - loss: 0.2972 - val_auc: 0.7815 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7854 - val_binary_accuracy: 0.9044 - val_loss: 0.2632\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9040 - loss: 0.2719 - val_auc: 0.7871 - val_binary_accuracy: 0.9044 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9040 - loss: 0.2690 - val_auc: 0.7925 - val_binary_accuracy: 0.9044 - val_loss: 0.2590\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9041 - loss: 0.2673 - val_auc: 0.7960 - val_binary_accuracy: 0.9072 - val_loss: 0.2575\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.7983 - val_binary_accuracy: 0.9093 - val_loss: 0.2560\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2642 - val_auc: 0.8011 - val_binary_accuracy: 0.9100 - val_loss: 0.2547\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9087 - loss: 0.2630 - val_auc: 0.8025 - val_binary_accuracy: 0.9107 - val_loss: 0.2537\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8133 - binary_accuracy: 0.9093 - loss: 0.2513\n",
            "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9107, AUC = 0.8025\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2609\n",
            "Average Accuracy: 0.9081\n",
            "Average AUC: 0.7970\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 4, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5312 - binary_accuracy: 0.8037 - loss: 0.4185 - val_auc: 0.7559 - val_binary_accuracy: 0.9044 - val_loss: 0.2886\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9069 - loss: 0.2722 - val_auc: 0.7699 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7748 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9070 - loss: 0.2568 - val_auc: 0.7811 - val_binary_accuracy: 0.9044 - val_loss: 0.2661\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9078 - loss: 0.2548 - val_auc: 0.7855 - val_binary_accuracy: 0.9071 - val_loss: 0.2647\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9101 - loss: 0.2532 - val_auc: 0.7873 - val_binary_accuracy: 0.9085 - val_loss: 0.2635\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9121 - loss: 0.2518 - val_auc: 0.7886 - val_binary_accuracy: 0.9096 - val_loss: 0.2626\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8066 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7890 - val_binary_accuracy: 0.9100 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9131 - loss: 0.2495 - val_auc: 0.7893 - val_binary_accuracy: 0.9099 - val_loss: 0.2610\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7880 - binary_accuracy: 0.9131 - loss: 0.2545\n",
            "Fold 1 Metrics: Loss = 0.2610, Accuracy = 0.9099, AUC = 0.7893\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5575 - binary_accuracy: 0.9029 - loss: 0.3253 - val_auc: 0.7887 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9029 - loss: 0.2727 - val_auc: 0.8010 - val_binary_accuracy: 0.9042 - val_loss: 0.2620\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9036 - loss: 0.2681 - val_auc: 0.8052 - val_binary_accuracy: 0.9042 - val_loss: 0.2599\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9044 - loss: 0.2652 - val_auc: 0.8097 - val_binary_accuracy: 0.9051 - val_loss: 0.2574\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9052 - loss: 0.2629 - val_auc: 0.8098 - val_binary_accuracy: 0.9065 - val_loss: 0.2565\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9065 - loss: 0.2613 - val_auc: 0.8099 - val_binary_accuracy: 0.9071 - val_loss: 0.2560\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9067 - loss: 0.2602 - val_auc: 0.8104 - val_binary_accuracy: 0.9076 - val_loss: 0.2560\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9078 - loss: 0.2595 - val_auc: 0.8109 - val_binary_accuracy: 0.9084 - val_loss: 0.2557\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9073 - loss: 0.2589 - val_auc: 0.8114 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9075 - loss: 0.2584 - val_auc: 0.8107 - val_binary_accuracy: 0.9090 - val_loss: 0.2563\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8160 - binary_accuracy: 0.9130 - loss: 0.2456\n",
            "Fold 2 Metrics: Loss = 0.2563, Accuracy = 0.9090, AUC = 0.8107\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5587 - binary_accuracy: 0.8865 - loss: 0.3486 - val_auc: 0.7627 - val_binary_accuracy: 0.9042 - val_loss: 0.2795\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9051 - loss: 0.2726 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9051 - loss: 0.2673 - val_auc: 0.7875 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9052 - loss: 0.2654 - val_auc: 0.7923 - val_binary_accuracy: 0.9059 - val_loss: 0.2640\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9061 - loss: 0.2636 - val_auc: 0.7946 - val_binary_accuracy: 0.9097 - val_loss: 0.2620\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9085 - loss: 0.2626 - val_auc: 0.7963 - val_binary_accuracy: 0.9100 - val_loss: 0.2603\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9089 - loss: 0.2616 - val_auc: 0.7992 - val_binary_accuracy: 0.9102 - val_loss: 0.2591\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9091 - loss: 0.2610 - val_auc: 0.7993 - val_binary_accuracy: 0.9115 - val_loss: 0.2584\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.7996 - val_binary_accuracy: 0.9113 - val_loss: 0.2578\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9101 - loss: 0.2599 - val_auc: 0.8005 - val_binary_accuracy: 0.9110 - val_loss: 0.2574\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7935 - binary_accuracy: 0.9123 - loss: 0.2578\n",
            "Fold 3 Metrics: Loss = 0.2574, Accuracy = 0.9110, AUC = 0.8005\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5406 - binary_accuracy: 0.9043 - loss: 0.3519 - val_auc: 0.7755 - val_binary_accuracy: 0.9044 - val_loss: 0.2751\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9047 - loss: 0.2710 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7918 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9060 - loss: 0.2643 - val_auc: 0.7959 - val_binary_accuracy: 0.9072 - val_loss: 0.2626\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9085 - loss: 0.2623 - val_auc: 0.7982 - val_binary_accuracy: 0.9076 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9097 - loss: 0.2608 - val_auc: 0.8011 - val_binary_accuracy: 0.9085 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9104 - loss: 0.2596 - val_auc: 0.8037 - val_binary_accuracy: 0.9097 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9110 - loss: 0.2586 - val_auc: 0.8063 - val_binary_accuracy: 0.9104 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9112 - loss: 0.2579 - val_auc: 0.8073 - val_binary_accuracy: 0.9106 - val_loss: 0.2554\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9114 - loss: 0.2573 - val_auc: 0.8079 - val_binary_accuracy: 0.9104 - val_loss: 0.2549\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7903 - binary_accuracy: 0.9099 - loss: 0.2603\n",
            "Fold 4 Metrics: Loss = 0.2549, Accuracy = 0.9104, AUC = 0.8079\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5695 - binary_accuracy: 0.9040 - loss: 0.3262 - val_auc: 0.7827 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.7938 - val_binary_accuracy: 0.9044 - val_loss: 0.2604\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9041 - loss: 0.2694 - val_auc: 0.7970 - val_binary_accuracy: 0.9073 - val_loss: 0.2585\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9066 - loss: 0.2670 - val_auc: 0.7983 - val_binary_accuracy: 0.9081 - val_loss: 0.2575\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9079 - loss: 0.2656 - val_auc: 0.8006 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8025 - val_binary_accuracy: 0.9095 - val_loss: 0.2547\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8033 - val_binary_accuracy: 0.9104 - val_loss: 0.2539\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9089 - loss: 0.2623 - val_auc: 0.8048 - val_binary_accuracy: 0.9107 - val_loss: 0.2533\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9088 - loss: 0.2617 - val_auc: 0.8058 - val_binary_accuracy: 0.9109 - val_loss: 0.2529\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9087 - loss: 0.2611 - val_auc: 0.8069 - val_binary_accuracy: 0.9109 - val_loss: 0.2526\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8163 - binary_accuracy: 0.9092 - loss: 0.2503\n",
            "Fold 5 Metrics: Loss = 0.2526, Accuracy = 0.9109, AUC = 0.8069\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2565\n",
            "Average Accuracy: 0.9102\n",
            "Average AUC: 0.8031\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 4, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6197 - binary_accuracy: 0.9069 - loss: 0.3147 - val_auc: 0.7702 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9069 - loss: 0.2611 - val_auc: 0.7781 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9071 - loss: 0.2578 - val_auc: 0.7843 - val_binary_accuracy: 0.9044 - val_loss: 0.2651\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9092 - loss: 0.2548 - val_auc: 0.7886 - val_binary_accuracy: 0.9062 - val_loss: 0.2639\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9116 - loss: 0.2522 - val_auc: 0.7908 - val_binary_accuracy: 0.9081 - val_loss: 0.2624\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8073 - binary_accuracy: 0.9117 - loss: 0.2502 - val_auc: 0.7922 - val_binary_accuracy: 0.9085 - val_loss: 0.2612\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9122 - loss: 0.2488 - val_auc: 0.7934 - val_binary_accuracy: 0.9084 - val_loss: 0.2602\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8111 - binary_accuracy: 0.9129 - loss: 0.2479 - val_auc: 0.7930 - val_binary_accuracy: 0.9082 - val_loss: 0.2595\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9133 - loss: 0.2472 - val_auc: 0.7943 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8130 - binary_accuracy: 0.9133 - loss: 0.2466 - val_auc: 0.7937 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7931 - binary_accuracy: 0.9124 - loss: 0.2511\n",
            "Fold 1 Metrics: Loss = 0.2588, Accuracy = 0.9085, AUC = 0.7937\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5774 - binary_accuracy: 0.8554 - loss: 0.3685 - val_auc: 0.7944 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2710 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2600\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9040 - loss: 0.2665 - val_auc: 0.8060 - val_binary_accuracy: 0.9050 - val_loss: 0.2584\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9055 - loss: 0.2638 - val_auc: 0.8064 - val_binary_accuracy: 0.9066 - val_loss: 0.2574\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9068 - loss: 0.2621 - val_auc: 0.8075 - val_binary_accuracy: 0.9075 - val_loss: 0.2561\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9075 - loss: 0.2608 - val_auc: 0.8077 - val_binary_accuracy: 0.9082 - val_loss: 0.2557\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9075 - loss: 0.2600 - val_auc: 0.8078 - val_binary_accuracy: 0.9081 - val_loss: 0.2555\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9077 - loss: 0.2593 - val_auc: 0.8079 - val_binary_accuracy: 0.9081 - val_loss: 0.2552\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.8088 - val_binary_accuracy: 0.9084 - val_loss: 0.2550\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9080 - loss: 0.2582 - val_auc: 0.8093 - val_binary_accuracy: 0.9085 - val_loss: 0.2549\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9118 - loss: 0.2445\n",
            "Fold 2 Metrics: Loss = 0.2549, Accuracy = 0.9085, AUC = 0.8093\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6086 - binary_accuracy: 0.9051 - loss: 0.3213 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9051 - loss: 0.2719 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9057 - loss: 0.2687 - val_auc: 0.7903 - val_binary_accuracy: 0.9060 - val_loss: 0.2641\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9075 - loss: 0.2669 - val_auc: 0.7944 - val_binary_accuracy: 0.9093 - val_loss: 0.2616\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9084 - loss: 0.2655 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9088 - loss: 0.2644 - val_auc: 0.8006 - val_binary_accuracy: 0.9102 - val_loss: 0.2583\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9094 - loss: 0.2633 - val_auc: 0.8016 - val_binary_accuracy: 0.9109 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9098 - loss: 0.2625 - val_auc: 0.8036 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9096 - loss: 0.2618 - val_auc: 0.8048 - val_binary_accuracy: 0.9109 - val_loss: 0.2558\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8052 - val_binary_accuracy: 0.9112 - val_loss: 0.2554\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7985 - binary_accuracy: 0.9124 - loss: 0.2559\n",
            "Fold 3 Metrics: Loss = 0.2554, Accuracy = 0.9112, AUC = 0.8052\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5807 - binary_accuracy: 0.9047 - loss: 0.3278 - val_auc: 0.7863 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9050 - loss: 0.2676 - val_auc: 0.7948 - val_binary_accuracy: 0.9057 - val_loss: 0.2624\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9071 - loss: 0.2640 - val_auc: 0.7995 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9095 - loss: 0.2618 - val_auc: 0.8028 - val_binary_accuracy: 0.9097 - val_loss: 0.2571\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9104 - loss: 0.2604 - val_auc: 0.8042 - val_binary_accuracy: 0.9097 - val_loss: 0.2562\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9106 - loss: 0.2595 - val_auc: 0.8053 - val_binary_accuracy: 0.9095 - val_loss: 0.2558\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9108 - loss: 0.2588 - val_auc: 0.8070 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9110 - loss: 0.2582 - val_auc: 0.8077 - val_binary_accuracy: 0.9091 - val_loss: 0.2552\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9112 - loss: 0.2578 - val_auc: 0.8083 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9113 - loss: 0.2574 - val_auc: 0.8093 - val_binary_accuracy: 0.9090 - val_loss: 0.2547\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7916 - binary_accuracy: 0.9077 - loss: 0.2608\n",
            "Fold 4 Metrics: Loss = 0.2547, Accuracy = 0.9090, AUC = 0.8093\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5985 - binary_accuracy: 0.9040 - loss: 0.3231 - val_auc: 0.7888 - val_binary_accuracy: 0.9044 - val_loss: 0.2640\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9041 - loss: 0.2728 - val_auc: 0.7949 - val_binary_accuracy: 0.9079 - val_loss: 0.2604\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9053 - loss: 0.2700 - val_auc: 0.7979 - val_binary_accuracy: 0.9082 - val_loss: 0.2588\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9075 - loss: 0.2680 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9080 - loss: 0.2666 - val_auc: 0.8024 - val_binary_accuracy: 0.9106 - val_loss: 0.2561\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.8038 - val_binary_accuracy: 0.9104 - val_loss: 0.2549\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.8046 - val_binary_accuracy: 0.9112 - val_loss: 0.2540\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9093 - loss: 0.2630 - val_auc: 0.8059 - val_binary_accuracy: 0.9104 - val_loss: 0.2532\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.8061 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9093 - loss: 0.2615 - val_auc: 0.8066 - val_binary_accuracy: 0.9109 - val_loss: 0.2522\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9086 - loss: 0.2498\n",
            "Fold 5 Metrics: Loss = 0.2522, Accuracy = 0.9109, AUC = 0.8066\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2552\n",
            "Average Accuracy: 0.9096\n",
            "Average AUC: 0.8048\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 4, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6381 - binary_accuracy: 0.8901 - loss: 0.3081 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9076 - loss: 0.2585 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9098 - loss: 0.2556 - val_auc: 0.7888 - val_binary_accuracy: 0.9062 - val_loss: 0.2658\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9115 - loss: 0.2531 - val_auc: 0.7911 - val_binary_accuracy: 0.9075 - val_loss: 0.2642\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9120 - loss: 0.2511 - val_auc: 0.7925 - val_binary_accuracy: 0.9078 - val_loss: 0.2633\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8077 - binary_accuracy: 0.9122 - loss: 0.2497 - val_auc: 0.7945 - val_binary_accuracy: 0.9084 - val_loss: 0.2617\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9128 - loss: 0.2485 - val_auc: 0.7945 - val_binary_accuracy: 0.9084 - val_loss: 0.2607\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8114 - binary_accuracy: 0.9130 - loss: 0.2476 - val_auc: 0.7954 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9129 - loss: 0.2470 - val_auc: 0.7955 - val_binary_accuracy: 0.9081 - val_loss: 0.2596\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7946 - binary_accuracy: 0.9114 - loss: 0.2515\n",
            "Fold 1 Metrics: Loss = 0.2596, Accuracy = 0.9081, AUC = 0.7955\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5940 - binary_accuracy: 0.8692 - loss: 0.3557 - val_auc: 0.7984 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9033 - loss: 0.2711 - val_auc: 0.8041 - val_binary_accuracy: 0.9044 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9048 - loss: 0.2683 - val_auc: 0.8066 - val_binary_accuracy: 0.9062 - val_loss: 0.2617\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9061 - loss: 0.2657 - val_auc: 0.8072 - val_binary_accuracy: 0.9069 - val_loss: 0.2608\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8071 - val_binary_accuracy: 0.9075 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9081 - loss: 0.2622 - val_auc: 0.8075 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9085 - loss: 0.2611 - val_auc: 0.8068 - val_binary_accuracy: 0.9085 - val_loss: 0.2600\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9088 - loss: 0.2603 - val_auc: 0.8077 - val_binary_accuracy: 0.9087 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9089 - loss: 0.2596 - val_auc: 0.8080 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9091 - loss: 0.2591 - val_auc: 0.8089 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9129 - loss: 0.2485\n",
            "Fold 2 Metrics: Loss = 0.2582, Accuracy = 0.9091, AUC = 0.8089\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6086 - binary_accuracy: 0.8865 - loss: 0.3291 - val_auc: 0.7805 - val_binary_accuracy: 0.9042 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9051 - loss: 0.2737 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9052 - loss: 0.2709 - val_auc: 0.7893 - val_binary_accuracy: 0.9057 - val_loss: 0.2650\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.7923 - val_binary_accuracy: 0.9097 - val_loss: 0.2637\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9076 - loss: 0.2675 - val_auc: 0.7948 - val_binary_accuracy: 0.9102 - val_loss: 0.2625\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9085 - loss: 0.2661 - val_auc: 0.7970 - val_binary_accuracy: 0.9106 - val_loss: 0.2612\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9089 - loss: 0.2650 - val_auc: 0.7995 - val_binary_accuracy: 0.9110 - val_loss: 0.2600\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9093 - loss: 0.2640 - val_auc: 0.8004 - val_binary_accuracy: 0.9109 - val_loss: 0.2589\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9093 - loss: 0.2633 - val_auc: 0.8019 - val_binary_accuracy: 0.9109 - val_loss: 0.2580\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9096 - loss: 0.2628 - val_auc: 0.8033 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7952 - binary_accuracy: 0.9124 - loss: 0.2578\n",
            "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9109, AUC = 0.8033\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5841 - binary_accuracy: 0.8714 - loss: 0.3610 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9055 - loss: 0.2683 - val_auc: 0.7940 - val_binary_accuracy: 0.9070 - val_loss: 0.2619\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9078 - loss: 0.2653 - val_auc: 0.7998 - val_binary_accuracy: 0.9085 - val_loss: 0.2591\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9090 - loss: 0.2630 - val_auc: 0.8024 - val_binary_accuracy: 0.9094 - val_loss: 0.2571\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9099 - loss: 0.2615 - val_auc: 0.8052 - val_binary_accuracy: 0.9082 - val_loss: 0.2561\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9099 - loss: 0.2604 - val_auc: 0.8064 - val_binary_accuracy: 0.9088 - val_loss: 0.2554\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9103 - loss: 0.2597 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9107 - loss: 0.2590 - val_auc: 0.8081 - val_binary_accuracy: 0.9090 - val_loss: 0.2547\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9108 - loss: 0.2585 - val_auc: 0.8087 - val_binary_accuracy: 0.9091 - val_loss: 0.2545\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9108 - loss: 0.2580 - val_auc: 0.8094 - val_binary_accuracy: 0.9091 - val_loss: 0.2543\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7911 - binary_accuracy: 0.9087 - loss: 0.2614\n",
            "Fold 4 Metrics: Loss = 0.2543, Accuracy = 0.9091, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6132 - binary_accuracy: 0.9040 - loss: 0.3212 - val_auc: 0.7890 - val_binary_accuracy: 0.9048 - val_loss: 0.2685\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9041 - loss: 0.2740 - val_auc: 0.7950 - val_binary_accuracy: 0.9078 - val_loss: 0.2656\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9052 - loss: 0.2709 - val_auc: 0.7987 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9073 - loss: 0.2684 - val_auc: 0.8017 - val_binary_accuracy: 0.9076 - val_loss: 0.2627\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9078 - loss: 0.2667 - val_auc: 0.8041 - val_binary_accuracy: 0.9087 - val_loss: 0.2610\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9084 - loss: 0.2653 - val_auc: 0.8053 - val_binary_accuracy: 0.9091 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9089 - loss: 0.2641 - val_auc: 0.8064 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9098 - loss: 0.2631 - val_auc: 0.8077 - val_binary_accuracy: 0.9106 - val_loss: 0.2553\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9096 - loss: 0.2622 - val_auc: 0.8074 - val_binary_accuracy: 0.9112 - val_loss: 0.2541\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9098 - loss: 0.2615 - val_auc: 0.8082 - val_binary_accuracy: 0.9113 - val_loss: 0.2531\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9092 - loss: 0.2512\n",
            "Fold 5 Metrics: Loss = 0.2531, Accuracy = 0.9113, AUC = 0.8082\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2564\n",
            "Average Accuracy: 0.9097\n",
            "Average AUC: 0.8051\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 5, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4973 - binary_accuracy: 0.7440 - loss: 0.5121 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3162\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5044 - binary_accuracy: 0.9069 - loss: 0.3101 - val_auc: 0.4999 - val_binary_accuracy: 0.9044 - val_loss: 0.3150\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5662 - binary_accuracy: 0.9069 - loss: 0.3091 - val_auc: 0.7259 - val_binary_accuracy: 0.9044 - val_loss: 0.3125\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7352 - binary_accuracy: 0.9069 - loss: 0.3041 - val_auc: 0.7583 - val_binary_accuracy: 0.9044 - val_loss: 0.2982\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7614 - binary_accuracy: 0.9069 - loss: 0.2857 - val_auc: 0.7465 - val_binary_accuracy: 0.9044 - val_loss: 0.2798\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.7755 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9069 - loss: 0.2613 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9069 - loss: 0.2595 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9069 - loss: 0.2578 - val_auc: 0.7835 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9069 - loss: 0.2569 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7856 - binary_accuracy: 0.9084 - loss: 0.2585\n",
            "Fold 1 Metrics: Loss = 0.2671, Accuracy = 0.9044, AUC = 0.7839\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5018 - binary_accuracy: 0.9029 - loss: 0.4375 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3155\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5285 - binary_accuracy: 0.9029 - loss: 0.3185 - val_auc: 0.7104 - val_binary_accuracy: 0.9042 - val_loss: 0.3150\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6496 - binary_accuracy: 0.9029 - loss: 0.3174 - val_auc: 0.7353 - val_binary_accuracy: 0.9042 - val_loss: 0.3104\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7362 - binary_accuracy: 0.9029 - loss: 0.3084 - val_auc: 0.7837 - val_binary_accuracy: 0.9042 - val_loss: 0.2815\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9029 - loss: 0.2819 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9029 - loss: 0.2731 - val_auc: 0.7931 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9029 - loss: 0.2711 - val_auc: 0.7961 - val_binary_accuracy: 0.9042 - val_loss: 0.2643\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9029 - loss: 0.2700 - val_auc: 0.7974 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2689 - val_auc: 0.7995 - val_binary_accuracy: 0.9042 - val_loss: 0.2621\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9029 - loss: 0.2681 - val_auc: 0.8006 - val_binary_accuracy: 0.9042 - val_loss: 0.2611\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8018 - binary_accuracy: 0.9092 - loss: 0.2522\n",
            "Fold 2 Metrics: Loss = 0.2611, Accuracy = 0.9042, AUC = 0.8006\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4998 - binary_accuracy: 0.7474 - loss: 0.4956 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3158\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4981 - binary_accuracy: 0.9051 - loss: 0.3138 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3155\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5111 - binary_accuracy: 0.9051 - loss: 0.3136 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3153\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5305 - binary_accuracy: 0.9051 - loss: 0.3133 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3146\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5968 - binary_accuracy: 0.9051 - loss: 0.3124 - val_auc: 0.7238 - val_binary_accuracy: 0.9042 - val_loss: 0.3115\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7208 - binary_accuracy: 0.9051 - loss: 0.3061 - val_auc: 0.7651 - val_binary_accuracy: 0.9042 - val_loss: 0.2848\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7559 - binary_accuracy: 0.9051 - loss: 0.2801 - val_auc: 0.7686 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9051 - loss: 0.2730 - val_auc: 0.7718 - val_binary_accuracy: 0.9042 - val_loss: 0.2725\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7622 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2725\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9051 - loss: 0.2691 - val_auc: 0.7719 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7689 - binary_accuracy: 0.9046 - loss: 0.2724\n",
            "Fold 3 Metrics: Loss = 0.2723, Accuracy = 0.9042, AUC = 0.7719\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4987 - binary_accuracy: 0.9047 - loss: 0.3930 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5932 - binary_accuracy: 0.9047 - loss: 0.3133 - val_auc: 0.7478 - val_binary_accuracy: 0.9044 - val_loss: 0.3086\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7324 - binary_accuracy: 0.9047 - loss: 0.3026 - val_auc: 0.7721 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9047 - loss: 0.2778 - val_auc: 0.7746 - val_binary_accuracy: 0.9044 - val_loss: 0.2757\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9047 - loss: 0.2697 - val_auc: 0.7784 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9047 - loss: 0.2678 - val_auc: 0.7677 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9047 - loss: 0.2673 - val_auc: 0.7790 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7833 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2655 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2678\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9047 - loss: 0.2652 - val_auc: 0.7777 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7564 - binary_accuracy: 0.9049 - loss: 0.2730\n",
            "Fold 4 Metrics: Loss = 0.2683, Accuracy = 0.9044, AUC = 0.7777\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5013 - binary_accuracy: 0.9040 - loss: 0.4339 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3152\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5197 - binary_accuracy: 0.9040 - loss: 0.3159 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6066 - binary_accuracy: 0.9040 - loss: 0.3148 - val_auc: 0.7457 - val_binary_accuracy: 0.9044 - val_loss: 0.3095\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7343 - binary_accuracy: 0.9040 - loss: 0.3048 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2764\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9040 - loss: 0.2780 - val_auc: 0.7844 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9040 - loss: 0.2727 - val_auc: 0.7884 - val_binary_accuracy: 0.9044 - val_loss: 0.2636\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9040 - loss: 0.2714 - val_auc: 0.7879 - val_binary_accuracy: 0.9044 - val_loss: 0.2630\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9040 - loss: 0.2703 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2625\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9040 - loss: 0.2696 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2625\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9040 - loss: 0.2692 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2619\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8004 - binary_accuracy: 0.9013 - loss: 0.2606\n",
            "Fold 5 Metrics: Loss = 0.2619, Accuracy = 0.9044, AUC = 0.7917\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2662\n",
            "Average Accuracy: 0.9043\n",
            "Average AUC: 0.7852\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 5, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5026 - binary_accuracy: 0.9069 - loss: 0.3597 - val_auc: 0.6572 - val_binary_accuracy: 0.9044 - val_loss: 0.3142\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6451 - binary_accuracy: 0.9069 - loss: 0.3047 - val_auc: 0.7599 - val_binary_accuracy: 0.9044 - val_loss: 0.2794\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.7708 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9069 - loss: 0.2602 - val_auc: 0.7748 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9069 - loss: 0.2587 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9069 - loss: 0.2579 - val_auc: 0.7780 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9069 - loss: 0.2572 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9069 - loss: 0.2566 - val_auc: 0.7803 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9069 - loss: 0.2560 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9069 - loss: 0.2551 - val_auc: 0.7861 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7829 - binary_accuracy: 0.9084 - loss: 0.2585\n",
            "Fold 1 Metrics: Loss = 0.2649, Accuracy = 0.9044, AUC = 0.7861\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5047 - binary_accuracy: 0.9029 - loss: 0.3619 - val_auc: 0.7054 - val_binary_accuracy: 0.9042 - val_loss: 0.3143\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6909 - binary_accuracy: 0.9029 - loss: 0.3084 - val_auc: 0.7925 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9029 - loss: 0.2722 - val_auc: 0.7999 - val_binary_accuracy: 0.9042 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9029 - loss: 0.2690 - val_auc: 0.8028 - val_binary_accuracy: 0.9042 - val_loss: 0.2633\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9029 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9042 - val_loss: 0.2633\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9029 - loss: 0.2669 - val_auc: 0.8054 - val_binary_accuracy: 0.9042 - val_loss: 0.2627\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9029 - loss: 0.2664 - val_auc: 0.8052 - val_binary_accuracy: 0.9042 - val_loss: 0.2626\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7906 - binary_accuracy: 0.9035 - loss: 0.2658 - val_auc: 0.8054 - val_binary_accuracy: 0.9042 - val_loss: 0.2625\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9049 - loss: 0.2650 - val_auc: 0.8058 - val_binary_accuracy: 0.9050 - val_loss: 0.2620\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9062 - loss: 0.2642 - val_auc: 0.8061 - val_binary_accuracy: 0.9062 - val_loss: 0.2615\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8058 - binary_accuracy: 0.9101 - loss: 0.2528\n",
            "Fold 2 Metrics: Loss = 0.2615, Accuracy = 0.9062, AUC = 0.8061\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5010 - binary_accuracy: 0.7300 - loss: 0.4890 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3154\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5254 - binary_accuracy: 0.9051 - loss: 0.3129 - val_auc: 0.7501 - val_binary_accuracy: 0.9042 - val_loss: 0.3068\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7356 - binary_accuracy: 0.9051 - loss: 0.2949 - val_auc: 0.7756 - val_binary_accuracy: 0.9042 - val_loss: 0.2748\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9051 - loss: 0.2704 - val_auc: 0.7812 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9051 - loss: 0.2673 - val_auc: 0.7856 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2676\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9051 - loss: 0.2654 - val_auc: 0.7883 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9051 - loss: 0.2651 - val_auc: 0.7908 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9052 - loss: 0.2643 - val_auc: 0.7913 - val_binary_accuracy: 0.9063 - val_loss: 0.2643\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9062 - loss: 0.2637 - val_auc: 0.7925 - val_binary_accuracy: 0.9100 - val_loss: 0.2632\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7864 - binary_accuracy: 0.9103 - loss: 0.2638\n",
            "Fold 3 Metrics: Loss = 0.2632, Accuracy = 0.9100, AUC = 0.7925\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4988 - binary_accuracy: 0.8179 - loss: 0.4269 - val_auc: 0.6953 - val_binary_accuracy: 0.9044 - val_loss: 0.3144\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6380 - binary_accuracy: 0.9047 - loss: 0.3116 - val_auc: 0.7670 - val_binary_accuracy: 0.9044 - val_loss: 0.2962\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7441 - binary_accuracy: 0.9047 - loss: 0.2865 - val_auc: 0.7732 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9047 - loss: 0.2683 - val_auc: 0.7796 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9047 - loss: 0.2664 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9050 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9045 - val_loss: 0.2640\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9076 - loss: 0.2622 - val_auc: 0.7892 - val_binary_accuracy: 0.9073 - val_loss: 0.2642\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9091 - loss: 0.2608 - val_auc: 0.7937 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9097 - loss: 0.2598 - val_auc: 0.7958 - val_binary_accuracy: 0.9082 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.7973 - val_binary_accuracy: 0.9088 - val_loss: 0.2603\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7782 - binary_accuracy: 0.9085 - loss: 0.2655\n",
            "Fold 4 Metrics: Loss = 0.2603, Accuracy = 0.9088, AUC = 0.7973\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5080 - binary_accuracy: 0.7764 - loss: 0.4473 - val_auc: 0.6901 - val_binary_accuracy: 0.9044 - val_loss: 0.3133\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6971 - binary_accuracy: 0.9040 - loss: 0.3102 - val_auc: 0.7698 - val_binary_accuracy: 0.9044 - val_loss: 0.2806\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7589 - binary_accuracy: 0.9040 - loss: 0.2803 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2645\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9040 - loss: 0.2713 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9040 - loss: 0.2694 - val_auc: 0.7942 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9040 - loss: 0.2682 - val_auc: 0.7950 - val_binary_accuracy: 0.9044 - val_loss: 0.2599\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9040 - loss: 0.2674 - val_auc: 0.7961 - val_binary_accuracy: 0.9044 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9040 - loss: 0.2667 - val_auc: 0.7972 - val_binary_accuracy: 0.9044 - val_loss: 0.2589\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9040 - loss: 0.2659 - val_auc: 0.7993 - val_binary_accuracy: 0.9044 - val_loss: 0.2581\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9044 - loss: 0.2653 - val_auc: 0.7986 - val_binary_accuracy: 0.9081 - val_loss: 0.2576\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8077 - binary_accuracy: 0.9069 - loss: 0.2551\n",
            "Fold 5 Metrics: Loss = 0.2576, Accuracy = 0.9081, AUC = 0.7986\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2615\n",
            "Average Accuracy: 0.9075\n",
            "Average AUC: 0.7961\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 5, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5420 - binary_accuracy: 0.9069 - loss: 0.3254 - val_auc: 0.7619 - val_binary_accuracy: 0.9044 - val_loss: 0.2807\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9069 - loss: 0.2660 - val_auc: 0.7734 - val_binary_accuracy: 0.9044 - val_loss: 0.2726\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9069 - loss: 0.2603 - val_auc: 0.7774 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9069 - loss: 0.2581 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9071 - loss: 0.2562 - val_auc: 0.7832 - val_binary_accuracy: 0.9056 - val_loss: 0.2658\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8002 - binary_accuracy: 0.9091 - loss: 0.2545 - val_auc: 0.7851 - val_binary_accuracy: 0.9078 - val_loss: 0.2641\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9118 - loss: 0.2532 - val_auc: 0.7867 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9122 - loss: 0.2518 - val_auc: 0.7875 - val_binary_accuracy: 0.9090 - val_loss: 0.2609\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9129 - loss: 0.2507 - val_auc: 0.7894 - val_binary_accuracy: 0.9091 - val_loss: 0.2602\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9132 - loss: 0.2496 - val_auc: 0.7899 - val_binary_accuracy: 0.9088 - val_loss: 0.2597\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7861 - binary_accuracy: 0.9128 - loss: 0.2532\n",
            "Fold 1 Metrics: Loss = 0.2597, Accuracy = 0.9088, AUC = 0.7899\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5275 - binary_accuracy: 0.8436 - loss: 0.3803 - val_auc: 0.7777 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9029 - loss: 0.2805 - val_auc: 0.7999 - val_binary_accuracy: 0.9042 - val_loss: 0.2628\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2687 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2598\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9031 - loss: 0.2663 - val_auc: 0.8063 - val_binary_accuracy: 0.9042 - val_loss: 0.2588\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9057 - loss: 0.2644 - val_auc: 0.8079 - val_binary_accuracy: 0.9066 - val_loss: 0.2587\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9068 - loss: 0.2629 - val_auc: 0.8081 - val_binary_accuracy: 0.9075 - val_loss: 0.2586\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9076 - loss: 0.2617 - val_auc: 0.8057 - val_binary_accuracy: 0.9072 - val_loss: 0.2591\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9083 - loss: 0.2609 - val_auc: 0.8058 - val_binary_accuracy: 0.9072 - val_loss: 0.2594\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9083 - loss: 0.2603 - val_auc: 0.8066 - val_binary_accuracy: 0.9075 - val_loss: 0.2598\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9084 - loss: 0.2597 - val_auc: 0.8069 - val_binary_accuracy: 0.9082 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9128 - loss: 0.2491\n",
            "Fold 2 Metrics: Loss = 0.2599, Accuracy = 0.9082, AUC = 0.8069\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5089 - binary_accuracy: 0.7474 - loss: 0.4985 - val_auc: 0.7218 - val_binary_accuracy: 0.9042 - val_loss: 0.3102\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7207 - binary_accuracy: 0.9051 - loss: 0.2970 - val_auc: 0.7743 - val_binary_accuracy: 0.9042 - val_loss: 0.2752\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9051 - loss: 0.2705 - val_auc: 0.7817 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7897 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9059 - loss: 0.2653 - val_auc: 0.7896 - val_binary_accuracy: 0.9097 - val_loss: 0.2642\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.7916 - val_binary_accuracy: 0.9099 - val_loss: 0.2625\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9088 - loss: 0.2635 - val_auc: 0.7947 - val_binary_accuracy: 0.9104 - val_loss: 0.2607\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7970 - val_binary_accuracy: 0.9112 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9090 - loss: 0.2620 - val_auc: 0.7987 - val_binary_accuracy: 0.9116 - val_loss: 0.2582\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9134 - loss: 0.2586\n",
            "Fold 3 Metrics: Loss = 0.2582, Accuracy = 0.9116, AUC = 0.7987\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5045 - binary_accuracy: 0.9047 - loss: 0.3483 - val_auc: 0.7596 - val_binary_accuracy: 0.9044 - val_loss: 0.2908\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7565 - binary_accuracy: 0.9047 - loss: 0.2779 - val_auc: 0.7874 - val_binary_accuracy: 0.9044 - val_loss: 0.2658\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9047 - loss: 0.2657 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2642\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9049 - loss: 0.2636 - val_auc: 0.7943 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9064 - loss: 0.2620 - val_auc: 0.7993 - val_binary_accuracy: 0.9066 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9089 - loss: 0.2606 - val_auc: 0.8023 - val_binary_accuracy: 0.9082 - val_loss: 0.2580\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9098 - loss: 0.2597 - val_auc: 0.8035 - val_binary_accuracy: 0.9085 - val_loss: 0.2568\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9093 - loss: 0.2589 - val_auc: 0.8057 - val_binary_accuracy: 0.9087 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9098 - loss: 0.2586 - val_auc: 0.8056 - val_binary_accuracy: 0.9088 - val_loss: 0.2560\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9102 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9091 - val_loss: 0.2557\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9087 - loss: 0.2614\n",
            "Fold 4 Metrics: Loss = 0.2557, Accuracy = 0.9091, AUC = 0.8071\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5529 - binary_accuracy: 0.9040 - loss: 0.3187 - val_auc: 0.7836 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.7918 - val_binary_accuracy: 0.9044 - val_loss: 0.2614\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9040 - loss: 0.2702 - val_auc: 0.7938 - val_binary_accuracy: 0.9045 - val_loss: 0.2605\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9047 - loss: 0.2684 - val_auc: 0.7953 - val_binary_accuracy: 0.9079 - val_loss: 0.2590\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9073 - loss: 0.2670 - val_auc: 0.7974 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9083 - loss: 0.2658 - val_auc: 0.7999 - val_binary_accuracy: 0.9091 - val_loss: 0.2565\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9083 - loss: 0.2648 - val_auc: 0.8004 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8026 - val_binary_accuracy: 0.9091 - val_loss: 0.2548\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9089 - loss: 0.2631 - val_auc: 0.8036 - val_binary_accuracy: 0.9098 - val_loss: 0.2541\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8037 - val_binary_accuracy: 0.9103 - val_loss: 0.2536\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8138 - binary_accuracy: 0.9081 - loss: 0.2509\n",
            "Fold 5 Metrics: Loss = 0.2536, Accuracy = 0.9103, AUC = 0.8037\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2574\n",
            "Average Accuracy: 0.9096\n",
            "Average AUC: 0.8013\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 5, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5788 - binary_accuracy: 0.8757 - loss: 0.3350 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9069 - loss: 0.2623 - val_auc: 0.7760 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9069 - loss: 0.2591 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9071 - loss: 0.2567 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9089 - loss: 0.2543 - val_auc: 0.7881 - val_binary_accuracy: 0.9065 - val_loss: 0.2633\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8040 - binary_accuracy: 0.9113 - loss: 0.2522 - val_auc: 0.7906 - val_binary_accuracy: 0.9079 - val_loss: 0.2618\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9121 - loss: 0.2505 - val_auc: 0.7912 - val_binary_accuracy: 0.9087 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8085 - binary_accuracy: 0.9120 - loss: 0.2494 - val_auc: 0.7919 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8105 - binary_accuracy: 0.9127 - loss: 0.2484 - val_auc: 0.7918 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8116 - binary_accuracy: 0.9131 - loss: 0.2476 - val_auc: 0.7925 - val_binary_accuracy: 0.9090 - val_loss: 0.2592\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7916 - binary_accuracy: 0.9130 - loss: 0.2516\n",
            "Fold 1 Metrics: Loss = 0.2592, Accuracy = 0.9090, AUC = 0.7925\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5215 - binary_accuracy: 0.8554 - loss: 0.3773 - val_auc: 0.7895 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9029 - loss: 0.2742 - val_auc: 0.7998 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8044 - val_binary_accuracy: 0.9042 - val_loss: 0.2604\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9030 - loss: 0.2676 - val_auc: 0.8065 - val_binary_accuracy: 0.9042 - val_loss: 0.2592\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9052 - loss: 0.2652 - val_auc: 0.8082 - val_binary_accuracy: 0.9062 - val_loss: 0.2580\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9064 - loss: 0.2632 - val_auc: 0.8087 - val_binary_accuracy: 0.9075 - val_loss: 0.2570\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9075 - loss: 0.2616 - val_auc: 0.8086 - val_binary_accuracy: 0.9078 - val_loss: 0.2564\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9081 - loss: 0.2606 - val_auc: 0.8084 - val_binary_accuracy: 0.9078 - val_loss: 0.2559\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9080 - loss: 0.2598 - val_auc: 0.8092 - val_binary_accuracy: 0.9084 - val_loss: 0.2555\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9084 - loss: 0.2592 - val_auc: 0.8089 - val_binary_accuracy: 0.9084 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9123 - loss: 0.2447\n",
            "Fold 2 Metrics: Loss = 0.2551, Accuracy = 0.9084, AUC = 0.8089\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5237 - binary_accuracy: 0.8325 - loss: 0.4001 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2727\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7596 - binary_accuracy: 0.9051 - loss: 0.2740 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2702 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2665\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9053 - loss: 0.2684 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9068 - loss: 0.2673 - val_auc: 0.7928 - val_binary_accuracy: 0.9100 - val_loss: 0.2627\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7952 - val_binary_accuracy: 0.9103 - val_loss: 0.2610\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9083 - loss: 0.2653 - val_auc: 0.7984 - val_binary_accuracy: 0.9110 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9085 - loss: 0.2646 - val_auc: 0.8002 - val_binary_accuracy: 0.9113 - val_loss: 0.2585\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8018 - val_binary_accuracy: 0.9112 - val_loss: 0.2576\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9089 - loss: 0.2632 - val_auc: 0.8034 - val_binary_accuracy: 0.9112 - val_loss: 0.2570\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7960 - binary_accuracy: 0.9128 - loss: 0.2577\n",
            "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9112, AUC = 0.8034\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5373 - binary_accuracy: 0.8714 - loss: 0.3583 - val_auc: 0.7820 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9047 - loss: 0.2687 - val_auc: 0.7899 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9065 - loss: 0.2651 - val_auc: 0.7940 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9094 - loss: 0.2631 - val_auc: 0.7965 - val_binary_accuracy: 0.9090 - val_loss: 0.2596\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.7982 - val_binary_accuracy: 0.9093 - val_loss: 0.2586\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9099 - loss: 0.2606 - val_auc: 0.8004 - val_binary_accuracy: 0.9097 - val_loss: 0.2578\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9106 - loss: 0.2599 - val_auc: 0.8022 - val_binary_accuracy: 0.9095 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9106 - loss: 0.2593 - val_auc: 0.8034 - val_binary_accuracy: 0.9098 - val_loss: 0.2566\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9110 - loss: 0.2589 - val_auc: 0.8048 - val_binary_accuracy: 0.9095 - val_loss: 0.2562\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9112 - loss: 0.2584 - val_auc: 0.8057 - val_binary_accuracy: 0.9097 - val_loss: 0.2557\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7869 - binary_accuracy: 0.9091 - loss: 0.2618\n",
            "Fold 4 Metrics: Loss = 0.2557, Accuracy = 0.9097, AUC = 0.8057\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5867 - binary_accuracy: 0.9040 - loss: 0.3168 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9041 - loss: 0.2742 - val_auc: 0.7943 - val_binary_accuracy: 0.9073 - val_loss: 0.2612\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9042 - loss: 0.2710 - val_auc: 0.7981 - val_binary_accuracy: 0.9069 - val_loss: 0.2596\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9065 - loss: 0.2689 - val_auc: 0.8007 - val_binary_accuracy: 0.9091 - val_loss: 0.2583\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9083 - loss: 0.2673 - val_auc: 0.8028 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9082 - loss: 0.2659 - val_auc: 0.8045 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9090 - loss: 0.2647 - val_auc: 0.8057 - val_binary_accuracy: 0.9106 - val_loss: 0.2546\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.8075 - val_binary_accuracy: 0.9110 - val_loss: 0.2534\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9094 - loss: 0.2629 - val_auc: 0.8077 - val_binary_accuracy: 0.9115 - val_loss: 0.2524\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9095 - loss: 0.2620 - val_auc: 0.8085 - val_binary_accuracy: 0.9121 - val_loss: 0.2518\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9102 - loss: 0.2490\n",
            "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9121, AUC = 0.8085\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2558\n",
            "Average Accuracy: 0.9101\n",
            "Average AUC: 0.8038\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 5, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5900 - binary_accuracy: 0.8901 - loss: 0.3228 - val_auc: 0.7708 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2701\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2596 - val_auc: 0.7834 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9072 - loss: 0.2571 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9102 - loss: 0.2549 - val_auc: 0.7906 - val_binary_accuracy: 0.9065 - val_loss: 0.2654\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9115 - loss: 0.2530 - val_auc: 0.7923 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8049 - binary_accuracy: 0.9119 - loss: 0.2514 - val_auc: 0.7938 - val_binary_accuracy: 0.9088 - val_loss: 0.2632\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9124 - loss: 0.2502 - val_auc: 0.7938 - val_binary_accuracy: 0.9087 - val_loss: 0.2623\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9131 - loss: 0.2493 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2613\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9128 - loss: 0.2484 - val_auc: 0.7945 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7941 - binary_accuracy: 0.9117 - loss: 0.2521\n",
            "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9085, AUC = 0.7945\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5756 - binary_accuracy: 0.8847 - loss: 0.3358 - val_auc: 0.7968 - val_binary_accuracy: 0.9042 - val_loss: 0.2679\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.8036 - val_binary_accuracy: 0.9042 - val_loss: 0.2654\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9041 - loss: 0.2690 - val_auc: 0.8057 - val_binary_accuracy: 0.9047 - val_loss: 0.2633\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9062 - loss: 0.2658 - val_auc: 0.8066 - val_binary_accuracy: 0.9066 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9066 - loss: 0.2637 - val_auc: 0.8076 - val_binary_accuracy: 0.9068 - val_loss: 0.2605\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9075 - loss: 0.2621 - val_auc: 0.8079 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9077 - loss: 0.2610 - val_auc: 0.8076 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9080 - loss: 0.2603 - val_auc: 0.8082 - val_binary_accuracy: 0.9079 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8012 - binary_accuracy: 0.9078 - loss: 0.2597 - val_auc: 0.8088 - val_binary_accuracy: 0.9079 - val_loss: 0.2595\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9080 - loss: 0.2593 - val_auc: 0.8085 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9116 - loss: 0.2494\n",
            "Fold 2 Metrics: Loss = 0.2590, Accuracy = 0.9078, AUC = 0.8085\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - auc: 0.5779 - binary_accuracy: 0.8865 - loss: 0.3352 - val_auc: 0.7785 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7545 - binary_accuracy: 0.9051 - loss: 0.2757 - val_auc: 0.7834 - val_binary_accuracy: 0.9042 - val_loss: 0.2678\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9051 - loss: 0.2719 - val_auc: 0.7873 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9051 - loss: 0.2700 - val_auc: 0.7896 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9054 - loss: 0.2687 - val_auc: 0.7923 - val_binary_accuracy: 0.9090 - val_loss: 0.2638\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9068 - loss: 0.2675 - val_auc: 0.7952 - val_binary_accuracy: 0.9099 - val_loss: 0.2624\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9082 - loss: 0.2664 - val_auc: 0.7980 - val_binary_accuracy: 0.9109 - val_loss: 0.2612\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9087 - loss: 0.2653 - val_auc: 0.7999 - val_binary_accuracy: 0.9107 - val_loss: 0.2601\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9091 - loss: 0.2644 - val_auc: 0.8019 - val_binary_accuracy: 0.9107 - val_loss: 0.2591\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8037 - val_binary_accuracy: 0.9112 - val_loss: 0.2580\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9126 - loss: 0.2589\n",
            "Fold 3 Metrics: Loss = 0.2580, Accuracy = 0.9112, AUC = 0.8037\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5519 - binary_accuracy: 0.8866 - loss: 0.3507 - val_auc: 0.7860 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9047 - loss: 0.2698 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2636\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9054 - loss: 0.2668 - val_auc: 0.7966 - val_binary_accuracy: 0.9081 - val_loss: 0.2608\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9080 - loss: 0.2648 - val_auc: 0.7992 - val_binary_accuracy: 0.9094 - val_loss: 0.2593\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8004 - val_binary_accuracy: 0.9090 - val_loss: 0.2582\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9098 - loss: 0.2620 - val_auc: 0.8016 - val_binary_accuracy: 0.9090 - val_loss: 0.2577\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9104 - loss: 0.2611 - val_auc: 0.8030 - val_binary_accuracy: 0.9084 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9107 - loss: 0.2603 - val_auc: 0.8049 - val_binary_accuracy: 0.9091 - val_loss: 0.2563\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9109 - loss: 0.2596 - val_auc: 0.8061 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9112 - loss: 0.2591 - val_auc: 0.8070 - val_binary_accuracy: 0.9093 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9092 - loss: 0.2622\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9093, AUC = 0.8070\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5931 - binary_accuracy: 0.9040 - loss: 0.3197 - val_auc: 0.7878 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9040 - loss: 0.2748 - val_auc: 0.7934 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9041 - loss: 0.2720 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2633\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9048 - loss: 0.2699 - val_auc: 0.7999 - val_binary_accuracy: 0.9093 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9070 - loss: 0.2679 - val_auc: 0.8018 - val_binary_accuracy: 0.9091 - val_loss: 0.2620\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9085 - loss: 0.2664 - val_auc: 0.8035 - val_binary_accuracy: 0.9097 - val_loss: 0.2618\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9081 - loss: 0.2652 - val_auc: 0.8056 - val_binary_accuracy: 0.9097 - val_loss: 0.2613\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9090 - loss: 0.2642 - val_auc: 0.8070 - val_binary_accuracy: 0.9101 - val_loss: 0.2605\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9092 - loss: 0.2633 - val_auc: 0.8072 - val_binary_accuracy: 0.9097 - val_loss: 0.2595\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9093 - loss: 0.2627 - val_auc: 0.8085 - val_binary_accuracy: 0.9103 - val_loss: 0.2583\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8171 - binary_accuracy: 0.9119 - loss: 0.2560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|   | 2/3 [55:17<27:40, 1660.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 Metrics: Loss = 0.2583, Accuracy = 0.9103, AUC = 0.8085\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2582\n",
            "Average Accuracy: 0.9094\n",
            "Average AUC: 0.8044\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 1, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5266 - binary_accuracy: 0.6977 - loss: 0.5188 - val_auc: 0.6882 - val_binary_accuracy: 0.9041 - val_loss: 0.2958\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7066 - binary_accuracy: 0.9069 - loss: 0.2843 - val_auc: 0.7156 - val_binary_accuracy: 0.9044 - val_loss: 0.2857\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7444 - binary_accuracy: 0.9069 - loss: 0.2756 - val_auc: 0.7374 - val_binary_accuracy: 0.9042 - val_loss: 0.2824\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7606 - binary_accuracy: 0.9069 - loss: 0.2714 - val_auc: 0.7393 - val_binary_accuracy: 0.9044 - val_loss: 0.2792\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9069 - loss: 0.2688 - val_auc: 0.7333 - val_binary_accuracy: 0.9044 - val_loss: 0.2777\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7395 - val_binary_accuracy: 0.9044 - val_loss: 0.2770\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9069 - loss: 0.2660 - val_auc: 0.7345 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9069 - loss: 0.2652 - val_auc: 0.7471 - val_binary_accuracy: 0.9041 - val_loss: 0.2758\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9069 - loss: 0.2645 - val_auc: 0.7442 - val_binary_accuracy: 0.9041 - val_loss: 0.2753\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9069 - loss: 0.2639 - val_auc: 0.7444 - val_binary_accuracy: 0.9041 - val_loss: 0.2749\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7428 - binary_accuracy: 0.9081 - loss: 0.2662\n",
            "Fold 1 Metrics: Loss = 0.2749, Accuracy = 0.9041, AUC = 0.7444\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5584 - binary_accuracy: 0.7373 - loss: 0.5031 - val_auc: 0.7282 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7379 - binary_accuracy: 0.9029 - loss: 0.2878 - val_auc: 0.7527 - val_binary_accuracy: 0.9042 - val_loss: 0.2819\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7542 - binary_accuracy: 0.9029 - loss: 0.2822 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7659 - binary_accuracy: 0.9029 - loss: 0.2775 - val_auc: 0.7833 - val_binary_accuracy: 0.9042 - val_loss: 0.2716\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2734 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7802 - binary_accuracy: 0.9029 - loss: 0.2704 - val_auc: 0.7926 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2685 - val_auc: 0.7953 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7872 - binary_accuracy: 0.9043 - loss: 0.2676 - val_auc: 0.7943 - val_binary_accuracy: 0.9053 - val_loss: 0.2657\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9072 - loss: 0.2666 - val_auc: 0.7934 - val_binary_accuracy: 0.9065 - val_loss: 0.2658\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7911 - val_binary_accuracy: 0.9076 - val_loss: 0.2662\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9112 - loss: 0.2568\n",
            "Fold 2 Metrics: Loss = 0.2662, Accuracy = 0.9076, AUC = 0.7911\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5662 - binary_accuracy: 0.8890 - loss: 0.3588 - val_auc: 0.7475 - val_binary_accuracy: 0.9042 - val_loss: 0.2856\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7347 - binary_accuracy: 0.9051 - loss: 0.2849 - val_auc: 0.7552 - val_binary_accuracy: 0.9042 - val_loss: 0.2783\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7453 - binary_accuracy: 0.9051 - loss: 0.2784 - val_auc: 0.7623 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7551 - binary_accuracy: 0.9051 - loss: 0.2734 - val_auc: 0.7645 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7613 - binary_accuracy: 0.9051 - loss: 0.2702 - val_auc: 0.7666 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7656 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7695 - val_binary_accuracy: 0.9042 - val_loss: 0.2701\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2667 - val_auc: 0.7708 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9051 - loss: 0.2656 - val_auc: 0.7716 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9051 - loss: 0.2645 - val_auc: 0.7711 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9051 - loss: 0.2637 - val_auc: 0.7710 - val_binary_accuracy: 0.9042 - val_loss: 0.2683\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7722 - binary_accuracy: 0.9046 - loss: 0.2666\n",
            "Fold 3 Metrics: Loss = 0.2683, Accuracy = 0.9042, AUC = 0.7710\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6024 - binary_accuracy: 0.9021 - loss: 0.3401 - val_auc: 0.7602 - val_binary_accuracy: 0.9044 - val_loss: 0.2823\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7582 - binary_accuracy: 0.9047 - loss: 0.2790 - val_auc: 0.7630 - val_binary_accuracy: 0.9044 - val_loss: 0.2767\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9047 - loss: 0.2731 - val_auc: 0.7760 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9047 - loss: 0.2720 - val_auc: 0.7770 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7708 - binary_accuracy: 0.9047 - loss: 0.2704 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7707 - binary_accuracy: 0.9047 - loss: 0.2693 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9047 - loss: 0.2689 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2709\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9047 - loss: 0.2682 - val_auc: 0.7795 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9048 - loss: 0.2670 - val_auc: 0.7808 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9074 - loss: 0.2667 - val_auc: 0.7824 - val_binary_accuracy: 0.9048 - val_loss: 0.2698\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7642 - binary_accuracy: 0.9049 - loss: 0.2719\n",
            "Fold 4 Metrics: Loss = 0.2698, Accuracy = 0.9048, AUC = 0.7824\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5597 - binary_accuracy: 0.8180 - loss: 0.4326 - val_auc: 0.7197 - val_binary_accuracy: 0.9044 - val_loss: 0.2887\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7302 - binary_accuracy: 0.9040 - loss: 0.2872 - val_auc: 0.7675 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9040 - loss: 0.2770 - val_auc: 0.7802 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9040 - loss: 0.2736 - val_auc: 0.7830 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9049 - loss: 0.2708 - val_auc: 0.7877 - val_binary_accuracy: 0.9060 - val_loss: 0.2647\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9062 - loss: 0.2690 - val_auc: 0.7919 - val_binary_accuracy: 0.9075 - val_loss: 0.2610\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9074 - loss: 0.2680 - val_auc: 0.7888 - val_binary_accuracy: 0.9078 - val_loss: 0.2629\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9072 - loss: 0.2666 - val_auc: 0.7949 - val_binary_accuracy: 0.9094 - val_loss: 0.2591\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9082 - loss: 0.2663 - val_auc: 0.7945 - val_binary_accuracy: 0.9097 - val_loss: 0.2593\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9084 - loss: 0.2655 - val_auc: 0.7912 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8006 - binary_accuracy: 0.9073 - loss: 0.2610\n",
            "Fold 5 Metrics: Loss = 0.2611, Accuracy = 0.9094, AUC = 0.7912\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2680\n",
            "Average Accuracy: 0.9060\n",
            "Average AUC: 0.7760\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 1, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6618 - binary_accuracy: 0.7700 - loss: 0.4375 - val_auc: 0.7479 - val_binary_accuracy: 0.9044 - val_loss: 0.2784\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9069 - loss: 0.2648 - val_auc: 0.7617 - val_binary_accuracy: 0.9068 - val_loss: 0.2727\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9091 - loss: 0.2596 - val_auc: 0.7696 - val_binary_accuracy: 0.9079 - val_loss: 0.2694\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9095 - loss: 0.2574 - val_auc: 0.7734 - val_binary_accuracy: 0.9081 - val_loss: 0.2678\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9104 - loss: 0.2564 - val_auc: 0.7732 - val_binary_accuracy: 0.9087 - val_loss: 0.2672\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9107 - loss: 0.2558 - val_auc: 0.7736 - val_binary_accuracy: 0.9090 - val_loss: 0.2666\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9107 - loss: 0.2551 - val_auc: 0.7745 - val_binary_accuracy: 0.9088 - val_loss: 0.2660\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7958 - binary_accuracy: 0.9107 - loss: 0.2548 - val_auc: 0.7762 - val_binary_accuracy: 0.9091 - val_loss: 0.2655\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9113 - loss: 0.2546 - val_auc: 0.7766 - val_binary_accuracy: 0.9091 - val_loss: 0.2650\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9121 - loss: 0.2540 - val_auc: 0.7768 - val_binary_accuracy: 0.9093 - val_loss: 0.2646\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7754 - binary_accuracy: 0.9131 - loss: 0.2572\n",
            "Fold 1 Metrics: Loss = 0.2646, Accuracy = 0.9093, AUC = 0.7768\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6894 - binary_accuracy: 0.9016 - loss: 0.3190 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7709 - binary_accuracy: 0.9029 - loss: 0.2740 - val_auc: 0.7883 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9037 - loss: 0.2711 - val_auc: 0.7929 - val_binary_accuracy: 0.9042 - val_loss: 0.2669\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9057 - loss: 0.2695 - val_auc: 0.7960 - val_binary_accuracy: 0.9050 - val_loss: 0.2655\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9069 - loss: 0.2677 - val_auc: 0.7993 - val_binary_accuracy: 0.9056 - val_loss: 0.2648\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9070 - loss: 0.2667 - val_auc: 0.8006 - val_binary_accuracy: 0.9065 - val_loss: 0.2644\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9062 - loss: 0.2661 - val_auc: 0.8025 - val_binary_accuracy: 0.9065 - val_loss: 0.2614\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9066 - loss: 0.2653 - val_auc: 0.8017 - val_binary_accuracy: 0.9071 - val_loss: 0.2617\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9068 - loss: 0.2647 - val_auc: 0.8018 - val_binary_accuracy: 0.9078 - val_loss: 0.2604\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9070 - loss: 0.2630 - val_auc: 0.8031 - val_binary_accuracy: 0.9078 - val_loss: 0.2610\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8067 - binary_accuracy: 0.9119 - loss: 0.2508\n",
            "Fold 2 Metrics: Loss = 0.2610, Accuracy = 0.9078, AUC = 0.8031\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6874 - binary_accuracy: 0.8978 - loss: 0.3120 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2732\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7691 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7731 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7778 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9051 - loss: 0.2667 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7767 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7801 - val_binary_accuracy: 0.9047 - val_loss: 0.2676\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7792 - binary_accuracy: 0.9063 - loss: 0.2644 - val_auc: 0.7807 - val_binary_accuracy: 0.9069 - val_loss: 0.2670\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7811 - binary_accuracy: 0.9069 - loss: 0.2635 - val_auc: 0.7826 - val_binary_accuracy: 0.9075 - val_loss: 0.2663\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9071 - loss: 0.2626 - val_auc: 0.7835 - val_binary_accuracy: 0.9081 - val_loss: 0.2658\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7845 - binary_accuracy: 0.9075 - loss: 0.2619 - val_auc: 0.7850 - val_binary_accuracy: 0.9087 - val_loss: 0.2658\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7841 - binary_accuracy: 0.9077 - loss: 0.2616 - val_auc: 0.7867 - val_binary_accuracy: 0.9087 - val_loss: 0.2646\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7809 - binary_accuracy: 0.9096 - loss: 0.2653\n",
            "Fold 3 Metrics: Loss = 0.2646, Accuracy = 0.9087, AUC = 0.7867\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6057 - binary_accuracy: 0.6792 - loss: 0.5916 - val_auc: 0.7379 - val_binary_accuracy: 0.9044 - val_loss: 0.2846\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7347 - binary_accuracy: 0.9047 - loss: 0.2840 - val_auc: 0.7619 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7603 - binary_accuracy: 0.9048 - loss: 0.2746 - val_auc: 0.7738 - val_binary_accuracy: 0.9053 - val_loss: 0.2711\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7704 - binary_accuracy: 0.9059 - loss: 0.2706 - val_auc: 0.7752 - val_binary_accuracy: 0.9050 - val_loss: 0.2708\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7742 - binary_accuracy: 0.9068 - loss: 0.2688 - val_auc: 0.7797 - val_binary_accuracy: 0.9059 - val_loss: 0.2690\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7792 - binary_accuracy: 0.9080 - loss: 0.2661 - val_auc: 0.7833 - val_binary_accuracy: 0.9072 - val_loss: 0.2668\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9075 - loss: 0.2648 - val_auc: 0.7847 - val_binary_accuracy: 0.9085 - val_loss: 0.2656\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.7862 - val_binary_accuracy: 0.9081 - val_loss: 0.2653\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9091 - loss: 0.2630 - val_auc: 0.7871 - val_binary_accuracy: 0.9082 - val_loss: 0.2657\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9091 - loss: 0.2625 - val_auc: 0.7867 - val_binary_accuracy: 0.9082 - val_loss: 0.2664\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7648 - binary_accuracy: 0.9080 - loss: 0.2720\n",
            "Fold 4 Metrics: Loss = 0.2664, Accuracy = 0.9082, AUC = 0.7867\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6366 - binary_accuracy: 0.8897 - loss: 0.3399 - val_auc: 0.7799 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7812 - val_binary_accuracy: 0.9044 - val_loss: 0.2659\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7665 - binary_accuracy: 0.9043 - loss: 0.2737 - val_auc: 0.7878 - val_binary_accuracy: 0.9048 - val_loss: 0.2625\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7714 - binary_accuracy: 0.9061 - loss: 0.2713 - val_auc: 0.7884 - val_binary_accuracy: 0.9054 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7717 - binary_accuracy: 0.9065 - loss: 0.2710 - val_auc: 0.7891 - val_binary_accuracy: 0.9057 - val_loss: 0.2612\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2707 - val_auc: 0.7896 - val_binary_accuracy: 0.9066 - val_loss: 0.2603\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9072 - loss: 0.2694 - val_auc: 0.7900 - val_binary_accuracy: 0.9067 - val_loss: 0.2599\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9074 - loss: 0.2688 - val_auc: 0.7916 - val_binary_accuracy: 0.9084 - val_loss: 0.2593\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9073 - loss: 0.2686 - val_auc: 0.7900 - val_binary_accuracy: 0.9088 - val_loss: 0.2590\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9075 - loss: 0.2680 - val_auc: 0.7930 - val_binary_accuracy: 0.9084 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8015 - binary_accuracy: 0.9076 - loss: 0.2594\n",
            "Fold 5 Metrics: Loss = 0.2586, Accuracy = 0.9084, AUC = 0.7930\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2630\n",
            "Average Accuracy: 0.9085\n",
            "Average AUC: 0.7892\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 1, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7272 - binary_accuracy: 0.9069 - loss: 0.2821 - val_auc: 0.7683 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9069 - loss: 0.2599 - val_auc: 0.7758 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9073 - loss: 0.2565 - val_auc: 0.7821 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9078 - loss: 0.2540 - val_auc: 0.7857 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9090 - loss: 0.2519 - val_auc: 0.7861 - val_binary_accuracy: 0.9072 - val_loss: 0.2627\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9106 - loss: 0.2507 - val_auc: 0.7890 - val_binary_accuracy: 0.9079 - val_loss: 0.2617\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8086 - binary_accuracy: 0.9114 - loss: 0.2500 - val_auc: 0.7901 - val_binary_accuracy: 0.9088 - val_loss: 0.2606\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8097 - binary_accuracy: 0.9125 - loss: 0.2490 - val_auc: 0.7901 - val_binary_accuracy: 0.9103 - val_loss: 0.2601\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9131 - loss: 0.2481 - val_auc: 0.7910 - val_binary_accuracy: 0.9100 - val_loss: 0.2597\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9127 - loss: 0.2478 - val_auc: 0.7913 - val_binary_accuracy: 0.9104 - val_loss: 0.2595\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7898 - binary_accuracy: 0.9133 - loss: 0.2522\n",
            "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9104, AUC = 0.7913\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6781 - binary_accuracy: 0.9029 - loss: 0.3073 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2719 - val_auc: 0.7997 - val_binary_accuracy: 0.9042 - val_loss: 0.2645\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9035 - loss: 0.2684 - val_auc: 0.8021 - val_binary_accuracy: 0.9045 - val_loss: 0.2634\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9052 - loss: 0.2665 - val_auc: 0.8043 - val_binary_accuracy: 0.9057 - val_loss: 0.2623\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9057 - loss: 0.2656 - val_auc: 0.8046 - val_binary_accuracy: 0.9069 - val_loss: 0.2592\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7906 - binary_accuracy: 0.9071 - loss: 0.2644 - val_auc: 0.8049 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9077 - loss: 0.2635 - val_auc: 0.8068 - val_binary_accuracy: 0.9081 - val_loss: 0.2588\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7944 - binary_accuracy: 0.9078 - loss: 0.2625 - val_auc: 0.8068 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7956 - binary_accuracy: 0.9087 - loss: 0.2621 - val_auc: 0.8081 - val_binary_accuracy: 0.9088 - val_loss: 0.2593\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9082 - loss: 0.2617 - val_auc: 0.8089 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8161 - binary_accuracy: 0.9124 - loss: 0.2463\n",
            "Fold 2 Metrics: Loss = 0.2576, Accuracy = 0.9094, AUC = 0.8089\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7279 - binary_accuracy: 0.9051 - loss: 0.2831 - val_auc: 0.7758 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9055 - loss: 0.2684 - val_auc: 0.7836 - val_binary_accuracy: 0.9063 - val_loss: 0.2677\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9068 - loss: 0.2654 - val_auc: 0.7907 - val_binary_accuracy: 0.9088 - val_loss: 0.2641\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9079 - loss: 0.2637 - val_auc: 0.7966 - val_binary_accuracy: 0.9096 - val_loss: 0.2616\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9080 - loss: 0.2620 - val_auc: 0.8013 - val_binary_accuracy: 0.9102 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9091 - loss: 0.2613 - val_auc: 0.8036 - val_binary_accuracy: 0.9100 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9089 - loss: 0.2605 - val_auc: 0.8052 - val_binary_accuracy: 0.9109 - val_loss: 0.2573\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7884 - binary_accuracy: 0.9092 - loss: 0.2602 - val_auc: 0.8060 - val_binary_accuracy: 0.9112 - val_loss: 0.2567\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9095 - loss: 0.2596 - val_auc: 0.8072 - val_binary_accuracy: 0.9112 - val_loss: 0.2562\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9095 - loss: 0.2590 - val_auc: 0.8076 - val_binary_accuracy: 0.9113 - val_loss: 0.2559\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8000 - binary_accuracy: 0.9124 - loss: 0.2562\n",
            "Fold 3 Metrics: Loss = 0.2559, Accuracy = 0.9113, AUC = 0.8076\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6208 - binary_accuracy: 0.7267 - loss: 0.6144 - val_auc: 0.7587 - val_binary_accuracy: 0.9044 - val_loss: 0.2768\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7610 - binary_accuracy: 0.9047 - loss: 0.2750 - val_auc: 0.7804 - val_binary_accuracy: 0.9045 - val_loss: 0.2693\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9057 - loss: 0.2667 - val_auc: 0.7873 - val_binary_accuracy: 0.9050 - val_loss: 0.2670\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9066 - loss: 0.2642 - val_auc: 0.7935 - val_binary_accuracy: 0.9057 - val_loss: 0.2660\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7865 - binary_accuracy: 0.9071 - loss: 0.2629 - val_auc: 0.7933 - val_binary_accuracy: 0.9079 - val_loss: 0.2636\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9075 - loss: 0.2619 - val_auc: 0.7934 - val_binary_accuracy: 0.9069 - val_loss: 0.2662\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9088 - loss: 0.2614 - val_auc: 0.7942 - val_binary_accuracy: 0.9078 - val_loss: 0.2659\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9093 - loss: 0.2606 - val_auc: 0.7964 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9094 - loss: 0.2599 - val_auc: 0.7970 - val_binary_accuracy: 0.9085 - val_loss: 0.2636\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7927 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.7980 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7776 - binary_accuracy: 0.9085 - loss: 0.2684\n",
            "Fold 4 Metrics: Loss = 0.2631, Accuracy = 0.9082, AUC = 0.7980\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7277 - binary_accuracy: 0.9040 - loss: 0.2875 - val_auc: 0.7910 - val_binary_accuracy: 0.9057 - val_loss: 0.2616\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9043 - loss: 0.2694 - val_auc: 0.7962 - val_binary_accuracy: 0.9054 - val_loss: 0.2582\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9063 - loss: 0.2659 - val_auc: 0.7976 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9069 - loss: 0.2637 - val_auc: 0.8015 - val_binary_accuracy: 0.9081 - val_loss: 0.2557\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9072 - loss: 0.2636 - val_auc: 0.8047 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8041 - val_binary_accuracy: 0.9094 - val_loss: 0.2534\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9085 - loss: 0.2607 - val_auc: 0.8050 - val_binary_accuracy: 0.9097 - val_loss: 0.2531\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7957 - binary_accuracy: 0.9087 - loss: 0.2601 - val_auc: 0.8056 - val_binary_accuracy: 0.9103 - val_loss: 0.2528\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7969 - binary_accuracy: 0.9093 - loss: 0.2594 - val_auc: 0.8049 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7966 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.8069 - val_binary_accuracy: 0.9110 - val_loss: 0.2523\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9089 - loss: 0.2508\n",
            "Fold 5 Metrics: Loss = 0.2523, Accuracy = 0.9110, AUC = 0.8069\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2577\n",
            "Average Accuracy: 0.9101\n",
            "Average AUC: 0.8025\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 1, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7450 - binary_accuracy: 0.9069 - loss: 0.2758 - val_auc: 0.7784 - val_binary_accuracy: 0.9056 - val_loss: 0.2687\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7951 - binary_accuracy: 0.9083 - loss: 0.2566 - val_auc: 0.7872 - val_binary_accuracy: 0.9053 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9087 - loss: 0.2532 - val_auc: 0.7890 - val_binary_accuracy: 0.9069 - val_loss: 0.2620\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8047 - binary_accuracy: 0.9116 - loss: 0.2515 - val_auc: 0.7903 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9125 - loss: 0.2502 - val_auc: 0.7907 - val_binary_accuracy: 0.9084 - val_loss: 0.2609\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8094 - binary_accuracy: 0.9126 - loss: 0.2490 - val_auc: 0.7918 - val_binary_accuracy: 0.9096 - val_loss: 0.2603\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8102 - binary_accuracy: 0.9125 - loss: 0.2482 - val_auc: 0.7943 - val_binary_accuracy: 0.9094 - val_loss: 0.2590\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8120 - binary_accuracy: 0.9126 - loss: 0.2471 - val_auc: 0.7947 - val_binary_accuracy: 0.9097 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8136 - binary_accuracy: 0.9134 - loss: 0.2463 - val_auc: 0.7955 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8152 - binary_accuracy: 0.9136 - loss: 0.2457 - val_auc: 0.7972 - val_binary_accuracy: 0.9094 - val_loss: 0.2584\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9130 - loss: 0.2519\n",
            "Fold 1 Metrics: Loss = 0.2584, Accuracy = 0.9094, AUC = 0.7972\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6504 - binary_accuracy: 0.7876 - loss: 0.4939 - val_auc: 0.7916 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7828 - binary_accuracy: 0.9029 - loss: 0.2700 - val_auc: 0.8022 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7915 - binary_accuracy: 0.9042 - loss: 0.2653 - val_auc: 0.8065 - val_binary_accuracy: 0.9045 - val_loss: 0.2610\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9061 - loss: 0.2631 - val_auc: 0.8095 - val_binary_accuracy: 0.9056 - val_loss: 0.2591\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9067 - loss: 0.2620 - val_auc: 0.8092 - val_binary_accuracy: 0.9063 - val_loss: 0.2585\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9075 - loss: 0.2608 - val_auc: 0.8089 - val_binary_accuracy: 0.9069 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7989 - binary_accuracy: 0.9084 - loss: 0.2606 - val_auc: 0.8106 - val_binary_accuracy: 0.9073 - val_loss: 0.2573\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8010 - binary_accuracy: 0.9082 - loss: 0.2597 - val_auc: 0.8104 - val_binary_accuracy: 0.9078 - val_loss: 0.2573\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9086 - loss: 0.2596 - val_auc: 0.8090 - val_binary_accuracy: 0.9075 - val_loss: 0.2577\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8022 - binary_accuracy: 0.9076 - loss: 0.2593 - val_auc: 0.8099 - val_binary_accuracy: 0.9081 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8163 - binary_accuracy: 0.9121 - loss: 0.2474\n",
            "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9081, AUC = 0.8099\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6593 - binary_accuracy: 0.8358 - loss: 0.3686 - val_auc: 0.7730 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9056 - loss: 0.2678 - val_auc: 0.7836 - val_binary_accuracy: 0.9072 - val_loss: 0.2660\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9079 - loss: 0.2644 - val_auc: 0.7903 - val_binary_accuracy: 0.9090 - val_loss: 0.2631\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9084 - loss: 0.2629 - val_auc: 0.7951 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9092 - loss: 0.2618 - val_auc: 0.7962 - val_binary_accuracy: 0.9097 - val_loss: 0.2599\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9095 - loss: 0.2610 - val_auc: 0.7950 - val_binary_accuracy: 0.9096 - val_loss: 0.2597\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9091 - loss: 0.2602 - val_auc: 0.7995 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9096 - loss: 0.2593 - val_auc: 0.8022 - val_binary_accuracy: 0.9106 - val_loss: 0.2576\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7903 - binary_accuracy: 0.9098 - loss: 0.2591 - val_auc: 0.8015 - val_binary_accuracy: 0.9109 - val_loss: 0.2574\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7908 - binary_accuracy: 0.9093 - loss: 0.2590 - val_auc: 0.8032 - val_binary_accuracy: 0.9113 - val_loss: 0.2575\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7936 - binary_accuracy: 0.9123 - loss: 0.2592\n",
            "Fold 3 Metrics: Loss = 0.2575, Accuracy = 0.9113, AUC = 0.8032\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7258 - binary_accuracy: 0.9049 - loss: 0.2833 - val_auc: 0.7871 - val_binary_accuracy: 0.9054 - val_loss: 0.2654\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9080 - loss: 0.2650 - val_auc: 0.7945 - val_binary_accuracy: 0.9079 - val_loss: 0.2623\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7878 - binary_accuracy: 0.9099 - loss: 0.2616 - val_auc: 0.7993 - val_binary_accuracy: 0.9078 - val_loss: 0.2598\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9104 - loss: 0.2595 - val_auc: 0.7999 - val_binary_accuracy: 0.9079 - val_loss: 0.2598\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7929 - binary_accuracy: 0.9102 - loss: 0.2587 - val_auc: 0.8000 - val_binary_accuracy: 0.9090 - val_loss: 0.2591\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9101 - loss: 0.2590 - val_auc: 0.8015 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9104 - loss: 0.2579 - val_auc: 0.8010 - val_binary_accuracy: 0.9091 - val_loss: 0.2589\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9102 - loss: 0.2578 - val_auc: 0.8010 - val_binary_accuracy: 0.9091 - val_loss: 0.2586\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7952 - binary_accuracy: 0.9102 - loss: 0.2577 - val_auc: 0.8026 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7966 - binary_accuracy: 0.9102 - loss: 0.2569 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2589\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7858 - binary_accuracy: 0.9084 - loss: 0.2648\n",
            "Fold 4 Metrics: Loss = 0.2589, Accuracy = 0.9087, AUC = 0.8037\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7170 - binary_accuracy: 0.9007 - loss: 0.2948 - val_auc: 0.7877 - val_binary_accuracy: 0.9045 - val_loss: 0.2642\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7721 - binary_accuracy: 0.9062 - loss: 0.2709 - val_auc: 0.7960 - val_binary_accuracy: 0.9063 - val_loss: 0.2594\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9072 - loss: 0.2680 - val_auc: 0.7969 - val_binary_accuracy: 0.9082 - val_loss: 0.2571\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9080 - loss: 0.2658 - val_auc: 0.8007 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9079 - loss: 0.2643 - val_auc: 0.8047 - val_binary_accuracy: 0.9095 - val_loss: 0.2544\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9085 - loss: 0.2628 - val_auc: 0.8059 - val_binary_accuracy: 0.9100 - val_loss: 0.2533\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9089 - loss: 0.2621 - val_auc: 0.8063 - val_binary_accuracy: 0.9106 - val_loss: 0.2530\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9094 - loss: 0.2615 - val_auc: 0.8069 - val_binary_accuracy: 0.9106 - val_loss: 0.2523\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9098 - loss: 0.2609 - val_auc: 0.8058 - val_binary_accuracy: 0.9100 - val_loss: 0.2532\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8063 - val_binary_accuracy: 0.9098 - val_loss: 0.2536\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8166 - binary_accuracy: 0.9075 - loss: 0.2519\n",
            "Fold 5 Metrics: Loss = 0.2536, Accuracy = 0.9098, AUC = 0.8063\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2574\n",
            "Average Accuracy: 0.9095\n",
            "Average AUC: 0.8041\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 1, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7411 - binary_accuracy: 0.9076 - loss: 0.2779 - val_auc: 0.7812 - val_binary_accuracy: 0.9053 - val_loss: 0.2688\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9103 - loss: 0.2552 - val_auc: 0.7894 - val_binary_accuracy: 0.9066 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9114 - loss: 0.2526 - val_auc: 0.7911 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8064 - binary_accuracy: 0.9118 - loss: 0.2506 - val_auc: 0.7926 - val_binary_accuracy: 0.9079 - val_loss: 0.2629\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9121 - loss: 0.2496 - val_auc: 0.7926 - val_binary_accuracy: 0.9076 - val_loss: 0.2626\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9125 - loss: 0.2487 - val_auc: 0.7943 - val_binary_accuracy: 0.9078 - val_loss: 0.2618\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9130 - loss: 0.2482 - val_auc: 0.7932 - val_binary_accuracy: 0.9082 - val_loss: 0.2620\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8119 - binary_accuracy: 0.9131 - loss: 0.2475 - val_auc: 0.7942 - val_binary_accuracy: 0.9084 - val_loss: 0.2607\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8129 - binary_accuracy: 0.9130 - loss: 0.2470 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9132 - loss: 0.2463 - val_auc: 0.7956 - val_binary_accuracy: 0.9081 - val_loss: 0.2602\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9114 - loss: 0.2519\n",
            "Fold 1 Metrics: Loss = 0.2602, Accuracy = 0.9081, AUC = 0.7956\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6722 - binary_accuracy: 0.8454 - loss: 0.3876 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9038 - loss: 0.2691 - val_auc: 0.8036 - val_binary_accuracy: 0.9060 - val_loss: 0.2605\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9059 - loss: 0.2651 - val_auc: 0.8067 - val_binary_accuracy: 0.9065 - val_loss: 0.2591\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9063 - loss: 0.2635 - val_auc: 0.8077 - val_binary_accuracy: 0.9068 - val_loss: 0.2582\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7963 - binary_accuracy: 0.9077 - loss: 0.2620 - val_auc: 0.8086 - val_binary_accuracy: 0.9071 - val_loss: 0.2570\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7978 - binary_accuracy: 0.9075 - loss: 0.2610 - val_auc: 0.8077 - val_binary_accuracy: 0.9075 - val_loss: 0.2579\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7976 - binary_accuracy: 0.9081 - loss: 0.2607 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2573\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9084 - loss: 0.2602 - val_auc: 0.8079 - val_binary_accuracy: 0.9079 - val_loss: 0.2567\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8006 - binary_accuracy: 0.9082 - loss: 0.2595 - val_auc: 0.8077 - val_binary_accuracy: 0.9079 - val_loss: 0.2573\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9081 - loss: 0.2593 - val_auc: 0.8085 - val_binary_accuracy: 0.9082 - val_loss: 0.2571\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8184 - binary_accuracy: 0.9118 - loss: 0.2458\n",
            "Fold 2 Metrics: Loss = 0.2571, Accuracy = 0.9082, AUC = 0.8085\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7200 - binary_accuracy: 0.9013 - loss: 0.2934 - val_auc: 0.7870 - val_binary_accuracy: 0.9059 - val_loss: 0.2656\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9067 - loss: 0.2680 - val_auc: 0.7945 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9078 - loss: 0.2657 - val_auc: 0.7981 - val_binary_accuracy: 0.9090 - val_loss: 0.2602\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9078 - loss: 0.2643 - val_auc: 0.7971 - val_binary_accuracy: 0.9099 - val_loss: 0.2597\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8005 - val_binary_accuracy: 0.9100 - val_loss: 0.2582\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9090 - loss: 0.2627 - val_auc: 0.8011 - val_binary_accuracy: 0.9102 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9092 - loss: 0.2621 - val_auc: 0.8014 - val_binary_accuracy: 0.9106 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9098 - loss: 0.2614 - val_auc: 0.8027 - val_binary_accuracy: 0.9107 - val_loss: 0.2570\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9100 - loss: 0.2608 - val_auc: 0.8022 - val_binary_accuracy: 0.9102 - val_loss: 0.2578\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9096 - loss: 0.2605 - val_auc: 0.8036 - val_binary_accuracy: 0.9106 - val_loss: 0.2570\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9112 - loss: 0.2577\n",
            "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9106, AUC = 0.8036\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7369 - binary_accuracy: 0.9059 - loss: 0.2818 - val_auc: 0.7948 - val_binary_accuracy: 0.9082 - val_loss: 0.2608\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9097 - loss: 0.2631 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2580\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9110 - loss: 0.2609 - val_auc: 0.8008 - val_binary_accuracy: 0.9082 - val_loss: 0.2578\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9107 - loss: 0.2596 - val_auc: 0.8025 - val_binary_accuracy: 0.9085 - val_loss: 0.2570\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9107 - loss: 0.2587 - val_auc: 0.8047 - val_binary_accuracy: 0.9093 - val_loss: 0.2564\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9109 - loss: 0.2581 - val_auc: 0.8047 - val_binary_accuracy: 0.9091 - val_loss: 0.2562\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9107 - loss: 0.2573 - val_auc: 0.8056 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9110 - loss: 0.2574 - val_auc: 0.8054 - val_binary_accuracy: 0.9090 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7958 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2552\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9110 - loss: 0.2564 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7874 - binary_accuracy: 0.9081 - loss: 0.2626\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9081, AUC = 0.8072\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7378 - binary_accuracy: 0.9045 - loss: 0.2839 - val_auc: 0.7956 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9069 - loss: 0.2696 - val_auc: 0.8026 - val_binary_accuracy: 0.9088 - val_loss: 0.2601\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9073 - loss: 0.2684 - val_auc: 0.8037 - val_binary_accuracy: 0.9088 - val_loss: 0.2564\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9081 - loss: 0.2660 - val_auc: 0.8060 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.8079 - val_binary_accuracy: 0.9093 - val_loss: 0.2534\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8073 - val_binary_accuracy: 0.9098 - val_loss: 0.2531\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9087 - loss: 0.2626 - val_auc: 0.8084 - val_binary_accuracy: 0.9095 - val_loss: 0.2527\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9087 - loss: 0.2621 - val_auc: 0.8082 - val_binary_accuracy: 0.9093 - val_loss: 0.2522\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9084 - loss: 0.2617 - val_auc: 0.8076 - val_binary_accuracy: 0.9098 - val_loss: 0.2519\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9090 - loss: 0.2609 - val_auc: 0.8089 - val_binary_accuracy: 0.9101 - val_loss: 0.2515\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9084 - loss: 0.2504\n",
            "Fold 5 Metrics: Loss = 0.2515, Accuracy = 0.9101, AUC = 0.8089\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2562\n",
            "Average Accuracy: 0.9090\n",
            "Average AUC: 0.8047\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 2, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6182 - binary_accuracy: 0.7984 - loss: 0.4154 - val_auc: 0.7467 - val_binary_accuracy: 0.9044 - val_loss: 0.2788\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9069 - loss: 0.2674 - val_auc: 0.7560 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9069 - loss: 0.2627 - val_auc: 0.7626 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9092 - loss: 0.2606 - val_auc: 0.7673 - val_binary_accuracy: 0.9059 - val_loss: 0.2701\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.7688 - val_binary_accuracy: 0.9059 - val_loss: 0.2698\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9106 - loss: 0.2581 - val_auc: 0.7702 - val_binary_accuracy: 0.9069 - val_loss: 0.2683\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9111 - loss: 0.2574 - val_auc: 0.7720 - val_binary_accuracy: 0.9072 - val_loss: 0.2674\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.7714 - val_binary_accuracy: 0.9073 - val_loss: 0.2673\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9111 - loss: 0.2571 - val_auc: 0.7740 - val_binary_accuracy: 0.9076 - val_loss: 0.2669\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9122 - loss: 0.2564 - val_auc: 0.7748 - val_binary_accuracy: 0.9078 - val_loss: 0.2669\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7723 - binary_accuracy: 0.9104 - loss: 0.2597\n",
            "Fold 1 Metrics: Loss = 0.2669, Accuracy = 0.9078, AUC = 0.7748\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5405 - binary_accuracy: 0.9022 - loss: 0.3564 - val_auc: 0.7345 - val_binary_accuracy: 0.9042 - val_loss: 0.2920\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7368 - binary_accuracy: 0.9029 - loss: 0.2893 - val_auc: 0.7651 - val_binary_accuracy: 0.9042 - val_loss: 0.2800\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7604 - binary_accuracy: 0.9029 - loss: 0.2777 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2739\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7654 - binary_accuracy: 0.9029 - loss: 0.2757 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9029 - loss: 0.2744 - val_auc: 0.7915 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9029 - loss: 0.2738 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2696\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9029 - loss: 0.2735 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2732 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9029 - loss: 0.2729 - val_auc: 0.7914 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.7974 - val_binary_accuracy: 0.9042 - val_loss: 0.2669\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7991 - binary_accuracy: 0.9092 - loss: 0.2580\n",
            "Fold 2 Metrics: Loss = 0.2669, Accuracy = 0.9042, AUC = 0.7974\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6537 - binary_accuracy: 0.8582 - loss: 0.3662 - val_auc: 0.7539 - val_binary_accuracy: 0.9042 - val_loss: 0.2782\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9051 - loss: 0.2736 - val_auc: 0.7799 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7812 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9051 - loss: 0.2656 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9051 - loss: 0.2652 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9051 - loss: 0.2646 - val_auc: 0.7864 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2642 - val_auc: 0.7865 - val_binary_accuracy: 0.9042 - val_loss: 0.2679\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9051 - loss: 0.2638 - val_auc: 0.7863 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7823 - binary_accuracy: 0.9046 - loss: 0.2684\n",
            "Fold 3 Metrics: Loss = 0.2677, Accuracy = 0.9042, AUC = 0.7863\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6045 - binary_accuracy: 0.8124 - loss: 0.4151 - val_auc: 0.7433 - val_binary_accuracy: 0.9044 - val_loss: 0.2850\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7468 - binary_accuracy: 0.9047 - loss: 0.2800 - val_auc: 0.7575 - val_binary_accuracy: 0.9044 - val_loss: 0.2764\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9047 - loss: 0.2709 - val_auc: 0.7677 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9050 - loss: 0.2684 - val_auc: 0.7764 - val_binary_accuracy: 0.9050 - val_loss: 0.2710\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9058 - loss: 0.2669 - val_auc: 0.7786 - val_binary_accuracy: 0.9056 - val_loss: 0.2689\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9064 - loss: 0.2661 - val_auc: 0.7781 - val_binary_accuracy: 0.9059 - val_loss: 0.2681\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7784 - binary_accuracy: 0.9072 - loss: 0.2651 - val_auc: 0.7782 - val_binary_accuracy: 0.9064 - val_loss: 0.2687\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.7836 - val_binary_accuracy: 0.9072 - val_loss: 0.2689\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9085 - loss: 0.2639 - val_auc: 0.7846 - val_binary_accuracy: 0.9079 - val_loss: 0.2688\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9081 - loss: 0.2634 - val_auc: 0.7845 - val_binary_accuracy: 0.9081 - val_loss: 0.2687\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7650 - binary_accuracy: 0.9084 - loss: 0.2739\n",
            "Fold 4 Metrics: Loss = 0.2687, Accuracy = 0.9081, AUC = 0.7845\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5155 - binary_accuracy: 0.7282 - loss: 0.5179 - val_auc: 0.6883 - val_binary_accuracy: 0.9044 - val_loss: 0.3035\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6826 - binary_accuracy: 0.9039 - loss: 0.3017 - val_auc: 0.7339 - val_binary_accuracy: 0.9044 - val_loss: 0.2869\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7254 - binary_accuracy: 0.9039 - loss: 0.2886 - val_auc: 0.7520 - val_binary_accuracy: 0.9044 - val_loss: 0.2769\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7356 - binary_accuracy: 0.9039 - loss: 0.2813 - val_auc: 0.7600 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7478 - binary_accuracy: 0.9039 - loss: 0.2801 - val_auc: 0.7637 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7571 - binary_accuracy: 0.9039 - loss: 0.2771 - val_auc: 0.7667 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9039 - loss: 0.2764 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7566 - binary_accuracy: 0.9039 - loss: 0.2760 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7574 - binary_accuracy: 0.9039 - loss: 0.2757 - val_auc: 0.7691 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9039 - loss: 0.2754 - val_auc: 0.7700 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7850 - binary_accuracy: 0.9013 - loss: 0.2659\n",
            "Fold 5 Metrics: Loss = 0.2671, Accuracy = 0.9044, AUC = 0.7700\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2675\n",
            "Average Accuracy: 0.9057\n",
            "Average AUC: 0.7826\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 2, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6210 - binary_accuracy: 0.8316 - loss: 0.3766 - val_auc: 0.7564 - val_binary_accuracy: 0.9044 - val_loss: 0.2802\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9069 - loss: 0.2693 - val_auc: 0.7684 - val_binary_accuracy: 0.9044 - val_loss: 0.2736\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9069 - loss: 0.2634 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9069 - loss: 0.2588 - val_auc: 0.7793 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9069 - loss: 0.2574 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9069 - loss: 0.2565 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9069 - loss: 0.2559 - val_auc: 0.7813 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9069 - loss: 0.2552 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9069 - loss: 0.2545 - val_auc: 0.7845 - val_binary_accuracy: 0.9044 - val_loss: 0.2672\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7878 - binary_accuracy: 0.9084 - loss: 0.2590\n",
            "Fold 1 Metrics: Loss = 0.2672, Accuracy = 0.9044, AUC = 0.7845\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6579 - binary_accuracy: 0.8703 - loss: 0.3423 - val_auc: 0.7854 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9029 - loss: 0.2735 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9034 - loss: 0.2714 - val_auc: 0.7927 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9034 - loss: 0.2691 - val_auc: 0.7955 - val_binary_accuracy: 0.9048 - val_loss: 0.2655\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9051 - loss: 0.2676 - val_auc: 0.7972 - val_binary_accuracy: 0.9051 - val_loss: 0.2669\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9049 - loss: 0.2666 - val_auc: 0.8002 - val_binary_accuracy: 0.9062 - val_loss: 0.2674\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9057 - loss: 0.2654 - val_auc: 0.7997 - val_binary_accuracy: 0.9063 - val_loss: 0.2652\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9066 - loss: 0.2645 - val_auc: 0.8026 - val_binary_accuracy: 0.9059 - val_loss: 0.2649\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9064 - loss: 0.2640 - val_auc: 0.8047 - val_binary_accuracy: 0.9066 - val_loss: 0.2629\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9071 - loss: 0.2631 - val_auc: 0.8060 - val_binary_accuracy: 0.9071 - val_loss: 0.2616\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8109 - binary_accuracy: 0.9111 - loss: 0.2509\n",
            "Fold 2 Metrics: Loss = 0.2616, Accuracy = 0.9071, AUC = 0.8060\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5777 - binary_accuracy: 0.8146 - loss: 0.4277 - val_auc: 0.7277 - val_binary_accuracy: 0.9042 - val_loss: 0.2887\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7181 - binary_accuracy: 0.9051 - loss: 0.2872 - val_auc: 0.7590 - val_binary_accuracy: 0.9042 - val_loss: 0.2760\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7548 - binary_accuracy: 0.9051 - loss: 0.2739 - val_auc: 0.7703 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2695 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2721\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9051 - loss: 0.2681 - val_auc: 0.7765 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7710 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7782 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7795 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7723 - binary_accuracy: 0.9051 - loss: 0.2679 - val_auc: 0.7821 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7848 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7783 - binary_accuracy: 0.9046 - loss: 0.2700\n",
            "Fold 3 Metrics: Loss = 0.2694, Accuracy = 0.9042, AUC = 0.7848\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6428 - binary_accuracy: 0.8646 - loss: 0.3499 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9048 - loss: 0.2689 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9049 - loss: 0.2668 - val_auc: 0.7831 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9062 - loss: 0.2653 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9060 - loss: 0.2640 - val_auc: 0.7878 - val_binary_accuracy: 0.9064 - val_loss: 0.2660\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9068 - loss: 0.2631 - val_auc: 0.7898 - val_binary_accuracy: 0.9070 - val_loss: 0.2658\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9081 - loss: 0.2624 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2640\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9081 - loss: 0.2617 - val_auc: 0.7935 - val_binary_accuracy: 0.9081 - val_loss: 0.2637\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9084 - loss: 0.2609 - val_auc: 0.7947 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9085 - loss: 0.2604 - val_auc: 0.7917 - val_binary_accuracy: 0.9084 - val_loss: 0.2649\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7694 - binary_accuracy: 0.9074 - loss: 0.2708\n",
            "Fold 4 Metrics: Loss = 0.2649, Accuracy = 0.9084, AUC = 0.7917\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6287 - binary_accuracy: 0.8434 - loss: 0.3650 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7647 - binary_accuracy: 0.9040 - loss: 0.2751 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2643\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9040 - loss: 0.2722 - val_auc: 0.7903 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.7912 - val_binary_accuracy: 0.9044 - val_loss: 0.2613\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9040 - loss: 0.2701 - val_auc: 0.7929 - val_binary_accuracy: 0.9044 - val_loss: 0.2607\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2610\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9041 - loss: 0.2688 - val_auc: 0.7926 - val_binary_accuracy: 0.9044 - val_loss: 0.2596\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9046 - loss: 0.2674 - val_auc: 0.7946 - val_binary_accuracy: 0.9054 - val_loss: 0.2588\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9053 - loss: 0.2668 - val_auc: 0.7965 - val_binary_accuracy: 0.9044 - val_loss: 0.2580\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9042 - loss: 0.2663 - val_auc: 0.7954 - val_binary_accuracy: 0.9078 - val_loss: 0.2580\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8084 - binary_accuracy: 0.9055 - loss: 0.2550\n",
            "Fold 5 Metrics: Loss = 0.2580, Accuracy = 0.9078, AUC = 0.7954\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2642\n",
            "Average Accuracy: 0.9064\n",
            "Average AUC: 0.7925\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 2, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7302 - binary_accuracy: 0.9069 - loss: 0.2803 - val_auc: 0.7687 - val_binary_accuracy: 0.9044 - val_loss: 0.2716\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9079 - loss: 0.2593 - val_auc: 0.7789 - val_binary_accuracy: 0.9069 - val_loss: 0.2654\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9100 - loss: 0.2550 - val_auc: 0.7823 - val_binary_accuracy: 0.9068 - val_loss: 0.2640\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9106 - loss: 0.2526 - val_auc: 0.7833 - val_binary_accuracy: 0.9073 - val_loss: 0.2637\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8049 - binary_accuracy: 0.9118 - loss: 0.2509 - val_auc: 0.7853 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8066 - binary_accuracy: 0.9122 - loss: 0.2496 - val_auc: 0.7853 - val_binary_accuracy: 0.9084 - val_loss: 0.2628\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8084 - binary_accuracy: 0.9125 - loss: 0.2487 - val_auc: 0.7856 - val_binary_accuracy: 0.9091 - val_loss: 0.2626\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9130 - loss: 0.2485 - val_auc: 0.7869 - val_binary_accuracy: 0.9096 - val_loss: 0.2618\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8111 - binary_accuracy: 0.9126 - loss: 0.2473 - val_auc: 0.7876 - val_binary_accuracy: 0.9094 - val_loss: 0.2616\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8124 - binary_accuracy: 0.9130 - loss: 0.2466 - val_auc: 0.7878 - val_binary_accuracy: 0.9094 - val_loss: 0.2616\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7879 - binary_accuracy: 0.9129 - loss: 0.2539\n",
            "Fold 1 Metrics: Loss = 0.2616, Accuracy = 0.9094, AUC = 0.7878\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.7044 - binary_accuracy: 0.8960 - loss: 0.3059 - val_auc: 0.7818 - val_binary_accuracy: 0.9051 - val_loss: 0.2685\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9045 - loss: 0.2723 - val_auc: 0.7957 - val_binary_accuracy: 0.9057 - val_loss: 0.2623\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9050 - loss: 0.2676 - val_auc: 0.8027 - val_binary_accuracy: 0.9054 - val_loss: 0.2587\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9061 - loss: 0.2645 - val_auc: 0.8040 - val_binary_accuracy: 0.9059 - val_loss: 0.2576\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9062 - loss: 0.2628 - val_auc: 0.8042 - val_binary_accuracy: 0.9062 - val_loss: 0.2574\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9073 - loss: 0.2617 - val_auc: 0.8032 - val_binary_accuracy: 0.9065 - val_loss: 0.2574\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9070 - loss: 0.2612 - val_auc: 0.8021 - val_binary_accuracy: 0.9069 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9074 - loss: 0.2604 - val_auc: 0.8037 - val_binary_accuracy: 0.9068 - val_loss: 0.2576\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9072 - loss: 0.2599 - val_auc: 0.8041 - val_binary_accuracy: 0.9066 - val_loss: 0.2578\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8020 - binary_accuracy: 0.9071 - loss: 0.2595 - val_auc: 0.8032 - val_binary_accuracy: 0.9066 - val_loss: 0.2582\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8091 - binary_accuracy: 0.9102 - loss: 0.2482\n",
            "Fold 2 Metrics: Loss = 0.2582, Accuracy = 0.9066, AUC = 0.8032\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7223 - binary_accuracy: 0.9053 - loss: 0.2857 - val_auc: 0.7872 - val_binary_accuracy: 0.9051 - val_loss: 0.2662\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9063 - loss: 0.2711 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2626\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.7959 - val_binary_accuracy: 0.9065 - val_loss: 0.2615\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9081 - loss: 0.2654 - val_auc: 0.7966 - val_binary_accuracy: 0.9088 - val_loss: 0.2607\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9086 - loss: 0.2641 - val_auc: 0.7980 - val_binary_accuracy: 0.9096 - val_loss: 0.2597\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9089 - loss: 0.2630 - val_auc: 0.7982 - val_binary_accuracy: 0.9100 - val_loss: 0.2590\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8013 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9090 - loss: 0.2614 - val_auc: 0.8016 - val_binary_accuracy: 0.9107 - val_loss: 0.2584\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9096 - loss: 0.2612 - val_auc: 0.8015 - val_binary_accuracy: 0.9110 - val_loss: 0.2577\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2574\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7950 - binary_accuracy: 0.9123 - loss: 0.2580\n",
            "Fold 3 Metrics: Loss = 0.2574, Accuracy = 0.9107, AUC = 0.8029\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6472 - binary_accuracy: 0.8780 - loss: 0.3309 - val_auc: 0.7821 - val_binary_accuracy: 0.9048 - val_loss: 0.2671\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9063 - loss: 0.2671 - val_auc: 0.7907 - val_binary_accuracy: 0.9073 - val_loss: 0.2628\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9084 - loss: 0.2652 - val_auc: 0.7940 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9089 - loss: 0.2633 - val_auc: 0.7953 - val_binary_accuracy: 0.9082 - val_loss: 0.2607\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9099 - loss: 0.2627 - val_auc: 0.7957 - val_binary_accuracy: 0.9093 - val_loss: 0.2595\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.7978 - val_binary_accuracy: 0.9097 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9104 - loss: 0.2598 - val_auc: 0.8003 - val_binary_accuracy: 0.9100 - val_loss: 0.2579\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9102 - loss: 0.2595 - val_auc: 0.8008 - val_binary_accuracy: 0.9109 - val_loss: 0.2585\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9106 - loss: 0.2586 - val_auc: 0.8022 - val_binary_accuracy: 0.9104 - val_loss: 0.2578\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9103 - loss: 0.2583 - val_auc: 0.8015 - val_binary_accuracy: 0.9101 - val_loss: 0.2577\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7813 - binary_accuracy: 0.9099 - loss: 0.2636\n",
            "Fold 4 Metrics: Loss = 0.2577, Accuracy = 0.9101, AUC = 0.8015\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6722 - binary_accuracy: 0.9038 - loss: 0.3049 - val_auc: 0.7820 - val_binary_accuracy: 0.9050 - val_loss: 0.2658\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9042 - loss: 0.2749 - val_auc: 0.7932 - val_binary_accuracy: 0.9045 - val_loss: 0.2604\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2704 - val_auc: 0.7930 - val_binary_accuracy: 0.9059 - val_loss: 0.2605\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9070 - loss: 0.2689 - val_auc: 0.7959 - val_binary_accuracy: 0.9097 - val_loss: 0.2572\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9082 - loss: 0.2667 - val_auc: 0.7991 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9083 - loss: 0.2654 - val_auc: 0.8011 - val_binary_accuracy: 0.9107 - val_loss: 0.2552\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9086 - loss: 0.2640 - val_auc: 0.8025 - val_binary_accuracy: 0.9113 - val_loss: 0.2546\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9093 - loss: 0.2632 - val_auc: 0.8036 - val_binary_accuracy: 0.9113 - val_loss: 0.2538\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8044 - val_binary_accuracy: 0.9113 - val_loss: 0.2534\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9096 - loss: 0.2624 - val_auc: 0.8062 - val_binary_accuracy: 0.9118 - val_loss: 0.2528\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9100 - loss: 0.2509\n",
            "Fold 5 Metrics: Loss = 0.2528, Accuracy = 0.9118, AUC = 0.8062\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2576\n",
            "Average Accuracy: 0.9097\n",
            "Average AUC: 0.8003\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 2, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.7228 - binary_accuracy: 0.9067 - loss: 0.2842 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9083 - loss: 0.2595 - val_auc: 0.7859 - val_binary_accuracy: 0.9069 - val_loss: 0.2660\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9104 - loss: 0.2555 - val_auc: 0.7893 - val_binary_accuracy: 0.9062 - val_loss: 0.2652\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8012 - binary_accuracy: 0.9113 - loss: 0.2529 - val_auc: 0.7898 - val_binary_accuracy: 0.9072 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9122 - loss: 0.2506 - val_auc: 0.7907 - val_binary_accuracy: 0.9082 - val_loss: 0.2632\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9121 - loss: 0.2489 - val_auc: 0.7918 - val_binary_accuracy: 0.9081 - val_loss: 0.2616\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8102 - binary_accuracy: 0.9129 - loss: 0.2478 - val_auc: 0.7920 - val_binary_accuracy: 0.9079 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9126 - loss: 0.2468 - val_auc: 0.7926 - val_binary_accuracy: 0.9081 - val_loss: 0.2603\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8135 - binary_accuracy: 0.9131 - loss: 0.2461 - val_auc: 0.7921 - val_binary_accuracy: 0.9091 - val_loss: 0.2598\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8144 - binary_accuracy: 0.9131 - loss: 0.2455 - val_auc: 0.7924 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7912 - binary_accuracy: 0.9129 - loss: 0.2519\n",
            "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9094, AUC = 0.7924\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6794 - binary_accuracy: 0.8797 - loss: 0.3308 - val_auc: 0.8003 - val_binary_accuracy: 0.9057 - val_loss: 0.2620\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9054 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9065 - val_loss: 0.2609\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.8038 - val_binary_accuracy: 0.9075 - val_loss: 0.2594\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9075 - loss: 0.2639 - val_auc: 0.8055 - val_binary_accuracy: 0.9082 - val_loss: 0.2584\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9080 - loss: 0.2621 - val_auc: 0.8062 - val_binary_accuracy: 0.9068 - val_loss: 0.2581\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9085 - loss: 0.2610 - val_auc: 0.8077 - val_binary_accuracy: 0.9081 - val_loss: 0.2569\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.8082 - val_binary_accuracy: 0.9082 - val_loss: 0.2564\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9083 - loss: 0.2594 - val_auc: 0.8093 - val_binary_accuracy: 0.9081 - val_loss: 0.2555\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9081 - loss: 0.2591 - val_auc: 0.8086 - val_binary_accuracy: 0.9085 - val_loss: 0.2558\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9081 - loss: 0.2588 - val_auc: 0.8088 - val_binary_accuracy: 0.9079 - val_loss: 0.2557\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9115 - loss: 0.2464\n",
            "Fold 2 Metrics: Loss = 0.2557, Accuracy = 0.9079, AUC = 0.8088\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7255 - binary_accuracy: 0.8980 - loss: 0.2938 - val_auc: 0.7890 - val_binary_accuracy: 0.9068 - val_loss: 0.2669\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9067 - loss: 0.2703 - val_auc: 0.7921 - val_binary_accuracy: 0.9068 - val_loss: 0.2653\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.7951 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9080 - loss: 0.2667 - val_auc: 0.7981 - val_binary_accuracy: 0.9090 - val_loss: 0.2613\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9082 - loss: 0.2653 - val_auc: 0.7986 - val_binary_accuracy: 0.9091 - val_loss: 0.2612\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8002 - val_binary_accuracy: 0.9093 - val_loss: 0.2607\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2593\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9087 - loss: 0.2630 - val_auc: 0.8005 - val_binary_accuracy: 0.9096 - val_loss: 0.2589\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8017 - val_binary_accuracy: 0.9099 - val_loss: 0.2582\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2572\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7949 - binary_accuracy: 0.9116 - loss: 0.2581\n",
            "Fold 3 Metrics: Loss = 0.2572, Accuracy = 0.9107, AUC = 0.8029\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6892 - binary_accuracy: 0.8896 - loss: 0.3105 - val_auc: 0.7928 - val_binary_accuracy: 0.9087 - val_loss: 0.2617\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9066 - loss: 0.2673 - val_auc: 0.7984 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9078 - loss: 0.2639 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2586\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9083 - loss: 0.2625 - val_auc: 0.8014 - val_binary_accuracy: 0.9091 - val_loss: 0.2569\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9088 - loss: 0.2611 - val_auc: 0.8038 - val_binary_accuracy: 0.9098 - val_loss: 0.2565\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9087 - loss: 0.2606 - val_auc: 0.8011 - val_binary_accuracy: 0.9088 - val_loss: 0.2571\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9090 - loss: 0.2596 - val_auc: 0.8024 - val_binary_accuracy: 0.9094 - val_loss: 0.2563\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.8035 - val_binary_accuracy: 0.9094 - val_loss: 0.2559\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9098 - loss: 0.2588 - val_auc: 0.8040 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9097 - loss: 0.2584 - val_auc: 0.8060 - val_binary_accuracy: 0.9097 - val_loss: 0.2550\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7860 - binary_accuracy: 0.9088 - loss: 0.2620\n",
            "Fold 4 Metrics: Loss = 0.2550, Accuracy = 0.9097, AUC = 0.8060\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6383 - binary_accuracy: 0.8697 - loss: 0.3769 - val_auc: 0.7925 - val_binary_accuracy: 0.9090 - val_loss: 0.2635\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9050 - loss: 0.2729 - val_auc: 0.7996 - val_binary_accuracy: 0.9085 - val_loss: 0.2635\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9046 - loss: 0.2706 - val_auc: 0.8026 - val_binary_accuracy: 0.9103 - val_loss: 0.2606\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9076 - loss: 0.2680 - val_auc: 0.8032 - val_binary_accuracy: 0.9101 - val_loss: 0.2565\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9089 - loss: 0.2664 - val_auc: 0.8036 - val_binary_accuracy: 0.9109 - val_loss: 0.2557\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9091 - loss: 0.2654 - val_auc: 0.8045 - val_binary_accuracy: 0.9107 - val_loss: 0.2539\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9094 - loss: 0.2643 - val_auc: 0.8040 - val_binary_accuracy: 0.9104 - val_loss: 0.2533\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9103 - loss: 0.2633 - val_auc: 0.8042 - val_binary_accuracy: 0.9110 - val_loss: 0.2530\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9106 - loss: 0.2627 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2526\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9101 - loss: 0.2621 - val_auc: 0.8061 - val_binary_accuracy: 0.9113 - val_loss: 0.2527\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9094 - loss: 0.2504\n",
            "Fold 5 Metrics: Loss = 0.2527, Accuracy = 0.9113, AUC = 0.8061\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2560\n",
            "Average Accuracy: 0.9098\n",
            "Average AUC: 0.8032\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 2, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7019 - binary_accuracy: 0.8908 - loss: 0.3147 - val_auc: 0.7819 - val_binary_accuracy: 0.9054 - val_loss: 0.2656\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9098 - loss: 0.2581 - val_auc: 0.7872 - val_binary_accuracy: 0.9078 - val_loss: 0.2634\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9109 - loss: 0.2548 - val_auc: 0.7884 - val_binary_accuracy: 0.9078 - val_loss: 0.2646\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9115 - loss: 0.2530 - val_auc: 0.7906 - val_binary_accuracy: 0.9079 - val_loss: 0.2642\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9119 - loss: 0.2513 - val_auc: 0.7908 - val_binary_accuracy: 0.9078 - val_loss: 0.2635\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9120 - loss: 0.2501 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2625\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9122 - loss: 0.2493 - val_auc: 0.7936 - val_binary_accuracy: 0.9087 - val_loss: 0.2618\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9124 - loss: 0.2486 - val_auc: 0.7933 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8096 - binary_accuracy: 0.9129 - loss: 0.2479 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2607\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8105 - binary_accuracy: 0.9131 - loss: 0.2475 - val_auc: 0.7947 - val_binary_accuracy: 0.9084 - val_loss: 0.2606\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9108 - loss: 0.2526\n",
            "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9084, AUC = 0.7947\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7231 - binary_accuracy: 0.9035 - loss: 0.2977 - val_auc: 0.7994 - val_binary_accuracy: 0.9056 - val_loss: 0.2685\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9050 - loss: 0.2684 - val_auc: 0.8049 - val_binary_accuracy: 0.9065 - val_loss: 0.2631\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9059 - loss: 0.2655 - val_auc: 0.8050 - val_binary_accuracy: 0.9072 - val_loss: 0.2612\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9073 - loss: 0.2636 - val_auc: 0.8075 - val_binary_accuracy: 0.9081 - val_loss: 0.2599\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9071 - loss: 0.2624 - val_auc: 0.8096 - val_binary_accuracy: 0.9082 - val_loss: 0.2594\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9081 - loss: 0.2612 - val_auc: 0.8101 - val_binary_accuracy: 0.9079 - val_loss: 0.2591\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9087 - loss: 0.2605 - val_auc: 0.8096 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9084 - loss: 0.2598 - val_auc: 0.8099 - val_binary_accuracy: 0.9084 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9092 - loss: 0.2593 - val_auc: 0.8106 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9092 - loss: 0.2592 - val_auc: 0.8111 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8190 - binary_accuracy: 0.9134 - loss: 0.2492\n",
            "Fold 2 Metrics: Loss = 0.2587, Accuracy = 0.9091, AUC = 0.8111\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7099 - binary_accuracy: 0.9052 - loss: 0.2995 - val_auc: 0.7868 - val_binary_accuracy: 0.9085 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7685 - binary_accuracy: 0.9083 - loss: 0.2690 - val_auc: 0.7927 - val_binary_accuracy: 0.9104 - val_loss: 0.2645\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9086 - loss: 0.2666 - val_auc: 0.7960 - val_binary_accuracy: 0.9106 - val_loss: 0.2623\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9080 - loss: 0.2658 - val_auc: 0.7983 - val_binary_accuracy: 0.9107 - val_loss: 0.2614\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.8003 - val_binary_accuracy: 0.9107 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8008 - val_binary_accuracy: 0.9112 - val_loss: 0.2601\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7775 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8021 - val_binary_accuracy: 0.9110 - val_loss: 0.2592\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7786 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8037 - val_binary_accuracy: 0.9112 - val_loss: 0.2590\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9087 - loss: 0.2631 - val_auc: 0.8038 - val_binary_accuracy: 0.9112 - val_loss: 0.2590\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9094 - loss: 0.2631 - val_auc: 0.8050 - val_binary_accuracy: 0.9110 - val_loss: 0.2576\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7977 - binary_accuracy: 0.9121 - loss: 0.2584\n",
            "Fold 3 Metrics: Loss = 0.2576, Accuracy = 0.9110, AUC = 0.8050\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6967 - binary_accuracy: 0.8868 - loss: 0.3252 - val_auc: 0.7942 - val_binary_accuracy: 0.9087 - val_loss: 0.2616\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9065 - loss: 0.2666 - val_auc: 0.7995 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9084 - loss: 0.2642 - val_auc: 0.8013 - val_binary_accuracy: 0.9067 - val_loss: 0.2587\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9085 - loss: 0.2625 - val_auc: 0.8037 - val_binary_accuracy: 0.9066 - val_loss: 0.2576\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8041 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8054 - val_binary_accuracy: 0.9094 - val_loss: 0.2558\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9104 - loss: 0.2599 - val_auc: 0.8067 - val_binary_accuracy: 0.9094 - val_loss: 0.2551\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9105 - loss: 0.2594 - val_auc: 0.8090 - val_binary_accuracy: 0.9093 - val_loss: 0.2540\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9105 - loss: 0.2590 - val_auc: 0.8088 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9107 - loss: 0.2586 - val_auc: 0.8094 - val_binary_accuracy: 0.9093 - val_loss: 0.2539\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7899 - binary_accuracy: 0.9091 - loss: 0.2620\n",
            "Fold 4 Metrics: Loss = 0.2539, Accuracy = 0.9093, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6883 - binary_accuracy: 0.8934 - loss: 0.3195 - val_auc: 0.7951 - val_binary_accuracy: 0.9087 - val_loss: 0.2591\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9060 - loss: 0.2712 - val_auc: 0.8000 - val_binary_accuracy: 0.9057 - val_loss: 0.2620\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.8027 - val_binary_accuracy: 0.9088 - val_loss: 0.2615\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9079 - loss: 0.2657 - val_auc: 0.8038 - val_binary_accuracy: 0.9094 - val_loss: 0.2619\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9081 - loss: 0.2650 - val_auc: 0.8050 - val_binary_accuracy: 0.9095 - val_loss: 0.2609\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9082 - loss: 0.2643 - val_auc: 0.8055 - val_binary_accuracy: 0.9091 - val_loss: 0.2598\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2635 - val_auc: 0.8056 - val_binary_accuracy: 0.9091 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8069 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.8066 - val_binary_accuracy: 0.9095 - val_loss: 0.2588\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9086 - loss: 0.2624 - val_auc: 0.8070 - val_binary_accuracy: 0.9079 - val_loss: 0.2591\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9088 - loss: 0.2563\n",
            "Fold 5 Metrics: Loss = 0.2591, Accuracy = 0.9079, AUC = 0.8070\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2580\n",
            "Average Accuracy: 0.9091\n",
            "Average AUC: 0.8054\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 3, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6231 - binary_accuracy: 0.9069 - loss: 0.3285 - val_auc: 0.7382 - val_binary_accuracy: 0.9044 - val_loss: 0.2813\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9069 - loss: 0.2674 - val_auc: 0.7482 - val_binary_accuracy: 0.9044 - val_loss: 0.2780\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9070 - loss: 0.2644 - val_auc: 0.7539 - val_binary_accuracy: 0.9044 - val_loss: 0.2757\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9070 - loss: 0.2631 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2730\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9070 - loss: 0.2620 - val_auc: 0.7639 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9070 - loss: 0.2618 - val_auc: 0.7644 - val_binary_accuracy: 0.9044 - val_loss: 0.2721\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.7645 - val_binary_accuracy: 0.9044 - val_loss: 0.2715\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9070 - loss: 0.2613 - val_auc: 0.7656 - val_binary_accuracy: 0.9044 - val_loss: 0.2715\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9069 - loss: 0.2610 - val_auc: 0.7660 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9069 - loss: 0.2608 - val_auc: 0.7669 - val_binary_accuracy: 0.9042 - val_loss: 0.2712\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7601 - binary_accuracy: 0.9082 - loss: 0.2640\n",
            "Fold 1 Metrics: Loss = 0.2712, Accuracy = 0.9042, AUC = 0.7669\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6295 - binary_accuracy: 0.8972 - loss: 0.3282 - val_auc: 0.7588 - val_binary_accuracy: 0.9042 - val_loss: 0.2822\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7492 - binary_accuracy: 0.9029 - loss: 0.2815 - val_auc: 0.7734 - val_binary_accuracy: 0.9042 - val_loss: 0.2742\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9029 - loss: 0.2763 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7646 - binary_accuracy: 0.9029 - loss: 0.2744 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2704\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9029 - loss: 0.2728 - val_auc: 0.7898 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9029 - loss: 0.2707 - val_auc: 0.7922 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.7952 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9029 - loss: 0.2695 - val_auc: 0.7962 - val_binary_accuracy: 0.9042 - val_loss: 0.2647\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9029 - loss: 0.2691 - val_auc: 0.7973 - val_binary_accuracy: 0.9042 - val_loss: 0.2643\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2689 - val_auc: 0.7991 - val_binary_accuracy: 0.9042 - val_loss: 0.2642\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7969 - binary_accuracy: 0.9092 - loss: 0.2540\n",
            "Fold 2 Metrics: Loss = 0.2642, Accuracy = 0.9042, AUC = 0.7991\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5201 - binary_accuracy: 0.9051 - loss: 0.3335 - val_auc: 0.7416 - val_binary_accuracy: 0.9042 - val_loss: 0.2879\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7409 - binary_accuracy: 0.9051 - loss: 0.2804 - val_auc: 0.7647 - val_binary_accuracy: 0.9042 - val_loss: 0.2747\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9051 - loss: 0.2696 - val_auc: 0.7767 - val_binary_accuracy: 0.9042 - val_loss: 0.2728\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9061 - loss: 0.2685 - val_auc: 0.7792 - val_binary_accuracy: 0.9066 - val_loss: 0.2711\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9066 - loss: 0.2674 - val_auc: 0.7848 - val_binary_accuracy: 0.9075 - val_loss: 0.2694\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9075 - loss: 0.2666 - val_auc: 0.7859 - val_binary_accuracy: 0.9076 - val_loss: 0.2671\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7886 - val_binary_accuracy: 0.9087 - val_loss: 0.2653\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9083 - loss: 0.2654 - val_auc: 0.7886 - val_binary_accuracy: 0.9099 - val_loss: 0.2642\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9089 - loss: 0.2650 - val_auc: 0.7896 - val_binary_accuracy: 0.9104 - val_loss: 0.2635\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9085 - loss: 0.2645 - val_auc: 0.7904 - val_binary_accuracy: 0.9100 - val_loss: 0.2631\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7841 - binary_accuracy: 0.9098 - loss: 0.2643\n",
            "Fold 3 Metrics: Loss = 0.2631, Accuracy = 0.9100, AUC = 0.7904\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5469 - binary_accuracy: 0.9047 - loss: 0.3493 - val_auc: 0.7014 - val_binary_accuracy: 0.9044 - val_loss: 0.2931\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7048 - binary_accuracy: 0.9047 - loss: 0.2899 - val_auc: 0.7433 - val_binary_accuracy: 0.9044 - val_loss: 0.2826\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7378 - binary_accuracy: 0.9047 - loss: 0.2812 - val_auc: 0.7586 - val_binary_accuracy: 0.9044 - val_loss: 0.2754\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7527 - binary_accuracy: 0.9047 - loss: 0.2763 - val_auc: 0.7696 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9047 - loss: 0.2738 - val_auc: 0.7721 - val_binary_accuracy: 0.9044 - val_loss: 0.2711\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9047 - loss: 0.2711 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9047 - loss: 0.2684 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9047 - loss: 0.2656 - val_auc: 0.7881 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9047 - loss: 0.2644 - val_auc: 0.7869 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9047 - loss: 0.2640 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7729 - binary_accuracy: 0.9049 - loss: 0.2698\n",
            "Fold 4 Metrics: Loss = 0.2675, Accuracy = 0.9044, AUC = 0.7872\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5982 - binary_accuracy: 0.9036 - loss: 0.3237 - val_auc: 0.7556 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7469 - binary_accuracy: 0.9037 - loss: 0.2794 - val_auc: 0.7687 - val_binary_accuracy: 0.9044 - val_loss: 0.2672\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7578 - binary_accuracy: 0.9039 - loss: 0.2767 - val_auc: 0.7793 - val_binary_accuracy: 0.9044 - val_loss: 0.2652\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7633 - binary_accuracy: 0.9039 - loss: 0.2742 - val_auc: 0.7822 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9040 - loss: 0.2730 - val_auc: 0.7838 - val_binary_accuracy: 0.9044 - val_loss: 0.2631\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9040 - loss: 0.2721 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2627\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9040 - loss: 0.2715 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2623\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.7875 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9040 - loss: 0.2698 - val_auc: 0.7885 - val_binary_accuracy: 0.9044 - val_loss: 0.2615\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8049 - binary_accuracy: 0.9013 - loss: 0.2585\n",
            "Fold 5 Metrics: Loss = 0.2615, Accuracy = 0.9044, AUC = 0.7885\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2655\n",
            "Average Accuracy: 0.9055\n",
            "Average AUC: 0.7864\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 3, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5706 - binary_accuracy: 0.9066 - loss: 0.3155 - val_auc: 0.7594 - val_binary_accuracy: 0.9044 - val_loss: 0.2817\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7713 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9069 - loss: 0.2621 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9071 - loss: 0.2591 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9083 - loss: 0.2572 - val_auc: 0.7832 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9089 - loss: 0.2557 - val_auc: 0.7820 - val_binary_accuracy: 0.9088 - val_loss: 0.2669\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9096 - loss: 0.2547 - val_auc: 0.7833 - val_binary_accuracy: 0.9082 - val_loss: 0.2650\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9111 - loss: 0.2537 - val_auc: 0.7852 - val_binary_accuracy: 0.9099 - val_loss: 0.2645\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9124 - loss: 0.2530 - val_auc: 0.7863 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9119 - loss: 0.2516 - val_auc: 0.7849 - val_binary_accuracy: 0.9090 - val_loss: 0.2644\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7846 - binary_accuracy: 0.9112 - loss: 0.2573\n",
            "Fold 1 Metrics: Loss = 0.2644, Accuracy = 0.9090, AUC = 0.7849\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6661 - binary_accuracy: 0.8577 - loss: 0.3449 - val_auc: 0.7872 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9043 - loss: 0.2716 - val_auc: 0.7932 - val_binary_accuracy: 0.9053 - val_loss: 0.2657\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9052 - loss: 0.2673 - val_auc: 0.7994 - val_binary_accuracy: 0.9065 - val_loss: 0.2612\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9059 - loss: 0.2646 - val_auc: 0.8019 - val_binary_accuracy: 0.9084 - val_loss: 0.2586\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9071 - loss: 0.2633 - val_auc: 0.8000 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9072 - loss: 0.2620 - val_auc: 0.7998 - val_binary_accuracy: 0.9093 - val_loss: 0.2592\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9082 - loss: 0.2609 - val_auc: 0.7977 - val_binary_accuracy: 0.9079 - val_loss: 0.2615\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9081 - loss: 0.2608 - val_auc: 0.7983 - val_binary_accuracy: 0.9078 - val_loss: 0.2618\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9087 - loss: 0.2607 - val_auc: 0.7985 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9098 - loss: 0.2605 - val_auc: 0.7985 - val_binary_accuracy: 0.9078 - val_loss: 0.2620\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8050 - binary_accuracy: 0.9118 - loss: 0.2514\n",
            "Fold 2 Metrics: Loss = 0.2620, Accuracy = 0.9078, AUC = 0.7985\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6525 - binary_accuracy: 0.8428 - loss: 0.3592 - val_auc: 0.7640 - val_binary_accuracy: 0.9048 - val_loss: 0.2753\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9058 - loss: 0.2722 - val_auc: 0.7723 - val_binary_accuracy: 0.9053 - val_loss: 0.2711\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7656 - binary_accuracy: 0.9063 - loss: 0.2700 - val_auc: 0.7733 - val_binary_accuracy: 0.9065 - val_loss: 0.2698\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9078 - loss: 0.2686 - val_auc: 0.7787 - val_binary_accuracy: 0.9082 - val_loss: 0.2690\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9086 - loss: 0.2673 - val_auc: 0.7782 - val_binary_accuracy: 0.9084 - val_loss: 0.2691\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9087 - loss: 0.2662 - val_auc: 0.7768 - val_binary_accuracy: 0.9084 - val_loss: 0.2689\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9085 - loss: 0.2655 - val_auc: 0.7776 - val_binary_accuracy: 0.9087 - val_loss: 0.2687\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9092 - loss: 0.2650 - val_auc: 0.7792 - val_binary_accuracy: 0.9088 - val_loss: 0.2685\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9094 - loss: 0.2646 - val_auc: 0.7790 - val_binary_accuracy: 0.9097 - val_loss: 0.2682\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9096 - loss: 0.2641 - val_auc: 0.7801 - val_binary_accuracy: 0.9093 - val_loss: 0.2679\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7731 - binary_accuracy: 0.9104 - loss: 0.2692\n",
            "Fold 3 Metrics: Loss = 0.2679, Accuracy = 0.9093, AUC = 0.7801\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6619 - binary_accuracy: 0.8546 - loss: 0.3482 - val_auc: 0.7817 - val_binary_accuracy: 0.9044 - val_loss: 0.2696\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9051 - loss: 0.2686 - val_auc: 0.7863 - val_binary_accuracy: 0.9047 - val_loss: 0.2671\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9069 - loss: 0.2656 - val_auc: 0.7906 - val_binary_accuracy: 0.9066 - val_loss: 0.2644\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.7924 - val_binary_accuracy: 0.9078 - val_loss: 0.2624\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9085 - loss: 0.2618 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2613\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2610 - val_auc: 0.7961 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9095 - loss: 0.2603 - val_auc: 0.7966 - val_binary_accuracy: 0.9087 - val_loss: 0.2610\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.7969 - val_binary_accuracy: 0.9087 - val_loss: 0.2609\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9100 - loss: 0.2595 - val_auc: 0.7972 - val_binary_accuracy: 0.9085 - val_loss: 0.2611\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9095 - loss: 0.2592 - val_auc: 0.7974 - val_binary_accuracy: 0.9084 - val_loss: 0.2613\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7778 - binary_accuracy: 0.9078 - loss: 0.2679\n",
            "Fold 4 Metrics: Loss = 0.2613, Accuracy = 0.9084, AUC = 0.7974\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7020 - binary_accuracy: 0.9041 - loss: 0.3018 - val_auc: 0.7885 - val_binary_accuracy: 0.9056 - val_loss: 0.2620\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9056 - loss: 0.2711 - val_auc: 0.7952 - val_binary_accuracy: 0.9063 - val_loss: 0.2594\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9071 - loss: 0.2690 - val_auc: 0.7975 - val_binary_accuracy: 0.9075 - val_loss: 0.2583\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9078 - loss: 0.2681 - val_auc: 0.7964 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9080 - loss: 0.2668 - val_auc: 0.7975 - val_binary_accuracy: 0.9097 - val_loss: 0.2574\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9080 - loss: 0.2657 - val_auc: 0.7985 - val_binary_accuracy: 0.9101 - val_loss: 0.2568\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8006 - val_binary_accuracy: 0.9091 - val_loss: 0.2561\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9075 - loss: 0.2642 - val_auc: 0.8026 - val_binary_accuracy: 0.9093 - val_loss: 0.2557\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.8023 - val_binary_accuracy: 0.9085 - val_loss: 0.2554\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9088 - loss: 0.2629 - val_auc: 0.8029 - val_binary_accuracy: 0.9085 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8135 - binary_accuracy: 0.9076 - loss: 0.2521\n",
            "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9085, AUC = 0.8029\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2621\n",
            "Average Accuracy: 0.9086\n",
            "Average AUC: 0.7928\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 3, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7186 - binary_accuracy: 0.9060 - loss: 0.2886 - val_auc: 0.7727 - val_binary_accuracy: 0.9044 - val_loss: 0.2707\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9082 - loss: 0.2591 - val_auc: 0.7799 - val_binary_accuracy: 0.9047 - val_loss: 0.2673\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9102 - loss: 0.2556 - val_auc: 0.7833 - val_binary_accuracy: 0.9054 - val_loss: 0.2650\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9120 - loss: 0.2533 - val_auc: 0.7855 - val_binary_accuracy: 0.9069 - val_loss: 0.2636\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9124 - loss: 0.2516 - val_auc: 0.7865 - val_binary_accuracy: 0.9072 - val_loss: 0.2628\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9124 - loss: 0.2504 - val_auc: 0.7874 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9127 - loss: 0.2496 - val_auc: 0.7857 - val_binary_accuracy: 0.9075 - val_loss: 0.2630\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9125 - loss: 0.2492 - val_auc: 0.7863 - val_binary_accuracy: 0.9078 - val_loss: 0.2631\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9126 - loss: 0.2493 - val_auc: 0.7871 - val_binary_accuracy: 0.9078 - val_loss: 0.2629\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9128 - loss: 0.2487 - val_auc: 0.7882 - val_binary_accuracy: 0.9082 - val_loss: 0.2622\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7870 - binary_accuracy: 0.9111 - loss: 0.2548\n",
            "Fold 1 Metrics: Loss = 0.2622, Accuracy = 0.9082, AUC = 0.7882\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6992 - binary_accuracy: 0.8989 - loss: 0.3037 - val_auc: 0.7879 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9037 - loss: 0.2709 - val_auc: 0.7982 - val_binary_accuracy: 0.9057 - val_loss: 0.2619\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9041 - loss: 0.2673 - val_auc: 0.7975 - val_binary_accuracy: 0.9063 - val_loss: 0.2609\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9058 - loss: 0.2652 - val_auc: 0.7974 - val_binary_accuracy: 0.9059 - val_loss: 0.2613\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9051 - loss: 0.2639 - val_auc: 0.7987 - val_binary_accuracy: 0.9069 - val_loss: 0.2601\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9059 - loss: 0.2635 - val_auc: 0.8015 - val_binary_accuracy: 0.9071 - val_loss: 0.2588\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9074 - loss: 0.2622 - val_auc: 0.8029 - val_binary_accuracy: 0.9072 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9077 - loss: 0.2613 - val_auc: 0.8046 - val_binary_accuracy: 0.9072 - val_loss: 0.2578\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9077 - loss: 0.2605 - val_auc: 0.8030 - val_binary_accuracy: 0.9069 - val_loss: 0.2586\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9077 - loss: 0.2605 - val_auc: 0.8030 - val_binary_accuracy: 0.9076 - val_loss: 0.2573\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8101 - binary_accuracy: 0.9118 - loss: 0.2467\n",
            "Fold 2 Metrics: Loss = 0.2573, Accuracy = 0.9076, AUC = 0.8030\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6749 - binary_accuracy: 0.8913 - loss: 0.3076 - val_auc: 0.7857 - val_binary_accuracy: 0.9053 - val_loss: 0.2664\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9064 - loss: 0.2713 - val_auc: 0.7879 - val_binary_accuracy: 0.9060 - val_loss: 0.2645\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9080 - loss: 0.2680 - val_auc: 0.7892 - val_binary_accuracy: 0.9099 - val_loss: 0.2658\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9080 - loss: 0.2651 - val_auc: 0.7945 - val_binary_accuracy: 0.9066 - val_loss: 0.2623\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9088 - loss: 0.2652 - val_auc: 0.7955 - val_binary_accuracy: 0.9069 - val_loss: 0.2615\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9088 - loss: 0.2644 - val_auc: 0.7971 - val_binary_accuracy: 0.9079 - val_loss: 0.2607\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9085 - loss: 0.2638 - val_auc: 0.7976 - val_binary_accuracy: 0.9091 - val_loss: 0.2596\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9085 - loss: 0.2631 - val_auc: 0.7983 - val_binary_accuracy: 0.9103 - val_loss: 0.2587\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9083 - loss: 0.2626 - val_auc: 0.7992 - val_binary_accuracy: 0.9106 - val_loss: 0.2583\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9082 - loss: 0.2622 - val_auc: 0.7996 - val_binary_accuracy: 0.9110 - val_loss: 0.2576\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9120 - loss: 0.2585\n",
            "Fold 3 Metrics: Loss = 0.2576, Accuracy = 0.9110, AUC = 0.7996\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6600 - binary_accuracy: 0.8742 - loss: 0.3284 - val_auc: 0.7844 - val_binary_accuracy: 0.9087 - val_loss: 0.2645\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9076 - loss: 0.2683 - val_auc: 0.7922 - val_binary_accuracy: 0.9084 - val_loss: 0.2601\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9092 - loss: 0.2638 - val_auc: 0.7939 - val_binary_accuracy: 0.9088 - val_loss: 0.2591\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9100 - loss: 0.2618 - val_auc: 0.7971 - val_binary_accuracy: 0.9087 - val_loss: 0.2583\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9105 - loss: 0.2604 - val_auc: 0.7999 - val_binary_accuracy: 0.9084 - val_loss: 0.2574\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9109 - loss: 0.2595 - val_auc: 0.8009 - val_binary_accuracy: 0.9085 - val_loss: 0.2572\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9112 - loss: 0.2591 - val_auc: 0.8001 - val_binary_accuracy: 0.9082 - val_loss: 0.2573\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9112 - loss: 0.2586 - val_auc: 0.8033 - val_binary_accuracy: 0.9082 - val_loss: 0.2569\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2583 - val_auc: 0.8029 - val_binary_accuracy: 0.9082 - val_loss: 0.2562\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9112 - loss: 0.2580 - val_auc: 0.8042 - val_binary_accuracy: 0.9091 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9085 - loss: 0.2616\n",
            "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9091, AUC = 0.8042\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6394 - binary_accuracy: 0.8589 - loss: 0.3551 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2648\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9040 - loss: 0.2752 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2607\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9045 - loss: 0.2725 - val_auc: 0.7961 - val_binary_accuracy: 0.9084 - val_loss: 0.2589\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9039 - loss: 0.2714 - val_auc: 0.8021 - val_binary_accuracy: 0.9098 - val_loss: 0.2562\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9056 - loss: 0.2692 - val_auc: 0.8040 - val_binary_accuracy: 0.9085 - val_loss: 0.2552\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.8037 - val_binary_accuracy: 0.9088 - val_loss: 0.2547\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9079 - loss: 0.2659 - val_auc: 0.8036 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2648 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2551\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9087 - loss: 0.2639 - val_auc: 0.8045 - val_binary_accuracy: 0.9093 - val_loss: 0.2549\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9088 - loss: 0.2632 - val_auc: 0.8044 - val_binary_accuracy: 0.9093 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8142 - binary_accuracy: 0.9077 - loss: 0.2534\n",
            "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9093, AUC = 0.8044\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2577\n",
            "Average Accuracy: 0.9091\n",
            "Average AUC: 0.7999\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 3, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6982 - binary_accuracy: 0.8899 - loss: 0.3054 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2685\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9073 - loss: 0.2610 - val_auc: 0.7826 - val_binary_accuracy: 0.9054 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9083 - loss: 0.2567 - val_auc: 0.7850 - val_binary_accuracy: 0.9056 - val_loss: 0.2643\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9093 - loss: 0.2549 - val_auc: 0.7874 - val_binary_accuracy: 0.9075 - val_loss: 0.2633\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8008 - binary_accuracy: 0.9098 - loss: 0.2530 - val_auc: 0.7896 - val_binary_accuracy: 0.9093 - val_loss: 0.2622\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9109 - loss: 0.2515 - val_auc: 0.7911 - val_binary_accuracy: 0.9090 - val_loss: 0.2611\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9120 - loss: 0.2505 - val_auc: 0.7922 - val_binary_accuracy: 0.9088 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9127 - loss: 0.2495 - val_auc: 0.7918 - val_binary_accuracy: 0.9087 - val_loss: 0.2602\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9130 - loss: 0.2491 - val_auc: 0.7932 - val_binary_accuracy: 0.9084 - val_loss: 0.2602\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9129 - loss: 0.2483 - val_auc: 0.7927 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9126 - loss: 0.2516\n",
            "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9087, AUC = 0.7927\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7276 - binary_accuracy: 0.9039 - loss: 0.2906 - val_auc: 0.8012 - val_binary_accuracy: 0.9068 - val_loss: 0.2673\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9055 - loss: 0.2699 - val_auc: 0.8019 - val_binary_accuracy: 0.9073 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9065 - loss: 0.2660 - val_auc: 0.8020 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9066 - loss: 0.2647 - val_auc: 0.8039 - val_binary_accuracy: 0.9069 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9074 - loss: 0.2629 - val_auc: 0.8043 - val_binary_accuracy: 0.9082 - val_loss: 0.2611\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9077 - loss: 0.2627 - val_auc: 0.8082 - val_binary_accuracy: 0.9071 - val_loss: 0.2602\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9082 - loss: 0.2618 - val_auc: 0.8084 - val_binary_accuracy: 0.9068 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9073 - loss: 0.2622 - val_auc: 0.8097 - val_binary_accuracy: 0.9053 - val_loss: 0.2602\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9077 - loss: 0.2618 - val_auc: 0.8109 - val_binary_accuracy: 0.9068 - val_loss: 0.2596\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9070 - loss: 0.2611 - val_auc: 0.8111 - val_binary_accuracy: 0.9069 - val_loss: 0.2596\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8178 - binary_accuracy: 0.9106 - loss: 0.2501\n",
            "Fold 2 Metrics: Loss = 0.2596, Accuracy = 0.9069, AUC = 0.8111\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7209 - binary_accuracy: 0.9055 - loss: 0.2889 - val_auc: 0.7895 - val_binary_accuracy: 0.9068 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9072 - loss: 0.2686 - val_auc: 0.7918 - val_binary_accuracy: 0.9051 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9074 - loss: 0.2679 - val_auc: 0.7945 - val_binary_accuracy: 0.9066 - val_loss: 0.2654\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9076 - loss: 0.2671 - val_auc: 0.7964 - val_binary_accuracy: 0.9056 - val_loss: 0.2639\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9072 - loss: 0.2664 - val_auc: 0.7968 - val_binary_accuracy: 0.9071 - val_loss: 0.2637\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9086 - loss: 0.2653 - val_auc: 0.7985 - val_binary_accuracy: 0.9056 - val_loss: 0.2619\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9083 - loss: 0.2647 - val_auc: 0.7982 - val_binary_accuracy: 0.9066 - val_loss: 0.2624\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.7989 - val_binary_accuracy: 0.9072 - val_loss: 0.2618\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8003 - val_binary_accuracy: 0.9084 - val_loss: 0.2605\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8008 - val_binary_accuracy: 0.9088 - val_loss: 0.2600\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7933 - binary_accuracy: 0.9100 - loss: 0.2607\n",
            "Fold 3 Metrics: Loss = 0.2600, Accuracy = 0.9088, AUC = 0.8008\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7056 - binary_accuracy: 0.8967 - loss: 0.2995 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2625\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9074 - loss: 0.2666 - val_auc: 0.7962 - val_binary_accuracy: 0.9075 - val_loss: 0.2614\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9079 - loss: 0.2637 - val_auc: 0.7978 - val_binary_accuracy: 0.9084 - val_loss: 0.2601\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9084 - loss: 0.2616 - val_auc: 0.7988 - val_binary_accuracy: 0.9087 - val_loss: 0.2592\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2605 - val_auc: 0.8013 - val_binary_accuracy: 0.9087 - val_loss: 0.2575\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9102 - loss: 0.2595 - val_auc: 0.8031 - val_binary_accuracy: 0.9093 - val_loss: 0.2571\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.8035 - val_binary_accuracy: 0.9097 - val_loss: 0.2568\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2582 - val_auc: 0.8035 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9106 - loss: 0.2583 - val_auc: 0.8044 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9112 - loss: 0.2577 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7875 - binary_accuracy: 0.9083 - loss: 0.2636\n",
            "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9094, AUC = 0.8062\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7007 - binary_accuracy: 0.9041 - loss: 0.2985 - val_auc: 0.7899 - val_binary_accuracy: 0.9066 - val_loss: 0.2644\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9056 - loss: 0.2744 - val_auc: 0.7980 - val_binary_accuracy: 0.9072 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9069 - loss: 0.2705 - val_auc: 0.8010 - val_binary_accuracy: 0.9084 - val_loss: 0.2629\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9073 - loss: 0.2680 - val_auc: 0.8044 - val_binary_accuracy: 0.9085 - val_loss: 0.2612\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9076 - loss: 0.2666 - val_auc: 0.8042 - val_binary_accuracy: 0.9090 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9070 - loss: 0.2655 - val_auc: 0.8077 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9084 - loss: 0.2638 - val_auc: 0.8081 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8086 - val_binary_accuracy: 0.9090 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8089 - val_binary_accuracy: 0.9109 - val_loss: 0.2550\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9094 - loss: 0.2618 - val_auc: 0.8090 - val_binary_accuracy: 0.9115 - val_loss: 0.2543\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9097 - loss: 0.2522\n",
            "Fold 5 Metrics: Loss = 0.2543, Accuracy = 0.9115, AUC = 0.8090\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2579\n",
            "Average Accuracy: 0.9091\n",
            "Average AUC: 0.8040\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 3, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7155 - binary_accuracy: 0.9054 - loss: 0.2915 - val_auc: 0.7776 - val_binary_accuracy: 0.9045 - val_loss: 0.2668\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9086 - loss: 0.2600 - val_auc: 0.7844 - val_binary_accuracy: 0.9081 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9106 - loss: 0.2559 - val_auc: 0.7884 - val_binary_accuracy: 0.9093 - val_loss: 0.2613\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9111 - loss: 0.2545 - val_auc: 0.7904 - val_binary_accuracy: 0.9094 - val_loss: 0.2608\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9118 - loss: 0.2529 - val_auc: 0.7904 - val_binary_accuracy: 0.9088 - val_loss: 0.2622\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9111 - loss: 0.2521 - val_auc: 0.7908 - val_binary_accuracy: 0.9093 - val_loss: 0.2624\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9120 - loss: 0.2511 - val_auc: 0.7907 - val_binary_accuracy: 0.9096 - val_loss: 0.2622\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9122 - loss: 0.2503 - val_auc: 0.7912 - val_binary_accuracy: 0.9097 - val_loss: 0.2623\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9126 - loss: 0.2501 - val_auc: 0.7921 - val_binary_accuracy: 0.9093 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8058 - binary_accuracy: 0.9130 - loss: 0.2500 - val_auc: 0.7916 - val_binary_accuracy: 0.9090 - val_loss: 0.2615\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7895 - binary_accuracy: 0.9121 - loss: 0.2539\n",
            "Fold 1 Metrics: Loss = 0.2615, Accuracy = 0.9090, AUC = 0.7916\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - auc: 0.7058 - binary_accuracy: 0.9016 - loss: 0.3067 - val_auc: 0.8011 - val_binary_accuracy: 0.9045 - val_loss: 0.2670\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9034 - loss: 0.2702 - val_auc: 0.8061 - val_binary_accuracy: 0.9072 - val_loss: 0.2626\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9061 - loss: 0.2669 - val_auc: 0.8086 - val_binary_accuracy: 0.9082 - val_loss: 0.2598\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9063 - loss: 0.2648 - val_auc: 0.8084 - val_binary_accuracy: 0.9081 - val_loss: 0.2599\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9070 - loss: 0.2638 - val_auc: 0.8094 - val_binary_accuracy: 0.9075 - val_loss: 0.2613\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9074 - loss: 0.2635 - val_auc: 0.8095 - val_binary_accuracy: 0.9071 - val_loss: 0.2621\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9071 - loss: 0.2628 - val_auc: 0.8095 - val_binary_accuracy: 0.9071 - val_loss: 0.2615\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9080 - loss: 0.2623 - val_auc: 0.8093 - val_binary_accuracy: 0.9069 - val_loss: 0.2620\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9079 - loss: 0.2618 - val_auc: 0.8097 - val_binary_accuracy: 0.9065 - val_loss: 0.2633\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8111 - val_binary_accuracy: 0.9066 - val_loss: 0.2624\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9101 - loss: 0.2539\n",
            "Fold 2 Metrics: Loss = 0.2624, Accuracy = 0.9066, AUC = 0.8111\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7028 - binary_accuracy: 0.8871 - loss: 0.3199 - val_auc: 0.7849 - val_binary_accuracy: 0.9075 - val_loss: 0.2674\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9070 - loss: 0.2691 - val_auc: 0.7910 - val_binary_accuracy: 0.9088 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9075 - loss: 0.2676 - val_auc: 0.7931 - val_binary_accuracy: 0.9102 - val_loss: 0.2620\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9066 - loss: 0.2686 - val_auc: 0.7954 - val_binary_accuracy: 0.9100 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9067 - loss: 0.2673 - val_auc: 0.7965 - val_binary_accuracy: 0.9094 - val_loss: 0.2618\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9077 - loss: 0.2670 - val_auc: 0.7979 - val_binary_accuracy: 0.9107 - val_loss: 0.2617\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9079 - loss: 0.2662 - val_auc: 0.7992 - val_binary_accuracy: 0.9107 - val_loss: 0.2616\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9077 - loss: 0.2661 - val_auc: 0.7977 - val_binary_accuracy: 0.9106 - val_loss: 0.2624\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9072 - loss: 0.2659 - val_auc: 0.8003 - val_binary_accuracy: 0.9103 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9084 - loss: 0.2648 - val_auc: 0.7996 - val_binary_accuracy: 0.9103 - val_loss: 0.2625\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7917 - binary_accuracy: 0.9101 - loss: 0.2635\n",
            "Fold 3 Metrics: Loss = 0.2625, Accuracy = 0.9103, AUC = 0.7996\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6977 - binary_accuracy: 0.9047 - loss: 0.3033 - val_auc: 0.7941 - val_binary_accuracy: 0.9062 - val_loss: 0.2647\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9066 - loss: 0.2681 - val_auc: 0.7963 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9071 - loss: 0.2652 - val_auc: 0.7989 - val_binary_accuracy: 0.9087 - val_loss: 0.2612\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9079 - loss: 0.2638 - val_auc: 0.8008 - val_binary_accuracy: 0.9047 - val_loss: 0.2661\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8018 - val_binary_accuracy: 0.9098 - val_loss: 0.2606\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9094 - loss: 0.2620 - val_auc: 0.8039 - val_binary_accuracy: 0.9088 - val_loss: 0.2584\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9102 - loss: 0.2611 - val_auc: 0.8054 - val_binary_accuracy: 0.9094 - val_loss: 0.2575\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9106 - loss: 0.2604 - val_auc: 0.8066 - val_binary_accuracy: 0.9098 - val_loss: 0.2569\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9107 - loss: 0.2600 - val_auc: 0.8066 - val_binary_accuracy: 0.9098 - val_loss: 0.2569\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9106 - loss: 0.2593 - val_auc: 0.8087 - val_binary_accuracy: 0.9095 - val_loss: 0.2565\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7896 - binary_accuracy: 0.9087 - loss: 0.2656\n",
            "Fold 4 Metrics: Loss = 0.2565, Accuracy = 0.9095, AUC = 0.8087\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6900 - binary_accuracy: 0.9031 - loss: 0.3169 - val_auc: 0.7962 - val_binary_accuracy: 0.9093 - val_loss: 0.2583\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7672 - binary_accuracy: 0.9044 - loss: 0.2726 - val_auc: 0.8012 - val_binary_accuracy: 0.9093 - val_loss: 0.2577\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9064 - loss: 0.2681 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2581\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9072 - loss: 0.2658 - val_auc: 0.8042 - val_binary_accuracy: 0.9090 - val_loss: 0.2584\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9078 - loss: 0.2646 - val_auc: 0.8042 - val_binary_accuracy: 0.9087 - val_loss: 0.2575\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9084 - loss: 0.2640 - val_auc: 0.8046 - val_binary_accuracy: 0.9095 - val_loss: 0.2588\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9085 - loss: 0.2638 - val_auc: 0.8046 - val_binary_accuracy: 0.9100 - val_loss: 0.2587\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8055 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9083 - loss: 0.2629 - val_auc: 0.8066 - val_binary_accuracy: 0.9107 - val_loss: 0.2576\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9089 - loss: 0.2626 - val_auc: 0.8068 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8149 - binary_accuracy: 0.9102 - loss: 0.2535\n",
            "Fold 5 Metrics: Loss = 0.2573, Accuracy = 0.9091, AUC = 0.8068\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2600\n",
            "Average Accuracy: 0.9089\n",
            "Average AUC: 0.8036\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 4, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6476 - binary_accuracy: 0.8983 - loss: 0.3192 - val_auc: 0.7569 - val_binary_accuracy: 0.9040 - val_loss: 0.2772\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7598 - val_binary_accuracy: 0.9040 - val_loss: 0.2751\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9068 - loss: 0.2630 - val_auc: 0.7618 - val_binary_accuracy: 0.9040 - val_loss: 0.2753\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9068 - loss: 0.2627 - val_auc: 0.7640 - val_binary_accuracy: 0.9038 - val_loss: 0.2747\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9068 - loss: 0.2619 - val_auc: 0.7646 - val_binary_accuracy: 0.9038 - val_loss: 0.2740\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9068 - loss: 0.2614 - val_auc: 0.7650 - val_binary_accuracy: 0.9038 - val_loss: 0.2738\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9069 - loss: 0.2610 - val_auc: 0.7653 - val_binary_accuracy: 0.9038 - val_loss: 0.2738\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7663 - val_binary_accuracy: 0.9038 - val_loss: 0.2735\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9069 - loss: 0.2603 - val_auc: 0.7658 - val_binary_accuracy: 0.9038 - val_loss: 0.2730\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2601 - val_auc: 0.7674 - val_binary_accuracy: 0.9038 - val_loss: 0.2727\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7665 - binary_accuracy: 0.9078 - loss: 0.2653\n",
            "Fold 1 Metrics: Loss = 0.2727, Accuracy = 0.9038, AUC = 0.7674\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5976 - binary_accuracy: 0.8574 - loss: 0.3663 - val_auc: 0.7235 - val_binary_accuracy: 0.9042 - val_loss: 0.2919\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7143 - binary_accuracy: 0.9029 - loss: 0.2893 - val_auc: 0.7334 - val_binary_accuracy: 0.9042 - val_loss: 0.2892\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7256 - binary_accuracy: 0.9029 - loss: 0.2847 - val_auc: 0.7427 - val_binary_accuracy: 0.9042 - val_loss: 0.2839\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7418 - binary_accuracy: 0.9029 - loss: 0.2799 - val_auc: 0.7575 - val_binary_accuracy: 0.9042 - val_loss: 0.2784\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7509 - binary_accuracy: 0.9029 - loss: 0.2768 - val_auc: 0.7835 - val_binary_accuracy: 0.9042 - val_loss: 0.2731\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7626 - binary_accuracy: 0.9029 - loss: 0.2743 - val_auc: 0.7865 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9029 - loss: 0.2726 - val_auc: 0.7858 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9029 - loss: 0.2719 - val_auc: 0.7888 - val_binary_accuracy: 0.9042 - val_loss: 0.2709\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2707 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2713\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9029 - loss: 0.2709 - val_auc: 0.7875 - val_binary_accuracy: 0.9042 - val_loss: 0.2717\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7795 - binary_accuracy: 0.9092 - loss: 0.2621\n",
            "Fold 2 Metrics: Loss = 0.2717, Accuracy = 0.9042, AUC = 0.7875\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6142 - binary_accuracy: 0.9045 - loss: 0.3365 - val_auc: 0.7581 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7563 - binary_accuracy: 0.9048 - loss: 0.2747 - val_auc: 0.7709 - val_binary_accuracy: 0.9042 - val_loss: 0.2748\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9051 - loss: 0.2687 - val_auc: 0.7749 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7773 - val_binary_accuracy: 0.9041 - val_loss: 0.2727\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7809 - val_binary_accuracy: 0.9041 - val_loss: 0.2716\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7819 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9052 - loss: 0.2641 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9052 - loss: 0.2634 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9051 - loss: 0.2630 - val_auc: 0.7866 - val_binary_accuracy: 0.9042 - val_loss: 0.2672\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9051 - loss: 0.2627 - val_auc: 0.7878 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7824 - binary_accuracy: 0.9046 - loss: 0.2674\n",
            "Fold 3 Metrics: Loss = 0.2668, Accuracy = 0.9042, AUC = 0.7878\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4936 - binary_accuracy: 0.8270 - loss: 0.4017 - val_auc: 0.4962 - val_binary_accuracy: 0.9044 - val_loss: 0.3157\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5056 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4973 - val_binary_accuracy: 0.9044 - val_loss: 0.3157\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5047 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4976 - val_binary_accuracy: 0.9044 - val_loss: 0.3158\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5095 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4977 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5098 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4978 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5085 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4982 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5084 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4982 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5086 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5007 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5086 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5009 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5093 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5037 - val_binary_accuracy: 0.9044 - val_loss: 0.3158\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.5056 - binary_accuracy: 0.9049 - loss: 0.3146\n",
            "Fold 4 Metrics: Loss = 0.3158, Accuracy = 0.9044, AUC = 0.5037\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6141 - binary_accuracy: 0.8867 - loss: 0.3614 - val_auc: 0.7363 - val_binary_accuracy: 0.9044 - val_loss: 0.2835\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7209 - binary_accuracy: 0.9040 - loss: 0.2870 - val_auc: 0.7400 - val_binary_accuracy: 0.9044 - val_loss: 0.2800\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7253 - binary_accuracy: 0.9040 - loss: 0.2848 - val_auc: 0.7499 - val_binary_accuracy: 0.9045 - val_loss: 0.2768\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7319 - binary_accuracy: 0.9039 - loss: 0.2826 - val_auc: 0.7638 - val_binary_accuracy: 0.9045 - val_loss: 0.2738\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7450 - binary_accuracy: 0.9039 - loss: 0.2790 - val_auc: 0.7665 - val_binary_accuracy: 0.9044 - val_loss: 0.2721\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7503 - binary_accuracy: 0.9038 - loss: 0.2774 - val_auc: 0.7707 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7519 - binary_accuracy: 0.9039 - loss: 0.2781 - val_auc: 0.7705 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7553 - binary_accuracy: 0.9039 - loss: 0.2771 - val_auc: 0.7736 - val_binary_accuracy: 0.9044 - val_loss: 0.2678\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7564 - binary_accuracy: 0.9039 - loss: 0.2753 - val_auc: 0.7763 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9039 - loss: 0.2752 - val_auc: 0.7754 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9013 - loss: 0.2665\n",
            "Fold 5 Metrics: Loss = 0.2664, Accuracy = 0.9044, AUC = 0.7754\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2787\n",
            "Average Accuracy: 0.9042\n",
            "Average AUC: 0.7244\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 4, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6469 - binary_accuracy: 0.9069 - loss: 0.3076 - val_auc: 0.7691 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9068 - loss: 0.2585 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9070 - loss: 0.2564 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9072 - loss: 0.2549 - val_auc: 0.7883 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9075 - loss: 0.2535 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2655\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9085 - loss: 0.2521 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2642\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9085 - loss: 0.2515 - val_auc: 0.7904 - val_binary_accuracy: 0.9051 - val_loss: 0.2641\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8073 - binary_accuracy: 0.9104 - loss: 0.2506 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2622\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9105 - loss: 0.2500 - val_auc: 0.7925 - val_binary_accuracy: 0.9063 - val_loss: 0.2620\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7918 - binary_accuracy: 0.9094 - loss: 0.2548\n",
            "Fold 1 Metrics: Loss = 0.2620, Accuracy = 0.9063, AUC = 0.7925\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6112 - binary_accuracy: 0.8474 - loss: 0.3625 - val_auc: 0.7593 - val_binary_accuracy: 0.9042 - val_loss: 0.2813\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7562 - binary_accuracy: 0.9028 - loss: 0.2805 - val_auc: 0.7715 - val_binary_accuracy: 0.9041 - val_loss: 0.2794\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9040 - loss: 0.2762 - val_auc: 0.7959 - val_binary_accuracy: 0.9053 - val_loss: 0.2630\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2688 - val_auc: 0.7993 - val_binary_accuracy: 0.9056 - val_loss: 0.2637\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9052 - loss: 0.2676 - val_auc: 0.7997 - val_binary_accuracy: 0.9053 - val_loss: 0.2632\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9052 - loss: 0.2667 - val_auc: 0.8000 - val_binary_accuracy: 0.9063 - val_loss: 0.2607\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9066 - loss: 0.2654 - val_auc: 0.8003 - val_binary_accuracy: 0.9066 - val_loss: 0.2605\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9064 - loss: 0.2647 - val_auc: 0.8012 - val_binary_accuracy: 0.9063 - val_loss: 0.2603\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9067 - loss: 0.2631 - val_auc: 0.8048 - val_binary_accuracy: 0.9066 - val_loss: 0.2595\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9071 - loss: 0.2634 - val_auc: 0.8021 - val_binary_accuracy: 0.9072 - val_loss: 0.2603\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8054 - binary_accuracy: 0.9113 - loss: 0.2502\n",
            "Fold 2 Metrics: Loss = 0.2603, Accuracy = 0.9072, AUC = 0.8021\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6254 - binary_accuracy: 0.8785 - loss: 0.3328 - val_auc: 0.7636 - val_binary_accuracy: 0.9042 - val_loss: 0.2742\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9057 - loss: 0.2729 - val_auc: 0.7714 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9057 - loss: 0.2714 - val_auc: 0.7759 - val_binary_accuracy: 0.9047 - val_loss: 0.2708\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9063 - loss: 0.2688 - val_auc: 0.7749 - val_binary_accuracy: 0.9059 - val_loss: 0.2697\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7704 - binary_accuracy: 0.9064 - loss: 0.2677 - val_auc: 0.7763 - val_binary_accuracy: 0.9084 - val_loss: 0.2684\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9073 - loss: 0.2669 - val_auc: 0.7775 - val_binary_accuracy: 0.9073 - val_loss: 0.2684\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9065 - loss: 0.2664 - val_auc: 0.7790 - val_binary_accuracy: 0.9073 - val_loss: 0.2673\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9072 - loss: 0.2657 - val_auc: 0.7827 - val_binary_accuracy: 0.9076 - val_loss: 0.2661\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9081 - loss: 0.2653 - val_auc: 0.7839 - val_binary_accuracy: 0.9072 - val_loss: 0.2658\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9082 - loss: 0.2649 - val_auc: 0.7824 - val_binary_accuracy: 0.9075 - val_loss: 0.2657\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7762 - binary_accuracy: 0.9084 - loss: 0.2651\n",
            "Fold 3 Metrics: Loss = 0.2657, Accuracy = 0.9075, AUC = 0.7824\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6732 - binary_accuracy: 0.9052 - loss: 0.3074 - val_auc: 0.7863 - val_binary_accuracy: 0.9063 - val_loss: 0.2671\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9079 - loss: 0.2681 - val_auc: 0.7978 - val_binary_accuracy: 0.9075 - val_loss: 0.2623\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9087 - loss: 0.2650 - val_auc: 0.8024 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2632 - val_auc: 0.8036 - val_binary_accuracy: 0.9081 - val_loss: 0.2594\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9094 - loss: 0.2618 - val_auc: 0.8049 - val_binary_accuracy: 0.9082 - val_loss: 0.2586\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8057 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8049 - val_binary_accuracy: 0.9088 - val_loss: 0.2588\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9099 - loss: 0.2601 - val_auc: 0.8061 - val_binary_accuracy: 0.9090 - val_loss: 0.2587\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9097 - loss: 0.2598 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2586\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9097 - loss: 0.2596 - val_auc: 0.8076 - val_binary_accuracy: 0.9091 - val_loss: 0.2584\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7949 - binary_accuracy: 0.9090 - loss: 0.2623\n",
            "Fold 4 Metrics: Loss = 0.2584, Accuracy = 0.9091, AUC = 0.8076\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6298 - binary_accuracy: 0.9040 - loss: 0.3124 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9039 - loss: 0.2767 - val_auc: 0.7848 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9038 - loss: 0.2732 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2633\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9036 - loss: 0.2715 - val_auc: 0.7863 - val_binary_accuracy: 0.9044 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9042 - loss: 0.2696 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2610\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9038 - loss: 0.2686 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2602\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9053 - loss: 0.2677 - val_auc: 0.7962 - val_binary_accuracy: 0.9101 - val_loss: 0.2589\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9060 - loss: 0.2670 - val_auc: 0.7951 - val_binary_accuracy: 0.9106 - val_loss: 0.2581\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9070 - loss: 0.2659 - val_auc: 0.7973 - val_binary_accuracy: 0.9112 - val_loss: 0.2576\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2656 - val_auc: 0.7970 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8080 - binary_accuracy: 0.9111 - loss: 0.2538\n",
            "Fold 5 Metrics: Loss = 0.2571, Accuracy = 0.9112, AUC = 0.7970\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2607\n",
            "Average Accuracy: 0.9083\n",
            "Average AUC: 0.7963\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 4, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7309 - binary_accuracy: 0.9069 - loss: 0.2815 - val_auc: 0.7759 - val_binary_accuracy: 0.9048 - val_loss: 0.2681\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9086 - loss: 0.2589 - val_auc: 0.7823 - val_binary_accuracy: 0.9056 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9091 - loss: 0.2556 - val_auc: 0.7835 - val_binary_accuracy: 0.9054 - val_loss: 0.2649\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9088 - loss: 0.2539 - val_auc: 0.7848 - val_binary_accuracy: 0.9069 - val_loss: 0.2629\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9099 - loss: 0.2526 - val_auc: 0.7862 - val_binary_accuracy: 0.9100 - val_loss: 0.2617\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9102 - loss: 0.2520 - val_auc: 0.7867 - val_binary_accuracy: 0.9099 - val_loss: 0.2616\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9113 - loss: 0.2511 - val_auc: 0.7886 - val_binary_accuracy: 0.9096 - val_loss: 0.2612\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9114 - loss: 0.2505 - val_auc: 0.7881 - val_binary_accuracy: 0.9099 - val_loss: 0.2608\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9117 - loss: 0.2498 - val_auc: 0.7888 - val_binary_accuracy: 0.9099 - val_loss: 0.2605\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9120 - loss: 0.2491 - val_auc: 0.7889 - val_binary_accuracy: 0.9096 - val_loss: 0.2603\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7861 - binary_accuracy: 0.9128 - loss: 0.2534\n",
            "Fold 1 Metrics: Loss = 0.2603, Accuracy = 0.9096, AUC = 0.7889\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6884 - binary_accuracy: 0.8922 - loss: 0.3070 - val_auc: 0.7908 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9029 - loss: 0.2733 - val_auc: 0.8033 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9038 - loss: 0.2673 - val_auc: 0.8096 - val_binary_accuracy: 0.9042 - val_loss: 0.2601\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9056 - loss: 0.2648 - val_auc: 0.8118 - val_binary_accuracy: 0.9042 - val_loss: 0.2590\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9060 - loss: 0.2634 - val_auc: 0.8124 - val_binary_accuracy: 0.9042 - val_loss: 0.2589\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9056 - loss: 0.2627 - val_auc: 0.8121 - val_binary_accuracy: 0.9042 - val_loss: 0.2596\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9050 - loss: 0.2618 - val_auc: 0.8112 - val_binary_accuracy: 0.9047 - val_loss: 0.2597\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9061 - loss: 0.2609 - val_auc: 0.8109 - val_binary_accuracy: 0.9047 - val_loss: 0.2595\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9069 - loss: 0.2601 - val_auc: 0.8107 - val_binary_accuracy: 0.9051 - val_loss: 0.2585\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9079 - loss: 0.2598 - val_auc: 0.8099 - val_binary_accuracy: 0.9051 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9100 - loss: 0.2487\n",
            "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9051, AUC = 0.8099\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6706 - binary_accuracy: 0.8878 - loss: 0.3112 - val_auc: 0.7894 - val_binary_accuracy: 0.9065 - val_loss: 0.2684\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9063 - loss: 0.2710 - val_auc: 0.7957 - val_binary_accuracy: 0.9084 - val_loss: 0.2655\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9074 - loss: 0.2681 - val_auc: 0.7979 - val_binary_accuracy: 0.9099 - val_loss: 0.2635\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9089 - loss: 0.2666 - val_auc: 0.7986 - val_binary_accuracy: 0.9079 - val_loss: 0.2644\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9090 - loss: 0.2659 - val_auc: 0.7970 - val_binary_accuracy: 0.9066 - val_loss: 0.2641\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9084 - loss: 0.2657 - val_auc: 0.7996 - val_binary_accuracy: 0.9053 - val_loss: 0.2624\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9080 - loss: 0.2651 - val_auc: 0.7999 - val_binary_accuracy: 0.9053 - val_loss: 0.2614\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9087 - loss: 0.2644 - val_auc: 0.8002 - val_binary_accuracy: 0.9054 - val_loss: 0.2611\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8011 - val_binary_accuracy: 0.9054 - val_loss: 0.2609\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9086 - loss: 0.2632 - val_auc: 0.8008 - val_binary_accuracy: 0.9054 - val_loss: 0.2608\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9058 - loss: 0.2620\n",
            "Fold 3 Metrics: Loss = 0.2608, Accuracy = 0.9054, AUC = 0.8008\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7012 - binary_accuracy: 0.9004 - loss: 0.2989 - val_auc: 0.7891 - val_binary_accuracy: 0.9072 - val_loss: 0.2649\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9075 - loss: 0.2686 - val_auc: 0.7877 - val_binary_accuracy: 0.9079 - val_loss: 0.2645\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9086 - loss: 0.2659 - val_auc: 0.7927 - val_binary_accuracy: 0.9090 - val_loss: 0.2622\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9096 - loss: 0.2634 - val_auc: 0.7951 - val_binary_accuracy: 0.9095 - val_loss: 0.2610\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9096 - loss: 0.2622 - val_auc: 0.7975 - val_binary_accuracy: 0.9097 - val_loss: 0.2594\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9099 - loss: 0.2613 - val_auc: 0.7966 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.7971 - val_binary_accuracy: 0.9082 - val_loss: 0.2596\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9101 - loss: 0.2600 - val_auc: 0.7978 - val_binary_accuracy: 0.9082 - val_loss: 0.2595\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9103 - loss: 0.2594 - val_auc: 0.7976 - val_binary_accuracy: 0.9081 - val_loss: 0.2598\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9109 - loss: 0.2592 - val_auc: 0.7963 - val_binary_accuracy: 0.9085 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7777 - binary_accuracy: 0.9082 - loss: 0.2666\n",
            "Fold 4 Metrics: Loss = 0.2599, Accuracy = 0.9085, AUC = 0.7963\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6674 - binary_accuracy: 0.9039 - loss: 0.3090 - val_auc: 0.7882 - val_binary_accuracy: 0.9036 - val_loss: 0.2714\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9042 - loss: 0.2758 - val_auc: 0.7931 - val_binary_accuracy: 0.9038 - val_loss: 0.2647\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9045 - loss: 0.2723 - val_auc: 0.7967 - val_binary_accuracy: 0.9047 - val_loss: 0.2590\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9059 - loss: 0.2694 - val_auc: 0.7981 - val_binary_accuracy: 0.9060 - val_loss: 0.2573\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9066 - loss: 0.2671 - val_auc: 0.8001 - val_binary_accuracy: 0.9078 - val_loss: 0.2562\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9074 - loss: 0.2658 - val_auc: 0.8005 - val_binary_accuracy: 0.9073 - val_loss: 0.2559\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8017 - val_binary_accuracy: 0.9088 - val_loss: 0.2557\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8021 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9094 - loss: 0.2630 - val_auc: 0.8023 - val_binary_accuracy: 0.9088 - val_loss: 0.2553\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8027 - val_binary_accuracy: 0.9093 - val_loss: 0.2553\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.9075 - loss: 0.2533\n",
            "Fold 5 Metrics: Loss = 0.2553, Accuracy = 0.9093, AUC = 0.8027\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2590\n",
            "Average Accuracy: 0.9076\n",
            "Average AUC: 0.7998\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 4, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7170 - binary_accuracy: 0.9062 - loss: 0.2874 - val_auc: 0.7769 - val_binary_accuracy: 0.9045 - val_loss: 0.2674\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9063 - loss: 0.2616 - val_auc: 0.7833 - val_binary_accuracy: 0.9062 - val_loss: 0.2640\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9076 - loss: 0.2578 - val_auc: 0.7875 - val_binary_accuracy: 0.9076 - val_loss: 0.2623\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9091 - loss: 0.2555 - val_auc: 0.7903 - val_binary_accuracy: 0.9079 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9098 - loss: 0.2537 - val_auc: 0.7909 - val_binary_accuracy: 0.9079 - val_loss: 0.2608\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9104 - loss: 0.2525 - val_auc: 0.7931 - val_binary_accuracy: 0.9076 - val_loss: 0.2604\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9111 - loss: 0.2514 - val_auc: 0.7918 - val_binary_accuracy: 0.9088 - val_loss: 0.2602\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9123 - loss: 0.2508 - val_auc: 0.7924 - val_binary_accuracy: 0.9082 - val_loss: 0.2606\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9120 - loss: 0.2495 - val_auc: 0.7917 - val_binary_accuracy: 0.9084 - val_loss: 0.2609\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9126 - loss: 0.2489 - val_auc: 0.7926 - val_binary_accuracy: 0.9073 - val_loss: 0.2619\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7877 - binary_accuracy: 0.9115 - loss: 0.2551\n",
            "Fold 1 Metrics: Loss = 0.2619, Accuracy = 0.9073, AUC = 0.7926\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7122 - binary_accuracy: 0.8908 - loss: 0.3019 - val_auc: 0.7951 - val_binary_accuracy: 0.9042 - val_loss: 0.2736\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9029 - loss: 0.2708 - val_auc: 0.8036 - val_binary_accuracy: 0.9059 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9052 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9085 - val_loss: 0.2620\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9065 - loss: 0.2649 - val_auc: 0.8022 - val_binary_accuracy: 0.9060 - val_loss: 0.2644\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9062 - loss: 0.2635 - val_auc: 0.8047 - val_binary_accuracy: 0.9073 - val_loss: 0.2643\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9079 - loss: 0.2625 - val_auc: 0.8024 - val_binary_accuracy: 0.9072 - val_loss: 0.2644\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9084 - loss: 0.2621 - val_auc: 0.8017 - val_binary_accuracy: 0.9062 - val_loss: 0.2645\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9082 - loss: 0.2619 - val_auc: 0.8079 - val_binary_accuracy: 0.9060 - val_loss: 0.2634\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9081 - loss: 0.2612 - val_auc: 0.8081 - val_binary_accuracy: 0.9057 - val_loss: 0.2628\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9081 - loss: 0.2608 - val_auc: 0.8064 - val_binary_accuracy: 0.9053 - val_loss: 0.2640\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8128 - binary_accuracy: 0.9099 - loss: 0.2548\n",
            "Fold 2 Metrics: Loss = 0.2640, Accuracy = 0.9053, AUC = 0.8064\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7225 - binary_accuracy: 0.8978 - loss: 0.2938 - val_auc: 0.7896 - val_binary_accuracy: 0.9048 - val_loss: 0.2683\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9068 - loss: 0.2687 - val_auc: 0.7924 - val_binary_accuracy: 0.9054 - val_loss: 0.2647\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9062 - loss: 0.2689 - val_auc: 0.7954 - val_binary_accuracy: 0.9073 - val_loss: 0.2624\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9070 - loss: 0.2683 - val_auc: 0.7969 - val_binary_accuracy: 0.9054 - val_loss: 0.2632\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9073 - loss: 0.2669 - val_auc: 0.7973 - val_binary_accuracy: 0.9075 - val_loss: 0.2621\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9088 - loss: 0.2654 - val_auc: 0.7995 - val_binary_accuracy: 0.9059 - val_loss: 0.2623\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9088 - loss: 0.2655 - val_auc: 0.7997 - val_binary_accuracy: 0.9059 - val_loss: 0.2628\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8017 - val_binary_accuracy: 0.9054 - val_loss: 0.2628\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9090 - loss: 0.2648 - val_auc: 0.8025 - val_binary_accuracy: 0.9047 - val_loss: 0.2630\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9084 - loss: 0.2647 - val_auc: 0.8046 - val_binary_accuracy: 0.9056 - val_loss: 0.2620\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7969 - binary_accuracy: 0.9058 - loss: 0.2628\n",
            "Fold 3 Metrics: Loss = 0.2620, Accuracy = 0.9056, AUC = 0.8046\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7177 - binary_accuracy: 0.9056 - loss: 0.2889 - val_auc: 0.7918 - val_binary_accuracy: 0.9056 - val_loss: 0.2641\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9074 - loss: 0.2679 - val_auc: 0.7957 - val_binary_accuracy: 0.9059 - val_loss: 0.2622\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9083 - loss: 0.2656 - val_auc: 0.7999 - val_binary_accuracy: 0.9067 - val_loss: 0.2603\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9071 - loss: 0.2633 - val_auc: 0.8017 - val_binary_accuracy: 0.9075 - val_loss: 0.2592\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9084 - loss: 0.2619 - val_auc: 0.8021 - val_binary_accuracy: 0.9094 - val_loss: 0.2588\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9090 - loss: 0.2612 - val_auc: 0.8021 - val_binary_accuracy: 0.9098 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9091 - loss: 0.2607 - val_auc: 0.8014 - val_binary_accuracy: 0.9093 - val_loss: 0.2591\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8013 - val_binary_accuracy: 0.9095 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8017 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9099 - loss: 0.2593 - val_auc: 0.8041 - val_binary_accuracy: 0.9084 - val_loss: 0.2591\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7847 - binary_accuracy: 0.9082 - loss: 0.2677\n",
            "Fold 4 Metrics: Loss = 0.2591, Accuracy = 0.9084, AUC = 0.8041\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7079 - binary_accuracy: 0.8894 - loss: 0.3020 - val_auc: 0.7946 - val_binary_accuracy: 0.9076 - val_loss: 0.2590\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9049 - loss: 0.2734 - val_auc: 0.8002 - val_binary_accuracy: 0.9079 - val_loss: 0.2577\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9064 - loss: 0.2691 - val_auc: 0.8024 - val_binary_accuracy: 0.9091 - val_loss: 0.2584\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9070 - loss: 0.2669 - val_auc: 0.8034 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9073 - loss: 0.2655 - val_auc: 0.8040 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9074 - loss: 0.2642 - val_auc: 0.8039 - val_binary_accuracy: 0.9093 - val_loss: 0.2561\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9084 - loss: 0.2635 - val_auc: 0.8043 - val_binary_accuracy: 0.9095 - val_loss: 0.2557\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9086 - loss: 0.2628 - val_auc: 0.8045 - val_binary_accuracy: 0.9097 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9084 - loss: 0.2623 - val_auc: 0.8047 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9084 - loss: 0.2618 - val_auc: 0.8069 - val_binary_accuracy: 0.9095 - val_loss: 0.2548\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9101 - loss: 0.2511\n",
            "Fold 5 Metrics: Loss = 0.2548, Accuracy = 0.9095, AUC = 0.8069\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2603\n",
            "Average Accuracy: 0.9072\n",
            "Average AUC: 0.8029\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 4, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6985 - binary_accuracy: 0.8899 - loss: 0.3071 - val_auc: 0.7799 - val_binary_accuracy: 0.9081 - val_loss: 0.2732\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9073 - loss: 0.2623 - val_auc: 0.7851 - val_binary_accuracy: 0.9048 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9086 - loss: 0.2582 - val_auc: 0.7885 - val_binary_accuracy: 0.9119 - val_loss: 0.2609\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9098 - loss: 0.2551 - val_auc: 0.7872 - val_binary_accuracy: 0.9103 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9114 - loss: 0.2539 - val_auc: 0.7890 - val_binary_accuracy: 0.9081 - val_loss: 0.2647\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9111 - loss: 0.2529 - val_auc: 0.7882 - val_binary_accuracy: 0.9099 - val_loss: 0.2660\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9120 - loss: 0.2523 - val_auc: 0.7898 - val_binary_accuracy: 0.9097 - val_loss: 0.2645\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8033 - binary_accuracy: 0.9124 - loss: 0.2512 - val_auc: 0.7897 - val_binary_accuracy: 0.9088 - val_loss: 0.2643\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9127 - loss: 0.2508 - val_auc: 0.7917 - val_binary_accuracy: 0.9088 - val_loss: 0.2646\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9111 - loss: 0.2524 - val_auc: 0.7914 - val_binary_accuracy: 0.9091 - val_loss: 0.2643\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7888 - binary_accuracy: 0.9119 - loss: 0.2559\n",
            "Fold 1 Metrics: Loss = 0.2643, Accuracy = 0.9091, AUC = 0.7914\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6840 - binary_accuracy: 0.8860 - loss: 0.3194 - val_auc: 0.8017 - val_binary_accuracy: 0.9060 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9037 - loss: 0.2699 - val_auc: 0.7980 - val_binary_accuracy: 0.9082 - val_loss: 0.2638\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9052 - loss: 0.2691 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2651\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9069 - loss: 0.2680 - val_auc: 0.8022 - val_binary_accuracy: 0.9091 - val_loss: 0.2636\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9070 - loss: 0.2654 - val_auc: 0.8038 - val_binary_accuracy: 0.9090 - val_loss: 0.2672\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9073 - loss: 0.2652 - val_auc: 0.8056 - val_binary_accuracy: 0.9090 - val_loss: 0.2673\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9080 - loss: 0.2652 - val_auc: 0.8075 - val_binary_accuracy: 0.9094 - val_loss: 0.2707\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9082 - loss: 0.2635 - val_auc: 0.8056 - val_binary_accuracy: 0.9088 - val_loss: 0.2662\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9075 - loss: 0.2638 - val_auc: 0.8079 - val_binary_accuracy: 0.9094 - val_loss: 0.2690\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9090 - loss: 0.2643 - val_auc: 0.8094 - val_binary_accuracy: 0.9076 - val_loss: 0.2668\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9113 - loss: 0.2576\n",
            "Fold 2 Metrics: Loss = 0.2668, Accuracy = 0.9076, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6674 - binary_accuracy: 0.8867 - loss: 0.3288 - val_auc: 0.7851 - val_binary_accuracy: 0.9050 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7624 - binary_accuracy: 0.9048 - loss: 0.2717 - val_auc: 0.7902 - val_binary_accuracy: 0.9078 - val_loss: 0.2668\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9075 - loss: 0.2677 - val_auc: 0.7931 - val_binary_accuracy: 0.9096 - val_loss: 0.2634\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9065 - loss: 0.2688 - val_auc: 0.7939 - val_binary_accuracy: 0.9112 - val_loss: 0.2629\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9069 - loss: 0.2684 - val_auc: 0.7966 - val_binary_accuracy: 0.9109 - val_loss: 0.2616\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9063 - loss: 0.2695 - val_auc: 0.7955 - val_binary_accuracy: 0.9096 - val_loss: 0.2618\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9069 - loss: 0.2699 - val_auc: 0.7983 - val_binary_accuracy: 0.9109 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9067 - loss: 0.2675 - val_auc: 0.7994 - val_binary_accuracy: 0.9073 - val_loss: 0.2658\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9078 - loss: 0.2660 - val_auc: 0.7987 - val_binary_accuracy: 0.9112 - val_loss: 0.2624\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9082 - loss: 0.2661 - val_auc: 0.8020 - val_binary_accuracy: 0.9054 - val_loss: 0.2645\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7948 - binary_accuracy: 0.9059 - loss: 0.2651\n",
            "Fold 3 Metrics: Loss = 0.2645, Accuracy = 0.9054, AUC = 0.8020\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6779 - binary_accuracy: 0.8991 - loss: 0.3164 - val_auc: 0.7880 - val_binary_accuracy: 0.9038 - val_loss: 0.2694\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9054 - loss: 0.2715 - val_auc: 0.7949 - val_binary_accuracy: 0.9025 - val_loss: 0.2700\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9072 - loss: 0.2675 - val_auc: 0.7984 - val_binary_accuracy: 0.9041 - val_loss: 0.2680\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9076 - loss: 0.2666 - val_auc: 0.7982 - val_binary_accuracy: 0.9035 - val_loss: 0.2690\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9083 - loss: 0.2660 - val_auc: 0.8014 - val_binary_accuracy: 0.9017 - val_loss: 0.2681\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9082 - loss: 0.2641 - val_auc: 0.8040 - val_binary_accuracy: 0.9087 - val_loss: 0.2621\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.8042 - val_binary_accuracy: 0.9084 - val_loss: 0.2615\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8039 - val_binary_accuracy: 0.9095 - val_loss: 0.2602\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9095 - loss: 0.2614 - val_auc: 0.8040 - val_binary_accuracy: 0.9078 - val_loss: 0.2628\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2611 - val_auc: 0.8068 - val_binary_accuracy: 0.9082 - val_loss: 0.2565\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7854 - binary_accuracy: 0.9079 - loss: 0.2659\n",
            "Fold 4 Metrics: Loss = 0.2565, Accuracy = 0.9082, AUC = 0.8068\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6716 - binary_accuracy: 0.8855 - loss: 0.3284 - val_auc: 0.7931 - val_binary_accuracy: 0.9020 - val_loss: 0.2629\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7566 - binary_accuracy: 0.9030 - loss: 0.2780 - val_auc: 0.8001 - val_binary_accuracy: 0.9087 - val_loss: 0.2571\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9055 - loss: 0.2716 - val_auc: 0.8025 - val_binary_accuracy: 0.9085 - val_loss: 0.2571\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9064 - loss: 0.2688 - val_auc: 0.8052 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9067 - loss: 0.2671 - val_auc: 0.8062 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9074 - loss: 0.2661 - val_auc: 0.8079 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9074 - loss: 0.2657 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8077 - val_binary_accuracy: 0.9101 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8059 - val_binary_accuracy: 0.9104 - val_loss: 0.2555\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9097 - loss: 0.2629 - val_auc: 0.8078 - val_binary_accuracy: 0.9104 - val_loss: 0.2560\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9086 - loss: 0.2534\n",
            "Fold 5 Metrics: Loss = 0.2560, Accuracy = 0.9104, AUC = 0.8078\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2616\n",
            "Average Accuracy: 0.9082\n",
            "Average AUC: 0.8035\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 5, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6146 - binary_accuracy: 0.9011 - loss: 0.3375 - val_auc: 0.7421 - val_binary_accuracy: 0.9038 - val_loss: 0.2842\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7610 - binary_accuracy: 0.9069 - loss: 0.2687 - val_auc: 0.7503 - val_binary_accuracy: 0.9041 - val_loss: 0.2796\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9069 - loss: 0.2657 - val_auc: 0.7475 - val_binary_accuracy: 0.9040 - val_loss: 0.2767\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9069 - loss: 0.2636 - val_auc: 0.7646 - val_binary_accuracy: 0.9040 - val_loss: 0.2741\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7649 - val_binary_accuracy: 0.9040 - val_loss: 0.2732\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9069 - loss: 0.2622 - val_auc: 0.7666 - val_binary_accuracy: 0.9040 - val_loss: 0.2727\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9069 - loss: 0.2620 - val_auc: 0.7651 - val_binary_accuracy: 0.9040 - val_loss: 0.2725\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7659 - val_binary_accuracy: 0.9040 - val_loss: 0.2723\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9069 - loss: 0.2616 - val_auc: 0.7654 - val_binary_accuracy: 0.9040 - val_loss: 0.2721\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9069 - loss: 0.2614 - val_auc: 0.7652 - val_binary_accuracy: 0.9040 - val_loss: 0.2719\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7591 - binary_accuracy: 0.9079 - loss: 0.2648\n",
            "Fold 1 Metrics: Loss = 0.2719, Accuracy = 0.9040, AUC = 0.7652\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5868 - binary_accuracy: 0.8233 - loss: 0.3924 - val_auc: 0.6861 - val_binary_accuracy: 0.9042 - val_loss: 0.2951\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6966 - binary_accuracy: 0.9029 - loss: 0.2874 - val_auc: 0.7223 - val_binary_accuracy: 0.9042 - val_loss: 0.2889\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7317 - binary_accuracy: 0.9029 - loss: 0.2829 - val_auc: 0.7781 - val_binary_accuracy: 0.9042 - val_loss: 0.2733\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9029 - loss: 0.2762 - val_auc: 0.7869 - val_binary_accuracy: 0.9042 - val_loss: 0.2711\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7629 - binary_accuracy: 0.9029 - loss: 0.2747 - val_auc: 0.7901 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9029 - loss: 0.2733 - val_auc: 0.7924 - val_binary_accuracy: 0.9042 - val_loss: 0.2672\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.7894 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9032 - loss: 0.2728 - val_auc: 0.7895 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9029 - loss: 0.2718 - val_auc: 0.7921 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9038 - loss: 0.2710 - val_auc: 0.7937 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7886 - binary_accuracy: 0.9092 - loss: 0.2573\n",
            "Fold 2 Metrics: Loss = 0.2659, Accuracy = 0.9042, AUC = 0.7937\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5018 - binary_accuracy: 0.8569 - loss: 0.3752 - val_auc: 0.4997 - val_binary_accuracy: 0.9042 - val_loss: 0.3157\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5982 - binary_accuracy: 0.9051 - loss: 0.3065 - val_auc: 0.7714 - val_binary_accuracy: 0.9042 - val_loss: 0.2797\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7594 - binary_accuracy: 0.9051 - loss: 0.2745 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9051 - loss: 0.2699 - val_auc: 0.7779 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9051 - loss: 0.2687 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7796 - val_binary_accuracy: 0.9042 - val_loss: 0.2719\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9051 - loss: 0.2672 - val_auc: 0.7815 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9051 - loss: 0.2669 - val_auc: 0.7784 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7802 - val_binary_accuracy: 0.9042 - val_loss: 0.2696\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9051 - loss: 0.2643 - val_auc: 0.7816 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7779 - binary_accuracy: 0.9046 - loss: 0.2690\n",
            "Fold 3 Metrics: Loss = 0.2693, Accuracy = 0.9042, AUC = 0.7816\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5972 - binary_accuracy: 0.8563 - loss: 0.3674 - val_auc: 0.7605 - val_binary_accuracy: 0.9048 - val_loss: 0.2780\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7537 - binary_accuracy: 0.9066 - loss: 0.2746 - val_auc: 0.7719 - val_binary_accuracy: 0.9069 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9076 - loss: 0.2687 - val_auc: 0.7793 - val_binary_accuracy: 0.9079 - val_loss: 0.2671\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9080 - loss: 0.2668 - val_auc: 0.7884 - val_binary_accuracy: 0.9081 - val_loss: 0.2649\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9077 - loss: 0.2653 - val_auc: 0.7904 - val_binary_accuracy: 0.9081 - val_loss: 0.2648\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.7916 - val_binary_accuracy: 0.9076 - val_loss: 0.2650\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9088 - loss: 0.2633 - val_auc: 0.7922 - val_binary_accuracy: 0.9082 - val_loss: 0.2649\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.7924 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.7927 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9094 - loss: 0.2619 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2647\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7690 - binary_accuracy: 0.9086 - loss: 0.2704\n",
            "Fold 4 Metrics: Loss = 0.2647, Accuracy = 0.9085, AUC = 0.7923\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5539 - binary_accuracy: 0.9038 - loss: 0.3430 - val_auc: 0.7328 - val_binary_accuracy: 0.9044 - val_loss: 0.2860\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7154 - binary_accuracy: 0.9040 - loss: 0.2896 - val_auc: 0.7559 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7375 - binary_accuracy: 0.9040 - loss: 0.2833 - val_auc: 0.7601 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7402 - binary_accuracy: 0.9040 - loss: 0.2814 - val_auc: 0.7622 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7418 - binary_accuracy: 0.9040 - loss: 0.2806 - val_auc: 0.7629 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7433 - binary_accuracy: 0.9040 - loss: 0.2801 - val_auc: 0.7624 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7432 - binary_accuracy: 0.9040 - loss: 0.2796 - val_auc: 0.7623 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7446 - binary_accuracy: 0.9040 - loss: 0.2793 - val_auc: 0.7618 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7443 - binary_accuracy: 0.9040 - loss: 0.2790 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7459 - binary_accuracy: 0.9040 - loss: 0.2787 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7784 - binary_accuracy: 0.9013 - loss: 0.2666\n",
            "Fold 5 Metrics: Loss = 0.2681, Accuracy = 0.9044, AUC = 0.7615\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2680\n",
            "Average Accuracy: 0.9051\n",
            "Average AUC: 0.7788\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 5, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7006 - binary_accuracy: 0.9069 - loss: 0.2901 - val_auc: 0.7626 - val_binary_accuracy: 0.9044 - val_loss: 0.2774\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9069 - loss: 0.2667 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9069 - loss: 0.2631 - val_auc: 0.7772 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2752\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9069 - loss: 0.2609 - val_auc: 0.7797 - val_binary_accuracy: 0.9044 - val_loss: 0.2744\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9069 - loss: 0.2604 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9069 - loss: 0.2597 - val_auc: 0.7809 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9069 - loss: 0.2593 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9069 - loss: 0.2588 - val_auc: 0.7823 - val_binary_accuracy: 0.9044 - val_loss: 0.2702\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7835 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7794 - binary_accuracy: 0.9084 - loss: 0.2645\n",
            "Fold 1 Metrics: Loss = 0.2700, Accuracy = 0.9044, AUC = 0.7835\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6584 - binary_accuracy: 0.8835 - loss: 0.3277 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9037 - loss: 0.2734 - val_auc: 0.7959 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9029 - loss: 0.2712 - val_auc: 0.7965 - val_binary_accuracy: 0.9054 - val_loss: 0.2647\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9029 - loss: 0.2694 - val_auc: 0.8010 - val_binary_accuracy: 0.9042 - val_loss: 0.2626\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9039 - loss: 0.2668 - val_auc: 0.8040 - val_binary_accuracy: 0.9044 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9048 - loss: 0.2661 - val_auc: 0.8045 - val_binary_accuracy: 0.9056 - val_loss: 0.2601\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9058 - loss: 0.2650 - val_auc: 0.8053 - val_binary_accuracy: 0.9054 - val_loss: 0.2596\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9056 - loss: 0.2646 - val_auc: 0.8052 - val_binary_accuracy: 0.9054 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9064 - loss: 0.2643 - val_auc: 0.8047 - val_binary_accuracy: 0.9053 - val_loss: 0.2598\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9056 - loss: 0.2631 - val_auc: 0.8056 - val_binary_accuracy: 0.9051 - val_loss: 0.2600\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8100 - binary_accuracy: 0.9096 - loss: 0.2494\n",
            "Fold 2 Metrics: Loss = 0.2600, Accuracy = 0.9051, AUC = 0.8056\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5811 - binary_accuracy: 0.8507 - loss: 0.3665 - val_auc: 0.7571 - val_binary_accuracy: 0.9042 - val_loss: 0.2802\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9051 - loss: 0.2753 - val_auc: 0.7719 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7639 - binary_accuracy: 0.9051 - loss: 0.2722 - val_auc: 0.7703 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9051 - loss: 0.2710 - val_auc: 0.7728 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9051 - loss: 0.2694 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9051 - loss: 0.2688 - val_auc: 0.7819 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9051 - loss: 0.2689 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9051 - loss: 0.2668 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7826 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7771 - binary_accuracy: 0.9046 - loss: 0.2683\n",
            "Fold 3 Metrics: Loss = 0.2677, Accuracy = 0.9042, AUC = 0.7826\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6636 - binary_accuracy: 0.8729 - loss: 0.3319 - val_auc: 0.7745 - val_binary_accuracy: 0.9056 - val_loss: 0.2709\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9052 - loss: 0.2702 - val_auc: 0.7851 - val_binary_accuracy: 0.9073 - val_loss: 0.2644\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9067 - loss: 0.2659 - val_auc: 0.7946 - val_binary_accuracy: 0.9070 - val_loss: 0.2613\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2639 - val_auc: 0.7966 - val_binary_accuracy: 0.9081 - val_loss: 0.2593\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9081 - loss: 0.2626 - val_auc: 0.7977 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2615 - val_auc: 0.7975 - val_binary_accuracy: 0.9090 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9096 - loss: 0.2602 - val_auc: 0.7985 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9095 - loss: 0.2599 - val_auc: 0.7996 - val_binary_accuracy: 0.9079 - val_loss: 0.2582\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9101 - loss: 0.2590 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.8006 - val_binary_accuracy: 0.9075 - val_loss: 0.2589\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7793 - binary_accuracy: 0.9075 - loss: 0.2657\n",
            "Fold 4 Metrics: Loss = 0.2589, Accuracy = 0.9075, AUC = 0.8006\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6761 - binary_accuracy: 0.8716 - loss: 0.3302 - val_auc: 0.7795 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7591 - binary_accuracy: 0.9040 - loss: 0.2769 - val_auc: 0.7820 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7626 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7655 - binary_accuracy: 0.9040 - loss: 0.2747 - val_auc: 0.7855 - val_binary_accuracy: 0.9044 - val_loss: 0.2634\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7874 - val_binary_accuracy: 0.9044 - val_loss: 0.2628\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9040 - loss: 0.2734 - val_auc: 0.7876 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9040 - loss: 0.2730 - val_auc: 0.7910 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9040 - loss: 0.2724 - val_auc: 0.7899 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9040 - loss: 0.2716 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2613\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8038 - binary_accuracy: 0.9013 - loss: 0.2577\n",
            "Fold 5 Metrics: Loss = 0.2613, Accuracy = 0.9044, AUC = 0.7889\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2636\n",
            "Average Accuracy: 0.9051\n",
            "Average AUC: 0.7923\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 5, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7032 - binary_accuracy: 0.8961 - loss: 0.2951 - val_auc: 0.7677 - val_binary_accuracy: 0.9048 - val_loss: 0.2721\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9072 - loss: 0.2615 - val_auc: 0.7749 - val_binary_accuracy: 0.9060 - val_loss: 0.2691\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9086 - loss: 0.2590 - val_auc: 0.7809 - val_binary_accuracy: 0.9081 - val_loss: 0.2654\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9092 - loss: 0.2572 - val_auc: 0.7846 - val_binary_accuracy: 0.9096 - val_loss: 0.2629\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9102 - loss: 0.2556 - val_auc: 0.7846 - val_binary_accuracy: 0.9090 - val_loss: 0.2627\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9115 - loss: 0.2539 - val_auc: 0.7869 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9123 - loss: 0.2530 - val_auc: 0.7871 - val_binary_accuracy: 0.9057 - val_loss: 0.2636\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9114 - loss: 0.2519 - val_auc: 0.7886 - val_binary_accuracy: 0.9068 - val_loss: 0.2628\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9111 - loss: 0.2516 - val_auc: 0.7897 - val_binary_accuracy: 0.9053 - val_loss: 0.2629\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9111 - loss: 0.2506 - val_auc: 0.7914 - val_binary_accuracy: 0.9054 - val_loss: 0.2625\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7902 - binary_accuracy: 0.9097 - loss: 0.2552\n",
            "Fold 1 Metrics: Loss = 0.2625, Accuracy = 0.9054, AUC = 0.7914\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6903 - binary_accuracy: 0.8854 - loss: 0.3112 - val_auc: 0.7976 - val_binary_accuracy: 0.9063 - val_loss: 0.2643\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.8024 - val_binary_accuracy: 0.9066 - val_loss: 0.2615\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9061 - loss: 0.2676 - val_auc: 0.8006 - val_binary_accuracy: 0.9069 - val_loss: 0.2632\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9064 - loss: 0.2669 - val_auc: 0.8002 - val_binary_accuracy: 0.9071 - val_loss: 0.2654\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9066 - loss: 0.2657 - val_auc: 0.8015 - val_binary_accuracy: 0.9072 - val_loss: 0.2643\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8034 - val_binary_accuracy: 0.9072 - val_loss: 0.2642\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9074 - loss: 0.2638 - val_auc: 0.8030 - val_binary_accuracy: 0.9073 - val_loss: 0.2629\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9070 - loss: 0.2635 - val_auc: 0.8028 - val_binary_accuracy: 0.9075 - val_loss: 0.2632\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9086 - loss: 0.2625 - val_auc: 0.8054 - val_binary_accuracy: 0.9071 - val_loss: 0.2627\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9079 - loss: 0.2617 - val_auc: 0.8055 - val_binary_accuracy: 0.9066 - val_loss: 0.2619\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9105 - loss: 0.2510\n",
            "Fold 2 Metrics: Loss = 0.2619, Accuracy = 0.9066, AUC = 0.8055\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7101 - binary_accuracy: 0.9050 - loss: 0.2927 - val_auc: 0.7822 - val_binary_accuracy: 0.9047 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9048 - loss: 0.2738 - val_auc: 0.7888 - val_binary_accuracy: 0.9054 - val_loss: 0.2690\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7666 - binary_accuracy: 0.9057 - loss: 0.2702 - val_auc: 0.7911 - val_binary_accuracy: 0.9053 - val_loss: 0.2658\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9062 - loss: 0.2679 - val_auc: 0.7912 - val_binary_accuracy: 0.9050 - val_loss: 0.2677\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9076 - loss: 0.2678 - val_auc: 0.7939 - val_binary_accuracy: 0.9051 - val_loss: 0.2667\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9077 - loss: 0.2673 - val_auc: 0.7965 - val_binary_accuracy: 0.9056 - val_loss: 0.2669\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9078 - loss: 0.2671 - val_auc: 0.7985 - val_binary_accuracy: 0.9050 - val_loss: 0.2650\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7982 - val_binary_accuracy: 0.9053 - val_loss: 0.2640\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7990 - val_binary_accuracy: 0.9060 - val_loss: 0.2628\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.7984 - val_binary_accuracy: 0.9068 - val_loss: 0.2609\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7910 - binary_accuracy: 0.9071 - loss: 0.2620\n",
            "Fold 3 Metrics: Loss = 0.2609, Accuracy = 0.9068, AUC = 0.7984\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6462 - binary_accuracy: 0.8846 - loss: 0.3234 - val_auc: 0.7892 - val_binary_accuracy: 0.9051 - val_loss: 0.2630\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9048 - loss: 0.2695 - val_auc: 0.7938 - val_binary_accuracy: 0.9063 - val_loss: 0.2610\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9071 - loss: 0.2671 - val_auc: 0.7968 - val_binary_accuracy: 0.9066 - val_loss: 0.2605\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9065 - loss: 0.2655 - val_auc: 0.7995 - val_binary_accuracy: 0.9081 - val_loss: 0.2593\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9082 - loss: 0.2636 - val_auc: 0.7995 - val_binary_accuracy: 0.9072 - val_loss: 0.2600\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9082 - loss: 0.2631 - val_auc: 0.8012 - val_binary_accuracy: 0.9075 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8026 - val_binary_accuracy: 0.9081 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9094 - loss: 0.2609 - val_auc: 0.8039 - val_binary_accuracy: 0.9078 - val_loss: 0.2571\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9095 - loss: 0.2605 - val_auc: 0.8058 - val_binary_accuracy: 0.9091 - val_loss: 0.2566\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9097 - loss: 0.2601 - val_auc: 0.8040 - val_binary_accuracy: 0.9087 - val_loss: 0.2566\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7852 - binary_accuracy: 0.9090 - loss: 0.2631\n",
            "Fold 4 Metrics: Loss = 0.2566, Accuracy = 0.9087, AUC = 0.8040\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6929 - binary_accuracy: 0.9040 - loss: 0.2997 - val_auc: 0.7949 - val_binary_accuracy: 0.9063 - val_loss: 0.2659\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9044 - loss: 0.2725 - val_auc: 0.7987 - val_binary_accuracy: 0.9079 - val_loss: 0.2643\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.8001 - val_binary_accuracy: 0.9070 - val_loss: 0.2618\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9055 - loss: 0.2680 - val_auc: 0.8014 - val_binary_accuracy: 0.9087 - val_loss: 0.2601\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9066 - loss: 0.2669 - val_auc: 0.8017 - val_binary_accuracy: 0.9091 - val_loss: 0.2588\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9079 - loss: 0.2657 - val_auc: 0.8008 - val_binary_accuracy: 0.9098 - val_loss: 0.2579\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9080 - loss: 0.2648 - val_auc: 0.8002 - val_binary_accuracy: 0.9100 - val_loss: 0.2567\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9092 - loss: 0.2636 - val_auc: 0.8027 - val_binary_accuracy: 0.9100 - val_loss: 0.2556\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9101 - loss: 0.2626 - val_auc: 0.8026 - val_binary_accuracy: 0.9098 - val_loss: 0.2551\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9101 - loss: 0.2623 - val_auc: 0.8028 - val_binary_accuracy: 0.9098 - val_loss: 0.2546\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8165 - binary_accuracy: 0.9080 - loss: 0.2513\n",
            "Fold 5 Metrics: Loss = 0.2546, Accuracy = 0.9098, AUC = 0.8028\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2593\n",
            "Average Accuracy: 0.9075\n",
            "Average AUC: 0.8004\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 5, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6891 - binary_accuracy: 0.8898 - loss: 0.2983 - val_auc: 0.7726 - val_binary_accuracy: 0.9072 - val_loss: 0.2803\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9075 - loss: 0.2651 - val_auc: 0.7823 - val_binary_accuracy: 0.9087 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9087 - loss: 0.2590 - val_auc: 0.7844 - val_binary_accuracy: 0.9091 - val_loss: 0.2642\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9106 - loss: 0.2564 - val_auc: 0.7864 - val_binary_accuracy: 0.9096 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9111 - loss: 0.2539 - val_auc: 0.7872 - val_binary_accuracy: 0.9090 - val_loss: 0.2619\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9119 - loss: 0.2524 - val_auc: 0.7862 - val_binary_accuracy: 0.9094 - val_loss: 0.2626\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9129 - loss: 0.2518 - val_auc: 0.7882 - val_binary_accuracy: 0.9045 - val_loss: 0.2642\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9125 - loss: 0.2509 - val_auc: 0.7905 - val_binary_accuracy: 0.9073 - val_loss: 0.2626\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9136 - loss: 0.2506 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2647\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9107 - loss: 0.2519 - val_auc: 0.7902 - val_binary_accuracy: 0.9075 - val_loss: 0.2624\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7858 - binary_accuracy: 0.9106 - loss: 0.2559\n",
            "Fold 1 Metrics: Loss = 0.2624, Accuracy = 0.9075, AUC = 0.7902\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7181 - binary_accuracy: 0.9023 - loss: 0.2955 - val_auc: 0.7961 - val_binary_accuracy: 0.9053 - val_loss: 0.2736\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9028 - loss: 0.2721 - val_auc: 0.8051 - val_binary_accuracy: 0.9068 - val_loss: 0.2648\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9057 - loss: 0.2683 - val_auc: 0.8043 - val_binary_accuracy: 0.9084 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9067 - loss: 0.2666 - val_auc: 0.8036 - val_binary_accuracy: 0.9079 - val_loss: 0.2644\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9073 - loss: 0.2655 - val_auc: 0.8086 - val_binary_accuracy: 0.9081 - val_loss: 0.2640\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9073 - loss: 0.2638 - val_auc: 0.8096 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9073 - loss: 0.2626 - val_auc: 0.8102 - val_binary_accuracy: 0.9088 - val_loss: 0.2659\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9079 - loss: 0.2626 - val_auc: 0.8104 - val_binary_accuracy: 0.9088 - val_loss: 0.2678\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9085 - loss: 0.2625 - val_auc: 0.8103 - val_binary_accuracy: 0.9081 - val_loss: 0.2677\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9080 - loss: 0.2617 - val_auc: 0.8116 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8177 - binary_accuracy: 0.9127 - loss: 0.2547\n",
            "Fold 2 Metrics: Loss = 0.2636, Accuracy = 0.9082, AUC = 0.8116\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7121 - binary_accuracy: 0.8868 - loss: 0.2975 - val_auc: 0.7902 - val_binary_accuracy: 0.9047 - val_loss: 0.2664\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7666 - binary_accuracy: 0.9064 - loss: 0.2697 - val_auc: 0.7958 - val_binary_accuracy: 0.9066 - val_loss: 0.2655\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9070 - loss: 0.2679 - val_auc: 0.7986 - val_binary_accuracy: 0.9063 - val_loss: 0.2666\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9073 - loss: 0.2676 - val_auc: 0.7986 - val_binary_accuracy: 0.9081 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9070 - loss: 0.2690 - val_auc: 0.8012 - val_binary_accuracy: 0.9103 - val_loss: 0.2637\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9081 - loss: 0.2668 - val_auc: 0.8016 - val_binary_accuracy: 0.9093 - val_loss: 0.2650\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9078 - loss: 0.2664 - val_auc: 0.8017 - val_binary_accuracy: 0.9096 - val_loss: 0.2656\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.8025 - val_binary_accuracy: 0.9071 - val_loss: 0.2665\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9085 - loss: 0.2641 - val_auc: 0.8029 - val_binary_accuracy: 0.9057 - val_loss: 0.2660\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8027 - val_binary_accuracy: 0.9079 - val_loss: 0.2643\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7951 - binary_accuracy: 0.9082 - loss: 0.2656\n",
            "Fold 3 Metrics: Loss = 0.2643, Accuracy = 0.9079, AUC = 0.8027\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7232 - binary_accuracy: 0.8964 - loss: 0.2925 - val_auc: 0.7937 - val_binary_accuracy: 0.9064 - val_loss: 0.2670\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.7957 - val_binary_accuracy: 0.9056 - val_loss: 0.2658\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.7972 - val_binary_accuracy: 0.9050 - val_loss: 0.2676\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9081 - loss: 0.2639 - val_auc: 0.7979 - val_binary_accuracy: 0.9075 - val_loss: 0.2663\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7977 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9093 - loss: 0.2621 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2655\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9095 - loss: 0.2618 - val_auc: 0.7987 - val_binary_accuracy: 0.9082 - val_loss: 0.2629\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9099 - loss: 0.2612 - val_auc: 0.8001 - val_binary_accuracy: 0.9100 - val_loss: 0.2613\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2607 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2627\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9094 - loss: 0.2601 - val_auc: 0.8002 - val_binary_accuracy: 0.9095 - val_loss: 0.2606\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7807 - binary_accuracy: 0.9091 - loss: 0.2699\n",
            "Fold 4 Metrics: Loss = 0.2606, Accuracy = 0.9095, AUC = 0.8002\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7040 - binary_accuracy: 0.9036 - loss: 0.2973 - val_auc: 0.7878 - val_binary_accuracy: 0.9067 - val_loss: 0.2627\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9041 - loss: 0.2760 - val_auc: 0.7976 - val_binary_accuracy: 0.9075 - val_loss: 0.2586\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9063 - loss: 0.2704 - val_auc: 0.8002 - val_binary_accuracy: 0.9095 - val_loss: 0.2600\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9072 - loss: 0.2676 - val_auc: 0.8030 - val_binary_accuracy: 0.9101 - val_loss: 0.2597\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9077 - loss: 0.2663 - val_auc: 0.8040 - val_binary_accuracy: 0.9088 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8047 - val_binary_accuracy: 0.9103 - val_loss: 0.2597\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9083 - loss: 0.2642 - val_auc: 0.8050 - val_binary_accuracy: 0.9104 - val_loss: 0.2570\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9092 - loss: 0.2633 - val_auc: 0.8059 - val_binary_accuracy: 0.9107 - val_loss: 0.2574\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9081 - loss: 0.2634 - val_auc: 0.8061 - val_binary_accuracy: 0.9107 - val_loss: 0.2583\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9080 - loss: 0.2637 - val_auc: 0.8035 - val_binary_accuracy: 0.9094 - val_loss: 0.2575\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9094 - loss: 0.2534\n",
            "Fold 5 Metrics: Loss = 0.2575, Accuracy = 0.9094, AUC = 0.8035\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2617\n",
            "Average Accuracy: 0.9085\n",
            "Average AUC: 0.8017\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 5, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6891 - binary_accuracy: 0.8859 - loss: 0.3075 - val_auc: 0.7797 - val_binary_accuracy: 0.9102 - val_loss: 0.2736\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9080 - loss: 0.2624 - val_auc: 0.7868 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9064 - loss: 0.2611 - val_auc: 0.7890 - val_binary_accuracy: 0.9103 - val_loss: 0.2617\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9092 - loss: 0.2579 - val_auc: 0.7894 - val_binary_accuracy: 0.9119 - val_loss: 0.2606\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9115 - loss: 0.2552 - val_auc: 0.7902 - val_binary_accuracy: 0.9103 - val_loss: 0.2633\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9114 - loss: 0.2541 - val_auc: 0.7910 - val_binary_accuracy: 0.9094 - val_loss: 0.2605\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9092 - loss: 0.2569 - val_auc: 0.7927 - val_binary_accuracy: 0.9118 - val_loss: 0.2637\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9124 - loss: 0.2555 - val_auc: 0.7904 - val_binary_accuracy: 0.9066 - val_loss: 0.2643\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9109 - loss: 0.2542 - val_auc: 0.7875 - val_binary_accuracy: 0.9088 - val_loss: 0.2627\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9115 - loss: 0.2561 - val_auc: 0.7898 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7844 - binary_accuracy: 0.9113 - loss: 0.2558\n",
            "Fold 1 Metrics: Loss = 0.2631, Accuracy = 0.9082, AUC = 0.7898\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6904 - binary_accuracy: 0.8845 - loss: 0.3209 - val_auc: 0.8003 - val_binary_accuracy: 0.9060 - val_loss: 0.2667\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9040 - loss: 0.2722 - val_auc: 0.8018 - val_binary_accuracy: 0.9081 - val_loss: 0.2638\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9057 - loss: 0.2689 - val_auc: 0.8025 - val_binary_accuracy: 0.9081 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9071 - loss: 0.2676 - val_auc: 0.8006 - val_binary_accuracy: 0.9078 - val_loss: 0.2662\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9071 - loss: 0.2675 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2649\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9057 - loss: 0.2692 - val_auc: 0.8060 - val_binary_accuracy: 0.9066 - val_loss: 0.2660\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9050 - loss: 0.2675 - val_auc: 0.7934 - val_binary_accuracy: 0.9088 - val_loss: 0.2690\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9057 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9096 - val_loss: 0.2650\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9070 - loss: 0.2656 - val_auc: 0.7989 - val_binary_accuracy: 0.9091 - val_loss: 0.2674\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9078 - loss: 0.2650 - val_auc: 0.8125 - val_binary_accuracy: 0.9094 - val_loss: 0.2620\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8172 - binary_accuracy: 0.9135 - loss: 0.2530\n",
            "Fold 2 Metrics: Loss = 0.2620, Accuracy = 0.9094, AUC = 0.8125\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6702 - binary_accuracy: 0.8862 - loss: 0.3217 - val_auc: 0.7878 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9043 - loss: 0.2728 - val_auc: 0.7924 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7658 - binary_accuracy: 0.9055 - loss: 0.2699 - val_auc: 0.7955 - val_binary_accuracy: 0.9078 - val_loss: 0.2668\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9063 - loss: 0.2700 - val_auc: 0.7952 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9053 - loss: 0.2719 - val_auc: 0.7937 - val_binary_accuracy: 0.9042 - val_loss: 0.2637\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9053 - loss: 0.2716 - val_auc: 0.7965 - val_binary_accuracy: 0.9093 - val_loss: 0.2663\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9075 - loss: 0.2690 - val_auc: 0.7963 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7640 - binary_accuracy: 0.9072 - loss: 0.2703 - val_auc: 0.7961 - val_binary_accuracy: 0.9090 - val_loss: 0.2607\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7630 - binary_accuracy: 0.9089 - loss: 0.2683 - val_auc: 0.7968 - val_binary_accuracy: 0.9066 - val_loss: 0.2639\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9077 - loss: 0.2685 - val_auc: 0.7962 - val_binary_accuracy: 0.9104 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7872 - binary_accuracy: 0.9115 - loss: 0.2634\n",
            "Fold 3 Metrics: Loss = 0.2635, Accuracy = 0.9104, AUC = 0.7962\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6836 - binary_accuracy: 0.9007 - loss: 0.3080 - val_auc: 0.7859 - val_binary_accuracy: 0.9056 - val_loss: 0.2716\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9044 - loss: 0.2734 - val_auc: 0.7899 - val_binary_accuracy: 0.9032 - val_loss: 0.2683\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9053 - loss: 0.2704 - val_auc: 0.7958 - val_binary_accuracy: 0.9087 - val_loss: 0.2708\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9059 - loss: 0.2687 - val_auc: 0.7993 - val_binary_accuracy: 0.8992 - val_loss: 0.2815\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9067 - loss: 0.2706 - val_auc: 0.7954 - val_binary_accuracy: 0.9085 - val_loss: 0.2641\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9078 - loss: 0.2652 - val_auc: 0.7958 - val_binary_accuracy: 0.9072 - val_loss: 0.2635\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9092 - loss: 0.2649 - val_auc: 0.7956 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9088 - loss: 0.2632 - val_auc: 0.7937 - val_binary_accuracy: 0.9051 - val_loss: 0.2675\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9092 - loss: 0.2638 - val_auc: 0.7939 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9088 - loss: 0.2671 - val_auc: 0.7916 - val_binary_accuracy: 0.9084 - val_loss: 0.2619\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7694 - binary_accuracy: 0.9085 - loss: 0.2711\n",
            "Fold 4 Metrics: Loss = 0.2619, Accuracy = 0.9084, AUC = 0.7916\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6762 - binary_accuracy: 0.8851 - loss: 0.3195 - val_auc: 0.7930 - val_binary_accuracy: 0.9084 - val_loss: 0.2611\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7539 - binary_accuracy: 0.9025 - loss: 0.2790 - val_auc: 0.7988 - val_binary_accuracy: 0.9075 - val_loss: 0.2572\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9053 - loss: 0.2720 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9058 - loss: 0.2698 - val_auc: 0.8034 - val_binary_accuracy: 0.9097 - val_loss: 0.2588\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9063 - loss: 0.2684 - val_auc: 0.8045 - val_binary_accuracy: 0.9104 - val_loss: 0.2573\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9067 - loss: 0.2668 - val_auc: 0.8047 - val_binary_accuracy: 0.9098 - val_loss: 0.2571\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9097 - loss: 0.2655 - val_auc: 0.8072 - val_binary_accuracy: 0.9044 - val_loss: 0.2556\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9072 - loss: 0.2654 - val_auc: 0.8057 - val_binary_accuracy: 0.9101 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9071 - loss: 0.2701 - val_auc: 0.8062 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9090 - loss: 0.2655 - val_auc: 0.8044 - val_binary_accuracy: 0.9098 - val_loss: 0.2548\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8136 - binary_accuracy: 0.9076 - loss: 0.2527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 3/3 [1:22:51<00:00, 1657.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 Metrics: Loss = 0.2548, Accuracy = 0.9098, AUC = 0.8044\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2610\n",
            "Average Accuracy: 0.9093\n",
            "Average AUC: 0.7989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# setting a seed\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# defining options\n",
        "hidden_layer_configs = [1,2,3,4,5]\n",
        "activation_config = ['relu', 'sigmoid', 'tanh']\n",
        "node_configs = [16, 32, 64, 128, 256]\n",
        "\n",
        "comparison_list = []\n",
        "comparison_df_new = pd.DataFrame()\n",
        "\n",
        "# training models\n",
        "with tf.device('/GPU:0'):\n",
        "    for activation in tqdm.tqdm(activation_config):\n",
        "        for hl in hidden_layer_configs:\n",
        "            for nodes in node_configs:\n",
        "                print(\"-\"*40)\n",
        "                print(f\"Performing training for: {activation, hl, nodes}\")\n",
        "                print(\"-\"*40)\n",
        "                # train model\n",
        "                fold_loss, fold_accuracies, fold_aucs, _ = k_fold_cross_validation(hl=hl, nodes=nodes, activation=activation, epochs = 10)\n",
        "                # store output\n",
        "                comparison_list.append((activation, hl, nodes, fold_loss, fold_accuracies, fold_aucs))\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_list)\n",
        "comparison_df.to_csv(\"/content/drive/MyDrive/Data Analytics/Assignments/Group Project/model_comparison_five_fold_strat.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "anByv4R4hb0V",
      "metadata": {
        "id": "anByv4R4hb0V"
      },
      "outputs": [],
      "source": [
        "comparison_df = pd.read_csv(\"/content/drive/MyDrive/Data Analytics/Assignments/Group Project/model_comparison_five_fold.csv\")\n",
        "comparison_df.columns = [\"act\", \"hl\", \"nodes\", \"loss\", \"acc\", \"auc\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VmycvIWdhuWE",
      "metadata": {
        "id": "VmycvIWdhuWE"
      },
      "outputs": [],
      "source": [
        "comparison_df[\"avg_loss\"] = comparison_df[\"loss\"].apply(lambda x: np.mean(ast.literal_eval(x)))\n",
        "comparison_df[\"avg_acc\"] = comparison_df[\"acc\"].apply(lambda x: np.mean(ast.literal_eval(x)))\n",
        "comparison_df[\"avg_auc\"] = comparison_df[\"auc\"].apply(lambda x: np.mean(ast.literal_eval(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jVC4AixTiKlo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "jVC4AixTiKlo",
        "outputId": "7e9539e1-d29e-408d-ec9e-2aca2190ec4a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"act\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"relu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nodes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85,\n        \"min\": 64,\n        \"max\": 256,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0.31858211755752563, 0.36027613282203674, 0.25885921716690063, 0.25837039947509766, 0.2512544095516205]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0.9083800315856934, 0.8490705490112305, 0.9091177582740784, 0.9052678346633911, 0.9107274413108826]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0.7873588800430298, 0.81210857629776, 0.7963587045669556, 0.810806930065155, 0.8128728270530701]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007085299939217751,\n        \"min\": 0.2765244722366333,\n        \"max\": 0.29502456188201903,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2894684553146362\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0021013830792327172,\n        \"min\": 0.8942399024963379,\n        \"max\": 0.8998175263404846,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8965127229690552\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007605461845128445,\n        \"min\": 0.8024112820625305,\n        \"max\": 0.8039302110671998,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8039011836051941\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e92f3c0a-7377-478e-960a-562f7279b0d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act</th>\n",
              "      <th>hl</th>\n",
              "      <th>nodes</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>auc</th>\n",
              "      <th>avg_loss</th>\n",
              "      <th>avg_acc</th>\n",
              "      <th>avg_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>relu</td>\n",
              "      <td>1</td>\n",
              "      <td>128</td>\n",
              "      <td>[0.30871862173080444, 0.343106210231781, 0.261...</td>\n",
              "      <td>[0.9092652797698975, 0.8623487949371338, 0.909...</td>\n",
              "      <td>[0.7868945002555847, 0.8111099600791931, 0.796...</td>\n",
              "      <td>0.295025</td>\n",
              "      <td>0.894240</td>\n",
              "      <td>0.803930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relu</td>\n",
              "      <td>1</td>\n",
              "      <td>256</td>\n",
              "      <td>[0.31858211755752563, 0.36027613282203674, 0.2...</td>\n",
              "      <td>[0.9083800315856934, 0.8490705490112305, 0.909...</td>\n",
              "      <td>[0.7873588800430298, 0.81210857629776, 0.79635...</td>\n",
              "      <td>0.289468</td>\n",
              "      <td>0.896513</td>\n",
              "      <td>0.803901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>relu</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>[0.3157957196235657, 0.36118727922439575, 0.25...</td>\n",
              "      <td>[0.9079374670982361, 0.8591029644012451, 0.909...</td>\n",
              "      <td>[0.7880730032920837, 0.809856116771698, 0.7958...</td>\n",
              "      <td>0.292142</td>\n",
              "      <td>0.897191</td>\n",
              "      <td>0.802667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>relu</td>\n",
              "      <td>2</td>\n",
              "      <td>256</td>\n",
              "      <td>[0.26953381299972534, 0.33885297179222107, 0.2...</td>\n",
              "      <td>[0.9117733836174011, 0.8619061708450317, 0.909...</td>\n",
              "      <td>[0.7870328426361084, 0.8068638443946838, 0.797...</td>\n",
              "      <td>0.276524</td>\n",
              "      <td>0.899818</td>\n",
              "      <td>0.802533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>relu</td>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>[0.295051246881485, 0.37400567531585693, 0.262...</td>\n",
              "      <td>[0.9097079038619995, 0.8436116576194763, 0.908...</td>\n",
              "      <td>[0.7852222919464111, 0.811111330986023, 0.7942...</td>\n",
              "      <td>0.289289</td>\n",
              "      <td>0.895421</td>\n",
              "      <td>0.802411</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e92f3c0a-7377-478e-960a-562f7279b0d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e92f3c0a-7377-478e-960a-562f7279b0d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e92f3c0a-7377-478e-960a-562f7279b0d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ea63e787-6130-4a6d-806d-d49d9f01dbf0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea63e787-6130-4a6d-806d-d49d9f01dbf0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ea63e787-6130-4a6d-806d-d49d9f01dbf0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    act  hl  nodes                                               loss  \\\n",
              "3  relu   1    128  [0.30871862173080444, 0.343106210231781, 0.261...   \n",
              "4  relu   1    256  [0.31858211755752563, 0.36027613282203674, 0.2...   \n",
              "2  relu   1     64  [0.3157957196235657, 0.36118727922439575, 0.25...   \n",
              "9  relu   2    256  [0.26953381299972534, 0.33885297179222107, 0.2...   \n",
              "8  relu   2    128  [0.295051246881485, 0.37400567531585693, 0.262...   \n",
              "\n",
              "                                                 acc  \\\n",
              "3  [0.9092652797698975, 0.8623487949371338, 0.909...   \n",
              "4  [0.9083800315856934, 0.8490705490112305, 0.909...   \n",
              "2  [0.9079374670982361, 0.8591029644012451, 0.909...   \n",
              "9  [0.9117733836174011, 0.8619061708450317, 0.909...   \n",
              "8  [0.9097079038619995, 0.8436116576194763, 0.908...   \n",
              "\n",
              "                                                 auc  avg_loss   avg_acc  \\\n",
              "3  [0.7868945002555847, 0.8111099600791931, 0.796...  0.295025  0.894240   \n",
              "4  [0.7873588800430298, 0.81210857629776, 0.79635...  0.289468  0.896513   \n",
              "2  [0.7880730032920837, 0.809856116771698, 0.7958...  0.292142  0.897191   \n",
              "9  [0.7870328426361084, 0.8068638443946838, 0.797...  0.276524  0.899818   \n",
              "8  [0.7852222919464111, 0.811111330986023, 0.7942...  0.289289  0.895421   \n",
              "\n",
              "    avg_auc  \n",
              "3  0.803930  \n",
              "4  0.803901  \n",
              "2  0.802667  \n",
              "9  0.802533  \n",
              "8  0.802411  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df.sort_values(by = [\"avg_auc\", \"avg_acc\"], ascending = [False, False]).head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8djlZJci05oD",
      "metadata": {
        "id": "8djlZJci05oD"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "099hWGV8z_NF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "099hWGV8z_NF",
        "outputId": "89052de1-b832-445f-a1c2-e0f3e3ec970c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m339/339\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6722 - binary_accuracy: 0.8948 - loss: 0.3926 - val_auc: 0.7926 - val_binary_accuracy: 0.9048 - val_loss: 0.2645\n",
            "Epoch 2/10\n",
            "\u001b[1m339/339\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7734 - binary_accuracy: 0.9055 - loss: 0.2723 - val_auc: 0.7957 - val_binary_accuracy: 0.9037 - val_loss: 0.2633\n",
            "Epoch 3/10\n",
            "\u001b[1m339/339\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9058 - loss: 0.2707 - val_auc: 0.7962 - val_binary_accuracy: 0.9067 - val_loss: 0.2592\n",
            "Epoch 4/10\n",
            "\u001b[1m339/339\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9061 - loss: 0.2702 - val_auc: 0.7970 - val_binary_accuracy: 0.9086 - val_loss: 0.2582\n",
            "Epoch 5/10\n",
            "\u001b[1m339/339\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9070 - loss: 0.2697 - val_auc: 0.7975 - val_binary_accuracy: 0.9094 - val_loss: 0.2597\n",
            "Epoch 6/10\n",
            "\u001b[1m339/339\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9066 - loss: 0.2692 - val_auc: 0.7975 - val_binary_accuracy: 0.9095 - val_loss: 0.2614\n",
            "Epoch 7/10\n",
            "\u001b[1m339/339\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9072 - loss: 0.2686 - val_auc: 0.7984 - val_binary_accuracy: 0.9092 - val_loss: 0.2582\n",
            "Epoch 8/10\n",
            "\u001b[1m339/339\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9065 - loss: 0.2682 - val_auc: 0.7979 - val_binary_accuracy: 0.9097 - val_loss: 0.2620\n",
            "Epoch 9/10\n",
            "\u001b[1m339/339\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9071 - loss: 0.2686 - val_auc: 0.7985 - val_binary_accuracy: 0.9096 - val_loss: 0.2618\n",
            "Epoch 10/10\n",
            "\u001b[1m339/339\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9080 - loss: 0.2684 - val_auc: 0.7988 - val_binary_accuracy: 0.9094 - val_loss: 0.2606\n",
            "\u001b[1m354/354\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9054 - loss: 0.2713\n"
          ]
        }
      ],
      "source": [
        "# setting a seed\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# confusion matrix\n",
        "best_model, _, _ = train_and_evaluate_model(hl = 1, nodes = 128, activation = \"relu\", epochs = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C8eXy1kl1JHA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8eXy1kl1JHA",
        "outputId": "cb0f356a-f9ed-471c-e88e-a162fb616b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m354/354\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        }
      ],
      "source": [
        "pred_probs = best_model.predict(test_x)\n",
        "y_pred = (pred_probs > 0.5).astype(int)   # convert probabilities to 0/1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KJlC_Hkyc6z7",
      "metadata": {
        "id": "KJlC_Hkyc6z7"
      },
      "source": [
        "### **Confusion matrix**\n",
        "\n",
        "*I am not sure, if that is the right way to evaluate it*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YsY-yaAP1ZY4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsY-yaAP1ZY4",
        "outputId": "f4ba9312-ce18-4d9b-dbb2-2ab90d6717df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[10170    46]\n",
            " [  978   103]]\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(test_y, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qDmVlbUk55H8",
      "metadata": {
        "id": "qDmVlbUk55H8"
      },
      "source": [
        "# Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PU1dLc8tOpDv",
      "metadata": {
        "id": "PU1dLc8tOpDv"
      },
      "outputs": [],
      "source": [
        "evaluation = pd.DataFrame(pred_probs, test_y).reset_index()\n",
        "evaluation.columns = [\"outcome\", \"pred_prob\"]\n",
        "\n",
        "model_probs = np.linspace(0.025, 0.975, num = 20)\n",
        "true_probs = []\n",
        "\n",
        "for prob in model_probs:\n",
        "    true_probs.append(evaluation[(evaluation[\"pred_prob\"] >= prob -0.025) & (evaluation[\"pred_prob\"] <= prob + 0.025)][\"outcome\"].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b79YcRuXWCxu",
      "metadata": {
        "id": "b79YcRuXWCxu"
      },
      "source": [
        "There is no predicted probs above 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AbkHeuuDVlB9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "AbkHeuuDVlB9",
        "outputId": "4d3c66e3-9a38-40c6-b035-37d6bd0bef1e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_probs = np.linspace(0,1.01, num = 10)\n",
        "\n",
        "plt.plot(model_probs, true_probs, color = \"red\", marker='.', label = \"Model line\")\n",
        "plt.plot(plot_probs, plot_probs, alpha = 0.5, color = \"blue\", label = \"Ideal line\")\n",
        "plt.xlim(0,1)\n",
        "plt.ylim(0,1)\n",
        "#plt.axvspan(0.9, 1, alpha=0.1, label = \"No shots with prob > 0.9\", color = \"red\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Model Probability\")\n",
        "plt.ylabel(\"True Probability\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OAKQKJOWcV4E",
      "metadata": {
        "id": "OAKQKJOWcV4E"
      },
      "source": [
        "## Isometric regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "if5vt00o6GhD",
      "metadata": {
        "id": "if5vt00o6GhD"
      },
      "outputs": [],
      "source": [
        "f_X = football_df.drop(\"shot_outcome_encoded\", axis = 1)\n",
        "f_y = football_df[\"shot_outcome_encoded\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iGAzQ_k86GhD",
      "metadata": {
        "id": "iGAzQ_k86GhD"
      },
      "outputs": [],
      "source": [
        "# setting a seed\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# splitting the data\n",
        "f_train_x, f_test_x , f_train_y, f_test_y = train_test_split(\n",
        "    f_X, f_y,\n",
        "    test_size = 0.25,\n",
        "    random_state= 123,\n",
        "    stratify = y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WeezwtfN5_n-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeezwtfN5_n-",
        "outputId": "b4a65c86-61a3-4deb-a4ed-afa7277240dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking that both are the same\n",
        "sum(f_test_y == test_y.numpy()) == len(test_y.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2lURL85k6aQj",
      "metadata": {
        "id": "2lURL85k6aQj"
      },
      "outputs": [],
      "source": [
        "# comparing statsbomb and our expected goal probabilities\n",
        "test = pd.concat([f_test_x[\"shot_statsbomb_xg\"].reset_index(), pd.DataFrame(pred_probs).reset_index()], axis = 1, ignore_index=True).drop([0,2], axis = 1)\n",
        "test.columns = [\"shot_statsbomb_xg\", \"pred_prob\"]\n",
        "test[\"diff\"] = test[\"shot_statsbomb_xg\"] - test[\"pred_prob\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ie9x1trc7NDN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "Ie9x1trc7NDN",
        "outputId": "6146cfcd-35a3-4fe1-8f1a-8da2c58a0b23"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "f_i_r = sk_i.IsotonicRegression().fit(test[\"shot_statsbomb_xg\"], evaluation[\"outcome\"])\n",
        "i_r = sk_i.IsotonicRegression().fit(evaluation[\"pred_prob\"], evaluation[\"outcome\"])\n",
        "\n",
        "model_probs = np.linspace(0, 1, num=100)\n",
        "\n",
        "calibrated_probs = i_r.predict(model_probs)\n",
        "f_calibrated_probs = f_i_r.predict(model_probs)\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot([0, 1], [0, 1])\n",
        "\n",
        "plt.plot(model_probs, f_calibrated_probs, color='black', alpha = 0.3, label = \"Statsb. perf.\")\n",
        "plt.plot(model_probs, calibrated_probs, color='red', label = \"Model perf.\")\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel('Model probability')\n",
        "plt.ylabel('Calibrated probability')\n",
        "\n",
        "sns.despine()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fXcppND6-BxP",
      "metadata": {
        "id": "fXcppND6-BxP"
      },
      "source": [
        "## AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eqGunzpG7hI2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "eqGunzpG7hI2",
        "outputId": "4aeaffbb-ffbb-42e0-dbbc-bce1c3acc31c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC: 0.7993\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculate AUC\n",
        "auc = roc_auc_score(test_y, pred_probs)\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(test_y, pred_probs)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ct1Lf38D-HWy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "ct1Lf38D-HWy",
        "outputId": "1e6ef67a-5065-474f-fbf7-3f09d154c564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC: 0.8106\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAINCAYAAAB8nwY4AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAf7pJREFUeJzt3XdYFFcbBfCzdFCaQRAURY3Ye0ExBguKJUZjL1Fijb0bjQ07xm4So7Ebo8ESW+yxYGxRY+8Vu9gFkb57vz/mY2SlyOIuswvn9zz7ZGZ2ZvfdCbKHO3fuVQkhBIiIiIj0yEzpAoiIiCj7YcAgIiIivWPAICIiIr1jwCAiIiK9Y8AgIiIivWPAICIiIr1jwCAiIiK9Y8AgIiIivbNQuoCsptFo8OjRI9jb20OlUildDhERkckQQuDNmzfw8PCAmVn6bRQ5LmA8evQInp6eSpdBRERksu7fv48CBQqku0+OCxj29vYApJPj4OCgcDVERESmIzIyEp6envJ3aXpyXMBIuizi4ODAgEFERJQJGeliwE6eREREpHcMGERERKR3DBhERESkdzmuD0ZGCCGQmJgItVqtdClEpCBzc3NYWFjwlnaiTGDAeE98fDweP36M6OhopUshIiNgZ2cHd3d3WFlZKV0KkUlhwEhGo9EgLCwM5ubm8PDwgJWVFf9yIcqhhBCIj4/Hs2fPEBYWhmLFin1wYCEieocBI5n4+HhoNBp4enrCzs5O6XKISGG2trawtLTE3bt3ER8fDxsbG6VLIjIZjOOp4F8pRJSEvw+IMof/coiIiEjvGDCIiIhI7xgwiLLAvn37ULJkSd76bGQuX76MAgUK4O3bt0qXQpTtMGBkE8+ePUPv3r1RsGBBWFtbI1++fAgICMCRI0fkfby8vKBSqaBSqeQ7Zbp164ZXr16l+9rJj7Ozs0PZsmWxZMmSFPup1WrMmTMHZcuWhY2NDZydndGoUSOtGpLEx8dj+vTpKF++POzs7ODi4oKaNWti+fLlSEhISLMWIQQWLVoEHx8f5M6dG05OTqhSpQrmzp1r1LcWf/fddxgzZgzMzc21tsfExCBPnjxwcXFBXFxciuNUKhU2b96cYvs333yD5s2ba227efMmunTpggIFCsDa2hqFCxdG+/bt8d9//+nzo6Qwf/58eHl5wcbGBj4+Pjhx4sQHj5k7dy6KFy8OW1tbeHp6YvDgwYiNjZWf/+eff9C0aVN4eHikeQ6EEBg3bhzc3d1ha2sLf39/3LhxI8V+27dvh4+PD2xtbeHs7Kx13kqVKoXq1atj9uzZmfrsRJQOkcNEREQIACIiIiLFczExMeLy5csiJiZGgco+Tq1atYSPj4/Yv3+/uHPnjjh+/LiYOnWq2LJli7xPoUKFxMSJE8Xjx4/FgwcPxP79+8Wnn34qvv7663RfO/lxt27dEtOmTRMAxI4dO+R9NBqNaNWqlXBychKLFy8Wt2/fFmfPnhU9evQQFhYWYtOmTfK+cXFxonbt2sLZ2Vn8/PPP4syZM+LWrVti9erVomLFiuLMmTNp1tKxY0dha2srpkyZIk6cOCHCwsLE5s2bRe3atbXeQ1dxcXGZPvZDDh06JBwdHVP9uVq1apX47LPPRM2aNUVISEiK5wGk+rkCAwNFs2bN5PWTJ08KBwcH4evrK7Zt2yZu3rwpzpw5I8aPHy8+//xzfX4cLSEhIcLKykosW7ZMXLp0SfTo0UM4OTmJJ0+epHnM6tWrhbW1tVi9erUICwsTu3fvFu7u7mLw4MHyPjt27BCjR48WGzduTPMcTJs2TTg6OorNmzeLc+fOiS+//FIULlxY6zxv2LBBODs7iwULFohr166JS5cuibVr12q9zrZt24S7u7tISEhItV5T/r1ApG/pfYe+T9GAcfDgQfHFF18Id3f3NH+JvO/AgQOiYsWKwsrKShQtWlQsX75cp/fUNWBoNBoRFRWlyEOj0WToM7169UoAEKGhoenuV6hQITFnzhytbZMmTRKlSpXS+bg8efJofSGEhIQIAGLr1q0pjm/RooX45JNPRFRUlBBCiB9++EGYmZmJ06dPp9g3Pj5e3u99a9euFQDE5s2bUzyn0WjE69evhRBC+Pn5iYEDB2o936xZMxEYGKj1mSZOnCg6deok7O3tRWBgoKhRo4b47rvvtI57+vSpsLCwEAcPHhRCCBEbGyuGDh0qPDw8hJ2dnahWrZo4cOBAqvUm6du3r2jVqlWqz9WuXVssXLhQLFiwQNSvXz/F8xkJGBqNRpQuXVpUrlxZqNXqFPu+evUq3fo+RrVq1UTfvn3ldbVaLTw8PERwcHCax/Tt21fUrVtXa9uQIUNEzZo1U90/tXOg0WhEvnz5xIwZM+Rtr1+/FtbW1uKPP/4QQgiRkJAg8ufPL5YsWZLuZ4iLixPW1tZi7969qT7PgEH0ji4BQ9FLJG/fvkX58uUxf/78DO0fFhaGJk2aoE6dOjh79iwGDRqE7t27Y/fu3QarMTo6Grlz51bkkdEm/6T9N2/enGoze1oePnyIv/76Cz4+Phk+RqPR4M8//8SrV6+0RjZcs2YNvL290bRp0xTHDB06FC9evMDff/8NAFi9ejX8/f1RsWLFFPtaWloiV65cqb736tWrUbx4cTRr1izFcyqVCo6Ojhn+HAAwc+ZMlC9fHmfOnMHYsWPRsWNHhISEQAgh77N27Vp4eHigVq1aAIB+/frh2LFjCAkJwfnz59G6dWs0bNgw1ab5JIcOHUKVKlVSbL916xaOHTuGNm3aoE2bNjh06BDu3r2r02cAgLNnz+LSpUsYOnRoqrdUOjk5pXns1KlTP/hzeO/evVSPjY+Px6lTp+Dv7y9vMzMzg7+/P44dO5bme/r6+uLUqVPypZTbt29jx44daNy4cQY/sfS7IDw8XOu9HR0d4ePjI7/36dOn8fDhQ5iZmaFixYpwd3dHo0aNcPHiRa3XsrKyQoUKFXDo0KEMvz8RfZiiAaNRo0aYPHkyvvrqqwztv3DhQhQuXBizZs1CyZIl0a9fP7Rq1Qpz5swxcKXGzcLCAitWrMDKlSvh5OSEmjVrYtSoUTh//nyKfUeMGIHcuXPD1tYWBQoUgEqlytD156TjrK2t0apVKzg7O6N79+7y89evX0fJkiVTPTZp+/Xr1wEAN27cQIkSJXT+nDdu3EDx4sV1Pi4tdevWxdChQ1G0aFEULVoUbdq0waNHj3D48GF5nzVr1qB9+/ZQqVS4d+8eli9fjvXr16NWrVooWrQohg0bhs8++wzLly9P833u3r0LDw+PFNuXLVuGRo0awdnZGXny5EFAQEC6r5OWpHCTmXPaq1cvnD17Nt1HarUDwPPnz6FWq+Hm5qa13c3NDeHh4Wm+Z4cOHTBx4kR89tlnsLS0RNGiRVG7dm2MGjUqw3UnvX5673379m0AwPjx4zFmzBhs27YNzs7OqF27Nl6+fKl1nIeHR6bCHRGlzaRG8jx27JjWXywAEBAQgEGDBhnsPe3s7BAVFWWw1//Qe2dUy5Yt0aRJExw6dAj//vsvdu7cienTp2PJkiX45ptv5P2GDx+Ob775BkII3L9/H6NGjUKTJk3wzz//pOiAmFzScY8fP8bw4cPRp08ffPrpp1r7JP/LPz0Z3U9fx6Xl/VaFvHnzokGDBli9ejVq1aqFsLAwHDt2DL/++isA4MKFC1Cr1fD29tY6Li4uDp988kma7xMTE5NiBEi1Wo2VK1di3rx58ravv/4aw4YNw7hx43Qa3OljzkuePHmQJ0+eTB+fGaGhoZg6dSp++eUX+Pj44ObNmxg4cCAmTZqEsWPH6u19NBoNAGD06NFo2bIlAGD58uUoUKAA1q9fj2+//Vbe19bW1qg7CROlRwiBY8eOpRns69atm25LpqGYVMAIDw9P9S+WyMhIxMTEwNbWNsUxcXFxWpcNIiMjdXpPlUqVZpO9sbGxsUH9+vVRv359jB07Ft27d0dQUJBWwHBxcZGDQbFixTB37lzUqFEDBw4cSBHekks67tNPP8X69etRtmxZVKlSBaVKlQIAeHt748qVK6kem7Q96YvZ29sbV69e1fnzZfQ4MzOzFF+6qd2Zktr/144dO2LAgAH46aefsGbNGpQtWxZly5YFAERFRcHc3BynTp1KEcZy586dZj0uLi4p7tTZvXs3Hj58iLZt22ptV6vV2LdvH+rXrw8AsLe3R0RERIrXfP36tXxJKOm8Xr16NdXLTumZOnUqpk6dmu4+ly9fRsGCBVNsd3Fxgbm5OZ48eaK1/cmTJ8iXL1+arzd27Fh06tRJbgErW7Ys3r59i549e2L06NEZCldJr//kyRO4u7trvXeFChUAQN6e9DMKANbW1ihSpEiKyz4vX75E0aJFP/i+RMbg6tWrWLhwISwtLQFIl3vTc/bsWUUCRra/TTU4OBiOjo7yw9PTU+mSskypUqU+eH9/0hdlTExMhl/X09MTbdu2xffffy9va9euHW7cuIG//vorxf6zZs3CJ598In9pdujQAXv37sWZM2dS7JuQkJBmzR06dMD169exZcuWFM8JIeQv4rx58+Lx48fyc2q1OsV197Q0a9YMsbGx2LVrF9asWYOOHTvKz1WsWBFqtRpPnz6Vw1bSI70v1IoVK+Ly5cta25YuXYp27dqluBzRrl07LF26VN6vePHiOHXqlNaxarUa586dk4NFhQoVUKpUKcyaNUv+qz25169fp1nbx1wisbKyQuXKlbFv3z55m0ajwb59+1CjRo003zM6OjpFiEj6Ocxoa0zhwoWRL18+rfeOjIzE8ePH5feuXLkyrK2tce3aNXmfhIQE3LlzB4UKFdJ6vYsXL+oczoiUsHnzZpQsWRLz5s3DzJkzU4SLmjVrpngo9keywbqa6ggZuIukVq1aKe4OWLZsmXBwcEjzmNjYWBERESE/7t+/n+1uU33+/LmoU6eOWLVqlTh37py4ffu2WLdunXBzcxNdu3aV90t+u+mjR4/E8ePHhZ+fn8ibN694/vx5mq+f2l0kly5dEiqVSpw8eVIIIfXq/+qrr4Szs7NYsmSJCAsLE+fOnRM9e/ZMcZtqbGysqFWrlnyb6tmzZ8WtW7fE2rVrRaVKldK8TVWj0Yi2bdvKt6mePHlS3LlzR/z111+ibt268nssXLhQ2NnZiW3btokrV66IHj16CAcHhxR3kbz/mZJ07NhRlC9fXqhUKnH37t0Uz3l5eYk///xT3L59W74deNu2bWmevx9//FFUrlxZXn/69KmwtLQUO3fuTLHvjh07hLW1tXjx4oUQQog1a9YIW1tbMX/+fHH9+nVx5swZ0bVrV+Ho6CjCw8Pl444fPy7s7e2Fr6+v2L59u7h165Y4d+6cmDx5ssFvU7W2thYrVqwQly9fFj179hROTk5atXXq1EmMHDlSXg8KChL29vbijz/+ELdv3xZ79uwRRYsWFW3atJH3efPmjThz5ow4c+aMACBmz54tzpw5o/X/Y9q0acLJyUls2bJFnD9/XjRr1izFbaoDBw4U+fPnF7t37xZXr14V3bp1E66uruLly5fyPmFhYUKlUok7d+6k+hlN9fcCmZabN2+KMWPGiO7du4sePXoIAEKlUgkzMzOtBwD50ahRIzF8+HAxfPhwMXbsWOlW6//+E+Kbb4SIjzdInSZzm2pyGQkY3333nShTpozWtvbt24uAgIAMv092HAcjNjZWjBw5UlSqVEk4OjoKOzs7Ubx4cTFmzBgRHR0t71eoUCGtH868efOKxo0bpzvuRNJxqX0ZBwQEiEaNGsnrCQkJYsaMGaJ06dLCyspKODg4iICAAHH48OFUaw4ODhZly5YVNjY2Ik+ePKJmzZpixYoVaY5HIIR0G+SCBQtE1apVhZ2dnXBwcBCVK1cW8+bNkz9rfHy86N27t8iTJ49wdXUVwcHBqd6mmlbA2LFjhwCQ6hdzfHy8GDdunPDy8hKWlpbC3d1dfPXVV+L8+fNp1vzixQthY2Mjrl69KoQQYubMmcLJyUnEp/ILIC4uTjg5OYl58+bJ21avXi0qV64s7O3thZubm2jcuLE4d+5cimOvXbsmOnfuLDw8PISVlZUoVKiQaN++faq3A+vTTz/9JAoWLCisrKxEtWrVxL///qv1vJ+fn9a5T0hIEOPHjxdFixYVNjY2wtPTU/Tp00frdtoDBw5o/awmPZK/jkajEWPHjhVubm7C2tpa1KtXT1y7dk3rvePj48XQoUOFq6ursLe3F/7+/uLixYta+0ydOjXd3yGm+nuBjNObN2/EmzdvxMmTJ4Wzs7MoU6ZMqj/rH3r8+eefKV/8xAkhnJyEAIQYN84g9esSMFRC6LnnnA6ioqJw8+ZNAFIz8uzZs1GnTh3kyZMHBQsWxPfff4+HDx/it99+AyDdmlamTBn07dsXXbt2xf79+zFgwABs374dAQEBGXrPyMhIODo6IiIiAg4ODlrPxcbGIiwsDIULF+a0zKRXw4cPR2RkpNxhlIxDfHw8ihUrhjVr1qBmzZqp7sPfC/QxFi5ciP3798PMzAxr16794P4qlQoTJkyASqVCoUKF5EvLyTk5OaX8WTxxAmjQAIiIAGrWBHbuBOzt9fUxZOl9h75P0U6e//33H+rUqSOvDxkyBAAQGBiIFStW4PHjx1qdsQoXLozt27dj8ODBmDdvHgoUKIAlS5ZkOFwQKWX06NH45ZdfoNFoOP23Ebl37x5GjRqVZrgg+hCNRoMrV65g48aNWn2I/vjjDzx69OiDNxZ07NgRXbp0gbW1NapXrw4Li0x8LR8/LoWLyEjgs8+AHTsMEi50pWgLhhLYgkFEuuDvBUrL9evXMzw2z5w5c2Bubo4iRYrIf1hbWVllLlAk9++/QECAFC5q1ZLCRTp3tX0sk2nBICIiMkZPnz5FcHBwihbH2bNnw8HBASqVKsUt5N7e3lqt8gkJCejWrRsqVKig07hGGRYTA7RoIYULPz9g2zaDhgtdMWAQERFBCgTbtm3DyJEj5ZGHU/P+ZY9x48ZhwoQJhi4vJVtbYM0aYOZMYO1awMjGbGLAICKiHOv169e4evUqgoKCsGfPnhTPu7m5ITAwUGtb3rx55TmR8ufPb5jWifQkJAD/H2QLtWtLDyPEgEFERDnGxo0bMWfOHISHh8Pc3FxrILbk2rRpg9GjR6NcuXJZXOEHHD4MBAYCW7YAZcooXU26GDCIiChbiIqKwrFjx1IdEVYIgYYNG6Z5bKFChfDw4UOcPn1anh7A6Bw6BDRqBLx9C0yZAvzxh9IVpYsBg4iITNKzZ88QExODtWvXIjo6GuPHj8/wsc2aNUPPnj1ha2uLcuXKpTthoVH45x+gcWMpXPj7A8uWKV3RBzFgkF6oVCps2rQJzZs3V7qUVGVVfaGhoahTpw5evXolTy60efNmDBs2DGFhYejfvz8qVKiAQYMGpTtHCBFJXr9+jUaNGqW4JTK1/hJJnJ2dU8w3A0hjVhQsWBBbt26FSqXSe60Gc/CgFC6io4H69aXLI6lM7mlsGDCyiW+++QYrV64EAFhYWKBAgQJo3bo1Jk6cmO3v3Q8PD8eUKVOwfft2PHz4EK6urvKXeL169bK0Fl9fXzx+/Fie6RQAvv32W3Tp0gUDBgyAvb09LCws0Lhx4yyti8jYRURE4MGDB7hx4wb27duHn3/+Gfb29njz5s0Hj1WpVBBCoFevXqhYsSJ69uyZBRVnkQMHgC++kMJFQACwaZNJhAuAASNbadiwIZYvX46EhAScOnUKgYGBUKlU+OGHH5QuzWDu3LmDmjVrwsnJCTNmzEDZsmWRkJCA3bt3o2/fvpmaFv5jWFlZac2sGhUVhadPnyIgIEBrVlLbj/wFkZCQIE/VTGRKoqKisHXrVkRHR8vb7t+/j4kTJ6bYN3m4KFiwICZPnqz1/CeffIIGDRp8/GBVxkoIIDhYChcNG0rhwpT+YDTIbChGLDtOdiaEEIGBgaJZs2Za21q0aCEqVqworz9//ly0a9dOeHh4CFtbW1GmTBmxZs0arWP8/PxE//79xfDhw4Wzs7Nwc3MTQUFBWvtcv35d1KpVS1hbW4uSJUuKPXv2pJis7vz586JOnTryRGY9evQQb968SVHvlClThKurq3B0dBQTJkwQCQkJYtiwYcLZ2Vnkz59fLFu2LN3P3ahRI5E/f34RFRWV4rnkk2e9X993330nihUrJmxtbUXhwoXFmDFjtCYfO3v2rKhdu7bInTu3sLe3F5UqVZJnjr1z54744osvhJOTk7CzsxOlSpUS27dvF0K8m6Tr1atXqU7YdeDAAbF8+XLh6OioVevmzZtFxYoVhbW1tShcuLAYP3681qRvAMQvv/wimjZtKuzs7FL8PyHDMeXfC0pbtmyZ6NKli+jatWuGJ/FycXERAETbtm3Fzz//LG7cuCHPLpwjRUQIMWKEEEby86fLZGfZNPYZwNu3aT9nbq6dKtPb18xMu3krrX0/csCUixcv4ujRo1rXIWNjY1G5cmWMGDECDg4O2L59Ozp16oSiRYuiWrVq8n4rV67EkCFDcPz4cRw7dgzffPMNatasifr160Oj0aBFixZwc3PD8ePHERERgUGDBmm999u3bxEQEIAaNWrg5MmTePr0Kbp3745+/fphxYoV8n779+9HgQIF8M8//+DIkSPo1q0bjh49is8//xzHjx/H2rVr8e2336J+/fooUKBAis/48uVL7Nq1C1OmTEGuVM5XUh+I1Njb22PFihXw8PDAhQsX0KNHD9jb2+O7774DIM0PULFiRSxYsADm5uY4e/as3GLQt29fxMfH459//kGuXLlw+fJl5E5l9DxfX19cu3YNxYsXx59//glfX1/kyZMHd+7c0drv0KFD6Ny5M3788UfUqlULt27dkpt4g4KC5P3Gjx+PadOmYe7cudn3LzbKNurVq4f9+/en+bydnZ3WJcyEhAR06dIFbdq0yYryjNvdu0DS724HB2DaNGXryawsCDxGJdMtGFJjVeqPxo2197WzS3tfPz/tfV1cUt9PR4GBgcLc3FzkypVLWFtbCwDCzMxMbNiwId3jmjRpIoYOHSqv+/n5ic8++0xrn6pVq4oRI0YIIYTYvXu3sLCwEA8fPpSf37lzp1YLwaJFi4Szs7NWq8L27duFmZmZCA8Pl+stVKiQUKvV8j7FixcXtWrVktcTExNFrly5xB9//JFq7cePHxcAxMaNG9P9jEKkbMF434wZM0TlypXldXt7e7FixYpU9y1btqwYP358qs8lb8EQQmpFwf9bLpK834JRr149MXXqVK3XWbVqlXB3d9eqf9CgQWnWT4bDFozUXb9+XezcuTPVR0BAgFarxJQpU0RwcLBYunSpePr0qVZrJr1nzx4hbGyECA5WupJUsQUjh6pTpw4WLFiAt2/fYs6cObCwsEDLli3l59VqNaZOnYp169bh4cOHiI+PR1xcXIpR6N4fWMbd3R1Pnz4FAFy5cgWenp5a/Qlq1Kihtf+VK1dQvnx5rVaFmjVrQqPR4Nq1a3BzcwMAlC5dWmucfzc3N5RJNnCMubk5PvnkE/m93yc+Yp6+tWvX4scff8StW7cQFRWFxMRErV7qQ4YMQffu3bFq1Sr4+/ujdevWKFq0KABgwIAB6N27N/bs2QN/f3+0bNnyowbjOXfuHI4cOYIpU6bI29RqNWJjYxEdHS3//6lSpUqm34NIV5GRkbh48SJ27NgBc3NzeXtwcDASEhJ0eh17I5jZ0yTs2QN8+SUQFwccPQqo1VILuYliwMioqKi0n3v/ByCNL0QA0iWS5N5rLv8YuXLlwqeffgoAWLZsGcqXL4+lS5eiW7duAIAZM2Zg3rx5mDt3LsqWLYtcuXJh0KBBiI+P13qd9zsPqlQqaDQavdWZ3vvo8t7FihWDSqXSuSPnsWPH0LFjR0yYMAEBAQFwdHRESEgIZs2aJe8zfvx4dOjQAdu3b8fOnTsRFBSEkJAQfPXVV+jevTsCAgKwfft27NmzB8HBwZg1axb69++vUx1JoqKiMGHCBLRo0SLFc8nvAErtMhCRvt24cQMtWrTAxYsXM7R/pUqVUt3+8uVL7Ny5k+Eio3bvBpo1k8JFs2bAunUmHS4ABoyM0+WXu6H21YGZmRlGjRqFIUOGoEOHDrC1tcWRI0fQrFkzfP311wCke8KvX7+OUqVKZfh1S5Ysifv37+Px48dwd3cHAPz7778p9lmxYgXevn0rfykeOXIEZmZmGZ7aOCPy5MmDgIAAzJ8/HwMGDEjxBfz69etU+2Ek9U0ZPXq0vO3u3bsp9vP29oa3tzcGDx6M9u3bY/ny5fjqq68AAJ6enujVqxd69eqF77//HosXL850wKhUqRKuXbsmh0OirLJhwwaEhobi7du3WLFiBaysrFL8wQEAfn5+Wq2LDg4OaNOmDUqXLs27mfRh507gq6+kcNG8uTRxmZWV0lV9NAaMbKx169YYPnw45s+fj2HDhqFYsWLYsGEDjh49CmdnZ8yePRtPnjzRKWD4+/vD29sbgYGBmDFjBiIjI7W+qAGpg2RQUBACAwMxfvx4PHv2DP3790enTp3kyyP6Mn/+fNSsWRPVqlXDxIkTUa5cOSQmJuLvv//GggULcOXKlRTHFCtWDPfu3UNISAiqVq2K7du3Y9OmTfLzMTExGD58OFq1aoXChQvjwYMHOHnypHy5adCgQWjUqBG8vb3x6tUrHDhwACVLlsz0Zxg3bhy++OILFCxYEK1atYKZmRnOnTuHixcvprgtjyijhBC4cuUKjhw5AiEEgoOD4erqKj9/4sSJFMckDxflypXD3r17kTdv3iypN8fasUMKF/Hx0n9DQrJFuAAYMLI1CwsL9OvXD9OnT0fv3r0xZswY3L59GwEBAbCzs0PPnj3RvHlzREREZPg1zczMsGnTJnTr1g3VqlWDl5cXfvzxR60x/u3s7LB7924MHDgQVatWhZ2dHVq2bInZs2fr/TMWKVIEp0+fxpQpUzB06FA8fvwYefPmReXKlbFgwYJUj/nyyy8xePBg9OvXD3FxcWjSpAnGjh0rDzNsbm6OFy9eoHPnznjy5AlcXFzQokULeTpmtVqNvn374sGDB3BwcEDDhg0xZ86cTH+GgIAAbNu2DRMnTsQPP/wAS0tLlChRAt27d8/0a1LOtnXrVnm2z+Tev4MpSd++fZErVy5Ur14d5cuXh6enJ1smssrNm1K4aNlSmlskG513lfiYnnImKDIyEo6OjoiIiEgx9GxsbCzCwsJQuHDhbD/6JRFljLH/XhBCoGzZskhMTAQgXRp88uSJ1j6NGjWCpaUlHB0dtW4DdXBwQM2aNbU6cZIC/vpLGkjLBMJFet+h72MLBhGRCRJC4PTp0/jtt99w6dKlVPf56aef0KtXL46bYmz27wcqVgScnaX1pk2VrcdA+FNHRGRCVq5ciZs3b6baP+fgwYPycqVKlVIdAI4UtmUL0Lo1UL48sG+fNJBWNsWAQURkIkaNGoXg4OAU2318fPD999/j888/V6AqyrBNm4A2bYDERKBYMeC9MYiyGwYMIiIjpNFoMGfOHNy7dw8A8OOPP2o9369fPwDAxIkT4ZzU1E7Ga+NGoG1bKVx06ACsXAlk80tX2fvTERGZGLVajSNHjsDPzy/Nfa5evarXMWXIwP78E2jXTgoXHTtK4SIHdKxlwEhFDruxhojSYcjfB+PHj9e6dXT9+vVa05gnSRprJn/+/OjSpYtR3s1Cadi8WWq5UKuBTp2A5ctzRLgAGDC0JN33HR0dDdvkM54SUY6V9IWvj3EhHj16hHXr1iE+Ph4jRoz44P7fffcdgoKCUswXRCakZEnA1RWoXx9YtizHhAuAAUOLubk5nJyc5Mm17OzsoFKpFK6KiJQghEB0dDSePn0KJyenjxorYvTo0bh06RK2bNmS6vPTp0+Xl21sbNCiRQvky5eP41NkB8WLAydOAO7uOSpcAAwYKeTLlw8A0pzBk4hyFicnJ/n3gi6uXLmC2rVrp/q7xN3dHQ0aNECePHkwffp0jlOR3fzxB/DJJ0CDBtJ6gQLK1qMQ/lS/R6VSwd3dHa6urjpNSUxE2Y+lpeUHWxHu3buHw4cPQ61WY8aMGXBxcYEQAqGhoSn2XbhwIdzd3fHFF1/A7P2ZlSl7WL0a6NxZmk/kxAmgbFmlK1IMA0YazM3N2TxJRGn6888/0a5dO3mI7rR88cUXmDJlCkqXLs3fKdnd778DgYGARgN8/TVQurTSFSmKAYOISEe+vr44duyY1raaNWvCysoKefLkQatWrQBIo2l6e3srUSJltVWrpHAhBNCjB7BwIZDDW6kYMIiI3qPRaHDq1CnExMTI28LCwvDXX3/h+fPnWuEiKCgI3333He/0yMlWrgS6dJHCRc+ewIIFOT5cAAwYRERaEhISMGzYsBQjZ6YmIzNKUjYXGvouXPTqBcyfz3DxfwwYRJTjvHjxAseOHUsxiNaLFy/QpUsXrW0lSpSQl589e4YmTZqgXLlyaNKkCcMFAZ99Jg2k5ewshQsObSBjwCCiHKV+/frYu3fvB/dzcnLCzp07Ub169SyoikyWhYXU/8LcnOHiPQwYRJRtJSYmYs+ePTh69Ci2bduGly9f4v79+/Lz3t7eKSYKi4+Px9dff43BgwdzoD1K3ZIlwL//AosWSZdDOI5JqnhWiChbuX37NpYvX46VK1dqhYn3vXjxAnny5MnCyihbWLQI+PZbadnfX5rEjFLFgEFE2UJ8fDysra3TfL5q1ar48ssvUaJECdSpU4fhgnT3669SR04AGDhQ6ntBaWLAICKTplarcfLkSdSoUUNru5mZGcaNG4dOnTqhSJEiClVH2caCBUCfPtLy4MHArFnsc/EBDBhEZJIePnyI0qVLIyIiIsVziYmJHDWT9Gf+fKBfP2l56FBgxgyGiwzgzbpEZFI2bdoElUqFAgUKpAgXhQoVQmxsLMMF6c/du8CQIdLysGEMFzpgCwYRmYynT5+iRYsWWtu8vb2xdetWFC9eXKGqKFsrVAhYt06auGzyZIYLHTBgEJHRun//PkJDQ6HRaPDNN99oPTd8+HBMmjQp3Y6dRJn25g1gby8tN2smPUgnDBhEZDQePXqEx48fIyoqCr/99huWLVuW6n4FChTA9OnTs7g6yjHmzAHmzpWGAS9cWOlqTBYDBhEpKjo6GtWqVcOtW7cQGxub6j6+vr7IlSsX3N3dsWjRIrZakOHMni115ASAP/+U+l1QpjBgEJEiTpw4gaCgIOzatSvFc56enoiOjkbBggXxww8/oH79+gpUSDnOrFnvAsXYse+CBmUKAwYRZbnLly/Dx8dHa5uNjQ22bdsGX19f2NraKlQZ5VgzZgDffSctjxsHjB/PDp0fibepElGW8vX1RenSpeX1zp0747///kNMTAzq1avHcEFZb/r0d+Fi/HhgwgSGCz1gCwYRZYn4+HhMmDABx44dk7f16dMH8+fPV7AqyvFiY4HVq6XlCROk1gvSCwYMIjK4K1euoFSpUlrbHj9+jHz58ilUEdH/2dgAe/cCGze+m8SM9IKXSIjIoG7cuJEiXKxZs4bhgpR15sy75bx5GS4MgAGDiAzi77//xty5c+Ht7S1v69+/P4QQaN++vYKVUY43aRJQqZI09ToZDC+REJHePHr0CH379sXmzZtTPDds2DDMmDEj64siSm7CBKkjJwC8fKloKdkdAwYRfZSIiAhER0cjIiICJUuWTPF827Zt4e/vj+7duytQHVEySXeIAMC0acCIEYqWk90xYBCRzp4+fYqePXti27ZtUKvVKZ739PTE1KlT0aFDB5iZ8UosKUwIKVxMnCitT58ODB+uaEk5AQMGEX1QYmIigoKCEB8fj/Xr1+Pu3bsp9jE3N4darUbDhg2xc+dOBaokSoUQ0q2nkydL6zNncoTOLMKAQUSpSkxMxI4dOzBhwgScPn061X0KFiyImTNnokmTJrCzs8viCol0NHs2MHiw0lXkGAwYRJRCREQEnJycUn1u+P+blocNGwZXV9csrIooE1Qq6dJIo0aAr6/S1eQoDBhEhMTERDx48AADBw7E2bNnce/ePa3nGzZsiEmTJqFKlSoKVUikAyGAJUuAjh0BOzspZDBcZDkGDKIc7OXLlxg3blyaw3XnyZMHjx494vToZDqEkO4OmTEDWLsW2L0bMDdXuqociQGDKAeJiorC/PnzsWfPHpw8eRJv3rxJsY+7uzt++ukn+Pn5wcXFRYEqiTJJCGnSspkzpfWvvmK4UBADBlEO8eDBA3h6eqb6nIODA/766y/4+vrCwoK/FsgECQEMGyZ15ASA+fOBPn2UrSmH428SohzgwoULKFeunLxubW2N9u3bo02bNqhevTqcnZ0VrI7oIwkBDBkCzJ0rrS9YAPTqpWhJxIBBlO2dOHECPj4+8nr79u2xZs0aBSsi0rOxY9+Fi4ULOXGZkeAQe0TZVNKgWMnDxYABA7B69WoFqyIygBYtgDx5gF9/ZbgwImzBIMpG4uLi0L59e1y8eBE3btzQeu7nn39G3759FaqMyIAqVQJu3JBCBhkNBgwiE/b8+XOcOnUKixcvxpEjRxAeHp7qfmvWrOEU6ZR9JN2K2qIFUL26tI3hwugwYBCZoCtXrqBixYqIi4tLc589e/agSJEiKFq0aBZWRmRgGg3Qr5/UkXPxYuDWLYYLI8U+GEQmRKPRIDg4GKVKldIKFyVKlEDJkiWxaNEihIeHQwiB+vXrM1xQ9qLRSLeeLlggjc45dy7DhRFjCwaRiUhISICVlZXWtpYtW2Lp0qVwdHRUqCqiLKLRAL17A4sWSeFixQqgc2elq6J0MGAQGTkhBG7evAlvb2+t7fv370edOnUUqoooC2k00t0hS5YAZmbAypXA118rXRV9AAMGkZFKTExEmzZtsGnTphTPCSEUqIhIIfPnvwsXv/0mTWJGRo99MIiMTHx8POrWrQtLS8sU4eLzzz9Pdf4QomytRw+gSRNg1SqGCxPCFgwiI+Pq6oqIiAitbUeOHEHVqlVhaWmpUFVEWUyjkfpaqFSAjQ3w11/SMpkMxVsw5s+fDy8vL9jY2MDHxwcnTpxId/+5c+eiePHisLW1haenJwYPHozY2NgsqpbIcIQQKFeunFa4OH/+PIQQ8PX1ZbignEOtBrp0AYYPl8a8ABguTJCiLRhr167FkCFDsHDhQvj4+GDu3LkICAjAtWvX4OrqmmL/NWvWYOTIkVi2bBl8fX1x/fp1fPPNN1CpVJidNIMekYk6fvw4Lly4IK/HxcWluGuEKNtLCherVklTrXfqBJQvr3RVlAkqoWBvMR8fH1StWhU///wzAOkef09PT/Tv3x8jR45MsX+/fv1w5coV7Nu3T942dOhQHD9+HIcPH87Qe0ZGRsLR0RERERFwcHDQzwch+kgajQbm5uby+ps3b5A7d24FKyJSgFoNBAYCq1dL4SIkBGjVSumqKBldvkMVu0QSHx+PU6dOwd/f/10xZmbw9/fHsWPHUj3G19cXp06dki+j3L59Gzt27EDjxo2zpGYiQ6lXr5683L59e4YLynkSE6VxLVavBiwsgLVrGS5MnGKXSJ4/fw61Wg03Nzet7W5ubrh69Wqqx3To0AHPnz/HZ599BiEEEhMT0atXL4waNSrN94mLi9Ma8TAyMlI/H4BID9RqNXr37o3Q0FB5G2c7pRwnKVz88YcULtatA776Sumq6CMp3slTF6GhoZg6dSp++eUXnD59Ghs3bsT27dsxadKkNI8JDg6Go6Oj/PD09MzCionStn37dlhYWGDx4sXytsjISKjYmY1ymiNHpMshFhbA+vUMF9mEYn0w4uPjYWdnhw0bNqB58+by9sDAQLx+/RpbtmxJcUytWrVQvXp1zJgxQ972+++/o2fPnoiKioKZWcq8lFoLhqenJ/tgkKKOHz+O6kmzQP7fgQMHULt2bWUKIlLab78Bjo5As2ZKV0LpMIk+GFZWVqhcubJWh02NRoN9+/ahRo0aqR4THR2dIkQkdYxLKydZW1vDwcFB60GktOThYvTo0RBCMFxQzpKQADx79m69c2eGi2xG0dtUhwwZgsDAQFSpUgXVqlXD3Llz8fbtW3Tp0gUA0LlzZ+TPnx/BwcEAgKZNm2L27NmoWLEifHx8cPPmTYwdOxZNmzbV6oFPZKzi4+PRunVreb1ixYqYPHmyghURKSAhAWjfHrh0CThwAMiXT+mKyAAUDRht27bFs2fPMG7cOISHh6NChQrYtWuX3PHz3r17Wi0WY8aMgUqlwpgxY/Dw4UPkzZsXTZs2xZQpU5T6CEQ62bRpE7Zu3SqvHz16VMFqiBSQkAC0awds3AhYWQEXLzJgZFOKjoOhBI6DQVlNo9FAo9Hg1atXWgPIhYeHp7iLiihbi4+XwsWmTVK42LQJ4DADJsUk+mAQ5QS7du2Cubk5LC0ttcJF69atGS4oZ4mPB9q0kUKFtTWwZQvDRTbHyc6IDOTSpUto1KhRiu3VqlXDypUrFaiISCHx8UDr1sDWre/CRUCA0lWRgbEFg0jPhBDYv38/ypQpI28bNGgQXr58iZiYGBw/fhy2trYKVkiUxV6+lDp02thIIYPhIkdgCwaRHgkhUtxKPWbMmHQHgyPK9vLlk+4WuXkTqFNH6Wooi7AFg0hPNBpNinAxbdo0hgvKmeLigGRD4MPTk+Eih2ELBpEeXL9+HcWLF9faptFoOOw35UyxsUDLlsDu3dL8IsnGfqGcgy0YRB9pypQpDBdESWJjpblEduyQbkX95BOlKyKFMGAQfYTIyEiMGTNGXq9WrRrUajXDBeVMMTHScN+7dgF2dlLIqFtX6apIIbxEQvQRChQoIC+fO3cO5cqVU7AaIgUlhYu//34XLvz8lK6KFMQWDKJMSExMxFdffYU3b94AAHx9fRkuKOeKiwO+/FIKF7lyATt3MlwQAwZRZtSrVw+bN2+W1/fv369cMURKs7ICihV7Fy4+/1zpisgIMGAQ6Wjp0qX4559/5PU7d+7A2tpawYqIFKZSAT//DJw+DdSqpXQ1ZCQYMIgy6K+//oKnpye6d+8ub3v8+DEKFSqkYFVECnn7Fpg4UZodFQDMzABvb2VrIqPCTp5EGfDkyRN8+eWXWtv27duHfJxmmnKit2+BJk2AgweB27eBFSuUroiMEFswiNIRGRmJNm3aaAWJESNG4MWLF6jL2+8oJ4qKkmZBPXgQcHAAevVSuiIyUmzBIEqDEAKOjo5a2zp27Ihp06YpVBGRwpLCxaFDUrjYswfw8VG6KjJSDBhEaXh/XpEdO3akOv06UY7w5o0ULg4fBhwdpXBRrZrSVZERY8Ages+FCxdSjGmRkJAACwv+c6EcSghpPpHDhwEnJ2m8iypVlK6KjBz7YBC95/1wIYRguKCcTaUCvv8eyJ8f2LuX4YIyhAGDCFKIGD58uNYcIh07doRarVawKiIj4ucH3LwJVK6sdCVkIvhnGeV4cXFxsLGxSbH9999/V6AaIiMREQF8/TUQHAyUKSNtS+XfCVFa2IJBOZIQAkuXLoVKpUoRLoKDgxEbG6tQZURG4PVroEEDYNs2qe8FW/IoE9iCQTmORqOBubl5iu1mZmZITEzkVOuUsyWFi5MngU8+AUJCgFT+vRB9CFswKMeZMGGC1vqUKVMQGRkJtVrNcEE526tXQP36UrhwcQH27wfKl1e6KjJRbMGgHOfhw4fyskajYaggAoCXL6Vwcfr0u3BRtqzSVZEJY8CgHEMIgSVLlmDp0qUAgEGDBjFcECUZNUoKF3nzSuEiqWMnUSYxYFCOoFar4enpicePH8vbmjRpomBFREZmxgzgyRNg0iSGC9IL9sGgbG/AgAGwsLDQChcbN26Ev7+/glURGYGYmHfL9vbApk0MF6Q3bMGgbOvs2bNo1qwZ7t27p7X9wYMHyJ8/v0JVERmJ58+BevWAdu2kUTqJ9IwtGJQtCSFQsWJFrXDxzz//QKPRMFwQPXsG1K0LnD8PzJsndfAk0jMGDMqWRo0aJS937doVz58/R61atdipk+jpUylcXLgA5MsHhIYCefIoXRVlQ7xEQtmOj48PTpw4Ia8n3TVClOMlhYtLlwB3d+DAAaB4caWromyKLRiUrXTs2FErXJw9e1a5YoiMyZMnQJ06Urjw8JBaLhguyIDYgkHZhlqtxpo1a+T1Fy9eIA+bfokku3cDly+/CxfFiildEWVzDBiUbbRu3VpePn/+PMMFUXKdOwOxsVIrBsMFZQGVEEIoXURWioyMhKOjIyIiIuDg4KB0OaQnz58/R968eQFIk5apOfsjERAeDlhbA87OSldC2YQu36Hsg0EmLyQkRA4XAHDgwAEFqyEyEo8fA7VrSzOjvn6tdDWUA/ESCZmsmJgYlC5dGmFhYfK21q1b4/PPP1ewKiIj8OiRdCnk+nXA01OaJdXJSemqKIdhwCCTFBUVBXt7e61tS5cuRdeuXRWqiMhIPHwohYsbN4BChaRbUQsXVroqyoEYMMgkvR8uHj58CA8PD4WqITISDx5I4eLmTSlchIYCXl5KV0U5FPtgkMlISEhAw4YNtUbj9PPzgxCC4YLo/n2pz8XNm1KoYLgghbEFg0zCqVOnUKVKFa1t5ubmCA0NVaYgImMTEwNER0uXQw4ckFowiBTEgEFGr1ixYrh586bWtsuXL6NEiRIKVURkhLy9pWBhawsULKh0NUS8RELGbcGCBVrhIiAgAFFRUShZsiQnLiO6exfYt+/devHiDBdkNNiCQUbr0aNH6NOnj7weHR0NW1tbBSsiMiJ37kgdOh8/BnbskCYxIzIibMEgo7R7927kz59fXt+zZw/DBVGSO3ekDp137kjjXHDSMjJCbMEgo5I0DG1yvXr1Qv369RWqiMjIhIVJ4eLePWlOkQMHgGRhnMhYsAWDjMK1a9dQtWrVFOHixx9/xIIFCxSqisjI3L79Llx4e0u3ojJckJFiCwYp6unTp3Bzc0uxvWDBgrh9+zbMzc0VqIrICD16JIWL+/elSyIHDgDu7kpXRZQmtmCQYl69epUiXLi5uSEsLAx3795luCBKztUVqFkTKFGC4YJMAgMGKeLmzZvIkyePvN6wYUMkJiYiPDwcXhx9kCglCwtg1Srg0CGGCzIJDBiU5aKiolCsWDF5vWTJkti5cydbLIjed/06MHw4oNFI6xYWgIuLsjURZRD7YFCWSz5RWatWrRASEqJgNURG6tq1d+Nc5M4NBAUpXRGRTtiCQVnmyZMnKFKkiLyeL18+rF+/ni0XRO+7evVduChTBujdW+mKiHTGFgzKMvny5ZOXrayscPfuXQWrITJSSeEiPBwoW1YaCjxvXqWrItIZWzDI4MLCwhAcHCyvlyhRAjdu3ICVlZWCVREZoStXpFtRw8OBcuWA/fsZLshksQWDDComJkbrsggAXLx4kZdFiN4XGwsEBABPngAVKgB79wKffKJ0VUSZxhYMMog7d+7AzMwMdnZ28rYSJUrg999/Z7ggSo2NDTB/PuDjw3BB2QJbMEjvTpw4AR8fH61tnp6euHz5MqdYJ3qfEEDSv4umTYEmTQAz/u1Hpu+jfopjY2P1VQdlEy4uLinCxb1793Dv3j2GC6L3nT8PVKkizTGShOGCsgmdf5I1Gg0mTZqE/PnzI3fu3Lj9/38YY8eOxdKlS/VeIJmOiRMn4sWLF/K6n58fYmNj4enpqWBVREbq3Dmgbl3g9Glg2DClqyHSO50DxuTJk7FixQpMnz5d6y6AMmXKYMmSJXotjkxHTEwMgpINBBQXF4fQ0FBYW1srWBWRkTp7FqhXD3jxQmrB4B9nlA3pHDB+++03LFq0CB07dtTqrFe+fHlcvXpVr8WR6UjemfPIkSO8BZUoLWfOvAsXVasCf/8NODsrXRWR3ukcMB4+fIhPP/00xXaNRoOEhAS9FEWm5cSJE/Jy3bp14evrq2A1REbs9GkpXLx8CVSrJoULJyelqyIyCJ0DRqlSpXDo0KEU2zds2ICKFSvqpSgyLck7de7evVvBSoiMmBDA0KHAq1fSrah79gCOjkpXRWQwOt+mOm7cOAQGBuLhw4fQaDTYuHEjrl27ht9++w3btm0zRI1kxLZs2SIv16pVCxYWvPOZKFUqFbB+PTBiBDBnDuDgoHRFRAalEkIIXQ86dOgQJk6ciHPnziEqKgqVKlXCuHHj0KBBA0PUqFeRkZFwdHREREQEHPgP/KMsXrwYPXv2lNffvn2r1ReDiCD1teCgWZRN6PIdmqk/N2vVqoW///47U8VR9rBx40atcLF06VKGC6L3nTwpDf89bRqQ7N8LUU6gcx+MIkWKaI11kOT169cp5pyg7EmtVqNly5by+po1a9C1a1cFKyIyQidOAP7+Up+L1asBtVrpioiylM4tGHfu3IE6lX8ocXFxePjwoV6KIuM2YsQIeXnz5s1o1qyZgtUQGaHjx4EGDYDISKBWLWD7doBz8FAOk+GAsXXrVnl59+7dcEzW+1mtVmPfvn3w8vLSa3FkfGJjYzFr1ix5neGC6D3HjkmXRd68AT7/XAoXuXMrXRVRlstwwGjevDkAQKVSITAwUOs5S0tLeHl5aX3xUPazevVqfP311/J68vEviAjA0aNAw4ZSuKhdG9i2DciVS+mqiBSR4YCh0WgAAIULF8bJkyfh4uJisKLIuGzfvh1ffPGF1rZixYqhatWqClVEZKQOHJDCRZ06wF9/MVxQjqZzJ8+wsDC9hov58+fDy8sLNjY28PHx+eBfxa9fv0bfvn3h7u4Oa2treHt7Y8eOHXqrh1J6P1wsWbIE169fV6gaIiM2ahSwbBlbLoiQydtU3759i4MHD+LevXuIj4/Xem7AgAEZfp21a9diyJAhWLhwIXx8fDB37lwEBATg2rVrcHV1TbF/fHw86tevD1dXV2zYsAH58+fH3bt34cShdg3m3Llz8nLfvn0xY8YM2NraKlgRkZE5fRooXlwKFCoV0KWL0hURGQWdB9o6c+YMGjdujOjoaLx9+xZ58uTB8+fPYWdnB1dXV3n69ozw8fFB1apV8fPPPwOQLsN4enqif//+GDlyZIr9Fy5ciBkzZuDq1auwtLTUpWwZB9rSjUqlkpc1Go3WOlGO988/QOPG0rwi27YBHAuGsjldvkN1vkQyePBgNG3aFK9evYKtrS3+/fdf3L17F5UrV8bMmTMz/Drx8fE4deoU/P393xVjZgZ/f38cO3Ys1WO2bt2KGjVqoG/fvnBzc0OZMmUwderUVG+bpY/36NEjeblcuXIMF0TJHTwINGoEvH0LWFpKrRdEJNM5YJw9exZDhw6FmZkZzM3NERcXB09PT0yfPh2jRo3K8Os8f/4carUabm5uWtvd3NwQHh6e6jG3b9/Ghg0boFarsWPHDowdOxazZs3C5MmT03yfuLg4REZGaj0oY9q3by8vHzlyRMFKiIxMaKjUchEdLd2SunkzwEuHRFp0DhiWlpYwM5MOc3V1xb179wAAjo6OuH//vn6re49Go4GrqysWLVqEypUro23bthg9ejQWLlyY5jHBwcFwdHSUH56engatMbuYM2cO/vnnHwCAra0tcvM+fiLJ/v3vwkXDhgwXRGnQOWBUrFgRJ0+eBAD4+flh3LhxWL16NQYNGoQyZcpk+HVcXFxgbm6OJ0+eaG1/8uQJ8uXLl+ox7u7u8Pb2hnmyEfFKliyJ8PDwFJ1Nk3z//feIiIiQH4YOQdnB27dvMWTIEHmdrRdE/7d/P/DFF0BMjHR5ZNMmwMZG6aqIjJLOAWPq1Klwd3cHAEyZMgXOzs7o3bs3nj17hl9//TXDr2NlZYXKlStj37598jaNRoN9+/ahRo0aqR5Ts2ZN3Lx5Ux6TAwCuX78Od3d3WFlZpXqMtbU1HBwctB6UNo1Gg/Lly8vra9euRcWKFRWsiMiIODlJgaJJE4YLog/I1HTt+rJ27VoEBgbi119/RbVq1TB37lysW7cOV69ehZubGzp37oz8+fMjODgYAHD//n2ULl0agYGB6N+/P27cuIGuXbtiwIABGD16dIbek3eRpK9p06bYtm2bvM47R4jec/UqULgwYG2tdCVEWc7g07Wn5vTp0xg3bpzWl9OHtG3bFs+ePcO4ceMQHh6OChUqYNeuXXLHz3v37sn9PQDA09MTu3fvxuDBg1GuXDnkz58fAwcO1Jp8iz5O8v9/Z86cYbgg2rNHmkvE11daL1FC2XqITIROLRi7d+/G33//DSsrK3Tv3h1FihTB1atXMXLkSPz1118ICAgw+lE12YKRth07dqBJkyYAgL1796JevXoKV0SksF27gObNASsraRKz0qWVrohIUQYZB2Pp0qVo1KgRVqxYgR9++AHVq1fH77//jho1aiBfvny4ePGi0YcLSptarZbDBQDUqlVLwWqIjMDOnVK4iIsD6tUDihVTuiIik5LhgDFv3jz88MMPeP78OdatW4fnz5/jl19+wYULF7Bw4UKULFnSkHWSgYWEhMjLS5cuTbPTLFGOsGPHu3Dx1VfAunVSKwYRZViGA8atW7fQunVrAECLFi1gYWGBGTNmoECBAgYrjrLOhQsX5OWuXbsqWAmRwrZtk0JFfDzQsiWwdq00UicR6STDASMmJgZ2/x9nX6VSwdraWr5dlUzf9OnTAYAtUZSzHT0KtGghhYtWrYA//mC4IMokne4iWbJkiTyiY2JiIlasWJFi6nZdZlMl45HU17d48eIKV0KkoEqVAH9/6a6R1asZLog+QobvIvHy8vrgLYsqlUqn2VSVwLtIUqpVqxYOHz4MADh69GiaA50R5QixsYCFhfQgIi26fIcqOtCWEhgwtN27dw+FChWS13PYjwORNCLnv/8C06ZxRlSiD1BkoC0yTStXrpSXExMTFayESAEbNwJt2wKJiUCFCkCyGYSJ6OPoPBcJZS9Hjx4FAOTOnVtrEjmibG/DBqBNGylcdOwI/P8uOSLSDwaMHOzGjRvYtWsXAKBBgwYKV0OUhdavB9q1A9RqoFMnYOVK9rkg0jMGjBxKCAFvb295vWfPngpWQ5SF1q6VLoWo1UDnzsDy5QBb74j0jgEjh0q6NAIAvXv3ZgsG5Qz370stFmo1EBgILFvGcEFkIJkKGLdu3cKYMWPQvn17PH36FACwc+dOXLp0Sa/FkeH8+uuv8vIvv/zCWVMpZ/D0BJYsAbp1A5YuZbggMiCdA8bBgwdRtmxZHD9+HBs3bkRUVBQA4Ny5cwgKCtJ7gaR/T58+xapVqwAA1atXV7gaoiyQkPBuuXNnKWQwXBAZlM4BY+TIkZg8ebI8bXuSunXr4t9//9VrcaR/kZGRcHNzk9c58iple7//DlSsCISHK10JUY6ic8C4cOECvvrqqxTbXV1d8fz5c70URYYzZcoUeblixYpo166dgtUQGdiqVVJfi0uXgEWLlK6GKEfROWA4OTnh8ePHKbafOXMG+fPn10tRZBhHjx6VJzUDgBMnTrDvBWVfK1dK4UKjAb79FhgzRumKiHIUnQNGu3btMGLECISHh0OlUkGj0eDIkSMYNmwYOnfubIgaSQ8uX76MmjVryuuhoaGw4H3/lF2tWAF06QIIAfTqBfzyC2DGm+aIspLO/+KmTp2KEiVKwNPTE1FRUShVqhQ+//xz+Pr6Ygz/QjBamzdvlpeXLl0KPz8/5YohMqTly4GuXaVw0acPwwWRQjI92dm9e/dw8eJFREVFoWLFiihWrJi+azOInDrZWadOnfD777/js88+w6FDh5Quh8gwYmOBcuWAGzeAvn2Bn37iBGZEemTQyc4OHz6Mzz77DAULFkTBggUzXSRlrd9//x0A4OHhoXAlRAZkYwPs2yf1vxg9muGCSEE6txvWrVsXhQsXxqhRo3D58mVD1ER6lnzGVI57QdlSWNi7ZU9PqUMnwwWRonQOGI8ePcLQoUNx8OBBlClTBhUqVMCMGTPw4MEDQ9RHerBixQp5uUePHsoVQmQIv/4KeHsD69YpXQkRJaNzwHBxcUG/fv1w5MgR3Lp1C61bt8bKlSvh5eWFunXrGqJG+kihoaEAgOHDhyN37tzKFkOkTwsWSHeJJCYCJ08qXQ0RJfNRXasLFy6MkSNHYtq0aShbtiwOHjyor7pIT5K3LCWfPZXI5P3yi3SXCAAMHQokG+OFiJSX6YBx5MgR9OnTB+7u7ujQoQPKlCmD7du367M20oPkY198/fXXClZCpEc//yzdJQIAw4cDM2awzwWRkdH5LpLvv/8eISEhePToEerXr4958+ahWbNmsLOzM0R99BEmTZqEe/fuAQDq1KkDGxsbhSsi0oOffgKS5tD57jtg2jSGCyIjpHPA+OeffzB8+HC0adMGLi4uhqiJ9GD37t0YN26cvM7WJco2rl2T/jtyJDB1KsMFkZHSOWAcOXLEEHWQniW/c+Tq1auwtbVVrhgiffrpJ6BBA6BpU4YLIiOWoYCxdetWNGrUCJaWlti6dWu6+3755Zd6KYw+zvHjxwEAHTt2RPHixRWuhugjbdkCNGoEWFlJoYK/Z4iMXoYCRvPmzREeHg5XV1c0b948zf1UKhXUarW+aqNMSkxMRNj/Bx4qXbq0wtUQfaRZs4Bhw4DmzYENGwBzc6UrIqIMyFDA0Gg0qS6TcdqwYYO8nF4gJDJ6M2ZIHTkBaY4RTlpGZDJ0/tf622+/IS4uLsX2+Ph4/Pbbb3opij7O/fv35eWSJUsqWAnRR/jhh3fhIigImDCBfS6ITIjOAaNLly6IiIhIsf3Nmzfo0qWLXoqij7NgwQIAQM+ePRWuhCiTpk2T7hIBgPHjpQcRmRSd7yIRQkCVyl8RDx48gKOjo16KosyLioqS+18kJiYqXA1RJsyYAXz/vbQ8cSIwdqyy9RBRpmQ4YFSsWBEqlQoqlQr16tWDhcW7Q9VqNcLCwtCwYUODFEkZN2vWLHl5ZNJfgESmpFo1wM5OChljxihdDRFlUoYDRlJnwbNnzyIgIEBr0iwrKyt4eXmhZcuWei+QdHPr1i15uVixYgpWQpRJfn7AlStAwYJKV0JEHyHDASMoKAgA4OXlhbZt23LYaSO1atUqAECLFi0UroRIBzNnAg0bAmXKSOsMF0QmT+dOnoGBgQwXRio6Olpebt26tYKVEOlg/HhpwrK6dYEXL5Suhoj0JEMtGHny5MH169fh4uICZ2fnVDt5Jnn58qXeiiPdPH36VF5u1aqVgpUQZYAQUriYOFFa/+474JNPFC2JiPQnQwFjzpw5sLe3l5fTCxiknDZt2sjLyTvhEhkdIYBx44DJk6X1mTOBoUOVrYmI9EolhBBKF5GVIiMj4ejoiIiICDg4OChdjt6cOnUKVapUAQDkz58fDx48ULgiojQIId16OmWKtD57NjB4sLI1EVGG6PIdqnMfjNOnT+PChQvy+pYtW9C8eXOMGjUK8fHxuldLejF79mx5+dSpUwpWQvQBS5a8Cxdz5jBcEGVTOgeMb7/9FtevXwcA3L59G23btoWdnR3Wr1+P75KG9aUsd/DgQQDSZRI3NzeFqyFKR7t2QM2awNy5wKBBSldDRAaic8C4fv06KlSoAABYv349/Pz8sGbNGqxYsQJ//vmnvuujDHr48CEAwMfHR+FKiFKR/EqsvT0QGgoMHKhYOURkeDoHDCGEPKPq3r170bhxYwCAp6cnnj9/rt/qKEOS97fw9/dXsBKiVAgh3YYaHPxuGzshE2V7Ov8rr1KlCiZPngx/f38cPHhQnlgrLCyMTfMKCQkJkZfLlSunYCVE7xECGDZM6sgJSINpVayobE1ElCV0bsGYO3cuTp8+jX79+mH06NH49NNPAQAbNmyAr6+v3gukDxs+fLjSJRClJAQwZMi7cLFgAcMFUQ6icwtGuXLltO4iSTJjxgyYm5vrpSjKnCFDhihdApFECOnukHnzpPVffwV69lS2JiLKUpm+EHrq1ClcuXIFAFCqVClUqlRJb0VR5gQGBipdApEULgYOBH76SVpftAjo0UPZmogoy+kcMJ4+fYq2bdvi4MGDcHJyAgC8fv0aderUQUhICPLmzavvGikd58+fl5cLcoIoMgYHD0rhQqUCFi8GunVTuiIiUoDOfTD69++PqKgoXLp0CS9fvsTLly9x8eJFREZGYsCAAYaokdIxKNk4AkmBj0hRtWtLY1wsWcJwQZSD6TxUuKOjI/bu3YuqVatqbT9x4gQaNGiA169f67M+vctuQ4UnzQvTunVrrFu3TuFqKMfSaIC3b6UxLogo2zLoUOEajQaWlpYptltaWsrjY1DWSD5z7fjx45UrhHI2jQbo0weoUwcw8j8wiCjr6Bww6tati4EDB+LRo0fytocPH2Lw4MGoV6+eXouj9P2U1IkOUkdboiyn0QC9ekl3iZw+Dfzzj9IVEZGR0Dlg/Pzzz4iMjISXlxeKFi2KokWLonDhwoiMjNT6wiPDO3nypNIlUE6m0QDffit15DQzA377DfjyS6WrIiIjofNdJJ6enjh9+jT27dsn36ZasmRJDlGtgO3btwMAZs2apXAllONoNNKtp8uWvQsXHTsqXRURGRGdAsbatWuxdetWxMfHo169eujfv7+h6qIPSH57arVq1RSshHIcjQbo3h1YvlwKF6tWAR06KF0VERmZDAeMBQsWoG/fvihWrBhsbW2xceNG3Lp1CzNmzDBkfZSGixcvyss1a9ZUsBLKcR4/BnbtksLF6tXS9OtERO/JcB+Mn3/+GUFBQbh27RrOnj2LlStX4pdffjFkbZSOpFtSa9WqJd+qSpQl8ucHDhwA1q9nuCCiNGV4HAxbW1tcuXIFXl5eAKTbVW1tbXHnzh24u7sbska9yi7jYCSFCh8fH/z7778KV0PZnloNXLgAVKigdCVEpCCDjIMRFxeHXLlyvTvQzAxWVlaIiYnJfKWUKXfu3JGX27dvr1whlDOo1cA33wDVqwO7dytdDRGZCJ06eY4dOxZ2dnbyenx8PKZMmQJHR0d52+ykqZnJYHr16iUv9+nTR8FKKNtLTAQCA4E1awALCyAqSumKiMhEZDhgfP7557h27ZrWNl9fX9y+fVteZ1+ArJGQkAAAyJcvX6qjqhLpRWIi0Lkz8McfUrhYuxZo0ULpqojIRGQ4YISGhhqwDNLF/v37AQBjxoxRuBLKthITga+/lkKFhQWwbh3w1VdKV0VEJkTngbZIWcnnH6lcubKClVC2lZgoDZq1bh1gaSndLdKsmdJVEZGJYcAwMd9//728zAG2yGDMzaVwsWEDh/8mokzReS4SUlZkZKS8bGbG/31kABYW0tDfR44wXBBRpvEbysSEhIQAALp06aJwJZStJCQAv/wi3ZIKSCGjalVlayIik8aAYUISExPl5Tp16ihYCWUr8fFA27ZA377Sg4hIDzIVMA4dOoSvv/4aNWrUwMOHDwEAq1atwuHDh/VaHGlLar0AOMAW6UlSuNi0CbC2ZmdOItIbnQPGn3/+iYCAANja2uLMmTOIi4sDAERERGDq1Kl6L5DeST4OiYUF++fSR4qPB1q3BjZvlsLF5s1Ao0ZKV0VE2YTOAWPy5MlYuHAhFi9erDXIU82aNXH69Gm9Fkfa5s+fDwDo3r27wpWQyYuLA1q1ArZuBWxspP82bKh0VUSUjegcMK5du4bPP/88xXZHR0e8fv06U0XMnz8fXl5esLGxgY+PD06cOJGh40JCQqBSqdC8efNMva+pefXqFQCgePHiCldCJq9jR+Cvv96FiwYNlK6IiLIZnQNGvnz5cPPmzRTbDx8+jCJFiuhcwNq1azFkyBAEBQXh9OnTKF++PAICAvD06dN0j7tz5w6GDRuGWrVq6fyepihpeHBAGqKd6KMEBgKOjlLIqF9f6WqIKBvSOWD06NEDAwcOxPHjx6FSqfDo0SOsXr0aw4YNQ+/evXUuYPbs2ejRowe6dOmCUqVKYeHChbCzs8OyZcvSPEatVqNjx46YMGFCpkKNKbpw4YK8XL58eQUroWyhaVPgzh3A31/pSogom9I5YIwcORIdOnRAvXr1EBUVhc8//xzdu3fHt99+i/79++v0WvHx8Th16hT8k/2SMzMzg7+/P44dO5bmcRMnToSrqyu6deuma/kma9WqVQAAV1dX5MqVS+FqyOTExgLdugHJJieEk5Ni5RBR9qfzrQgqlQqjR4/G8OHDcfPmTURFRaFUqVLInTu3zm/+/PlzqNVquLm5aW13c3PD1atXUz3m8OHDWLp0Kc6ePZuh94iLi5PvdAG0R8I0JXPnzgUA2NnZKVsImZ6YGKB5c2DPHuDYMeDCBWkocCIiA8r0vY5WVlYoVaqUPmv5oDdv3qBTp05YvHgxXFxcMnRMcHAwJkyYYODKss706dOVLoFMSUyMNLbF338DuXIBCxcyXBBRltA5YNSpUwcqlSrN55OmEs8IFxcXmJub48mTJ1rbnzx5gnz58qXY/9atW7hz5w6aNm0qb9NoNACkcSGuXbuGokWLah3z/fffY8iQIfJ6ZGQkPD09M1yjMUh+uYgjeFKGRUdL4WLvXilc7NwJ5JBO0USkPJ0DRoUKFbTWExIScPbsWVy8eBGBgYE6vZaVlRUqV66Mffv2ybeaajQa7Nu3D/369Uuxf4kSJbQ6OwLAmDFj8ObNG8ybNy/V4GBtbQ1ra2ud6jIm8fHxWneNfPLJJwpWQyYjOlqaqGzfPiB3bilcfPaZ0lURUQ6ic8CYM2dOqtvHjx+PqKgonQsYMmQIAgMDUaVKFVSrVg1z587F27dv5cm8OnfujPz58yM4OBg2NjYoU6aM1vFO/++o9v727KJPnz7y8qJFi9JtPSKSfffdu3CxaxdQs6bSFRFRDqO38aa//vprVKtWDTNnztTpuLZt2+LZs2cYN24cwsPDUaFCBezatUvu+Hnv3r0cPS350qVL5eUePXooWAmZlPHjgXPngB9+ADhuChEpQCWEEPp4oVWrVmHEiBF49OiRPl7OYCIjI+Ho6IiIiAg4ODgoXc4HJbVYTJ8+HcOHD1e4GjJqarV2B04hALZ4EZEe6fIdqnMLRosWLbTWhRB4/Pgx/vvvP4wdO1bXl6N0bNu2TV5uxlkuKT1RUcAXXwDt2wPffittY7ggIgXp3IKR1DciiZmZGfLmzYu6deuigQnMZ2BKLRjJ+1toNBr2v6DUvXkDNG4MHD4sDZ514waQwdu4iYh0YbAWDLVajS5duqBs2bJwdnb+qCIpfZcvX5aXBw0axHBBqXvzRppi/cgRaW6R3bsZLojIKOjUe9Lc3BwNGjTI9KyplHG1a9eWl0eOHKlcIWS8IiOlKdaTwsXffwPVqildFRERgEzMRVKmTBncTj6fARlEwYIFAQBeXl4phlInksPF0aPSZZG9e4GqVZWuiohIpnPAmDx5MoYNG4Zt27bh8ePHiIyM1HrQx0tMTMSpU6cAQOfbfimHWLdOmlfE2VkKF1WqKF0REZGWDPfBmDhxIoYOHYrGjRsDAL788kutfgFCCKhUKqjVav1XmcNUTfaXqJeXl3KFkPHq1g149gwICAAqVVK6GiKiFDJ8F4m5uTkeP36MK1eupLufn5+fXgozFFO4i4R3j1CqIiIACwtpXhEiIgUY5C6SpBxi7AHC1CXPe1euXGG4IMnr10CDBtLQ39u2AXZ2SldERJQunfpg8MvO8CIiIuRlU5v1lQzk1Sugfn3g5Eng/Hng3j2lKyIi+iCdxsHw9vb+YMh4+fLlRxWU050/f15ezsWmcHr5UgoXp09L41vs2weUKKF0VUREH6RTwJgwYQIcHR0NVQsBGDVqlNIlkLF4+RLw9wfOnJHCxf79QNmySldFRJQhOgWMdu3awdXV1VC1EIAjR44AeDcOBuVQL15I4eLsWSBvXilclCmjdFVERBmW4T4Y7H9heIcPH5aXOf5FDvfoEXD3LuDqChw4wHBBRCZH57tIyHC2b98uLzds2FDBSkhxZctKA2jZ2AClSildDRGRzjIcMDQajSHrIADTpk0DAAwZMgT29vYKV0NZ7vlzICzs3ZDfHECLiEyYzkOFk+GxI20O9OwZULcuUK8e8O+/SldDRPTRGDCMxMqVK+Xl7t27K1gJZbmnT6VwceGCNJCWs7PSFRERfTSd7iIhw0k+/oWHh4eClVCWSgoXly4BHh5Sh05vb6WrIiL6aGzBMBJXr14FAHTr1k3hSijLPHkC1KkjhYv8+YHQUIYLIso22IJhJHbs2AGAo3fmGM+eSeHiypV34eLTT5WuiohIbxgwjEB8fLy87Ovrq2AllGXs7QEvL+DNG+myCMMFEWUzDBhGYMuWLfJy69atFayEsoyNDbBxo9QHg6O2ElE2xD4YRuDRo0fyspkZ/5dkW48eAT/8ACQNWmdjw3BBRNkWWzCMwMmTJwEA/v7+CldCBvPwodTn4sYNQKMBvv9e6YqIiAyKfy4bgf/++w8AYGHBvJctPXgA1K4thYtChYD27ZWuiIjI4BgwjMCdO3cAABUqVFC0DjKA+/elcHHzptSp8+BB6b9ERNkcA4bCXr9+jbi4OACAj4+PwtWQXiWFi1u3gMKFpVtRCxVSuioioizBgKGwGTNmyMt16tRRsBLSq7g4aV6R27eBIkUYLogox2HAUNjGjRsBAAUKFOAkZ9mJtTUwbpw0MmdoKO8WIaIchwFDQUIIeYhw3kGSDX39NXD+PODpqXQlRERZjgFDQcePH5eXOYNqNhAWBjRsCDx+/G6btbVy9RARKYgBQ0GXLl2Sl2vWrKlgJfTRbt+WOnTu3g306qV0NUREimPAUFBsbCwAwNnZWeFK6KPcuiWFi3v3pD4XCxYoXRERkeI4spOCJk6cCIATnJm0pHDx4AFQvLg0cZm7u9JVEREpji0YCrl27RqePn0KAEhISFC4GsqUmzcBPz8pXJQoId0twnBBRASAAUMRERERKFGihLw+duxYBauhTOveXZpjpGRJqeUiXz6lKyIiMhoMGAr4999/5eVhw4bhs88+U7AayrRVq4CmTRkuiIhSwT4YCoiKipKXk4/kSSYgJgawtZWWPT2BrVuVrYeIyEixBUMBT548AQC2XJiaa9ekjpzr1ildCRGR0WPAUMCmTZsAAFZWVgpXQhl29ap0t8j9+8C0aUBiotIVEREZNQYMBVy7dg0AYGHBK1Qm4coVKVyEhwPlygF79gD8f0dElC4GDAXcv38fABAQEKBwJfRBly9L4eLJE6B8eWDfPsDFRemqiIiMHgNGFouLi5OXmzVrpmAl9EGXLgF16gBPnwIVKjBcEBHpgAEji4WGhsrLhQsXVq4Q+rA1a6RwUbGiFC4++UTpioiITAYvJGexQYMGyctmZsx3Rm3yZMDJCejWDciTR+lqiIhMCr/hslBiYiKuXr0KgK0XRuvmTSA+XlpWqYDhwxkuiIgygQEjC12+fFle3r9/v4KVUKrOnQOqVwfatHkXMoiIKFMYMLLQo0eP5GUvLy/lCqGUzp4F6tYFXrwAHj2SRuwkIqJMY8DIQosWLQIAlC9fXuFKSMuZM0C9esDLl4CPD/D334Cjo9JVERGZNAaMLPTgwQMAwLlz5xSuhGSnT78LF9WrA7t3M1wQEekBA0YWSpqivUuXLgpXQgCAU6ekcPHqFVCjBsMFEZEeMWBkofDwcABApUqVFK6EAABv30qdOX19gV27AAcHpSsiIso2OA5GFjp27BgAwNLSUuFKCADw+efAgQNAyZKAvb3S1RARZSsMGFkkMTERUVFRAIA8HFdBOSdOADY20qRlAFCtmrL1EBFlU7xEkkWSpmgHgAYNGihYSQ72779A/fpSv4v/D3hGRESGwYCRRW7fvi0vO7IjYdY7dgxo0ACIjARKlQIKFFC6IiKibI0BI4ssWLAAAFC7dm1lC8mJjh4FAgKAN28APz9gxw4gd26lqyIiytYYMLLIvXv3AHAEzyx35Mi7cFG7NrB9O5Arl9JVERFlewwYWUQIAQBo06aNwpXkIKdOAQ0bAlFR0jDgDBdERFmGd5FkgZcvX8rLZcqUUbCSHMbbGyhfXrprZOtWwM5O6YqIiHIMBowscOvWLXnZ09NTwUpyGHt7YOdOwNyc4YKIKIvxEkkWOH/+vNIl5BwHDwIzZrxbt7dnuCAiUgBbMLLAzJkzAQAFeGukYR04AHzxBRAdDRQsCLRtq3RFREQ5FlswssDV/w/q5OrqqnAl2dj+/UCTJlK4aNgQaNZM6YqIiHI0BgwDi4+Pl5eHDBmiYCXZ2L59UstFTAzQuDGwaZPUsZOIiBTDSyQGdvfuXXm5ZcuWClaSTe3dCzRtCsTGSuFi40bA2lrpqoiIcjy2YBjYxYsX5WUb/lWtXw8fAl9+KYWLJk0YLoiIjAhbMAzs4MGDAABnZ2eFK8mG8ucHpk2TWjHWr2e4ICIyImzBMLCkIcIrV66scCXZyP9HRQUADBgAbN7McEFEZGQYMAwsIiICAFCqVCmFK8kmdu4EatUCXr16t82MP8ZERMaGv5kNbP/+/QCAokWLKlxJNrBjB9C8uTSBWfLBtIiIyOgwYBjQ5cuX5WUXFxcFK8kGtm0DvvoKiI8HWrYEJkxQuiIiIkqHUQSM+fPnw8vLCzY2NvDx8cGJEyfS3Hfx4sWoVasWnJ2d4ezsDH9//3T3V9KKFSvk5fbt2ytXiKn76y+gRQspXLRqBfzxB2BpqXRVRESUDsUDxtq1azFkyBAEBQXh9OnTKF++PAICAvD06dNU9w8NDUX79u1x4MABHDt2DJ6enmjQoAEePnyYxZV/2H///QcAqFixIlQqlcLVmKitW6UWi4QEoHVrYM0ahgsiIhOgEiJ5l/ys5+Pjg6pVq+Lnn38GAGg0Gnh6eqJ///4YOXLkB49Xq9VwdnbGzz//jM6dO39w/8jISDg6OiIiIgIODg4fXX96cufOjbdv36JXr15YsGCBQd8rW4qLA0qUAO7ckeYV+f13wIJ3VhMRKUWX71BFWzDi4+Nx6tQp+Pv7y9vMzMzg7++PY8eOZeg1oqOjkZCQgDx58hiqzEx7+/YtAKBSpUoKV2KirK2B3buB/v0ZLoiITIyiv7GfP38OtVoNNzc3re1ubm7yBGEfMmLECHh4eGiFlOTi4uIQFxcnr0dGRma+YB3ExsbKy1WqVMmS98w2nj8HkjrFensDP/6obD1ERKQzxftgfIxp06YhJCQEmzZtSnMY7uDgYDg6OsoPT0/PLKkt+RwkFSpUyJL3zBY2bAAKF5ZaLoiIyGQpGjBcXFxgbm6OJ0+eaG1/8uQJ8uXLl+6xM2fOxLRp07Bnzx6UK1cuzf2+//57REREyI/79+/rpfYPWb9+PQDA3NycHTwzav16oF07ICpKChpERGSyFA0YVlZWqFy5Mvbt2ydv02g02LdvH2rUqJHmcdOnT8ekSZOwa9euD15+sLa2hoODg9YjKyS/LEMZsG4d0L49oFYDnTsDCxcqXREREX0ExXvNDRkyBIGBgahSpQqqVauGuXPn4u3bt+jSpQsAoHPnzsifPz+Cg4MBAD/88APGjRuHNWvWwMvLC+Hh4QCkOzZy586t2Od4X1IfksGDBytciQkICQG+/loKF4GBwNKlgLm50lUREdFHUDxgtG3bFs+ePcO4ceMQHh6OChUqYNeuXXLHz3v37sEs2VwTCxYsQHx8PFq1aqX1OkFBQRg/fnxWlp6u27dvAwASEhIUrsTI/fGHFC40GqBLF2DxYoYLIqJsQPGAAQD9+vVDv379Un0uNDRUa/3OnTuGL0gPHj16BIDTtH/Qzp1SuOjaVQoXnLiMiChbMIqAkR0lXbopX768wpUYuWXLAD8/qfWC4YKIKNvgb3QDK1iwoNIlGJ/Dh6X+FoA0eFa3bgwXRETZDH+rG8CzZ8/k5eLFiytYiRFauRL4/HMpVCSFDCIiynYYMAwgeT+RXLlyKVeIsVmxQroUIgRgawtwfBAiomyLAcMAOAZGKpYtkzpyCgH07g3Mn8/LIkRE2Rh/wxtA0i2qZcqUUbgSI7F0KdC9uxQu+vRhuCAiygH4W94ATp8+DQC4fv26wpUYgeThol8/4OefeWmEiCgH4G2qBuDq6goA8PLyUrYQY+DqClhaSpdF5s5luCAiyiEYMAxg586dAIAGDRooXIkRaNoUOHUKKFOG4YKIKAfhJRIDSBoe/NWrVwpXopCVK4Fbt96tly3LcEFElMMwYBjA48ePAeTQTp6//AJ88w1Qpw7w/LnS1RARkUIYMAwgaaCtpL4YOcb8+UDfvtJy27bAJ58oWw8RESmGAUPPhBCIiYkBAHz66acKV5OFfvpJuksEAL77Dpg+nZdFiIhyMAYMPYuKipKXc8wlkh9/BAYMkJZHjACmTWO4ICLK4Rgw9Cz5PCQ5Yqr2338HBg6Ulr//HggOZrggIiLepqpvSS0Yn3zyCVQ54Yu2YUOgXDnpdtRJkxguiIgIAAOG3p04cQIAEB0drXAlWcTFBTh6FLCzY7ggIiIZL5HoWdJEZ0kdPbOlGTOAhQvfrefKxXBBRERa2IKhZ0eOHAEAdO7cWeFKDOSHH4CRI6XlqlWBypWVrYeIiIwSWzD07P79+wCAp0+fKlyJAUyb9i5cTJjAcEFERGliwNAzW1tbAIC3t7fClejZ1KnSXSKA1Jlz3Dhl6yEiIqPGSyR69vfffwMAKlSooGwh+jRlCjBmzLvlUaOUrYeIiIweA4YeJU1yBgCFChVSsBI9+uefd+EieSsGERFROhgw9Cj5KJ6fffaZgpXo0eefS5dD7OykUTqJiIgygAFDj/777z952crKSsFKPpIQQEICkPQZJkxQth4iIjI57OSpRxs2bFC6hI8nBBAUBAQEADllsDAiItI7Bgw9Mjc3BwD4+fkpXEkmCSFdDpk0CQgNBbZtU7oiIiIyUbxEokeRkZEAgAYNGihcSSYIIXXmnDpVWp89G2jTRtmaiIjIZDFg6NHhw4cBABYWJnZahZBuPZ02TVqfMwcYNEjRkoiIyLSZ2Dehcbt79y4AwMzMhK48CSHdevrDD9L6vHnAgAHK1kRERCbPhL4JjV+BAgUAAMWKFVO4Eh08egQsWiQt//QTwwUREekFWzD06MGDBwAADw8PhSvRQf78wL59wH//AT16KF0NERFlEwwYemRmZgaNRoO8efMqXUr6hADu3AEKF5bWK1aUHkRERHrCSyR6otFooNFoAAC5cuVSuJp0CAEMHQqULw8cO6Z0NURElE0xYOhJYmKivGxpaalgJekQAhg8WLpL5M0b4NIlpSsiIqJsipdI9CR5wDDK21SFAAYOlDpyAlLHzu7dla2JiIiyLSP8JjRNz549k5etra0VrCQVQgD9+wPz50vrixczXBARkUExYOhJ8plUjeoSiRBAv37AL78AKhWwZAnQtavSVRERUTbHgKEnsbGxAIzwFtWEBOmOEZUKWLoU6NJF6YqIiCgHYMDQkwsXLihdQuqsrIA//wQOHpRmSCUiIsoCvItET5ImOouJiVG4EgAaDbB+vXR5BABsbBguiIgoSzFg6MnVq1cBADVq1FC2EI0G6NVLmgn1u++UrYWIiHIsXiLREzs7OwAKd/DUaICePaW+FmZmQIUKytVCREQ5GgOGnsyaNQsAULZsWWUK0GikuUSWLZPCxapVQIcOytRCREQ5Hi+R6ImnpycAICIiIuvfXK0GunV7Fy5Wr2a4ICIiRTFg6Mn9+/cBAJ06dcr6N+/ZE1ixAjA3B9asAdq1y/oaiIiIkmHA0IOkSc6Ad30xslSdOtLtqGvWAG3bZv37ExERvYd9MPQgLi5OXk66VJKlvv4a8PMDlHhvIiKiVLAFQw+SB4wsmYckMREYORJ4/PjdNoYLIiIyIgwYevDmzRt52crKyrBvlpgIdO4M/PCDNHhWsllciYiIjAUvkejB27dv5WWVSmW4N0pMBDp1AkJCAAsLYOJE6b9ERERGht9OehAdHQ0AcHd3N9ybJCYCHTsC69YBlpbSUODNmhnu/YiIiD4CA4YePHnyBID2pRK9SkiQwsX69VK4+PNPoGlTw7wXERGRHrAPhh4Y9LIIAIwYIYULKytg40aGCyIiMnoMGHoQHx8PAChTpoxh3mDIEKB0aSlcfPGFYd6DiIhIj3iJRA9u374NQM8TnQkBJLWMFCgAnD3LDp1ERGQy2IKhB7ly5QLwbsr2jxYfD7RuDaxd+24bwwUREZkQBgw9SEhIAADUqlXr418sLg5o1UrqyNmtG/Ds2ce/JhERURbjn8V6kBQwPvoSSVK42LYNsLGR+lzkzauHComIiLIWA4YeXLx4EcBHBoy4OKBlS2D7dilcbN0K1K+vpwqJiIiyFgOGHuTOnRsAEBYWlrkXiI2VwsWOHVK4+OsvwN9fjxUSERFlLfbB0AMzM+k0Vq9ePXMvsHKlFC5sbaXLIwwXRERk4tiCoQcajQbAR1wi6dkTuH4daNIEqFtXj5UREREpgwFDD4QQAHQc0TMmBjA3l0bnVKmAWbMMVB0REVHW4yUSPdA5YMTESBOVtWkjjXlBRESUzbAFQw+SAkZSX4x0RUdL4WLvXiBXLuDqVaBcOQNXSERElLUYMPQgqQ/GB1swoqOlicr275fCxc6dDBdERJQt8RKJHmToEsnbt9JEZfv3A7lzA7t2AfoY+ZOIiMgIsQVDDz4YMJLCRWgoYG8vhQtf36wrkIiIKIsxYOjBB/tgXL0KnDwphYvdu4EaNbKwOiIioqzHgKEHH+yDUbmyNAS4lRXDBRER5QgMGHqQ6iWSqCjgwQOgRAlp3c9PgcqIiIiUwU6eepAiYLx5AzRqJHXivHBBwcqIiIiUwYChB1p9MCIjgYYNgcOHgYQEaSIzIiKiHMYoAsb8+fPh5eUFGxsb+Pj44MSJE+nuv379epQoUQI2NjYoW7YsduzYkUWVpi6pD4Z1XJwULo4eBZycpMG0qlZVtDYiIiIlKB4w1q5diyFDhiAoKAinT59G+fLlERAQgKdPn6a6/9GjR9G+fXt069YNZ86cQfPmzdG8eXNcvHgxiyt/RwgBBwBtly8Hjh0DnJ2lcFGlimI1ERERKUklktr3FeLj44OqVavi559/BiC1Bnh6eqJ///4YOXJkiv3btm2Lt2/fYtu2bfK26tWro0KFCli4cOEH3y8yMhKOjo6IiIiAg4ODXj5D7w4dEPjHH6gOvAsXlSrp5bWJiIiMhS7foYq2YMTHx+PUqVPw9/eXt5mZmcHf3x/Hjh1L9Zhjx45p7Q8AAQEBae4fFxeHyMhIrYe+aQAkAoixswP27WO4ICKiHE/RgPH8+XOo1Wq4ublpbXdzc0N4eHiqx4SHh+u0f3BwMBwdHeWHp6enfopPpmDp0phYvTr2jx8PVKyo99cnIiIyNYr3wTC077//HhEREfLj/v37en+P0aNHY8+xY2gyfLjeX5uIiMgUKTrQlouLC8zNzfHkyROt7U+ePEG+fPlSPSZfvnw67W9tbQ1ra2v9FExEREQZomgLhpWVFSpXrox9+/bJ2zQaDfbt24caaQypXaNGDa39AeDvv/9Oc38iIiLKeooPFT5kyBAEBgaiSpUqqFatGubOnYu3b9+iS5cuAIDOnTsjf/78CA4OBgAMHDgQfn5+mDVrFpo0aYKQkBD8999/WLRokZIfg4iIiJJRPGC0bdsWz549w7hx4xAeHo4KFSpg165dckfOe/fuac1S6uvrizVr1mDMmDEYNWoUihUrhs2bN6NMmTJKfQQiIiJ6j+LjYGQ1Q4yDQURElBOYzDgYRERElD0xYBAREZHeMWAQERGR3jFgEBERkd4xYBAREZHeMWAQERGR3jFgEBERkd4xYBAREZHeMWAQERGR3jFgEBERkd4xYBAREZHeMWAQERGR3jFgEBERkd4pPl17VkuaPDYyMlLhSoiIiExL0ndnRiZiz3EB482bNwAAT09PhSshIiIyTW/evIGjo2O6+6hERmJINqLRaPDo0SPY29tDpVLp5TUjIyPh6emJ+/fvw8HBQS+vmdPxnOofz6l+8XzqH8+pfhnifAoh8ObNG3h4eMDMLP1eFjmuBcPMzAwFChQwyGs7ODjwH4We8ZzqH8+pfvF86h/PqX7p+3x+qOUiCTt5EhERkd4xYBAREZHeMWDogbW1NYKCgmBtba10KdkGz6n+8ZzqF8+n/vGc6pfS5zPHdfIkIiIiw2MLBhEREekdAwYRERHpHQMGERER6R0DBhEREekdA0YGzZ8/H15eXrCxsYGPjw9OnDiR7v7r169HiRIlYGNjg7Jly2LHjh1ZVKnp0OWcLl68GLVq1YKzszOcnZ3h7+//wf8HOY2uP6NJQkJCoFKp0Lx5c8MWaIJ0PaevX79G37594e7uDmtra3h7e/PffjK6ns+5c+eiePHisLW1haenJwYPHozY2Ngsqtb4/fPPP2jatCk8PDygUqmwefPmDx4TGhqKSpUqwdraGp9++ilWrFhhuAIFfVBISIiwsrISy5YtE5cuXRI9evQQTk5O4smTJ6nuf+TIEWFubi6mT58uLl++LMaMGSMsLS3FhQsXsrhy46XrOe3QoYOYP3++OHPmjLhy5Yr45ptvhKOjo3jw4EEWV26cdD2fScLCwkT+/PlFrVq1RLNmzbKmWBOh6zmNi4sTVapUEY0bNxaHDx8WYWFhIjQ0VJw9ezaLKzdOup7P1atXC2tra7F69WoRFhYmdu/eLdzd3cXgwYOzuHLjtWPHDjF69GixceNGAUBs2rQp3f1v374t7OzsxJAhQ8Tly5fFTz/9JMzNzcWuXbsMUh8DRgZUq1ZN9O3bV15Xq9XCw8NDBAcHp7p/mzZtRJMmTbS2+fj4iG+//dagdZoSXc/p+xITE4W9vb1YuXKloUo0KZk5n4mJicLX11csWbJEBAYGMmC8R9dzumDBAlGkSBERHx+fVSWaFF3PZ9++fUXdunW1tg0ZMkTUrFnToHWaqowEjO+++06ULl1aa1vbtm1FQECAQWriJZIPiI+Px6lTp+Dv7y9vMzMzg7+/P44dO5bqMceOHdPaHwACAgLS3D+nycw5fV90dDQSEhKQJ08eQ5VpMjJ7PidOnAhXV1d069YtK8o0KZk5p1u3bkWNGjXQt29fuLm5oUyZMpg6dSrUanVWlW20MnM+fX19cerUKfkyyu3bt7Fjxw40btw4S2rOjrL6uynHTXamq+fPn0OtVsPNzU1ru5ubG65evZrqMeHh4anuHx4ebrA6TUlmzun7RowYAQ8PjxT/WHKizJzPw4cPY+nSpTh79mwWVGh6MnNOb9++jf3796Njx47YsWMHbt68iT59+iAhIQFBQUFZUbbRysz57NChA54/f47PPvsMQggkJiaiV69eGDVqVFaUnC2l9d0UGRmJmJgY2Nra6vX92IJBJmfatGkICQnBpk2bYGNjo3Q5JufNmzfo1KkTFi9eDBcXF6XLyTY0Gg1cXV2xaNEiVK5cGW3btsXo0aOxcOFCpUszSaGhoZg6dSp++eUXnD59Ghs3bsT27dsxadIkpUujDGILxge4uLjA3NwcT5480dr+5MkT5MuXL9Vj8uXLp9P+OU1mzmmSmTNnYtq0adi7dy/KlStnyDJNhq7n89atW7hz5w6aNm0qb9NoNAAACwsLXLt2DUWLFjVs0UYuMz+j7u7usLS0hLm5ubytZMmSCA8PR3x8PKysrAxaszHLzPkcO3YsOnXqhO7duwMAypYti7dv36Jnz54YPXo0zMz497Gu0vpucnBw0HvrBcAWjA+ysrJC5cqVsW/fPnmbRqPBvn37UKNGjVSPqVGjhtb+APD333+nuX9Ok5lzCgDTp0/HpEmTsGvXLlSpUiUrSjUJup7PEiVK4MKFCzh79qz8+PLLL1GnTh2cPXsWnp6eWVm+UcrMz2jNmjVx8+ZNOawBwPXr1+Hu7p6jwwWQufMZHR2dIkQkhTfBKbQyJcu/mwzSdTSbCQkJEdbW1mLFihXi8uXLomfPnsLJyUmEh4cLIYTo1KmTGDlypLz/kSNHhIWFhZg5c6a4cuWKCAoK4m2q79H1nE6bNk1YWVmJDRs2iMePH8uPN2/eKPURjIqu5/N9vIskJV3P6b1794S9vb3o16+fuHbtmti2bZtwdXUVkydPVuojGBVdz2dQUJCwt7cXf/zxh7h9+7bYs2ePKFq0qGjTpo1SH8HovHnzRpw5c0acOXNGABCzZ88WZ86cEXfv3hVCCDFy5EjRqVMnef+k21SHDx8urly5IubPn8/bVI3BTz/9JAoWLCisrKxEtWrVxL///is/5+fnJwIDA7X2X7dunfD29hZWVlaidOnSYvv27VlcsfHT5ZwWKlRIAEjxCAoKyvrCjZSuP6PJMWCkTtdzevToUeHj4yOsra1FkSJFxJQpU0RiYmIWV228dDmfCQkJYvz48aJo0aLCxsZGeHp6ij59+ohXr15lfeFG6sCBA6n+Xkw6j4GBgcLPzy/FMRUqVBBWVlaiSJEiYvny5Qarj9O1ExERkd6xDwYRERHpHQMGERER6R0DBhEREekdAwYRERHpHQMGERER6R0DBhEREekdAwYRERHpHQMGUTazYsUKODk5KV1GpqlUKmzevDndfb755hs0b948S+ohosxhwCAyQt988w1UKlWKx82bN5UuDStWrJDrMTMzQ4ECBdClSxc8ffpUL6//+PFjNGrUCABw584dqFSqFNPKz5s3DytWrNDL+6Vl/Pjx8uc0NzeHp6cnevbsiZcvX+r0OgxDlFNxNlUiI9WwYUMsX75ca1vevHkVqkabg4MDrl27Bo1Gg3PnzqFLly549OgRdu/e/dGvnZFZhx0dHT/6fTKidOnS2Lt3L9RqNa5cuYKuXbsiIiICa9euzZL3JzJlbMEgMlLW1tbIly+f1sPc3ByzZ89G2bJlkStXLnh6eqJPnz6IiopK83XOnTuHOnXqwN7eHg4ODqhcuTL+++8/+fnDhw+jVq1asLW1haenJwYMGIC3b9+mW5tKpUK+fPng4eGBRo0aYcCAAdi7dy9iYmKg0WgwceJEFChQANbW1qhQoQJ27dolHxsfH49+/frB3d0dNjY2KFSoEIKDg7VeO+kSSeHChQEAFStWhEqlQu3atQFotwosWrQIHh4eWrOYAkCzZs3QtWtXeX3Lli2oVKkSbGxsUKRIEUyYMAGJiYnpfk4LCwvky5cP+fPnh7+/P1q3bo2///5bfl6tVqNbt24oXLgwbG1tUbx4ccybN09+fvz48Vi5ciW2bNkit4aEhoYCAO7fv482bdrAyckJefLkQbNmzXDnzp106yEyJQwYRCbGzMwMP/74Iy5duoSVK1di//79+O6779Lcv2PHjihQoABOnjyJU6dOYeTIkbC0tAQA3Lp1Cw0bNkTLli1x/vx5rF27FocPH0a/fv10qsnW1hYajQaJiYmYN28eZs2ahZkzZ+L8+fMICAjAl19+iRs3bgAAfvzxR2zduhXr1q3DtWvXsHr1anh5eaX6uidOnAAA7N27F48fP8bGjRtT7NO6dWu8ePECBw4ckLe9fPkSu3btQseOHQEAhw4dQufOnTFw4EBcvnwZv/76K1asWIEpU6Zk+DPeuXMHu3fv1pp6XaPRoECBAli/fj0uX76McePGYdSoUVi3bh0AYNiwYWjTpg0aNmyIx48f4/Hjx/D19UVCQgICAgJgb2+PQ4cO4ciRI8idOzcaNmyI+Pj4DNdEZNQMNo0aEWVaYGCgMDc3F7ly5ZIfrVq1SnXf9evXi08++UReX758uXB0dJTX7e3txYoVK1I9tlu3bqJnz55a2w4dOiTMzMxETExMqse8//rXr18X3t7eokqVKkIIITw8PMSUKVO0jqlataro06ePEEKI/v37i7p16wqNRpPq6wMQmzZtEkIIERYWJgCIM2fOaO3z/uyvzZo1E127dpXXf/31V+Hh4SHUarUQQoh69eqJqVOnar3GqlWrhLu7e6o1CCFNF25mZiZy5colbGxs5JkqZ8+eneYxQgjRt29f0bJlyzRrTXrv4sWLa52DuLg4YWtrK3bv3p3u6xOZCvbBIDJSderUwYIFC+T1XLlyAZD+mg8ODsbVq1cRGRmJxMRExMbGIjo6GnZ2dileZ8iQIejevTtWrVolN/MXLVoUgHT55Pz581i9erW8vxACGo0GYWFhKFmyZKq1RUREIHfu3NBoNIiNjcVnn32GJUuWIDIyEo8ePULNmjW19q9ZsybOnTsHQLq8Ub9+fRQvXhwNGzbEF198gQYNGnzUuerYsSN69OiBX375BdbW1li9ejXatWsHMzMz+XMeOXJEq8VCrVane94AoHjx4ti6dStiY2Px+++/4+zZs+jfv7/WPvPnz8eyZctw7949xMTEID4+HhUqVEi33nPnzuHmzZuwt7fX2h4bG4tbt25l4gwQGR8GDCIjlStXLnz66ada2+7cuYMvvvgCvXv3xpQpU5AnTx4cPnwY3bp1Q3x8fKpflOPHj0eHDh2wfft27Ny5E0FBQQgJCcFXX32FqKgofPvttxgwYECK4woWLJhmbfb29jh9+jTMzMzg7u4OW1tbAEBkZOQHP1elSpUQFhaGnTt3Yu/evWjTpg38/f2xYcOGDx6blqZNm0IIge3bt6Nq1ao4dOgQ5syZIz8fFRWFCRMmoEWLFimOtbGxSfN1rays5P8H06ZNQ5MmTTBhwgRMmjQJABASEoJhw4Zh1qxZqFGjBuzt7TFjxgwcP3483XqjoqJQuXJlrWCXxFg68hJ9LAYMIhNy6tQpaDQazJo1S/7rPOl6f3q8vb3h7e2NwYMHo3379li+fDm++uorVKpUCZcvX04RZD7EzMws1WMcHBzg4eGBI0eOwM/PT95+5MgRVKtWTWu/tm3bom3btmjVqhUaNmyIly9fIk+ePFqvl9TfQa1Wp1uPjY0NWrRogdWrV+PmzZsoXrw4KlWqJD9fqVIlXLt2TefP+b4xY8agbt266N27t/w5fX190adPH3mf91sgrKysUtRfqVIlrF27Fq6urnBwcPiomoiMFTt5EpmQTz/9FAkJCfjpp59w+/ZtrFq1CgsXLkxz/5iYGPTr1w+hoaG4e/cujhw5gpMnT8qXPkaMGIGjR4+iX79+OHv2LG7cuIEtW7bo3MkzueHDh+OHH37A2rVrce3aNYwcORJnz57FwIEDAQCzZ8/GH3/8gatXr+L69etYv3498uXLl+rgYK6urrC1tcWuXbvw5MkTREREpPm+HTt2xPbt27Fs2TK5c2eScePG4bfffsOECRNw6dIlXLlyBSEhIRgzZoxOn61GjRooV64cpk6dCgAoVqwY/vvvP+zevRvXr1/H2LFjcfLkSa1jvLy8cP78eVy7dg3Pnz9HQkICOnbsCBcXFzRr1gyHDh1CWFgYQkNDMWDAADx48ECnmoiMltKdQIgopdQ6BiaZPXu2cHd3F7a2tiIgIED89ttvAoB49eqVEEK7E2ZcXJxo166d8PT0FFZWVsLDw0P069dPqwPniRMnRP369UXu3LlFrly5RLly5VJ00kzu/U6e71Or1WL8+PEif/78wtLSUpQvX17s3LlTfn7RokWiQoUKIleuXMLBwUHUq1dPnD59Wn4eyTp5CiHE4sWLhaenpzAzMxN+fn5pnh+1Wi3c3d0FAHHr1q0Ude3atUv4+voKW1tb4eDgIKpVqyYWLVqU5ucICgoS5cuXT7H9jz/+ENbW1uLevXsiNjZWfPPNN8LR0VE4OTmJ3r17i5EjR2od9/TpU/n8AhAHDhwQQgjx+PFj0blzZ+Hi4iKsra1FkSJFRI8ePURERESaNRGZEpUQQigbcYiIiCi74SUSIiIi0jsGDCIiItI7BgwiIiLSOwYMIiIi0jsGDCIiItI7BgwiIiLSOwYMIiIi0jsGDCIiItI7BgwiIiLSOwYMIiIi0jsGDCIiItI7BgwiIiLSu/8B0kmPlrsvtSIAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculate AUC\n",
        "auc = roc_auc_score(test_y, test[\"shot_statsbomb_xg\"])\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(test_y, test[\"shot_statsbomb_xg\"])\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(fpr, tpr, color='black', label=f'SB ROC Curve (AUC = {auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
