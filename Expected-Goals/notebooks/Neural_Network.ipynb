{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4ba190db",
      "metadata": {
        "id": "4ba190db"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "133e8d59",
      "metadata": {
        "id": "133e8d59"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import ast\n",
        "import math\n",
        "import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Input\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import sklearn.isotonic as sk_i\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ea16aa4",
      "metadata": {
        "id": "2ea16aa4"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6SMrbzowm2VT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SMrbzowm2VT",
        "outputId": "d0e1fd0f-b88b-4021-b9ae-3ae40ea065b7"
      },
      "outputs": [],
      "source": [
        "PROJECT_ROOT = Path.cwd().resolve().parent\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "PROCESSED_DIR = DATA_DIR / \"processed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4df62e30",
      "metadata": {
        "id": "4df62e30"
      },
      "outputs": [],
      "source": [
        "football_model_df = pd.read_pickle(PROCESSED_DIR / 'football_model_processed.pickle')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0985d459",
      "metadata": {
        "id": "0985d459"
      },
      "source": [
        "# Looking at data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8a635472",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a635472",
        "outputId": "d2d919ad-17ef-4ac7-e0f7-646f30584150"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['under_pressure', 'shot_open_goal', 'shot_first_time',\n",
              "       'shot_one_on_one', 'shot_outcome_encoded', 'player_x', 'player_y',\n",
              "       'distance_from_goal_center', 'distance_from_goal_left_post',\n",
              "       'distance_from_goal_right_post', 'body_part_head', 'body_part_other',\n",
              "       'body_part_foot', 'shot_technique_backheel',\n",
              "       'shot_technique_diving_header', 'shot_technique_half_volley',\n",
              "       'shot_technique_lob', 'shot_technique_normal',\n",
              "       'shot_technique_overhead_kick', 'shot_technique_volley',\n",
              "       'play_pattern_from_corner', 'play_pattern_from_counter',\n",
              "       'play_pattern_from_free_kick', 'play_pattern_from_goal_kick',\n",
              "       'play_pattern_from_keeper', 'play_pattern_from_kick_off',\n",
              "       'play_pattern_from_throw_in', 'play_pattern_other',\n",
              "       'play_pattern_regular_play', 'shot_type_free_kick',\n",
              "       'shot_type_open_play', 'goalkeeper_x', 'goalkeeper_y',\n",
              "       'gk_distance_from_goal_center', 'gk_distance_from_goal_left_post',\n",
              "       'gk_distance_from_goal_right_post', 'shot_angle', 'distance_player_gk'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "football_model_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c8178d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c8178d6f",
        "outputId": "cb65947c-b4df-4c84-bc16-a706e19dd52a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1200 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15, 12))  # increase figure size\n",
        "sns.heatmap(football_model_df.corr(), annot=False, cmap=\"coolwarm\", center=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d05b33",
      "metadata": {
        "id": "82d05b33"
      },
      "source": [
        "# Preparing Data for training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125e8733",
      "metadata": {
        "id": "125e8733"
      },
      "source": [
        "Splitting train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9df5f83e",
      "metadata": {
        "id": "9df5f83e"
      },
      "outputs": [],
      "source": [
        "X = football_model_df.drop(\"shot_outcome_encoded\", axis = 1)\n",
        "y = football_model_df[\"shot_outcome_encoded\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b1751dd9",
      "metadata": {
        "id": "b1751dd9"
      },
      "outputs": [],
      "source": [
        "# setting a seed\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# splitting the data\n",
        "train_x, test_x , train_y, test_y = train_test_split(\n",
        "    X, y,\n",
        "    test_size = 0.25,\n",
        "    random_state= 123,\n",
        "    stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "Mtm5jifSmwde",
      "metadata": {
        "id": "Mtm5jifSmwde"
      },
      "outputs": [],
      "source": [
        "train_x, train_y = tf.convert_to_tensor(train_x, dtype=tf.float32), tf.convert_to_tensor(train_y, dtype=tf.float32)\n",
        "test_x, test_y = tf.convert_to_tensor(test_x, dtype=tf.float32), tf.convert_to_tensor(test_y, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91aa2fa6",
      "metadata": {
        "id": "91aa2fa6"
      },
      "source": [
        "# Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-87hAuFrDlr8",
      "metadata": {
        "id": "-87hAuFrDlr8"
      },
      "source": [
        "## Defining Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "56d253ea",
      "metadata": {
        "id": "56d253ea"
      },
      "outputs": [],
      "source": [
        "def build_model(hl: int = 1, nodes: int = 32, activation: str = 'relu', epochs: int = 5, batches: int = 100):\n",
        "\n",
        "    # initiating model\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # adding input layer\n",
        "    model.add(Input(shape=(37,), name = \"Input_Layer\")) # 37 input columns\n",
        "\n",
        "    # adding hidden layers\n",
        "    for i in range(hl):\n",
        "        model.add(Dense(units = nodes, activation = activation, name = f\"HL_{i+1}\"))\n",
        "\n",
        "    # add output layer\n",
        "    model.add(Dense(units = 1, activation = \"sigmoid\", name = \"Output_Layer\"))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"binary_accuracy\", tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "189d9dad",
      "metadata": {
        "id": "189d9dad"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(hl: int = 1,\n",
        "                             nodes: int = 32,\n",
        "                             activation: str = 'relu',\n",
        "                             epochs: int = 5,\n",
        "                             batches: int = 100,\n",
        "                             train_x = train_x,\n",
        "                             train_y = train_y,\n",
        "                             test_x = test_x,\n",
        "                             test_y = test_y\n",
        "                             ):\n",
        "\n",
        "    model = build_model(hl, nodes, activation, epochs, batches)\n",
        "\n",
        "    # training the model\n",
        "    history = model.fit(\n",
        "        train_x,\n",
        "        train_y,\n",
        "        epochs = epochs,\n",
        "        batch_size = batches,\n",
        "        validation_data = (test_x, test_y),\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    # getting accuracies\n",
        "    eval_accuracies = model.evaluate(test_x, test_y)\n",
        "\n",
        "    return model, history, eval_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "XvGeXqOLDr-k",
      "metadata": {
        "id": "XvGeXqOLDr-k"
      },
      "outputs": [],
      "source": [
        "def k_fold_cross_validation(hl: int = 1,\n",
        "                            nodes: int = 32,\n",
        "                            activation: str = 'relu',\n",
        "                            epochs: int = 5,\n",
        "                            batches: int = 100,\n",
        "                            k: int = 5,\n",
        "                            train_x = train_x,\n",
        "                            train_y = train_y\n",
        "                            ):\n",
        "\n",
        "    # set seed\n",
        "    seed = 123\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
        "\n",
        "    # Create empty lists to store metrics from each fold\n",
        "    fold_losses = []\n",
        "    fold_accuracies = []\n",
        "    fold_aucs = []\n",
        "\n",
        "    # Convert train_x and train_y to numpy for StratifiedKFold\n",
        "    train_x_np = train_x.numpy()\n",
        "    train_y_np = train_y.numpy()\n",
        "\n",
        "    # Loop through the splits\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(train_x_np, train_y_np)):\n",
        "        print(f\"\\n--- Starting Fold {fold+1}/{k} ---\")\n",
        "\n",
        "        # Create training and validation datasets for the current fold\n",
        "        fold_train_x = train_x_np[train_index]\n",
        "        fold_train_y = train_y_np[train_index]\n",
        "        fold_val_x = train_x_np[val_index]\n",
        "        fold_val_y = train_y_np[val_index]\n",
        "\n",
        "        # Convert to TensorFlow tensors\n",
        "        fold_train_x = tf.convert_to_tensor(fold_train_x, dtype=tf.float32)\n",
        "        fold_train_y = tf.convert_to_tensor(fold_train_y, dtype=tf.float32)\n",
        "        fold_val_x = tf.convert_to_tensor(fold_val_x, dtype=tf.float32)\n",
        "        fold_val_y = tf.convert_to_tensor(fold_val_y, dtype=tf.float32)\n",
        "\n",
        "        # Train and evaluate the model for the current fold\n",
        "        model, history, eval_accuracies = train_and_evaluate_model(\n",
        "            hl=hl,\n",
        "            nodes=nodes,\n",
        "            activation=activation,\n",
        "            epochs=epochs,\n",
        "            batches=batches,\n",
        "            train_x=fold_train_x,\n",
        "            train_y=fold_train_y,\n",
        "            test_x=fold_val_x,\n",
        "            test_y=fold_val_y\n",
        "        )\n",
        "\n",
        "        # eval_accuracies contains [loss, binary_accuracy, auc]\n",
        "        fold_losses.append(eval_accuracies[0])\n",
        "        fold_accuracies.append(eval_accuracies[1])\n",
        "        fold_aucs.append(eval_accuracies[2])\n",
        "\n",
        "        print(f\"Fold {fold+1} Metrics: Loss = {eval_accuracies[0]:.4f}, Accuracy = {eval_accuracies[1]:.4f}, AUC = {eval_accuracies[2]:.4f}\")\n",
        "\n",
        "    print(\"\\n--- K-Fold Cross-Validation Complete ---\")\n",
        "    print(f\"Average Loss: {np.mean(fold_losses):.4f}\")\n",
        "    print(f\"Average Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "    print(f\"Average AUC: {np.mean(fold_aucs):.4f}\")\n",
        "\n",
        "    return fold_losses, fold_accuracies, fold_aucs, model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4BBxgx0XgUrf",
      "metadata": {
        "id": "4BBxgx0XgUrf"
      },
      "source": [
        "# Looking at Training results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XIXijxpkDoEN",
      "metadata": {
        "id": "XIXijxpkDoEN"
      },
      "source": [
        "## Training the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FD-pBaOOGhGY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD-pBaOOGhGY",
        "outputId": "263c70df-0c15-4a58-f2f4-190631a56439"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Performing training for: ('relu', 1, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6250 - binary_accuracy: 0.7419 - loss: 2.9174 - val_auc: 0.7233 - val_binary_accuracy: 0.9023 - val_loss: 0.2893\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7684 - binary_accuracy: 0.8985 - loss: 0.2768 - val_auc: 0.7710 - val_binary_accuracy: 0.9034 - val_loss: 0.2737\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7898 - binary_accuracy: 0.9029 - loss: 0.2642 - val_auc: 0.7802 - val_binary_accuracy: 0.9062 - val_loss: 0.2763\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7945 - binary_accuracy: 0.9060 - loss: 0.2605 - val_auc: 0.7825 - val_binary_accuracy: 0.9068 - val_loss: 0.2724\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7973 - binary_accuracy: 0.9079 - loss: 0.2581 - val_auc: 0.7835 - val_binary_accuracy: 0.9072 - val_loss: 0.2663\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7994 - binary_accuracy: 0.9098 - loss: 0.2565 - val_auc: 0.7842 - val_binary_accuracy: 0.9066 - val_loss: 0.2645\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9096 - loss: 0.2557 - val_auc: 0.7851 - val_binary_accuracy: 0.9069 - val_loss: 0.2665\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9101 - loss: 0.2554 - val_auc: 0.7856 - val_binary_accuracy: 0.9054 - val_loss: 0.2695\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9103 - loss: 0.2554 - val_auc: 0.7869 - val_binary_accuracy: 0.9056 - val_loss: 0.2700\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7983 - binary_accuracy: 0.9108 - loss: 0.2551 - val_auc: 0.7872 - val_binary_accuracy: 0.9059 - val_loss: 0.2692\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7845 - binary_accuracy: 0.9087 - loss: 0.2646\n",
            "Fold 1 Metrics: Loss = 0.2692, Accuracy = 0.9059, AUC = 0.7872\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6458 - binary_accuracy: 0.7401 - loss: 1.6699 - val_auc: 0.7206 - val_binary_accuracy: 0.9065 - val_loss: 0.2979\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7412 - binary_accuracy: 0.9039 - loss: 0.2875 - val_auc: 0.7840 - val_binary_accuracy: 0.9081 - val_loss: 0.2675\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7819 - binary_accuracy: 0.9047 - loss: 0.2712 - val_auc: 0.7983 - val_binary_accuracy: 0.9096 - val_loss: 0.2613\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9052 - loss: 0.2674 - val_auc: 0.8031 - val_binary_accuracy: 0.9100 - val_loss: 0.2587\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7932 - binary_accuracy: 0.9062 - loss: 0.2653 - val_auc: 0.8059 - val_binary_accuracy: 0.9102 - val_loss: 0.2570\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7953 - binary_accuracy: 0.9070 - loss: 0.2639 - val_auc: 0.8074 - val_binary_accuracy: 0.9099 - val_loss: 0.2561\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7970 - binary_accuracy: 0.9073 - loss: 0.2630 - val_auc: 0.8096 - val_binary_accuracy: 0.9099 - val_loss: 0.2554\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9079 - loss: 0.2624 - val_auc: 0.8112 - val_binary_accuracy: 0.9099 - val_loss: 0.2546\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9081 - loss: 0.2619 - val_auc: 0.8117 - val_binary_accuracy: 0.9104 - val_loss: 0.2538\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8123 - val_binary_accuracy: 0.9104 - val_loss: 0.2533\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8149 - binary_accuracy: 0.9138 - loss: 0.2448\n",
            "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9104, AUC = 0.8123\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6087 - binary_accuracy: 0.8443 - loss: 0.4981 - val_auc: 0.7668 - val_binary_accuracy: 0.9063 - val_loss: 0.2722\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7682 - binary_accuracy: 0.9075 - loss: 0.2699 - val_auc: 0.7957 - val_binary_accuracy: 0.9071 - val_loss: 0.2641\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9079 - loss: 0.2636 - val_auc: 0.7999 - val_binary_accuracy: 0.9081 - val_loss: 0.2622\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9076 - loss: 0.2630 - val_auc: 0.8021 - val_binary_accuracy: 0.9093 - val_loss: 0.2608\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9084 - loss: 0.2627 - val_auc: 0.8034 - val_binary_accuracy: 0.9103 - val_loss: 0.2592\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7858 - binary_accuracy: 0.9091 - loss: 0.2625 - val_auc: 0.8041 - val_binary_accuracy: 0.9109 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9094 - loss: 0.2622 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2577\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9096 - loss: 0.2619 - val_auc: 0.8062 - val_binary_accuracy: 0.9110 - val_loss: 0.2572\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8057 - val_binary_accuracy: 0.9110 - val_loss: 0.2570\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9097 - loss: 0.2615 - val_auc: 0.8063 - val_binary_accuracy: 0.9110 - val_loss: 0.2568\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7996 - binary_accuracy: 0.9131 - loss: 0.2566\n",
            "Fold 3 Metrics: Loss = 0.2568, Accuracy = 0.9110, AUC = 0.8063\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6235 - binary_accuracy: 0.8994 - loss: 0.3500 - val_auc: 0.7747 - val_binary_accuracy: 0.9039 - val_loss: 0.2720\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7676 - binary_accuracy: 0.9040 - loss: 0.2741 - val_auc: 0.7865 - val_binary_accuracy: 0.9050 - val_loss: 0.2661\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7771 - binary_accuracy: 0.9056 - loss: 0.2696 - val_auc: 0.7906 - val_binary_accuracy: 0.9060 - val_loss: 0.2636\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7811 - binary_accuracy: 0.9065 - loss: 0.2672 - val_auc: 0.7939 - val_binary_accuracy: 0.9084 - val_loss: 0.2617\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7829 - binary_accuracy: 0.9073 - loss: 0.2656 - val_auc: 0.7964 - val_binary_accuracy: 0.9097 - val_loss: 0.2603\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7848 - binary_accuracy: 0.9078 - loss: 0.2644 - val_auc: 0.7986 - val_binary_accuracy: 0.9097 - val_loss: 0.2593\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2636 - val_auc: 0.8002 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7873 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8024 - val_binary_accuracy: 0.9100 - val_loss: 0.2572\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9090 - loss: 0.2625 - val_auc: 0.8033 - val_binary_accuracy: 0.9101 - val_loss: 0.2567\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9092 - loss: 0.2620 - val_auc: 0.8044 - val_binary_accuracy: 0.9103 - val_loss: 0.2563\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7873 - binary_accuracy: 0.9101 - loss: 0.2631\n",
            "Fold 4 Metrics: Loss = 0.2563, Accuracy = 0.9103, AUC = 0.8044\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6808 - binary_accuracy: 0.9036 - loss: 0.3078 - val_auc: 0.7917 - val_binary_accuracy: 0.8995 - val_loss: 0.2775\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7666 - binary_accuracy: 0.9011 - loss: 0.2789 - val_auc: 0.8004 - val_binary_accuracy: 0.8998 - val_loss: 0.2746\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7763 - binary_accuracy: 0.9021 - loss: 0.2731 - val_auc: 0.8049 - val_binary_accuracy: 0.9028 - val_loss: 0.2718\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7813 - binary_accuracy: 0.9043 - loss: 0.2693 - val_auc: 0.8059 - val_binary_accuracy: 0.9026 - val_loss: 0.2720\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9044 - loss: 0.2677 - val_auc: 0.8072 - val_binary_accuracy: 0.9032 - val_loss: 0.2711\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9052 - loss: 0.2666 - val_auc: 0.8078 - val_binary_accuracy: 0.9041 - val_loss: 0.2714\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9064 - loss: 0.2657 - val_auc: 0.8079 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9066 - loss: 0.2651 - val_auc: 0.8082 - val_binary_accuracy: 0.9054 - val_loss: 0.2698\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9070 - loss: 0.2646 - val_auc: 0.8076 - val_binary_accuracy: 0.9032 - val_loss: 0.2711\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9072 - loss: 0.2644 - val_auc: 0.8082 - val_binary_accuracy: 0.9036 - val_loss: 0.2706\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8170 - binary_accuracy: 0.9056 - loss: 0.2685\n",
            "Fold 5 Metrics: Loss = 0.2706, Accuracy = 0.9036, AUC = 0.8082\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2612\n",
            "Average Accuracy: 0.9083\n",
            "Average AUC: 0.8037\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 1, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6862 - binary_accuracy: 0.8592 - loss: 0.5908 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2762\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9071 - loss: 0.2693 - val_auc: 0.7723 - val_binary_accuracy: 0.9017 - val_loss: 0.2800\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.7786 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9106 - loss: 0.2594 - val_auc: 0.7839 - val_binary_accuracy: 0.9076 - val_loss: 0.2692\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7911 - binary_accuracy: 0.9115 - loss: 0.2565 - val_auc: 0.7872 - val_binary_accuracy: 0.9084 - val_loss: 0.2660\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9117 - loss: 0.2548 - val_auc: 0.7893 - val_binary_accuracy: 0.9085 - val_loss: 0.2638\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7968 - binary_accuracy: 0.9120 - loss: 0.2536 - val_auc: 0.7911 - val_binary_accuracy: 0.9090 - val_loss: 0.2623\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7984 - binary_accuracy: 0.9120 - loss: 0.2528 - val_auc: 0.7923 - val_binary_accuracy: 0.9090 - val_loss: 0.2615\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7932 - val_binary_accuracy: 0.9088 - val_loss: 0.2610\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9126 - loss: 0.2519 - val_auc: 0.7936 - val_binary_accuracy: 0.9088 - val_loss: 0.2605\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7857 - binary_accuracy: 0.9111 - loss: 0.2563\n",
            "Fold 1 Metrics: Loss = 0.2605, Accuracy = 0.9088, AUC = 0.7936\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6825 - binary_accuracy: 0.8857 - loss: 0.3480 - val_auc: 0.7850 - val_binary_accuracy: 0.9081 - val_loss: 0.2691\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7647 - binary_accuracy: 0.9056 - loss: 0.2777 - val_auc: 0.8016 - val_binary_accuracy: 0.9096 - val_loss: 0.2620\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7806 - binary_accuracy: 0.9065 - loss: 0.2707 - val_auc: 0.8064 - val_binary_accuracy: 0.9100 - val_loss: 0.2589\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7863 - binary_accuracy: 0.9068 - loss: 0.2678 - val_auc: 0.8093 - val_binary_accuracy: 0.9091 - val_loss: 0.2574\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9071 - loss: 0.2658 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2560\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7921 - binary_accuracy: 0.9075 - loss: 0.2644 - val_auc: 0.8114 - val_binary_accuracy: 0.9099 - val_loss: 0.2562\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7935 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8138 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9083 - loss: 0.2625 - val_auc: 0.8145 - val_binary_accuracy: 0.9099 - val_loss: 0.2559\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7972 - binary_accuracy: 0.9083 - loss: 0.2618 - val_auc: 0.8161 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9082 - loss: 0.2612 - val_auc: 0.8158 - val_binary_accuracy: 0.9090 - val_loss: 0.2553\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8227 - binary_accuracy: 0.9125 - loss: 0.2459\n",
            "Fold 2 Metrics: Loss = 0.2553, Accuracy = 0.9090, AUC = 0.8158\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7163 - binary_accuracy: 0.8859 - loss: 0.3651 - val_auc: 0.7699 - val_binary_accuracy: 0.8982 - val_loss: 0.2847\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7610 - binary_accuracy: 0.9030 - loss: 0.2754 - val_auc: 0.7911 - val_binary_accuracy: 0.9032 - val_loss: 0.2727\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7758 - binary_accuracy: 0.9063 - loss: 0.2673 - val_auc: 0.7974 - val_binary_accuracy: 0.9048 - val_loss: 0.2686\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7810 - binary_accuracy: 0.9072 - loss: 0.2647 - val_auc: 0.8013 - val_binary_accuracy: 0.9054 - val_loss: 0.2672\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7837 - binary_accuracy: 0.9080 - loss: 0.2631 - val_auc: 0.8034 - val_binary_accuracy: 0.9059 - val_loss: 0.2669\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2622 - val_auc: 0.8041 - val_binary_accuracy: 0.9057 - val_loss: 0.2666\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7869 - binary_accuracy: 0.9083 - loss: 0.2617 - val_auc: 0.8053 - val_binary_accuracy: 0.9056 - val_loss: 0.2675\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7876 - binary_accuracy: 0.9083 - loss: 0.2613 - val_auc: 0.8061 - val_binary_accuracy: 0.9057 - val_loss: 0.2676\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7886 - binary_accuracy: 0.9085 - loss: 0.2610 - val_auc: 0.8064 - val_binary_accuracy: 0.9056 - val_loss: 0.2677\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7890 - binary_accuracy: 0.9088 - loss: 0.2608 - val_auc: 0.8070 - val_binary_accuracy: 0.9056 - val_loss: 0.2678\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8043 - binary_accuracy: 0.9058 - loss: 0.2677\n",
            "Fold 3 Metrics: Loss = 0.2678, Accuracy = 0.9056, AUC = 0.8070\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6602 - binary_accuracy: 0.8776 - loss: 0.3897 - val_auc: 0.7762 - val_binary_accuracy: 0.9062 - val_loss: 0.2726\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7629 - binary_accuracy: 0.9050 - loss: 0.2777 - val_auc: 0.7908 - val_binary_accuracy: 0.9060 - val_loss: 0.2644\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7732 - binary_accuracy: 0.9068 - loss: 0.2709 - val_auc: 0.7972 - val_binary_accuracy: 0.9076 - val_loss: 0.2611\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7797 - binary_accuracy: 0.9078 - loss: 0.2675 - val_auc: 0.8001 - val_binary_accuracy: 0.9081 - val_loss: 0.2601\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7836 - binary_accuracy: 0.9080 - loss: 0.2655 - val_auc: 0.8028 - val_binary_accuracy: 0.9081 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7862 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8046 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7881 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2583\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7889 - binary_accuracy: 0.9082 - loss: 0.2621 - val_auc: 0.8077 - val_binary_accuracy: 0.9091 - val_loss: 0.2578\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7897 - binary_accuracy: 0.9083 - loss: 0.2617 - val_auc: 0.8084 - val_binary_accuracy: 0.9091 - val_loss: 0.2574\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7907 - binary_accuracy: 0.9090 - loss: 0.2613 - val_auc: 0.8090 - val_binary_accuracy: 0.9087 - val_loss: 0.2571\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9066 - loss: 0.2637\n",
            "Fold 4 Metrics: Loss = 0.2571, Accuracy = 0.9087, AUC = 0.8090\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6565 - binary_accuracy: 0.8934 - loss: 0.3689 - val_auc: 0.7838 - val_binary_accuracy: 0.9048 - val_loss: 0.2664\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7613 - binary_accuracy: 0.9052 - loss: 0.2762 - val_auc: 0.7952 - val_binary_accuracy: 0.9078 - val_loss: 0.2599\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7696 - binary_accuracy: 0.9075 - loss: 0.2717 - val_auc: 0.7998 - val_binary_accuracy: 0.9091 - val_loss: 0.2568\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9078 - loss: 0.2691 - val_auc: 0.8030 - val_binary_accuracy: 0.9106 - val_loss: 0.2558\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7778 - binary_accuracy: 0.9085 - loss: 0.2677 - val_auc: 0.8046 - val_binary_accuracy: 0.9104 - val_loss: 0.2548\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9087 - loss: 0.2668 - val_auc: 0.8068 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7806 - binary_accuracy: 0.9088 - loss: 0.2663 - val_auc: 0.8078 - val_binary_accuracy: 0.9101 - val_loss: 0.2534\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9077 - loss: 0.2656 - val_auc: 0.8072 - val_binary_accuracy: 0.9087 - val_loss: 0.2536\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7821 - binary_accuracy: 0.9082 - loss: 0.2655 - val_auc: 0.8076 - val_binary_accuracy: 0.9079 - val_loss: 0.2537\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7832 - binary_accuracy: 0.9089 - loss: 0.2651 - val_auc: 0.8080 - val_binary_accuracy: 0.9082 - val_loss: 0.2537\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9069 - loss: 0.2532\n",
            "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9082, AUC = 0.8080\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2589\n",
            "Average Accuracy: 0.9081\n",
            "Average AUC: 0.8067\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 1, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7034 - binary_accuracy: 0.8996 - loss: 0.3101 - val_auc: 0.7697 - val_binary_accuracy: 0.9081 - val_loss: 0.2725\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9089 - loss: 0.2643 - val_auc: 0.7847 - val_binary_accuracy: 0.9103 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9109 - loss: 0.2571 - val_auc: 0.7876 - val_binary_accuracy: 0.9099 - val_loss: 0.2676\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7957 - binary_accuracy: 0.9117 - loss: 0.2555 - val_auc: 0.7925 - val_binary_accuracy: 0.9097 - val_loss: 0.2603\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9120 - loss: 0.2532 - val_auc: 0.7931 - val_binary_accuracy: 0.9097 - val_loss: 0.2600\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9119 - loss: 0.2528 - val_auc: 0.7942 - val_binary_accuracy: 0.9097 - val_loss: 0.2597\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9122 - loss: 0.2521 - val_auc: 0.7947 - val_binary_accuracy: 0.9096 - val_loss: 0.2594\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9125 - loss: 0.2515 - val_auc: 0.7953 - val_binary_accuracy: 0.9099 - val_loss: 0.2593\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8048 - binary_accuracy: 0.9125 - loss: 0.2513 - val_auc: 0.7956 - val_binary_accuracy: 0.9093 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9127 - loss: 0.2508 - val_auc: 0.7962 - val_binary_accuracy: 0.9093 - val_loss: 0.2593\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7917 - binary_accuracy: 0.9135 - loss: 0.2520\n",
            "Fold 1 Metrics: Loss = 0.2593, Accuracy = 0.9093, AUC = 0.7962\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5927 - binary_accuracy: 0.8873 - loss: 0.7866 - val_auc: 0.7893 - val_binary_accuracy: 0.9068 - val_loss: 0.2654\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9050 - loss: 0.2744 - val_auc: 0.8040 - val_binary_accuracy: 0.9079 - val_loss: 0.2582\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7799 - binary_accuracy: 0.9065 - loss: 0.2693 - val_auc: 0.8073 - val_binary_accuracy: 0.9088 - val_loss: 0.2563\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7863 - binary_accuracy: 0.9064 - loss: 0.2670 - val_auc: 0.8056 - val_binary_accuracy: 0.9104 - val_loss: 0.2571\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7896 - binary_accuracy: 0.9065 - loss: 0.2658 - val_auc: 0.8097 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7927 - binary_accuracy: 0.9067 - loss: 0.2643 - val_auc: 0.8107 - val_binary_accuracy: 0.9082 - val_loss: 0.2552\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7934 - binary_accuracy: 0.9068 - loss: 0.2639 - val_auc: 0.8125 - val_binary_accuracy: 0.9090 - val_loss: 0.2537\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7962 - binary_accuracy: 0.9070 - loss: 0.2629 - val_auc: 0.8124 - val_binary_accuracy: 0.9088 - val_loss: 0.2539\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9070 - loss: 0.2630 - val_auc: 0.8131 - val_binary_accuracy: 0.9085 - val_loss: 0.2533\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9075 - loss: 0.2623 - val_auc: 0.8130 - val_binary_accuracy: 0.9087 - val_loss: 0.2533\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8199 - binary_accuracy: 0.9122 - loss: 0.2438\n",
            "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9087, AUC = 0.8130\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6633 - binary_accuracy: 0.8966 - loss: 0.4320 - val_auc: 0.7971 - val_binary_accuracy: 0.9096 - val_loss: 0.2604\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7724 - binary_accuracy: 0.9059 - loss: 0.2692 - val_auc: 0.8024 - val_binary_accuracy: 0.9106 - val_loss: 0.2572\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7767 - binary_accuracy: 0.9061 - loss: 0.2674 - val_auc: 0.8041 - val_binary_accuracy: 0.9107 - val_loss: 0.2562\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7777 - binary_accuracy: 0.9063 - loss: 0.2667 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7786 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.8062 - val_binary_accuracy: 0.9107 - val_loss: 0.2557\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7803 - binary_accuracy: 0.9066 - loss: 0.2658 - val_auc: 0.8074 - val_binary_accuracy: 0.9116 - val_loss: 0.2554\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7817 - binary_accuracy: 0.9069 - loss: 0.2652 - val_auc: 0.8072 - val_binary_accuracy: 0.9112 - val_loss: 0.2555\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7825 - binary_accuracy: 0.9072 - loss: 0.2648 - val_auc: 0.8082 - val_binary_accuracy: 0.9122 - val_loss: 0.2550\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7831 - binary_accuracy: 0.9076 - loss: 0.2643 - val_auc: 0.8072 - val_binary_accuracy: 0.9121 - val_loss: 0.2556\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9075 - loss: 0.2640 - val_auc: 0.8074 - val_binary_accuracy: 0.9124 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8025 - binary_accuracy: 0.9128 - loss: 0.2555\n",
            "Fold 3 Metrics: Loss = 0.2552, Accuracy = 0.9124, AUC = 0.8074\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5709 - binary_accuracy: 0.7201 - loss: 4.4762 - val_auc: 0.7878 - val_binary_accuracy: 0.9041 - val_loss: 0.2668\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7690 - binary_accuracy: 0.9050 - loss: 0.2725 - val_auc: 0.8000 - val_binary_accuracy: 0.9081 - val_loss: 0.2606\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7791 - binary_accuracy: 0.9080 - loss: 0.2666 - val_auc: 0.8041 - val_binary_accuracy: 0.9078 - val_loss: 0.2594\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7819 - binary_accuracy: 0.9085 - loss: 0.2651 - val_auc: 0.8063 - val_binary_accuracy: 0.9064 - val_loss: 0.2598\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7838 - binary_accuracy: 0.9089 - loss: 0.2641 - val_auc: 0.8078 - val_binary_accuracy: 0.9072 - val_loss: 0.2585\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7865 - binary_accuracy: 0.9090 - loss: 0.2629 - val_auc: 0.8090 - val_binary_accuracy: 0.9088 - val_loss: 0.2567\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7886 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8087 - val_binary_accuracy: 0.9104 - val_loss: 0.2558\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9094 - loss: 0.2620 - val_auc: 0.8094 - val_binary_accuracy: 0.9104 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7879 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8103 - val_binary_accuracy: 0.9104 - val_loss: 0.2550\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7879 - binary_accuracy: 0.9089 - loss: 0.2620 - val_auc: 0.8102 - val_binary_accuracy: 0.9103 - val_loss: 0.2550\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7952 - binary_accuracy: 0.9090 - loss: 0.2614\n",
            "Fold 4 Metrics: Loss = 0.2550, Accuracy = 0.9103, AUC = 0.8102\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6283 - binary_accuracy: 0.8896 - loss: 0.8065 - val_auc: 0.7923 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9053 - loss: 0.2773 - val_auc: 0.7995 - val_binary_accuracy: 0.9097 - val_loss: 0.2592\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7657 - binary_accuracy: 0.9060 - loss: 0.2736 - val_auc: 0.8023 - val_binary_accuracy: 0.9073 - val_loss: 0.2591\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7692 - binary_accuracy: 0.9066 - loss: 0.2720 - val_auc: 0.8053 - val_binary_accuracy: 0.9073 - val_loss: 0.2592\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7710 - binary_accuracy: 0.9063 - loss: 0.2711 - val_auc: 0.8066 - val_binary_accuracy: 0.9067 - val_loss: 0.2597\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7718 - binary_accuracy: 0.9065 - loss: 0.2709 - val_auc: 0.8074 - val_binary_accuracy: 0.9066 - val_loss: 0.2588\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7732 - binary_accuracy: 0.9073 - loss: 0.2704 - val_auc: 0.8080 - val_binary_accuracy: 0.9064 - val_loss: 0.2585\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9070 - loss: 0.2697 - val_auc: 0.8082 - val_binary_accuracy: 0.9062 - val_loss: 0.2578\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7762 - binary_accuracy: 0.9072 - loss: 0.2693 - val_auc: 0.8085 - val_binary_accuracy: 0.9067 - val_loss: 0.2573\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7768 - binary_accuracy: 0.9072 - loss: 0.2691 - val_auc: 0.8083 - val_binary_accuracy: 0.9059 - val_loss: 0.2567\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8140 - binary_accuracy: 0.9062 - loss: 0.2557\n",
            "Fold 5 Metrics: Loss = 0.2567, Accuracy = 0.9059, AUC = 0.8083\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2559\n",
            "Average Accuracy: 0.9093\n",
            "Average AUC: 0.8070\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 1, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6756 - binary_accuracy: 0.8977 - loss: 0.4019 - val_auc: 0.7866 - val_binary_accuracy: 0.9085 - val_loss: 0.2622\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7899 - binary_accuracy: 0.9116 - loss: 0.2575 - val_auc: 0.7926 - val_binary_accuracy: 0.9100 - val_loss: 0.2600\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7940 - binary_accuracy: 0.9120 - loss: 0.2555 - val_auc: 0.7960 - val_binary_accuracy: 0.9104 - val_loss: 0.2591\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7984 - binary_accuracy: 0.9123 - loss: 0.2535 - val_auc: 0.7967 - val_binary_accuracy: 0.9100 - val_loss: 0.2590\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7998 - binary_accuracy: 0.9126 - loss: 0.2527 - val_auc: 0.7972 - val_binary_accuracy: 0.9096 - val_loss: 0.2587\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8011 - binary_accuracy: 0.9127 - loss: 0.2522 - val_auc: 0.7987 - val_binary_accuracy: 0.9094 - val_loss: 0.2582\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8031 - binary_accuracy: 0.9129 - loss: 0.2515 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8033 - binary_accuracy: 0.9130 - loss: 0.2514 - val_auc: 0.7990 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9132 - loss: 0.2509 - val_auc: 0.7989 - val_binary_accuracy: 0.9097 - val_loss: 0.2574\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8052 - binary_accuracy: 0.9132 - loss: 0.2507 - val_auc: 0.7983 - val_binary_accuracy: 0.9099 - val_loss: 0.2576\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7944 - binary_accuracy: 0.9140 - loss: 0.2500\n",
            "Fold 1 Metrics: Loss = 0.2576, Accuracy = 0.9099, AUC = 0.7983\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5951 - binary_accuracy: 0.8489 - loss: 0.9462 - val_auc: 0.8019 - val_binary_accuracy: 0.9059 - val_loss: 0.2635\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9057 - loss: 0.2711 - val_auc: 0.8111 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9069 - loss: 0.2685 - val_auc: 0.8111 - val_binary_accuracy: 0.9099 - val_loss: 0.2563\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7852 - binary_accuracy: 0.9067 - loss: 0.2683 - val_auc: 0.8115 - val_binary_accuracy: 0.9099 - val_loss: 0.2557\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9063 - loss: 0.2683 - val_auc: 0.8118 - val_binary_accuracy: 0.9104 - val_loss: 0.2554\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7856 - binary_accuracy: 0.9066 - loss: 0.2683 - val_auc: 0.8115 - val_binary_accuracy: 0.9104 - val_loss: 0.2557\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7856 - binary_accuracy: 0.9063 - loss: 0.2681 - val_auc: 0.8113 - val_binary_accuracy: 0.9100 - val_loss: 0.2559\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9065 - loss: 0.2679 - val_auc: 0.8113 - val_binary_accuracy: 0.9100 - val_loss: 0.2558\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7875 - binary_accuracy: 0.9067 - loss: 0.2673 - val_auc: 0.8120 - val_binary_accuracy: 0.9097 - val_loss: 0.2559\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9069 - loss: 0.2665 - val_auc: 0.8124 - val_binary_accuracy: 0.9099 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8201 - binary_accuracy: 0.9141 - loss: 0.2456\n",
            "Fold 2 Metrics: Loss = 0.2552, Accuracy = 0.9099, AUC = 0.8124\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6426 - binary_accuracy: 0.8351 - loss: 1.1844 - val_auc: 0.7773 - val_binary_accuracy: 0.9087 - val_loss: 0.2691\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7591 - binary_accuracy: 0.9047 - loss: 0.2747 - val_auc: 0.7910 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7657 - binary_accuracy: 0.9053 - loss: 0.2727 - val_auc: 0.7981 - val_binary_accuracy: 0.9038 - val_loss: 0.2686\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7738 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.8018 - val_binary_accuracy: 0.9004 - val_loss: 0.2724\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7756 - binary_accuracy: 0.9069 - loss: 0.2682 - val_auc: 0.8036 - val_binary_accuracy: 0.8972 - val_loss: 0.2742\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7772 - binary_accuracy: 0.9066 - loss: 0.2682 - val_auc: 0.8053 - val_binary_accuracy: 0.8969 - val_loss: 0.2742\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7776 - binary_accuracy: 0.9060 - loss: 0.2677 - val_auc: 0.8064 - val_binary_accuracy: 0.8969 - val_loss: 0.2747\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9065 - loss: 0.2677 - val_auc: 0.8074 - val_binary_accuracy: 0.8948 - val_loss: 0.2769\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7789 - binary_accuracy: 0.9064 - loss: 0.2673 - val_auc: 0.8078 - val_binary_accuracy: 0.8942 - val_loss: 0.2772\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7800 - binary_accuracy: 0.9066 - loss: 0.2670 - val_auc: 0.8081 - val_binary_accuracy: 0.8952 - val_loss: 0.2765\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8043 - binary_accuracy: 0.8954 - loss: 0.2766\n",
            "Fold 3 Metrics: Loss = 0.2765, Accuracy = 0.8952, AUC = 0.8081\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6570 - binary_accuracy: 0.8842 - loss: 0.5254 - val_auc: 0.7953 - val_binary_accuracy: 0.9085 - val_loss: 0.2630\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9084 - loss: 0.2721 - val_auc: 0.8073 - val_binary_accuracy: 0.9091 - val_loss: 0.2611\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9088 - loss: 0.2692 - val_auc: 0.8104 - val_binary_accuracy: 0.9090 - val_loss: 0.2599\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7772 - binary_accuracy: 0.9090 - loss: 0.2674 - val_auc: 0.8116 - val_binary_accuracy: 0.9090 - val_loss: 0.2589\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7794 - binary_accuracy: 0.9094 - loss: 0.2663 - val_auc: 0.8130 - val_binary_accuracy: 0.9097 - val_loss: 0.2582\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7804 - binary_accuracy: 0.9089 - loss: 0.2658 - val_auc: 0.8144 - val_binary_accuracy: 0.9097 - val_loss: 0.2564\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7822 - binary_accuracy: 0.9093 - loss: 0.2649 - val_auc: 0.8145 - val_binary_accuracy: 0.9097 - val_loss: 0.2562\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7826 - binary_accuracy: 0.9095 - loss: 0.2649 - val_auc: 0.8143 - val_binary_accuracy: 0.9095 - val_loss: 0.2561\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2644 - val_auc: 0.8142 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7843 - binary_accuracy: 0.9096 - loss: 0.2643 - val_auc: 0.8145 - val_binary_accuracy: 0.9098 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7978 - binary_accuracy: 0.9082 - loss: 0.2625\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9098, AUC = 0.8145\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5360 - binary_accuracy: 0.8048 - loss: 1.9087 - val_auc: 0.7869 - val_binary_accuracy: 0.9063 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7625 - binary_accuracy: 0.9056 - loss: 0.2748 - val_auc: 0.8003 - val_binary_accuracy: 0.9090 - val_loss: 0.2569\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9065 - loss: 0.2711 - val_auc: 0.8047 - val_binary_accuracy: 0.9051 - val_loss: 0.2613\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7709 - binary_accuracy: 0.9061 - loss: 0.2709 - val_auc: 0.8069 - val_binary_accuracy: 0.9019 - val_loss: 0.2670\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9063 - loss: 0.2703 - val_auc: 0.8073 - val_binary_accuracy: 0.9014 - val_loss: 0.2696\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7751 - binary_accuracy: 0.9061 - loss: 0.2699 - val_auc: 0.8077 - val_binary_accuracy: 0.9005 - val_loss: 0.2702\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7751 - binary_accuracy: 0.9064 - loss: 0.2701 - val_auc: 0.8078 - val_binary_accuracy: 0.8997 - val_loss: 0.2712\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7752 - binary_accuracy: 0.9063 - loss: 0.2702 - val_auc: 0.8079 - val_binary_accuracy: 0.8988 - val_loss: 0.2723\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7752 - binary_accuracy: 0.9065 - loss: 0.2706 - val_auc: 0.8079 - val_binary_accuracy: 0.8991 - val_loss: 0.2726\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7747 - binary_accuracy: 0.9063 - loss: 0.2707 - val_auc: 0.8083 - val_binary_accuracy: 0.8995 - val_loss: 0.2723\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9035 - loss: 0.2698\n",
            "Fold 5 Metrics: Loss = 0.2723, Accuracy = 0.8995, AUC = 0.8083\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2633\n",
            "Average Accuracy: 0.9049\n",
            "Average AUC: 0.8083\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 1, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7102 - binary_accuracy: 0.9002 - loss: 0.3113 - val_auc: 0.7878 - val_binary_accuracy: 0.9062 - val_loss: 0.2950\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9093 - loss: 0.2649 - val_auc: 0.7940 - val_binary_accuracy: 0.9072 - val_loss: 0.3029\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9096 - loss: 0.2626 - val_auc: 0.7944 - val_binary_accuracy: 0.9079 - val_loss: 0.3055\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9106 - loss: 0.2611 - val_auc: 0.7986 - val_binary_accuracy: 0.9078 - val_loss: 0.3028\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7866 - binary_accuracy: 0.9106 - loss: 0.2602 - val_auc: 0.7988 - val_binary_accuracy: 0.9081 - val_loss: 0.3022\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7889 - binary_accuracy: 0.9111 - loss: 0.2591 - val_auc: 0.8007 - val_binary_accuracy: 0.9081 - val_loss: 0.3000\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7902 - binary_accuracy: 0.9110 - loss: 0.2587 - val_auc: 0.7994 - val_binary_accuracy: 0.9081 - val_loss: 0.2919\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7928 - binary_accuracy: 0.9108 - loss: 0.2572 - val_auc: 0.7990 - val_binary_accuracy: 0.9081 - val_loss: 0.2882\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9112 - loss: 0.2564 - val_auc: 0.7994 - val_binary_accuracy: 0.9088 - val_loss: 0.2844\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7958 - binary_accuracy: 0.9111 - loss: 0.2556 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2794\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7957 - binary_accuracy: 0.9128 - loss: 0.2695\n",
            "Fold 1 Metrics: Loss = 0.2794, Accuracy = 0.9088, AUC = 0.7997\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6661 - binary_accuracy: 0.8791 - loss: 0.4294 - val_auc: 0.8100 - val_binary_accuracy: 0.8960 - val_loss: 0.2967\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7596 - binary_accuracy: 0.9035 - loss: 0.2802 - val_auc: 0.8109 - val_binary_accuracy: 0.8964 - val_loss: 0.2970\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9048 - loss: 0.2791 - val_auc: 0.8142 - val_binary_accuracy: 0.8979 - val_loss: 0.2922\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9052 - loss: 0.2777 - val_auc: 0.8110 - val_binary_accuracy: 0.8991 - val_loss: 0.2890\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7701 - binary_accuracy: 0.9056 - loss: 0.2762 - val_auc: 0.8113 - val_binary_accuracy: 0.8991 - val_loss: 0.2898\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7716 - binary_accuracy: 0.9055 - loss: 0.2758 - val_auc: 0.8125 - val_binary_accuracy: 0.8986 - val_loss: 0.2876\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9055 - loss: 0.2743 - val_auc: 0.8114 - val_binary_accuracy: 0.8986 - val_loss: 0.2883\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7757 - binary_accuracy: 0.9058 - loss: 0.2740 - val_auc: 0.8065 - val_binary_accuracy: 0.9007 - val_loss: 0.2841\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7784 - binary_accuracy: 0.9059 - loss: 0.2727 - val_auc: 0.8114 - val_binary_accuracy: 0.9023 - val_loss: 0.2745\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7812 - binary_accuracy: 0.9059 - loss: 0.2707 - val_auc: 0.8090 - val_binary_accuracy: 0.9054 - val_loss: 0.2709\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9082 - loss: 0.2627\n",
            "Fold 2 Metrics: Loss = 0.2709, Accuracy = 0.9054, AUC = 0.8090\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6325 - binary_accuracy: 0.8668 - loss: 0.6690 - val_auc: 0.7893 - val_binary_accuracy: 0.9063 - val_loss: 0.2674\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7722 - binary_accuracy: 0.9058 - loss: 0.2699 - val_auc: 0.7994 - val_binary_accuracy: 0.9017 - val_loss: 0.2711\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7725 - binary_accuracy: 0.9071 - loss: 0.2699 - val_auc: 0.8024 - val_binary_accuracy: 0.9023 - val_loss: 0.2673\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9061 - loss: 0.2710 - val_auc: 0.8041 - val_binary_accuracy: 0.9038 - val_loss: 0.2652\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9066 - loss: 0.2706 - val_auc: 0.8042 - val_binary_accuracy: 0.9026 - val_loss: 0.2683\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7737 - binary_accuracy: 0.9067 - loss: 0.2698 - val_auc: 0.8055 - val_binary_accuracy: 0.9013 - val_loss: 0.2680\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9070 - loss: 0.2690 - val_auc: 0.8053 - val_binary_accuracy: 0.9006 - val_loss: 0.2705\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7766 - binary_accuracy: 0.9071 - loss: 0.2684 - val_auc: 0.8061 - val_binary_accuracy: 0.9003 - val_loss: 0.2717\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.8058 - val_binary_accuracy: 0.9014 - val_loss: 0.2721\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7788 - binary_accuracy: 0.9072 - loss: 0.2672 - val_auc: 0.8059 - val_binary_accuracy: 0.8988 - val_loss: 0.2736\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8025 - binary_accuracy: 0.9010 - loss: 0.2736\n",
            "Fold 3 Metrics: Loss = 0.2736, Accuracy = 0.8988, AUC = 0.8059\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7025 - binary_accuracy: 0.8919 - loss: 0.3483 - val_auc: 0.8065 - val_binary_accuracy: 0.9081 - val_loss: 0.2577\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7717 - binary_accuracy: 0.9084 - loss: 0.2697 - val_auc: 0.8101 - val_binary_accuracy: 0.9026 - val_loss: 0.2593\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9081 - loss: 0.2691 - val_auc: 0.8120 - val_binary_accuracy: 0.9033 - val_loss: 0.2579\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9078 - loss: 0.2686 - val_auc: 0.8125 - val_binary_accuracy: 0.9069 - val_loss: 0.2551\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9088 - loss: 0.2676 - val_auc: 0.8118 - val_binary_accuracy: 0.9097 - val_loss: 0.2648\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9096 - loss: 0.2665 - val_auc: 0.8111 - val_binary_accuracy: 0.9100 - val_loss: 0.2961\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7777 - binary_accuracy: 0.9089 - loss: 0.2671 - val_auc: 0.8101 - val_binary_accuracy: 0.9090 - val_loss: 0.3140\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7748 - binary_accuracy: 0.9085 - loss: 0.2688 - val_auc: 0.8092 - val_binary_accuracy: 0.9091 - val_loss: 0.3189\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7715 - binary_accuracy: 0.9086 - loss: 0.2717 - val_auc: 0.8132 - val_binary_accuracy: 0.9095 - val_loss: 0.2976\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7718 - binary_accuracy: 0.9075 - loss: 0.2720 - val_auc: 0.8129 - val_binary_accuracy: 0.9098 - val_loss: 0.2836\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7967 - binary_accuracy: 0.9093 - loss: 0.2904\n",
            "Fold 4 Metrics: Loss = 0.2836, Accuracy = 0.9098, AUC = 0.8129\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6815 - binary_accuracy: 0.8778 - loss: 0.4993 - val_auc: 0.7960 - val_binary_accuracy: 0.8927 - val_loss: 0.2965\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7478 - binary_accuracy: 0.9037 - loss: 0.2840 - val_auc: 0.8031 - val_binary_accuracy: 0.8918 - val_loss: 0.2983\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7524 - binary_accuracy: 0.9039 - loss: 0.2828 - val_auc: 0.8050 - val_binary_accuracy: 0.8895 - val_loss: 0.2979\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7557 - binary_accuracy: 0.9038 - loss: 0.2810 - val_auc: 0.8066 - val_binary_accuracy: 0.8889 - val_loss: 0.2970\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7587 - binary_accuracy: 0.9036 - loss: 0.2797 - val_auc: 0.8074 - val_binary_accuracy: 0.8920 - val_loss: 0.2937\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7622 - binary_accuracy: 0.9041 - loss: 0.2781 - val_auc: 0.8080 - val_binary_accuracy: 0.8935 - val_loss: 0.2897\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7637 - binary_accuracy: 0.9046 - loss: 0.2772 - val_auc: 0.8079 - val_binary_accuracy: 0.8942 - val_loss: 0.2887\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9048 - loss: 0.2763 - val_auc: 0.8083 - val_binary_accuracy: 0.8941 - val_loss: 0.2876\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7663 - binary_accuracy: 0.9052 - loss: 0.2756 - val_auc: 0.8083 - val_binary_accuracy: 0.8939 - val_loss: 0.2867\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7681 - binary_accuracy: 0.9054 - loss: 0.2749 - val_auc: 0.8082 - val_binary_accuracy: 0.8954 - val_loss: 0.2848\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.8988 - loss: 0.2816\n",
            "Fold 5 Metrics: Loss = 0.2848, Accuracy = 0.8954, AUC = 0.8082\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2785\n",
            "Average Accuracy: 0.9037\n",
            "Average AUC: 0.8072\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 2, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6672 - binary_accuracy: 0.8183 - loss: 0.9800 - val_auc: 0.7084 - val_binary_accuracy: 0.9062 - val_loss: 0.2851\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7467 - binary_accuracy: 0.9104 - loss: 0.2730 - val_auc: 0.7630 - val_binary_accuracy: 0.9085 - val_loss: 0.2725\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9115 - loss: 0.2640 - val_auc: 0.7712 - val_binary_accuracy: 0.9078 - val_loss: 0.2701\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9116 - loss: 0.2609 - val_auc: 0.7749 - val_binary_accuracy: 0.9081 - val_loss: 0.2696\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9110 - loss: 0.2592 - val_auc: 0.7790 - val_binary_accuracy: 0.9088 - val_loss: 0.2691\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9110 - loss: 0.2577 - val_auc: 0.7828 - val_binary_accuracy: 0.9082 - val_loss: 0.2687\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9112 - loss: 0.2566 - val_auc: 0.7846 - val_binary_accuracy: 0.9088 - val_loss: 0.2677\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9117 - loss: 0.2557 - val_auc: 0.7861 - val_binary_accuracy: 0.9091 - val_loss: 0.2670\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9118 - loss: 0.2546 - val_auc: 0.7875 - val_binary_accuracy: 0.9091 - val_loss: 0.2667\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9122 - loss: 0.2539 - val_auc: 0.7892 - val_binary_accuracy: 0.9093 - val_loss: 0.2660\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7822 - binary_accuracy: 0.9124 - loss: 0.2588\n",
            "Fold 1 Metrics: Loss = 0.2660, Accuracy = 0.9093, AUC = 0.7892\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6465 - binary_accuracy: 0.8995 - loss: 0.4357 - val_auc: 0.7847 - val_binary_accuracy: 0.9057 - val_loss: 0.2662\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9039 - loss: 0.2732 - val_auc: 0.7982 - val_binary_accuracy: 0.9069 - val_loss: 0.2611\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9050 - loss: 0.2692 - val_auc: 0.8029 - val_binary_accuracy: 0.9078 - val_loss: 0.2584\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9053 - loss: 0.2669 - val_auc: 0.8064 - val_binary_accuracy: 0.9091 - val_loss: 0.2565\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9062 - loss: 0.2651 - val_auc: 0.8092 - val_binary_accuracy: 0.9097 - val_loss: 0.2555\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9067 - loss: 0.2640 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2546\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9072 - loss: 0.2629 - val_auc: 0.8124 - val_binary_accuracy: 0.9097 - val_loss: 0.2535\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9074 - loss: 0.2617 - val_auc: 0.8130 - val_binary_accuracy: 0.9099 - val_loss: 0.2538\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9083 - loss: 0.2610 - val_auc: 0.8145 - val_binary_accuracy: 0.9102 - val_loss: 0.2532\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9082 - loss: 0.2601 - val_auc: 0.8131 - val_binary_accuracy: 0.9100 - val_loss: 0.2538\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9138 - loss: 0.2447\n",
            "Fold 2 Metrics: Loss = 0.2538, Accuracy = 0.9100, AUC = 0.8131\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - auc: 0.6251 - binary_accuracy: 0.6070 - loss: 7.7190 - val_auc: 0.7514 - val_binary_accuracy: 0.8979 - val_loss: 0.3540\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7481 - binary_accuracy: 0.9018 - loss: 0.3162 - val_auc: 0.7567 - val_binary_accuracy: 0.9062 - val_loss: 0.2830\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7510 - binary_accuracy: 0.9061 - loss: 0.2809 - val_auc: 0.7641 - val_binary_accuracy: 0.9073 - val_loss: 0.2780\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7572 - binary_accuracy: 0.9071 - loss: 0.2766 - val_auc: 0.7705 - val_binary_accuracy: 0.9084 - val_loss: 0.2747\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7611 - binary_accuracy: 0.9078 - loss: 0.2740 - val_auc: 0.7745 - val_binary_accuracy: 0.9088 - val_loss: 0.2721\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9084 - loss: 0.2722 - val_auc: 0.7785 - val_binary_accuracy: 0.9099 - val_loss: 0.2698\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9087 - loss: 0.2710 - val_auc: 0.7810 - val_binary_accuracy: 0.9099 - val_loss: 0.2681\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9083 - loss: 0.2700 - val_auc: 0.7833 - val_binary_accuracy: 0.9102 - val_loss: 0.2663\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9085 - loss: 0.2693 - val_auc: 0.7858 - val_binary_accuracy: 0.9107 - val_loss: 0.2647\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9084 - loss: 0.2688 - val_auc: 0.7874 - val_binary_accuracy: 0.9106 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7845 - binary_accuracy: 0.9120 - loss: 0.2628\n",
            "Fold 3 Metrics: Loss = 0.2635, Accuracy = 0.9106, AUC = 0.7874\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6090 - binary_accuracy: 0.7314 - loss: 1.4009 - val_auc: 0.7550 - val_binary_accuracy: 0.9044 - val_loss: 0.2814\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7491 - binary_accuracy: 0.9039 - loss: 0.2804 - val_auc: 0.7699 - val_binary_accuracy: 0.9044 - val_loss: 0.2756\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9047 - loss: 0.2751 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9051 - loss: 0.2718 - val_auc: 0.7811 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9062 - loss: 0.2696 - val_auc: 0.7847 - val_binary_accuracy: 0.9048 - val_loss: 0.2687\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9075 - loss: 0.2675 - val_auc: 0.7883 - val_binary_accuracy: 0.9051 - val_loss: 0.2663\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9082 - loss: 0.2657 - val_auc: 0.7931 - val_binary_accuracy: 0.9067 - val_loss: 0.2641\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9091 - loss: 0.2642 - val_auc: 0.7973 - val_binary_accuracy: 0.9075 - val_loss: 0.2617\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9091 - loss: 0.2629 - val_auc: 0.8005 - val_binary_accuracy: 0.9075 - val_loss: 0.2599\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9097 - loss: 0.2620 - val_auc: 0.8028 - val_binary_accuracy: 0.9064 - val_loss: 0.2588\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7843 - binary_accuracy: 0.9057 - loss: 0.2647\n",
            "Fold 4 Metrics: Loss = 0.2588, Accuracy = 0.9064, AUC = 0.8028\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.3823 - binary_accuracy: 0.6444 - loss: 2.6988 - val_auc: 0.7613 - val_binary_accuracy: 0.9044 - val_loss: 0.2801\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7563 - binary_accuracy: 0.9041 - loss: 0.2800 - val_auc: 0.7886 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9042 - loss: 0.2727 - val_auc: 0.7919 - val_binary_accuracy: 0.9057 - val_loss: 0.2651\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9053 - loss: 0.2699 - val_auc: 0.7942 - val_binary_accuracy: 0.9066 - val_loss: 0.2634\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9067 - loss: 0.2681 - val_auc: 0.7959 - val_binary_accuracy: 0.9079 - val_loss: 0.2619\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.7979 - val_binary_accuracy: 0.9088 - val_loss: 0.2607\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9086 - loss: 0.2658 - val_auc: 0.7985 - val_binary_accuracy: 0.9088 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9088 - loss: 0.2649 - val_auc: 0.7996 - val_binary_accuracy: 0.9098 - val_loss: 0.2583\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9089 - loss: 0.2642 - val_auc: 0.8003 - val_binary_accuracy: 0.9106 - val_loss: 0.2573\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9089 - loss: 0.2636 - val_auc: 0.8013 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8121 - binary_accuracy: 0.9093 - loss: 0.2559\n",
            "Fold 5 Metrics: Loss = 0.2564, Accuracy = 0.9107, AUC = 0.8013\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2597\n",
            "Average Accuracy: 0.9094\n",
            "Average AUC: 0.7988\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 2, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5850 - binary_accuracy: 0.7056 - loss: 3.5820 - val_auc: 0.7506 - val_binary_accuracy: 0.9032 - val_loss: 0.2870\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9062 - loss: 0.2728 - val_auc: 0.7654 - val_binary_accuracy: 0.9012 - val_loss: 0.2774\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9059 - loss: 0.2640 - val_auc: 0.7735 - val_binary_accuracy: 0.9051 - val_loss: 0.2695\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9073 - loss: 0.2599 - val_auc: 0.7791 - val_binary_accuracy: 0.9065 - val_loss: 0.2673\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9091 - loss: 0.2576 - val_auc: 0.7819 - val_binary_accuracy: 0.9076 - val_loss: 0.2669\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9104 - loss: 0.2560 - val_auc: 0.7850 - val_binary_accuracy: 0.9082 - val_loss: 0.2670\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9110 - loss: 0.2544 - val_auc: 0.7886 - val_binary_accuracy: 0.9081 - val_loss: 0.2660\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9113 - loss: 0.2538 - val_auc: 0.7912 - val_binary_accuracy: 0.9081 - val_loss: 0.2651\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8023 - binary_accuracy: 0.9117 - loss: 0.2529 - val_auc: 0.7917 - val_binary_accuracy: 0.9094 - val_loss: 0.2645\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8033 - binary_accuracy: 0.9117 - loss: 0.2523 - val_auc: 0.7925 - val_binary_accuracy: 0.9097 - val_loss: 0.2641\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7866 - binary_accuracy: 0.9138 - loss: 0.2563\n",
            "Fold 1 Metrics: Loss = 0.2641, Accuracy = 0.9097, AUC = 0.7925\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6988 - binary_accuracy: 0.8928 - loss: 0.3315 - val_auc: 0.8039 - val_binary_accuracy: 0.9093 - val_loss: 0.2594\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9051 - loss: 0.2747 - val_auc: 0.8084 - val_binary_accuracy: 0.9090 - val_loss: 0.2561\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9049 - loss: 0.2702 - val_auc: 0.8109 - val_binary_accuracy: 0.9088 - val_loss: 0.2545\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9062 - loss: 0.2671 - val_auc: 0.8095 - val_binary_accuracy: 0.9097 - val_loss: 0.2549\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9058 - loss: 0.2657 - val_auc: 0.8088 - val_binary_accuracy: 0.9102 - val_loss: 0.2549\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9070 - loss: 0.2641 - val_auc: 0.8103 - val_binary_accuracy: 0.9106 - val_loss: 0.2543\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9065 - loss: 0.2636 - val_auc: 0.8100 - val_binary_accuracy: 0.9096 - val_loss: 0.2549\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9065 - loss: 0.2628 - val_auc: 0.8152 - val_binary_accuracy: 0.9096 - val_loss: 0.2527\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9064 - loss: 0.2621 - val_auc: 0.8099 - val_binary_accuracy: 0.9088 - val_loss: 0.2554\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9065 - loss: 0.2616 - val_auc: 0.8157 - val_binary_accuracy: 0.9097 - val_loss: 0.2523\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8194 - binary_accuracy: 0.9133 - loss: 0.2432\n",
            "Fold 2 Metrics: Loss = 0.2523, Accuracy = 0.9097, AUC = 0.8157\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5993 - binary_accuracy: 0.6960 - loss: 4.3704 - val_auc: 0.7570 - val_binary_accuracy: 0.9032 - val_loss: 0.2827\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7523 - binary_accuracy: 0.9015 - loss: 0.2811 - val_auc: 0.7754 - val_binary_accuracy: 0.9037 - val_loss: 0.2753\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7638 - binary_accuracy: 0.9037 - loss: 0.2751 - val_auc: 0.7816 - val_binary_accuracy: 0.9062 - val_loss: 0.2684\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9043 - loss: 0.2722 - val_auc: 0.7873 - val_binary_accuracy: 0.9073 - val_loss: 0.2650\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9061 - loss: 0.2696 - val_auc: 0.7918 - val_binary_accuracy: 0.9081 - val_loss: 0.2634\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9074 - loss: 0.2678 - val_auc: 0.7946 - val_binary_accuracy: 0.9072 - val_loss: 0.2637\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9081 - loss: 0.2660 - val_auc: 0.7969 - val_binary_accuracy: 0.9079 - val_loss: 0.2639\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9087 - loss: 0.2645 - val_auc: 0.7983 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9084 - loss: 0.2638 - val_auc: 0.8001 - val_binary_accuracy: 0.9065 - val_loss: 0.2652\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8013 - val_binary_accuracy: 0.9071 - val_loss: 0.2658\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7952 - binary_accuracy: 0.9058 - loss: 0.2666\n",
            "Fold 3 Metrics: Loss = 0.2658, Accuracy = 0.9071, AUC = 0.8013\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6354 - binary_accuracy: 0.8301 - loss: 0.6190 - val_auc: 0.7861 - val_binary_accuracy: 0.9060 - val_loss: 0.2670\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9055 - loss: 0.2697 - val_auc: 0.7922 - val_binary_accuracy: 0.9066 - val_loss: 0.2635\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9058 - loss: 0.2663 - val_auc: 0.7966 - val_binary_accuracy: 0.9072 - val_loss: 0.2611\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9073 - loss: 0.2643 - val_auc: 0.8001 - val_binary_accuracy: 0.9072 - val_loss: 0.2598\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9078 - loss: 0.2634 - val_auc: 0.8021 - val_binary_accuracy: 0.9085 - val_loss: 0.2589\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9080 - loss: 0.2620 - val_auc: 0.8040 - val_binary_accuracy: 0.9064 - val_loss: 0.2586\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9085 - loss: 0.2612 - val_auc: 0.8061 - val_binary_accuracy: 0.9085 - val_loss: 0.2573\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9087 - loss: 0.2607 - val_auc: 0.8071 - val_binary_accuracy: 0.9081 - val_loss: 0.2568\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9095 - loss: 0.2599 - val_auc: 0.8083 - val_binary_accuracy: 0.9079 - val_loss: 0.2561\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9095 - loss: 0.2597 - val_auc: 0.8095 - val_binary_accuracy: 0.9084 - val_loss: 0.2556\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9072 - loss: 0.2619\n",
            "Fold 4 Metrics: Loss = 0.2556, Accuracy = 0.9084, AUC = 0.8095\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5681 - binary_accuracy: 0.8017 - loss: 1.5777 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7602 - binary_accuracy: 0.9040 - loss: 0.2780 - val_auc: 0.7966 - val_binary_accuracy: 0.9060 - val_loss: 0.2675\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9051 - loss: 0.2728 - val_auc: 0.8024 - val_binary_accuracy: 0.9063 - val_loss: 0.2599\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9068 - loss: 0.2695 - val_auc: 0.8041 - val_binary_accuracy: 0.9062 - val_loss: 0.2572\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.8061 - val_binary_accuracy: 0.9060 - val_loss: 0.2557\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9073 - loss: 0.2677 - val_auc: 0.8068 - val_binary_accuracy: 0.9057 - val_loss: 0.2553\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9074 - loss: 0.2674 - val_auc: 0.8077 - val_binary_accuracy: 0.9050 - val_loss: 0.2549\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9074 - loss: 0.2671 - val_auc: 0.8084 - val_binary_accuracy: 0.9076 - val_loss: 0.2534\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9075 - loss: 0.2661 - val_auc: 0.8089 - val_binary_accuracy: 0.9085 - val_loss: 0.2527\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7823 - binary_accuracy: 0.9077 - loss: 0.2656 - val_auc: 0.8085 - val_binary_accuracy: 0.9062 - val_loss: 0.2537\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8185 - binary_accuracy: 0.9057 - loss: 0.2510\n",
            "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9062, AUC = 0.8085\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2583\n",
            "Average Accuracy: 0.9082\n",
            "Average AUC: 0.8055\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 2, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7206 - binary_accuracy: 0.9015 - loss: 0.2951 - val_auc: 0.7831 - val_binary_accuracy: 0.9057 - val_loss: 0.2774\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9075 - loss: 0.2660 - val_auc: 0.7913 - val_binary_accuracy: 0.9082 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9103 - loss: 0.2602 - val_auc: 0.7923 - val_binary_accuracy: 0.9100 - val_loss: 0.2604\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9117 - loss: 0.2571 - val_auc: 0.7938 - val_binary_accuracy: 0.9093 - val_loss: 0.2603\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9121 - loss: 0.2553 - val_auc: 0.7942 - val_binary_accuracy: 0.9097 - val_loss: 0.2599\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9120 - loss: 0.2541 - val_auc: 0.7920 - val_binary_accuracy: 0.9090 - val_loss: 0.2725\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9104 - loss: 0.2563 - val_auc: 0.7953 - val_binary_accuracy: 0.9113 - val_loss: 0.2587\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9130 - loss: 0.2515 - val_auc: 0.7960 - val_binary_accuracy: 0.9113 - val_loss: 0.2612\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9125 - loss: 0.2512 - val_auc: 0.7964 - val_binary_accuracy: 0.9093 - val_loss: 0.2646\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9130 - loss: 0.2505 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2682\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9115 - loss: 0.2636\n",
            "Fold 1 Metrics: Loss = 0.2682, Accuracy = 0.9084, AUC = 0.7962\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6507 - binary_accuracy: 0.8843 - loss: 0.4740 - val_auc: 0.7976 - val_binary_accuracy: 0.8947 - val_loss: 0.3016\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7485 - binary_accuracy: 0.9023 - loss: 0.2852 - val_auc: 0.8083 - val_binary_accuracy: 0.9025 - val_loss: 0.2893\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9043 - loss: 0.2794 - val_auc: 0.8127 - val_binary_accuracy: 0.8916 - val_loss: 0.2959\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9051 - loss: 0.2766 - val_auc: 0.8112 - val_binary_accuracy: 0.8998 - val_loss: 0.2769\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9057 - loss: 0.2730 - val_auc: 0.8106 - val_binary_accuracy: 0.9073 - val_loss: 0.2647\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9065 - loss: 0.2696 - val_auc: 0.8122 - val_binary_accuracy: 0.9090 - val_loss: 0.2586\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9060 - loss: 0.2673 - val_auc: 0.8116 - val_binary_accuracy: 0.9078 - val_loss: 0.2565\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9058 - loss: 0.2656 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9065 - loss: 0.2643 - val_auc: 0.8129 - val_binary_accuracy: 0.9087 - val_loss: 0.2559\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9058 - loss: 0.2639 - val_auc: 0.8117 - val_binary_accuracy: 0.9084 - val_loss: 0.2563\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9129 - loss: 0.2466\n",
            "Fold 2 Metrics: Loss = 0.2563, Accuracy = 0.9084, AUC = 0.8117\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6639 - binary_accuracy: 0.8643 - loss: 0.6035 - val_auc: 0.7813 - val_binary_accuracy: 0.9066 - val_loss: 0.2673\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9042 - loss: 0.2733 - val_auc: 0.7930 - val_binary_accuracy: 0.9078 - val_loss: 0.2642\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9054 - loss: 0.2707 - val_auc: 0.7990 - val_binary_accuracy: 0.9073 - val_loss: 0.2617\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7723 - binary_accuracy: 0.9055 - loss: 0.2689 - val_auc: 0.8002 - val_binary_accuracy: 0.9088 - val_loss: 0.2587\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9066 - loss: 0.2686 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2568\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2682 - val_auc: 0.8021 - val_binary_accuracy: 0.9103 - val_loss: 0.2572\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9059 - loss: 0.2670 - val_auc: 0.8038 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9064 - loss: 0.2652 - val_auc: 0.8028 - val_binary_accuracy: 0.9102 - val_loss: 0.2566\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9071 - loss: 0.2647 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2565\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9075 - loss: 0.2614 - val_auc: 0.8046 - val_binary_accuracy: 0.9091 - val_loss: 0.2583\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7994 - binary_accuracy: 0.9108 - loss: 0.2583\n",
            "Fold 3 Metrics: Loss = 0.2583, Accuracy = 0.9091, AUC = 0.8046\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5694 - binary_accuracy: 0.8304 - loss: 1.5457 - val_auc: 0.7800 - val_binary_accuracy: 0.9056 - val_loss: 0.2700\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7628 - binary_accuracy: 0.9050 - loss: 0.2748 - val_auc: 0.7886 - val_binary_accuracy: 0.9076 - val_loss: 0.2643\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9077 - loss: 0.2698 - val_auc: 0.7945 - val_binary_accuracy: 0.9100 - val_loss: 0.2620\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9082 - loss: 0.2678 - val_auc: 0.7987 - val_binary_accuracy: 0.9101 - val_loss: 0.2602\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9079 - loss: 0.2668 - val_auc: 0.8028 - val_binary_accuracy: 0.9095 - val_loss: 0.2585\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9085 - loss: 0.2658 - val_auc: 0.8057 - val_binary_accuracy: 0.9093 - val_loss: 0.2578\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9085 - loss: 0.2653 - val_auc: 0.8074 - val_binary_accuracy: 0.9095 - val_loss: 0.2566\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.8083 - val_binary_accuracy: 0.9097 - val_loss: 0.2561\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9086 - loss: 0.2635 - val_auc: 0.8092 - val_binary_accuracy: 0.9098 - val_loss: 0.2557\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9086 - loss: 0.2629 - val_auc: 0.8098 - val_binary_accuracy: 0.9093 - val_loss: 0.2554\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7923 - binary_accuracy: 0.9090 - loss: 0.2623\n",
            "Fold 4 Metrics: Loss = 0.2554, Accuracy = 0.9093, AUC = 0.8098\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6531 - binary_accuracy: 0.8927 - loss: 0.4317 - val_auc: 0.7936 - val_binary_accuracy: 0.8969 - val_loss: 0.2813\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7395 - binary_accuracy: 0.9018 - loss: 0.2877 - val_auc: 0.8023 - val_binary_accuracy: 0.8939 - val_loss: 0.2877\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7499 - binary_accuracy: 0.9029 - loss: 0.2835 - val_auc: 0.8056 - val_binary_accuracy: 0.8904 - val_loss: 0.2915\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7577 - binary_accuracy: 0.9043 - loss: 0.2793 - val_auc: 0.8084 - val_binary_accuracy: 0.8942 - val_loss: 0.2893\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9052 - loss: 0.2770 - val_auc: 0.8088 - val_binary_accuracy: 0.8972 - val_loss: 0.2828\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9055 - loss: 0.2751 - val_auc: 0.8097 - val_binary_accuracy: 0.8977 - val_loss: 0.2783\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9063 - loss: 0.2732 - val_auc: 0.8101 - val_binary_accuracy: 0.8997 - val_loss: 0.2738\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9056 - loss: 0.2718 - val_auc: 0.8100 - val_binary_accuracy: 0.9005 - val_loss: 0.2708\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9055 - loss: 0.2708 - val_auc: 0.8100 - val_binary_accuracy: 0.9016 - val_loss: 0.2697\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.8098 - val_binary_accuracy: 0.9017 - val_loss: 0.2687\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8171 - binary_accuracy: 0.9044 - loss: 0.2660\n",
            "Fold 5 Metrics: Loss = 0.2687, Accuracy = 0.9017, AUC = 0.8098\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2614\n",
            "Average Accuracy: 0.9074\n",
            "Average AUC: 0.8064\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 2, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6751 - binary_accuracy: 0.8891 - loss: 0.4576 - val_auc: 0.7801 - val_binary_accuracy: 0.9048 - val_loss: 0.2903\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9071 - loss: 0.2705 - val_auc: 0.7893 - val_binary_accuracy: 0.9072 - val_loss: 0.2758\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9083 - loss: 0.2653 - val_auc: 0.7927 - val_binary_accuracy: 0.9068 - val_loss: 0.2953\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7971 - val_binary_accuracy: 0.9072 - val_loss: 0.2744\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9099 - loss: 0.2589 - val_auc: 0.7995 - val_binary_accuracy: 0.9100 - val_loss: 0.2568\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9128 - loss: 0.2536 - val_auc: 0.7993 - val_binary_accuracy: 0.9085 - val_loss: 0.2695\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9110 - loss: 0.2546 - val_auc: 0.7992 - val_binary_accuracy: 0.9104 - val_loss: 0.2565\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9133 - loss: 0.2506 - val_auc: 0.7986 - val_binary_accuracy: 0.9100 - val_loss: 0.2572\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9129 - loss: 0.2498 - val_auc: 0.7979 - val_binary_accuracy: 0.9109 - val_loss: 0.2608\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9135 - loss: 0.2497 - val_auc: 0.7989 - val_binary_accuracy: 0.9110 - val_loss: 0.2685\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7940 - binary_accuracy: 0.9147 - loss: 0.2639\n",
            "Fold 1 Metrics: Loss = 0.2685, Accuracy = 0.9110, AUC = 0.7989\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6523 - binary_accuracy: 0.8804 - loss: 0.4424 - val_auc: 0.8101 - val_binary_accuracy: 0.9072 - val_loss: 0.2617\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9016 - loss: 0.2777 - val_auc: 0.8124 - val_binary_accuracy: 0.9082 - val_loss: 0.2594\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7771 - binary_accuracy: 0.9039 - loss: 0.2722 - val_auc: 0.8119 - val_binary_accuracy: 0.9069 - val_loss: 0.2695\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7794 - binary_accuracy: 0.9050 - loss: 0.2712 - val_auc: 0.8135 - val_binary_accuracy: 0.9075 - val_loss: 0.2694\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9047 - loss: 0.2728 - val_auc: 0.8077 - val_binary_accuracy: 0.9032 - val_loss: 0.2869\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7746 - binary_accuracy: 0.9046 - loss: 0.2735 - val_auc: 0.8085 - val_binary_accuracy: 0.9062 - val_loss: 0.2697\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7793 - binary_accuracy: 0.9053 - loss: 0.2711 - val_auc: 0.8074 - val_binary_accuracy: 0.9085 - val_loss: 0.2583\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9061 - loss: 0.2668 - val_auc: 0.8010 - val_binary_accuracy: 0.9081 - val_loss: 0.2615\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9065 - loss: 0.2658 - val_auc: 0.8077 - val_binary_accuracy: 0.9097 - val_loss: 0.2575\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7954 - binary_accuracy: 0.9076 - loss: 0.2630 - val_auc: 0.8098 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8171 - binary_accuracy: 0.9121 - loss: 0.2472\n",
            "Fold 2 Metrics: Loss = 0.2560, Accuracy = 0.9090, AUC = 0.8098\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6354 - binary_accuracy: 0.8592 - loss: 1.1882 - val_auc: 0.7836 - val_binary_accuracy: 0.9063 - val_loss: 0.2833\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7343 - binary_accuracy: 0.9017 - loss: 0.2911 - val_auc: 0.7957 - val_binary_accuracy: 0.9054 - val_loss: 0.3158\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7497 - binary_accuracy: 0.9062 - loss: 0.2802 - val_auc: 0.7990 - val_binary_accuracy: 0.9063 - val_loss: 0.3010\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7469 - binary_accuracy: 0.9048 - loss: 0.2840 - val_auc: 0.8028 - val_binary_accuracy: 0.9103 - val_loss: 0.2643\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7557 - binary_accuracy: 0.9056 - loss: 0.2795 - val_auc: 0.8042 - val_binary_accuracy: 0.9079 - val_loss: 0.2603\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9059 - loss: 0.2735 - val_auc: 0.8053 - val_binary_accuracy: 0.9019 - val_loss: 0.2697\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9073 - loss: 0.2696 - val_auc: 0.8050 - val_binary_accuracy: 0.8979 - val_loss: 0.2764\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9063 - loss: 0.2675 - val_auc: 0.8050 - val_binary_accuracy: 0.9032 - val_loss: 0.2713\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9069 - loss: 0.2662 - val_auc: 0.8055 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9075 - loss: 0.2672 - val_auc: 0.8045 - val_binary_accuracy: 0.9106 - val_loss: 0.2564\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9113 - loss: 0.2574\n",
            "Fold 3 Metrics: Loss = 0.2564, Accuracy = 0.9106, AUC = 0.8045\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6163 - binary_accuracy: 0.8575 - loss: 1.0092 - val_auc: 0.7969 - val_binary_accuracy: 0.9069 - val_loss: 0.2687\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9063 - loss: 0.2717 - val_auc: 0.7996 - val_binary_accuracy: 0.9072 - val_loss: 0.2764\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9062 - loss: 0.2717 - val_auc: 0.8056 - val_binary_accuracy: 0.9084 - val_loss: 0.2722\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9072 - loss: 0.2693 - val_auc: 0.8056 - val_binary_accuracy: 0.9093 - val_loss: 0.2649\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9081 - loss: 0.2673 - val_auc: 0.8103 - val_binary_accuracy: 0.9088 - val_loss: 0.2744\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9080 - loss: 0.2664 - val_auc: 0.8102 - val_binary_accuracy: 0.9095 - val_loss: 0.2560\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9096 - loss: 0.2632 - val_auc: 0.8079 - val_binary_accuracy: 0.9090 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9099 - loss: 0.2632 - val_auc: 0.8097 - val_binary_accuracy: 0.9098 - val_loss: 0.2559\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2621 - val_auc: 0.8114 - val_binary_accuracy: 0.9091 - val_loss: 0.2548\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8106 - val_binary_accuracy: 0.9091 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9082 - loss: 0.2627\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9091, AUC = 0.8106\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6018 - binary_accuracy: 0.8659 - loss: 0.8248 - val_auc: 0.7914 - val_binary_accuracy: 0.8991 - val_loss: 0.2734\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7383 - binary_accuracy: 0.9010 - loss: 0.2886 - val_auc: 0.8022 - val_binary_accuracy: 0.8964 - val_loss: 0.2739\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7462 - binary_accuracy: 0.9019 - loss: 0.2855 - val_auc: 0.8053 - val_binary_accuracy: 0.8974 - val_loss: 0.2661\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7504 - binary_accuracy: 0.9025 - loss: 0.2836 - val_auc: 0.8068 - val_binary_accuracy: 0.8948 - val_loss: 0.2792\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7560 - binary_accuracy: 0.9043 - loss: 0.2796 - val_auc: 0.8080 - val_binary_accuracy: 0.8963 - val_loss: 0.2804\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9047 - loss: 0.2770 - val_auc: 0.8085 - val_binary_accuracy: 0.8954 - val_loss: 0.2792\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9050 - loss: 0.2745 - val_auc: 0.8091 - val_binary_accuracy: 0.8986 - val_loss: 0.2732\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9049 - loss: 0.2723 - val_auc: 0.8096 - val_binary_accuracy: 0.9004 - val_loss: 0.2684\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9050 - loss: 0.2709 - val_auc: 0.8097 - val_binary_accuracy: 0.9047 - val_loss: 0.2630\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9055 - loss: 0.2689 - val_auc: 0.8094 - val_binary_accuracy: 0.9036 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9055 - loss: 0.2615\n",
            "Fold 5 Metrics: Loss = 0.2635, Accuracy = 0.9036, AUC = 0.8094\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2599\n",
            "Average Accuracy: 0.9087\n",
            "Average AUC: 0.8066\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 2, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6504 - binary_accuracy: 0.8786 - loss: 0.5864 - val_auc: 0.7817 - val_binary_accuracy: 0.9090 - val_loss: 0.2642\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7497 - binary_accuracy: 0.9061 - loss: 0.2797 - val_auc: 0.7915 - val_binary_accuracy: 0.9097 - val_loss: 0.2596\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9094 - loss: 0.2658 - val_auc: 0.7916 - val_binary_accuracy: 0.9096 - val_loss: 0.2672\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9096 - loss: 0.2645 - val_auc: 0.7939 - val_binary_accuracy: 0.9072 - val_loss: 0.2882\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9106 - loss: 0.2604 - val_auc: 0.7954 - val_binary_accuracy: 0.9075 - val_loss: 0.2800\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9101 - loss: 0.2594 - val_auc: 0.7972 - val_binary_accuracy: 0.9106 - val_loss: 0.2575\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9119 - loss: 0.2534 - val_auc: 0.7982 - val_binary_accuracy: 0.9110 - val_loss: 0.2569\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9129 - loss: 0.2515 - val_auc: 0.7977 - val_binary_accuracy: 0.9118 - val_loss: 0.2590\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9126 - loss: 0.2512 - val_auc: 0.7983 - val_binary_accuracy: 0.9115 - val_loss: 0.2604\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9129 - loss: 0.2498 - val_auc: 0.7975 - val_binary_accuracy: 0.9100 - val_loss: 0.2641\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7943 - binary_accuracy: 0.9126 - loss: 0.2593\n",
            "Fold 1 Metrics: Loss = 0.2641, Accuracy = 0.9100, AUC = 0.7975\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6451 - binary_accuracy: 0.8699 - loss: 0.7414 - val_auc: 0.8049 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9026 - loss: 0.2829 - val_auc: 0.8066 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9054 - loss: 0.2741 - val_auc: 0.8084 - val_binary_accuracy: 0.9090 - val_loss: 0.2603\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9047 - loss: 0.2715 - val_auc: 0.8099 - val_binary_accuracy: 0.9093 - val_loss: 0.2710\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9046 - loss: 0.2708 - val_auc: 0.8078 - val_binary_accuracy: 0.9068 - val_loss: 0.2784\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.8036 - val_binary_accuracy: 0.9097 - val_loss: 0.2598\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9065 - loss: 0.2692 - val_auc: 0.8046 - val_binary_accuracy: 0.9094 - val_loss: 0.2610\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9070 - loss: 0.2643 - val_auc: 0.8036 - val_binary_accuracy: 0.9099 - val_loss: 0.2586\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9073 - loss: 0.2626 - val_auc: 0.8043 - val_binary_accuracy: 0.9099 - val_loss: 0.2599\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9074 - loss: 0.2612 - val_auc: 0.7874 - val_binary_accuracy: 0.9091 - val_loss: 0.2646\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7999 - binary_accuracy: 0.9126 - loss: 0.2546\n",
            "Fold 2 Metrics: Loss = 0.2646, Accuracy = 0.9091, AUC = 0.7874\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6312 - binary_accuracy: 0.8660 - loss: 1.1762 - val_auc: 0.7974 - val_binary_accuracy: 0.9044 - val_loss: 0.2904\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7125 - binary_accuracy: 0.8964 - loss: 0.3124 - val_auc: 0.8023 - val_binary_accuracy: 0.9088 - val_loss: 0.2753\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7300 - binary_accuracy: 0.9011 - loss: 0.2977 - val_auc: 0.8039 - val_binary_accuracy: 0.9102 - val_loss: 0.2717\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7544 - binary_accuracy: 0.9030 - loss: 0.2803 - val_auc: 0.8034 - val_binary_accuracy: 0.9109 - val_loss: 0.2582\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7682 - binary_accuracy: 0.9053 - loss: 0.2721 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2785\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9056 - loss: 0.2778 - val_auc: 0.8070 - val_binary_accuracy: 0.9029 - val_loss: 0.2728\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9071 - loss: 0.2688 - val_auc: 0.8083 - val_binary_accuracy: 0.9048 - val_loss: 0.2672\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9059 - loss: 0.2665 - val_auc: 0.8085 - val_binary_accuracy: 0.9102 - val_loss: 0.2558\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9066 - loss: 0.2673 - val_auc: 0.8046 - val_binary_accuracy: 0.9115 - val_loss: 0.2581\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9060 - loss: 0.2694 - val_auc: 0.8055 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7987 - binary_accuracy: 0.9127 - loss: 0.2570\n",
            "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9109, AUC = 0.8055\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6304 - binary_accuracy: 0.8679 - loss: 0.8913 - val_auc: 0.7991 - val_binary_accuracy: 0.9059 - val_loss: 0.2620\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7455 - binary_accuracy: 0.9030 - loss: 0.2861 - val_auc: 0.8030 - val_binary_accuracy: 0.8994 - val_loss: 0.2697\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7504 - binary_accuracy: 0.9039 - loss: 0.2830 - val_auc: 0.8068 - val_binary_accuracy: 0.9036 - val_loss: 0.2613\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7532 - binary_accuracy: 0.9046 - loss: 0.2829 - val_auc: 0.8096 - val_binary_accuracy: 0.9062 - val_loss: 0.2562\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9077 - loss: 0.2700 - val_auc: 0.8097 - val_binary_accuracy: 0.9097 - val_loss: 0.2577\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9083 - loss: 0.2682 - val_auc: 0.8111 - val_binary_accuracy: 0.9087 - val_loss: 0.2879\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9082 - loss: 0.2706 - val_auc: 0.8127 - val_binary_accuracy: 0.9098 - val_loss: 0.2601\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9086 - loss: 0.2642 - val_auc: 0.8118 - val_binary_accuracy: 0.9097 - val_loss: 0.2550\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9096 - loss: 0.2642 - val_auc: 0.8109 - val_binary_accuracy: 0.9079 - val_loss: 0.2547\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9090 - loss: 0.2631 - val_auc: 0.8117 - val_binary_accuracy: 0.9097 - val_loss: 0.2546\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7939 - binary_accuracy: 0.9087 - loss: 0.2618\n",
            "Fold 4 Metrics: Loss = 0.2546, Accuracy = 0.9097, AUC = 0.8117\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6253 - binary_accuracy: 0.8703 - loss: 0.8894 - val_auc: 0.7991 - val_binary_accuracy: 0.9020 - val_loss: 0.2607\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7261 - binary_accuracy: 0.8994 - loss: 0.2994 - val_auc: 0.8043 - val_binary_accuracy: 0.8976 - val_loss: 0.2687\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7441 - binary_accuracy: 0.9007 - loss: 0.2874 - val_auc: 0.8064 - val_binary_accuracy: 0.8941 - val_loss: 0.2824\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7505 - binary_accuracy: 0.9025 - loss: 0.2835 - val_auc: 0.8074 - val_binary_accuracy: 0.8932 - val_loss: 0.2816\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9044 - loss: 0.2779 - val_auc: 0.8087 - val_binary_accuracy: 0.8955 - val_loss: 0.2819\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7670 - binary_accuracy: 0.9047 - loss: 0.2749 - val_auc: 0.8082 - val_binary_accuracy: 0.8997 - val_loss: 0.2742\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9046 - loss: 0.2726 - val_auc: 0.8087 - val_binary_accuracy: 0.8982 - val_loss: 0.2733\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9045 - loss: 0.2717 - val_auc: 0.8086 - val_binary_accuracy: 0.9028 - val_loss: 0.2651\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9049 - loss: 0.2713 - val_auc: 0.8088 - val_binary_accuracy: 0.9091 - val_loss: 0.2544\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9082 - loss: 0.2678 - val_auc: 0.8098 - val_binary_accuracy: 0.9103 - val_loss: 0.2518\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9092 - loss: 0.2512\n",
            "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9103, AUC = 0.8098\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2584\n",
            "Average Accuracy: 0.9100\n",
            "Average AUC: 0.8024\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 3, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6665 - binary_accuracy: 0.8809 - loss: 0.3548 - val_auc: 0.7707 - val_binary_accuracy: 0.9053 - val_loss: 0.2720\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9099 - loss: 0.2599 - val_auc: 0.7797 - val_binary_accuracy: 0.9054 - val_loss: 0.2697\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9112 - loss: 0.2573 - val_auc: 0.7813 - val_binary_accuracy: 0.9088 - val_loss: 0.2655\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9124 - loss: 0.2552 - val_auc: 0.7835 - val_binary_accuracy: 0.9094 - val_loss: 0.2650\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9120 - loss: 0.2541 - val_auc: 0.7842 - val_binary_accuracy: 0.9097 - val_loss: 0.2642\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9124 - loss: 0.2531 - val_auc: 0.7844 - val_binary_accuracy: 0.9082 - val_loss: 0.2656\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9124 - loss: 0.2528 - val_auc: 0.7838 - val_binary_accuracy: 0.9084 - val_loss: 0.2655\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9131 - loss: 0.2516 - val_auc: 0.7850 - val_binary_accuracy: 0.9087 - val_loss: 0.2645\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9131 - loss: 0.2506 - val_auc: 0.7873 - val_binary_accuracy: 0.9084 - val_loss: 0.2631\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9137 - loss: 0.2498 - val_auc: 0.7884 - val_binary_accuracy: 0.9090 - val_loss: 0.2616\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7839 - binary_accuracy: 0.9112 - loss: 0.2553\n",
            "Fold 1 Metrics: Loss = 0.2616, Accuracy = 0.9090, AUC = 0.7884\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6155 - binary_accuracy: 0.6510 - loss: 4.1405 - val_auc: 0.7794 - val_binary_accuracy: 0.9062 - val_loss: 0.2693\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9053 - loss: 0.2719 - val_auc: 0.7858 - val_binary_accuracy: 0.9066 - val_loss: 0.2671\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9056 - loss: 0.2693 - val_auc: 0.7872 - val_binary_accuracy: 0.9069 - val_loss: 0.2670\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9059 - loss: 0.2673 - val_auc: 0.7906 - val_binary_accuracy: 0.9073 - val_loss: 0.2652\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9057 - loss: 0.2665 - val_auc: 0.7928 - val_binary_accuracy: 0.9071 - val_loss: 0.2647\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9060 - loss: 0.2655 - val_auc: 0.7938 - val_binary_accuracy: 0.9075 - val_loss: 0.2648\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9067 - loss: 0.2648 - val_auc: 0.7987 - val_binary_accuracy: 0.9082 - val_loss: 0.2628\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9065 - loss: 0.2640 - val_auc: 0.7981 - val_binary_accuracy: 0.9081 - val_loss: 0.2629\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9069 - loss: 0.2633 - val_auc: 0.7996 - val_binary_accuracy: 0.9082 - val_loss: 0.2611\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9071 - loss: 0.2624 - val_auc: 0.8021 - val_binary_accuracy: 0.9084 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8058 - binary_accuracy: 0.9120 - loss: 0.2503\n",
            "Fold 2 Metrics: Loss = 0.2599, Accuracy = 0.9084, AUC = 0.8021\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5921 - binary_accuracy: 0.8004 - loss: 0.7227 - val_auc: 0.7783 - val_binary_accuracy: 0.9045 - val_loss: 0.2729\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9058 - loss: 0.2708 - val_auc: 0.7856 - val_binary_accuracy: 0.9045 - val_loss: 0.2701\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.7903 - val_binary_accuracy: 0.9056 - val_loss: 0.2687\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9070 - loss: 0.2667 - val_auc: 0.7940 - val_binary_accuracy: 0.9059 - val_loss: 0.2657\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9072 - loss: 0.2661 - val_auc: 0.7964 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9076 - loss: 0.2651 - val_auc: 0.7981 - val_binary_accuracy: 0.9097 - val_loss: 0.2615\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9085 - loss: 0.2648 - val_auc: 0.7985 - val_binary_accuracy: 0.9104 - val_loss: 0.2605\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9091 - loss: 0.2640 - val_auc: 0.7985 - val_binary_accuracy: 0.9107 - val_loss: 0.2604\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.7994 - val_binary_accuracy: 0.9112 - val_loss: 0.2601\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9092 - loss: 0.2630 - val_auc: 0.7999 - val_binary_accuracy: 0.9118 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9134 - loss: 0.2596\n",
            "Fold 3 Metrics: Loss = 0.2599, Accuracy = 0.9118, AUC = 0.7999\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5840 - binary_accuracy: 0.9036 - loss: 0.6592 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2716\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9041 - loss: 0.2733 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9053 - loss: 0.2686 - val_auc: 0.7917 - val_binary_accuracy: 0.9047 - val_loss: 0.2635\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9066 - loss: 0.2660 - val_auc: 0.7953 - val_binary_accuracy: 0.9069 - val_loss: 0.2616\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.7974 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9084 - loss: 0.2631 - val_auc: 0.7989 - val_binary_accuracy: 0.9087 - val_loss: 0.2593\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9092 - loss: 0.2622 - val_auc: 0.8015 - val_binary_accuracy: 0.9098 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9099 - loss: 0.2614 - val_auc: 0.8030 - val_binary_accuracy: 0.9100 - val_loss: 0.2574\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.8052 - val_binary_accuracy: 0.9106 - val_loss: 0.2567\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9099 - loss: 0.2600 - val_auc: 0.8075 - val_binary_accuracy: 0.9101 - val_loss: 0.2560\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7887 - binary_accuracy: 0.9099 - loss: 0.2617\n",
            "Fold 4 Metrics: Loss = 0.2560, Accuracy = 0.9101, AUC = 0.8075\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6327 - binary_accuracy: 0.9013 - loss: 0.3295 - val_auc: 0.7975 - val_binary_accuracy: 0.9050 - val_loss: 0.2635\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9047 - loss: 0.2742 - val_auc: 0.8009 - val_binary_accuracy: 0.9054 - val_loss: 0.2606\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9044 - loss: 0.2713 - val_auc: 0.8029 - val_binary_accuracy: 0.9048 - val_loss: 0.2600\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9054 - loss: 0.2696 - val_auc: 0.8037 - val_binary_accuracy: 0.9060 - val_loss: 0.2603\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9063 - loss: 0.2679 - val_auc: 0.8051 - val_binary_accuracy: 0.9064 - val_loss: 0.2612\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9065 - loss: 0.2664 - val_auc: 0.8060 - val_binary_accuracy: 0.9070 - val_loss: 0.2612\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9067 - loss: 0.2652 - val_auc: 0.8068 - val_binary_accuracy: 0.9073 - val_loss: 0.2614\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9071 - loss: 0.2646 - val_auc: 0.8073 - val_binary_accuracy: 0.9060 - val_loss: 0.2625\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9074 - loss: 0.2641 - val_auc: 0.8077 - val_binary_accuracy: 0.9062 - val_loss: 0.2635\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8081 - val_binary_accuracy: 0.9056 - val_loss: 0.2646\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8173 - binary_accuracy: 0.9061 - loss: 0.2620\n",
            "Fold 5 Metrics: Loss = 0.2646, Accuracy = 0.9056, AUC = 0.8081\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2604\n",
            "Average Accuracy: 0.9090\n",
            "Average AUC: 0.8012\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 3, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - auc: 0.5937 - binary_accuracy: 0.8173 - loss: 0.9928 - val_auc: 0.7537 - val_binary_accuracy: 0.9044 - val_loss: 0.2783\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9072 - loss: 0.2688 - val_auc: 0.7666 - val_binary_accuracy: 0.9051 - val_loss: 0.2734\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9082 - loss: 0.2637 - val_auc: 0.7752 - val_binary_accuracy: 0.9060 - val_loss: 0.2701\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9094 - loss: 0.2592 - val_auc: 0.7817 - val_binary_accuracy: 0.9075 - val_loss: 0.2679\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9099 - loss: 0.2582 - val_auc: 0.7860 - val_binary_accuracy: 0.9063 - val_loss: 0.2665\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9105 - loss: 0.2556 - val_auc: 0.7906 - val_binary_accuracy: 0.9078 - val_loss: 0.2641\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9114 - loss: 0.2535 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2627\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9114 - loss: 0.2525 - val_auc: 0.7919 - val_binary_accuracy: 0.9099 - val_loss: 0.2621\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8050 - binary_accuracy: 0.9117 - loss: 0.2514 - val_auc: 0.7944 - val_binary_accuracy: 0.9096 - val_loss: 0.2622\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8067 - binary_accuracy: 0.9119 - loss: 0.2506 - val_auc: 0.7947 - val_binary_accuracy: 0.9096 - val_loss: 0.2614\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7928 - binary_accuracy: 0.9130 - loss: 0.2529\n",
            "Fold 1 Metrics: Loss = 0.2614, Accuracy = 0.9096, AUC = 0.7947\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6341 - binary_accuracy: 0.8556 - loss: 0.5990 - val_auc: 0.7921 - val_binary_accuracy: 0.9081 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9058 - loss: 0.2726 - val_auc: 0.8011 - val_binary_accuracy: 0.9071 - val_loss: 0.2636\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9061 - loss: 0.2684 - val_auc: 0.8076 - val_binary_accuracy: 0.9081 - val_loss: 0.2601\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9073 - loss: 0.2658 - val_auc: 0.8074 - val_binary_accuracy: 0.9088 - val_loss: 0.2601\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9070 - loss: 0.2646 - val_auc: 0.7926 - val_binary_accuracy: 0.9088 - val_loss: 0.2640\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9066 - loss: 0.2638 - val_auc: 0.8001 - val_binary_accuracy: 0.9097 - val_loss: 0.2617\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7975 - binary_accuracy: 0.9074 - loss: 0.2621 - val_auc: 0.8042 - val_binary_accuracy: 0.9097 - val_loss: 0.2602\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9077 - loss: 0.2613 - val_auc: 0.7962 - val_binary_accuracy: 0.9100 - val_loss: 0.2620\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9077 - loss: 0.2617 - val_auc: 0.7965 - val_binary_accuracy: 0.9096 - val_loss: 0.2630\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9080 - loss: 0.2611 - val_auc: 0.8082 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8139 - binary_accuracy: 0.9123 - loss: 0.2519\n",
            "Fold 2 Metrics: Loss = 0.2608, Accuracy = 0.9078, AUC = 0.8082\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7358 - binary_accuracy: 0.9028 - loss: 0.2868 - val_auc: 0.7793 - val_binary_accuracy: 0.9050 - val_loss: 0.2715\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7651 - binary_accuracy: 0.9059 - loss: 0.2716 - val_auc: 0.7876 - val_binary_accuracy: 0.9065 - val_loss: 0.2706\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9080 - loss: 0.2672 - val_auc: 0.7938 - val_binary_accuracy: 0.9034 - val_loss: 0.2710\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9079 - loss: 0.2655 - val_auc: 0.7952 - val_binary_accuracy: 0.9066 - val_loss: 0.2670\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9085 - loss: 0.2657 - val_auc: 0.7968 - val_binary_accuracy: 0.9038 - val_loss: 0.2660\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9086 - loss: 0.2650 - val_auc: 0.7997 - val_binary_accuracy: 0.9056 - val_loss: 0.2631\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9088 - loss: 0.2656 - val_auc: 0.8009 - val_binary_accuracy: 0.9087 - val_loss: 0.2597\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9090 - loss: 0.2644 - val_auc: 0.8020 - val_binary_accuracy: 0.9047 - val_loss: 0.2618\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9090 - loss: 0.2648 - val_auc: 0.8026 - val_binary_accuracy: 0.9063 - val_loss: 0.2604\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9094 - loss: 0.2647 - val_auc: 0.8032 - val_binary_accuracy: 0.9094 - val_loss: 0.2573\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7966 - binary_accuracy: 0.9113 - loss: 0.2573\n",
            "Fold 3 Metrics: Loss = 0.2573, Accuracy = 0.9094, AUC = 0.8032\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6065 - binary_accuracy: 0.8294 - loss: 0.9768 - val_auc: 0.7830 - val_binary_accuracy: 0.9060 - val_loss: 0.2673\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9069 - loss: 0.2726 - val_auc: 0.7948 - val_binary_accuracy: 0.9094 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9085 - loss: 0.2673 - val_auc: 0.7999 - val_binary_accuracy: 0.9093 - val_loss: 0.2596\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9090 - loss: 0.2647 - val_auc: 0.8028 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9095 - loss: 0.2630 - val_auc: 0.8046 - val_binary_accuracy: 0.9091 - val_loss: 0.2571\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8064 - val_binary_accuracy: 0.9088 - val_loss: 0.2565\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9100 - loss: 0.2608 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2561\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9101 - loss: 0.2604 - val_auc: 0.8080 - val_binary_accuracy: 0.9078 - val_loss: 0.2560\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9098 - loss: 0.2601 - val_auc: 0.8078 - val_binary_accuracy: 0.9073 - val_loss: 0.2560\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9105 - loss: 0.2591 - val_auc: 0.8093 - val_binary_accuracy: 0.9067 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7920 - binary_accuracy: 0.9055 - loss: 0.2624\n",
            "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9067, AUC = 0.8093\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6545 - binary_accuracy: 0.8859 - loss: 0.3953 - val_auc: 0.7898 - val_binary_accuracy: 0.9073 - val_loss: 0.2651\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7587 - binary_accuracy: 0.9047 - loss: 0.2773 - val_auc: 0.7965 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7628 - binary_accuracy: 0.9048 - loss: 0.2751 - val_auc: 0.8017 - val_binary_accuracy: 0.9093 - val_loss: 0.2603\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7659 - binary_accuracy: 0.9043 - loss: 0.2730 - val_auc: 0.8038 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9056 - loss: 0.2703 - val_auc: 0.8052 - val_binary_accuracy: 0.9097 - val_loss: 0.2551\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9068 - loss: 0.2681 - val_auc: 0.8063 - val_binary_accuracy: 0.9094 - val_loss: 0.2535\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9077 - loss: 0.2662 - val_auc: 0.8072 - val_binary_accuracy: 0.9101 - val_loss: 0.2548\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9082 - loss: 0.2650 - val_auc: 0.8072 - val_binary_accuracy: 0.9066 - val_loss: 0.2581\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8079 - val_binary_accuracy: 0.9076 - val_loss: 0.2598\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.8072 - val_binary_accuracy: 0.9007 - val_loss: 0.2656\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8175 - binary_accuracy: 0.9040 - loss: 0.2620\n",
            "Fold 5 Metrics: Loss = 0.2656, Accuracy = 0.9007, AUC = 0.8072\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2602\n",
            "Average Accuracy: 0.9068\n",
            "Average AUC: 0.8045\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 3, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6956 - binary_accuracy: 0.8981 - loss: 0.3256 - val_auc: 0.7753 - val_binary_accuracy: 0.9066 - val_loss: 0.2714\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9109 - loss: 0.2643 - val_auc: 0.7793 - val_binary_accuracy: 0.9051 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9109 - loss: 0.2587 - val_auc: 0.7843 - val_binary_accuracy: 0.9053 - val_loss: 0.2744\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9102 - loss: 0.2562 - val_auc: 0.7861 - val_binary_accuracy: 0.9076 - val_loss: 0.2693\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9111 - loss: 0.2540 - val_auc: 0.7888 - val_binary_accuracy: 0.9091 - val_loss: 0.2610\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9134 - loss: 0.2522 - val_auc: 0.7873 - val_binary_accuracy: 0.9088 - val_loss: 0.2628\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9128 - loss: 0.2523 - val_auc: 0.7875 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9132 - loss: 0.2509 - val_auc: 0.7874 - val_binary_accuracy: 0.9081 - val_loss: 0.2658\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9125 - loss: 0.2510 - val_auc: 0.7905 - val_binary_accuracy: 0.9078 - val_loss: 0.2643\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9126 - loss: 0.2500 - val_auc: 0.7934 - val_binary_accuracy: 0.9087 - val_loss: 0.2630\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7922 - binary_accuracy: 0.9116 - loss: 0.2540\n",
            "Fold 1 Metrics: Loss = 0.2630, Accuracy = 0.9087, AUC = 0.7934\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6361 - binary_accuracy: 0.8670 - loss: 0.5392 - val_auc: 0.7902 - val_binary_accuracy: 0.9072 - val_loss: 0.2664\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9043 - loss: 0.2703 - val_auc: 0.7981 - val_binary_accuracy: 0.9079 - val_loss: 0.2626\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9057 - loss: 0.2677 - val_auc: 0.8008 - val_binary_accuracy: 0.9084 - val_loss: 0.2616\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9062 - loss: 0.2668 - val_auc: 0.7989 - val_binary_accuracy: 0.9099 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9065 - loss: 0.2667 - val_auc: 0.8062 - val_binary_accuracy: 0.9097 - val_loss: 0.2585\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9079 - loss: 0.2630 - val_auc: 0.8099 - val_binary_accuracy: 0.9097 - val_loss: 0.2600\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9078 - loss: 0.2615 - val_auc: 0.8086 - val_binary_accuracy: 0.9085 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9077 - loss: 0.2622 - val_auc: 0.8068 - val_binary_accuracy: 0.9099 - val_loss: 0.2579\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9086 - loss: 0.2605 - val_auc: 0.7886 - val_binary_accuracy: 0.9085 - val_loss: 0.2636\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9079 - loss: 0.2608 - val_auc: 0.8095 - val_binary_accuracy: 0.9084 - val_loss: 0.2578\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9133 - loss: 0.2487\n",
            "Fold 2 Metrics: Loss = 0.2578, Accuracy = 0.9084, AUC = 0.8095\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5923 - binary_accuracy: 0.8422 - loss: 1.5019 - val_auc: 0.7845 - val_binary_accuracy: 0.9094 - val_loss: 0.2713\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9060 - loss: 0.2708 - val_auc: 0.7917 - val_binary_accuracy: 0.9102 - val_loss: 0.2628\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9057 - loss: 0.2703 - val_auc: 0.7971 - val_binary_accuracy: 0.9103 - val_loss: 0.2601\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9060 - loss: 0.2695 - val_auc: 0.7996 - val_binary_accuracy: 0.9106 - val_loss: 0.2588\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9062 - loss: 0.2684 - val_auc: 0.8010 - val_binary_accuracy: 0.9107 - val_loss: 0.2581\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9062 - loss: 0.2660 - val_auc: 0.8041 - val_binary_accuracy: 0.9104 - val_loss: 0.2568\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9076 - loss: 0.2639 - val_auc: 0.8044 - val_binary_accuracy: 0.9107 - val_loss: 0.2583\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9084 - loss: 0.2621 - val_auc: 0.8048 - val_binary_accuracy: 0.9100 - val_loss: 0.2609\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.8040 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9087 - loss: 0.2611 - val_auc: 0.8040 - val_binary_accuracy: 0.9071 - val_loss: 0.2631\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7953 - binary_accuracy: 0.9070 - loss: 0.2647\n",
            "Fold 3 Metrics: Loss = 0.2631, Accuracy = 0.9071, AUC = 0.8040\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6367 - binary_accuracy: 0.8423 - loss: 0.8825 - val_auc: 0.7859 - val_binary_accuracy: 0.9056 - val_loss: 0.2670\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9066 - loss: 0.2724 - val_auc: 0.7916 - val_binary_accuracy: 0.9063 - val_loss: 0.2652\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9070 - loss: 0.2686 - val_auc: 0.7988 - val_binary_accuracy: 0.9063 - val_loss: 0.2617\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9069 - loss: 0.2664 - val_auc: 0.8009 - val_binary_accuracy: 0.9079 - val_loss: 0.2597\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9078 - loss: 0.2651 - val_auc: 0.8030 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9088 - loss: 0.2630 - val_auc: 0.8057 - val_binary_accuracy: 0.9067 - val_loss: 0.2583\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9096 - loss: 0.2612 - val_auc: 0.8065 - val_binary_accuracy: 0.9060 - val_loss: 0.2581\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9094 - loss: 0.2607 - val_auc: 0.8071 - val_binary_accuracy: 0.9054 - val_loss: 0.2576\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9095 - loss: 0.2596 - val_auc: 0.8063 - val_binary_accuracy: 0.9029 - val_loss: 0.2584\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9096 - loss: 0.2590 - val_auc: 0.8078 - val_binary_accuracy: 0.9045 - val_loss: 0.2571\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7888 - binary_accuracy: 0.9034 - loss: 0.2643\n",
            "Fold 4 Metrics: Loss = 0.2571, Accuracy = 0.9045, AUC = 0.8078\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6077 - binary_accuracy: 0.8418 - loss: 1.1925 - val_auc: 0.7915 - val_binary_accuracy: 0.9060 - val_loss: 0.2669\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9026 - loss: 0.2794 - val_auc: 0.7980 - val_binary_accuracy: 0.9013 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7592 - binary_accuracy: 0.9033 - loss: 0.2775 - val_auc: 0.8011 - val_binary_accuracy: 0.9022 - val_loss: 0.2667\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9039 - loss: 0.2756 - val_auc: 0.8030 - val_binary_accuracy: 0.9059 - val_loss: 0.2590\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9045 - loss: 0.2732 - val_auc: 0.8042 - val_binary_accuracy: 0.9073 - val_loss: 0.2569\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9055 - loss: 0.2711 - val_auc: 0.8046 - val_binary_accuracy: 0.9095 - val_loss: 0.2549\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9066 - loss: 0.2716 - val_auc: 0.8053 - val_binary_accuracy: 0.9082 - val_loss: 0.2546\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9071 - loss: 0.2672 - val_auc: 0.8060 - val_binary_accuracy: 0.9079 - val_loss: 0.2548\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9076 - loss: 0.2658 - val_auc: 0.8058 - val_binary_accuracy: 0.9101 - val_loss: 0.2537\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9083 - loss: 0.2641 - val_auc: 0.8068 - val_binary_accuracy: 0.9091 - val_loss: 0.2604\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9103 - loss: 0.2588\n",
            "Fold 5 Metrics: Loss = 0.2604, Accuracy = 0.9091, AUC = 0.8068\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2603\n",
            "Average Accuracy: 0.9075\n",
            "Average AUC: 0.8043\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 3, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6620 - binary_accuracy: 0.8833 - loss: 0.4496 - val_auc: 0.7799 - val_binary_accuracy: 0.9063 - val_loss: 0.2659\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9081 - loss: 0.2658 - val_auc: 0.7848 - val_binary_accuracy: 0.9094 - val_loss: 0.2648\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9113 - loss: 0.2585 - val_auc: 0.7904 - val_binary_accuracy: 0.9099 - val_loss: 0.2627\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9116 - loss: 0.2551 - val_auc: 0.7899 - val_binary_accuracy: 0.9099 - val_loss: 0.2674\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9122 - loss: 0.2547 - val_auc: 0.7905 - val_binary_accuracy: 0.9116 - val_loss: 0.2607\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9130 - loss: 0.2520 - val_auc: 0.7956 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9134 - loss: 0.2508 - val_auc: 0.7931 - val_binary_accuracy: 0.9091 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9132 - loss: 0.2502 - val_auc: 0.7965 - val_binary_accuracy: 0.9094 - val_loss: 0.2582\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9127 - loss: 0.2493 - val_auc: 0.7941 - val_binary_accuracy: 0.9084 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9126 - loss: 0.2507 - val_auc: 0.7925 - val_binary_accuracy: 0.9078 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2541\n",
            "Fold 1 Metrics: Loss = 0.2635, Accuracy = 0.9078, AUC = 0.7925\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6600 - binary_accuracy: 0.8773 - loss: 0.4980 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7620 - binary_accuracy: 0.9007 - loss: 0.2799 - val_auc: 0.8084 - val_binary_accuracy: 0.9075 - val_loss: 0.2741\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9035 - loss: 0.2776 - val_auc: 0.8099 - val_binary_accuracy: 0.9087 - val_loss: 0.2728\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9048 - loss: 0.2731 - val_auc: 0.8094 - val_binary_accuracy: 0.9090 - val_loss: 0.2603\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9072 - loss: 0.2662 - val_auc: 0.8081 - val_binary_accuracy: 0.9085 - val_loss: 0.2601\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9079 - loss: 0.2648 - val_auc: 0.8067 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9073 - loss: 0.2640 - val_auc: 0.8100 - val_binary_accuracy: 0.9093 - val_loss: 0.2604\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9082 - loss: 0.2621 - val_auc: 0.8084 - val_binary_accuracy: 0.9088 - val_loss: 0.2623\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9086 - loss: 0.2616 - val_auc: 0.8096 - val_binary_accuracy: 0.9091 - val_loss: 0.2619\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9087 - loss: 0.2606 - val_auc: 0.8117 - val_binary_accuracy: 0.9094 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9136 - loss: 0.2495\n",
            "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9094, AUC = 0.8117\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6791 - binary_accuracy: 0.8861 - loss: 0.3834 - val_auc: 0.7818 - val_binary_accuracy: 0.9048 - val_loss: 0.2699\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7358 - binary_accuracy: 0.9021 - loss: 0.2882 - val_auc: 0.7873 - val_binary_accuracy: 0.9094 - val_loss: 0.2638\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9046 - loss: 0.2724 - val_auc: 0.7951 - val_binary_accuracy: 0.9096 - val_loss: 0.2608\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9066 - loss: 0.2682 - val_auc: 0.7976 - val_binary_accuracy: 0.9082 - val_loss: 0.2660\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9086 - loss: 0.2634 - val_auc: 0.7979 - val_binary_accuracy: 0.9106 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9092 - loss: 0.2634 - val_auc: 0.7986 - val_binary_accuracy: 0.9090 - val_loss: 0.2644\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9092 - loss: 0.2627 - val_auc: 0.8002 - val_binary_accuracy: 0.9096 - val_loss: 0.2616\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8004 - val_binary_accuracy: 0.9109 - val_loss: 0.2614\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9106 - loss: 0.2622 - val_auc: 0.8011 - val_binary_accuracy: 0.9112 - val_loss: 0.2604\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9095 - loss: 0.2622 - val_auc: 0.8030 - val_binary_accuracy: 0.9112 - val_loss: 0.2607\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7959 - binary_accuracy: 0.9136 - loss: 0.2612\n",
            "Fold 3 Metrics: Loss = 0.2607, Accuracy = 0.9112, AUC = 0.8030\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6388 - binary_accuracy: 0.8631 - loss: 0.8942 - val_auc: 0.7867 - val_binary_accuracy: 0.9048 - val_loss: 0.2682\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9056 - loss: 0.2752 - val_auc: 0.7949 - val_binary_accuracy: 0.9082 - val_loss: 0.2619\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9076 - loss: 0.2698 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2594\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9079 - loss: 0.2675 - val_auc: 0.8062 - val_binary_accuracy: 0.9093 - val_loss: 0.2566\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9082 - loss: 0.2656 - val_auc: 0.8061 - val_binary_accuracy: 0.9094 - val_loss: 0.2567\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9089 - loss: 0.2627 - val_auc: 0.8084 - val_binary_accuracy: 0.9094 - val_loss: 0.2554\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9092 - loss: 0.2613 - val_auc: 0.8066 - val_binary_accuracy: 0.9081 - val_loss: 0.2564\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9097 - loss: 0.2597 - val_auc: 0.8074 - val_binary_accuracy: 0.9087 - val_loss: 0.2563\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9098 - loss: 0.2596 - val_auc: 0.8103 - val_binary_accuracy: 0.9082 - val_loss: 0.2549\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9098 - loss: 0.2587 - val_auc: 0.8091 - val_binary_accuracy: 0.9084 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7912 - binary_accuracy: 0.9070 - loss: 0.2622\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9084, AUC = 0.8091\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6449 - binary_accuracy: 0.8789 - loss: 0.6324 - val_auc: 0.7935 - val_binary_accuracy: 0.8997 - val_loss: 0.2774\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7408 - binary_accuracy: 0.9024 - loss: 0.2866 - val_auc: 0.7989 - val_binary_accuracy: 0.8995 - val_loss: 0.2754\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9037 - loss: 0.2780 - val_auc: 0.8015 - val_binary_accuracy: 0.8991 - val_loss: 0.2727\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9040 - loss: 0.2746 - val_auc: 0.8044 - val_binary_accuracy: 0.9035 - val_loss: 0.2653\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9039 - loss: 0.2743 - val_auc: 0.8053 - val_binary_accuracy: 0.9091 - val_loss: 0.2541\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9058 - loss: 0.2716 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2536\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9079 - loss: 0.2663 - val_auc: 0.8048 - val_binary_accuracy: 0.9078 - val_loss: 0.2582\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9072 - loss: 0.2669 - val_auc: 0.8068 - val_binary_accuracy: 0.9066 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9074 - loss: 0.2647 - val_auc: 0.8064 - val_binary_accuracy: 0.9059 - val_loss: 0.2610\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9076 - loss: 0.2646 - val_auc: 0.8082 - val_binary_accuracy: 0.9073 - val_loss: 0.2601\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8170 - binary_accuracy: 0.9088 - loss: 0.2586\n",
            "Fold 5 Metrics: Loss = 0.2601, Accuracy = 0.9073, AUC = 0.8082\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2596\n",
            "Average Accuracy: 0.9088\n",
            "Average AUC: 0.8049\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 3, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6388 - binary_accuracy: 0.8800 - loss: 0.6860 - val_auc: 0.7757 - val_binary_accuracy: 0.9048 - val_loss: 0.2865\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9083 - loss: 0.2669 - val_auc: 0.7827 - val_binary_accuracy: 0.9106 - val_loss: 0.2686\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9112 - loss: 0.2575 - val_auc: 0.7874 - val_binary_accuracy: 0.9103 - val_loss: 0.2672\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9115 - loss: 0.2548 - val_auc: 0.7905 - val_binary_accuracy: 0.9100 - val_loss: 0.2609\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9129 - loss: 0.2533 - val_auc: 0.7899 - val_binary_accuracy: 0.9112 - val_loss: 0.2639\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9118 - loss: 0.2521 - val_auc: 0.7929 - val_binary_accuracy: 0.9100 - val_loss: 0.2595\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9128 - loss: 0.2509 - val_auc: 0.7960 - val_binary_accuracy: 0.9084 - val_loss: 0.2597\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9123 - loss: 0.2501 - val_auc: 0.7964 - val_binary_accuracy: 0.9071 - val_loss: 0.2621\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9127 - loss: 0.2490 - val_auc: 0.7963 - val_binary_accuracy: 0.9072 - val_loss: 0.2632\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8086 - binary_accuracy: 0.9128 - loss: 0.2486 - val_auc: 0.7955 - val_binary_accuracy: 0.9076 - val_loss: 0.2637\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7939 - binary_accuracy: 0.9108 - loss: 0.2548\n",
            "Fold 1 Metrics: Loss = 0.2637, Accuracy = 0.9076, AUC = 0.7955\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6477 - binary_accuracy: 0.8743 - loss: 0.6347 - val_auc: 0.8025 - val_binary_accuracy: 0.9075 - val_loss: 0.2917\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9032 - loss: 0.2789 - val_auc: 0.8055 - val_binary_accuracy: 0.9063 - val_loss: 0.2628\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9052 - loss: 0.2677 - val_auc: 0.8072 - val_binary_accuracy: 0.9084 - val_loss: 0.2620\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9069 - loss: 0.2647 - val_auc: 0.7967 - val_binary_accuracy: 0.9073 - val_loss: 0.2640\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9070 - loss: 0.2656 - val_auc: 0.8046 - val_binary_accuracy: 0.9084 - val_loss: 0.2632\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.8033 - val_binary_accuracy: 0.9096 - val_loss: 0.2651\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8108 - val_binary_accuracy: 0.9093 - val_loss: 0.2593\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9081 - loss: 0.2610 - val_auc: 0.8091 - val_binary_accuracy: 0.9082 - val_loss: 0.2620\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9084 - loss: 0.2606 - val_auc: 0.8068 - val_binary_accuracy: 0.9100 - val_loss: 0.2622\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9091 - loss: 0.2605 - val_auc: 0.8080 - val_binary_accuracy: 0.9094 - val_loss: 0.2625\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8152 - binary_accuracy: 0.9132 - loss: 0.2537\n",
            "Fold 2 Metrics: Loss = 0.2625, Accuracy = 0.9094, AUC = 0.8080\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6304 - binary_accuracy: 0.8858 - loss: 0.5479 - val_auc: 0.7825 - val_binary_accuracy: 0.9045 - val_loss: 0.2745\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9056 - loss: 0.2742 - val_auc: 0.7914 - val_binary_accuracy: 0.9096 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9059 - loss: 0.2710 - val_auc: 0.7938 - val_binary_accuracy: 0.9094 - val_loss: 0.2681\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9089 - loss: 0.2652 - val_auc: 0.7984 - val_binary_accuracy: 0.9099 - val_loss: 0.2606\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9084 - loss: 0.2637 - val_auc: 0.8018 - val_binary_accuracy: 0.9106 - val_loss: 0.2602\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9081 - loss: 0.2631 - val_auc: 0.8028 - val_binary_accuracy: 0.9104 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9091 - loss: 0.2626 - val_auc: 0.8040 - val_binary_accuracy: 0.9115 - val_loss: 0.2586\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8036 - val_binary_accuracy: 0.9113 - val_loss: 0.2588\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9094 - loss: 0.2616 - val_auc: 0.8056 - val_binary_accuracy: 0.9112 - val_loss: 0.2570\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9092 - loss: 0.2620 - val_auc: 0.8072 - val_binary_accuracy: 0.9113 - val_loss: 0.2564\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7995 - binary_accuracy: 0.9131 - loss: 0.2569\n",
            "Fold 3 Metrics: Loss = 0.2564, Accuracy = 0.9113, AUC = 0.8072\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6582 - binary_accuracy: 0.8837 - loss: 0.4978 - val_auc: 0.7885 - val_binary_accuracy: 0.9063 - val_loss: 0.2651\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7616 - binary_accuracy: 0.9074 - loss: 0.2732 - val_auc: 0.7977 - val_binary_accuracy: 0.9084 - val_loss: 0.2606\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9080 - loss: 0.2676 - val_auc: 0.7999 - val_binary_accuracy: 0.9063 - val_loss: 0.2605\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.8037 - val_binary_accuracy: 0.9073 - val_loss: 0.2583\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9086 - loss: 0.2626 - val_auc: 0.8056 - val_binary_accuracy: 0.9053 - val_loss: 0.2606\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8077 - val_binary_accuracy: 0.9073 - val_loss: 0.2570\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9099 - loss: 0.2607 - val_auc: 0.8077 - val_binary_accuracy: 0.9072 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9097 - loss: 0.2600 - val_auc: 0.8090 - val_binary_accuracy: 0.9095 - val_loss: 0.2550\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9100 - loss: 0.2594 - val_auc: 0.8111 - val_binary_accuracy: 0.9066 - val_loss: 0.2576\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9105 - loss: 0.2590 - val_auc: 0.8121 - val_binary_accuracy: 0.9094 - val_loss: 0.2541\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9083 - loss: 0.2626\n",
            "Fold 4 Metrics: Loss = 0.2541, Accuracy = 0.9094, AUC = 0.8121\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6539 - binary_accuracy: 0.8786 - loss: 0.5847 - val_auc: 0.7943 - val_binary_accuracy: 0.8989 - val_loss: 0.2791\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7515 - binary_accuracy: 0.9014 - loss: 0.2809 - val_auc: 0.7996 - val_binary_accuracy: 0.9003 - val_loss: 0.2678\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7562 - binary_accuracy: 0.9038 - loss: 0.2776 - val_auc: 0.8028 - val_binary_accuracy: 0.9098 - val_loss: 0.2559\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9069 - loss: 0.2694 - val_auc: 0.8029 - val_binary_accuracy: 0.9072 - val_loss: 0.2561\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9055 - loss: 0.2693 - val_auc: 0.8059 - val_binary_accuracy: 0.9064 - val_loss: 0.2601\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.8060 - val_binary_accuracy: 0.9064 - val_loss: 0.2627\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9074 - loss: 0.2652 - val_auc: 0.8074 - val_binary_accuracy: 0.9098 - val_loss: 0.2635\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9087 - loss: 0.2641 - val_auc: 0.8080 - val_binary_accuracy: 0.9107 - val_loss: 0.2613\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9091 - loss: 0.2633 - val_auc: 0.8089 - val_binary_accuracy: 0.9107 - val_loss: 0.2611\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8096 - val_binary_accuracy: 0.9119 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8174 - binary_accuracy: 0.9104 - loss: 0.2589\n",
            "Fold 5 Metrics: Loss = 0.2599, Accuracy = 0.9119, AUC = 0.8096\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2593\n",
            "Average Accuracy: 0.9099\n",
            "Average AUC: 0.8065\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 4, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6384 - binary_accuracy: 0.7253 - loss: 0.6739 - val_auc: 0.7654 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9078 - loss: 0.2624 - val_auc: 0.7704 - val_binary_accuracy: 0.9071 - val_loss: 0.2705\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9102 - loss: 0.2583 - val_auc: 0.7766 - val_binary_accuracy: 0.9076 - val_loss: 0.2668\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9113 - loss: 0.2560 - val_auc: 0.7785 - val_binary_accuracy: 0.9082 - val_loss: 0.2660\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9109 - loss: 0.2554 - val_auc: 0.7813 - val_binary_accuracy: 0.9088 - val_loss: 0.2646\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9116 - loss: 0.2536 - val_auc: 0.7830 - val_binary_accuracy: 0.9084 - val_loss: 0.2646\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9120 - loss: 0.2528 - val_auc: 0.7833 - val_binary_accuracy: 0.9084 - val_loss: 0.2649\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9120 - loss: 0.2531 - val_auc: 0.7844 - val_binary_accuracy: 0.9088 - val_loss: 0.2636\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9117 - loss: 0.2523 - val_auc: 0.7862 - val_binary_accuracy: 0.9088 - val_loss: 0.2633\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8023 - binary_accuracy: 0.9122 - loss: 0.2519 - val_auc: 0.7858 - val_binary_accuracy: 0.9084 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7829 - binary_accuracy: 0.9113 - loss: 0.2570\n",
            "Fold 1 Metrics: Loss = 0.2635, Accuracy = 0.9084, AUC = 0.7858\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7086 - binary_accuracy: 0.9021 - loss: 0.2949 - val_auc: 0.7871 - val_binary_accuracy: 0.9037 - val_loss: 0.2693\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9035 - loss: 0.2758 - val_auc: 0.7947 - val_binary_accuracy: 0.9045 - val_loss: 0.2644\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9039 - loss: 0.2725 - val_auc: 0.7982 - val_binary_accuracy: 0.9071 - val_loss: 0.2615\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9041 - loss: 0.2703 - val_auc: 0.7994 - val_binary_accuracy: 0.9069 - val_loss: 0.2612\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9053 - loss: 0.2685 - val_auc: 0.8018 - val_binary_accuracy: 0.9068 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9066 - loss: 0.2672 - val_auc: 0.8031 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9077 - loss: 0.2657 - val_auc: 0.8058 - val_binary_accuracy: 0.9081 - val_loss: 0.2574\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9080 - loss: 0.2645 - val_auc: 0.8058 - val_binary_accuracy: 0.9072 - val_loss: 0.2594\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9084 - loss: 0.2639 - val_auc: 0.8076 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9077 - loss: 0.2627 - val_auc: 0.8092 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8094 - binary_accuracy: 0.9120 - loss: 0.2474\n",
            "Fold 2 Metrics: Loss = 0.2549, Accuracy = 0.9091, AUC = 0.8092\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5823 - binary_accuracy: 0.8480 - loss: 0.3761 - val_auc: 0.7783 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7558 - binary_accuracy: 0.9051 - loss: 0.2762 - val_auc: 0.7873 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9054 - loss: 0.2711 - val_auc: 0.7906 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9059 - loss: 0.2684 - val_auc: 0.7936 - val_binary_accuracy: 0.9048 - val_loss: 0.2640\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9069 - loss: 0.2670 - val_auc: 0.7955 - val_binary_accuracy: 0.9071 - val_loss: 0.2631\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9076 - loss: 0.2658 - val_auc: 0.7965 - val_binary_accuracy: 0.9090 - val_loss: 0.2616\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9077 - loss: 0.2651 - val_auc: 0.7986 - val_binary_accuracy: 0.9090 - val_loss: 0.2609\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.8005 - val_binary_accuracy: 0.9096 - val_loss: 0.2598\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9089 - loss: 0.2628 - val_auc: 0.8015 - val_binary_accuracy: 0.9093 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9090 - loss: 0.2623 - val_auc: 0.8019 - val_binary_accuracy: 0.9100 - val_loss: 0.2583\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7959 - binary_accuracy: 0.9112 - loss: 0.2586\n",
            "Fold 3 Metrics: Loss = 0.2583, Accuracy = 0.9100, AUC = 0.8019\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5424 - binary_accuracy: 0.7829 - loss: 2.5380 - val_auc: 0.7417 - val_binary_accuracy: 0.9042 - val_loss: 0.2835\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7403 - binary_accuracy: 0.9047 - loss: 0.2825 - val_auc: 0.7766 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7654 - binary_accuracy: 0.9051 - loss: 0.2741 - val_auc: 0.7845 - val_binary_accuracy: 0.9060 - val_loss: 0.2684\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9057 - loss: 0.2713 - val_auc: 0.7886 - val_binary_accuracy: 0.9057 - val_loss: 0.2669\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9066 - loss: 0.2691 - val_auc: 0.7914 - val_binary_accuracy: 0.9067 - val_loss: 0.2646\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9073 - loss: 0.2670 - val_auc: 0.7940 - val_binary_accuracy: 0.9072 - val_loss: 0.2627\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9083 - loss: 0.2652 - val_auc: 0.7963 - val_binary_accuracy: 0.9078 - val_loss: 0.2610\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9085 - loss: 0.2642 - val_auc: 0.7988 - val_binary_accuracy: 0.9079 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.7999 - val_binary_accuracy: 0.9078 - val_loss: 0.2587\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.8012 - val_binary_accuracy: 0.9084 - val_loss: 0.2582\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7816 - binary_accuracy: 0.9074 - loss: 0.2649\n",
            "Fold 4 Metrics: Loss = 0.2582, Accuracy = 0.9084, AUC = 0.8012\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6275 - binary_accuracy: 0.7391 - loss: 0.8155 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9040 - loss: 0.2751 - val_auc: 0.7884 - val_binary_accuracy: 0.9047 - val_loss: 0.2655\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9050 - loss: 0.2705 - val_auc: 0.7919 - val_binary_accuracy: 0.9054 - val_loss: 0.2642\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9060 - loss: 0.2683 - val_auc: 0.7948 - val_binary_accuracy: 0.9064 - val_loss: 0.2613\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9070 - loss: 0.2670 - val_auc: 0.7955 - val_binary_accuracy: 0.9059 - val_loss: 0.2607\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9073 - loss: 0.2658 - val_auc: 0.7986 - val_binary_accuracy: 0.9062 - val_loss: 0.2584\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9080 - loss: 0.2647 - val_auc: 0.8002 - val_binary_accuracy: 0.9082 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9081 - loss: 0.2642 - val_auc: 0.8006 - val_binary_accuracy: 0.9098 - val_loss: 0.2568\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9085 - loss: 0.2635 - val_auc: 0.8030 - val_binary_accuracy: 0.9095 - val_loss: 0.2563\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9092 - loss: 0.2628 - val_auc: 0.8030 - val_binary_accuracy: 0.9101 - val_loss: 0.2553\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9084 - loss: 0.2544\n",
            "Fold 5 Metrics: Loss = 0.2553, Accuracy = 0.9101, AUC = 0.8030\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2580\n",
            "Average Accuracy: 0.9092\n",
            "Average AUC: 0.8002\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 4, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6757 - binary_accuracy: 0.8468 - loss: 0.5495 - val_auc: 0.7643 - val_binary_accuracy: 0.9044 - val_loss: 0.2779\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9066 - loss: 0.2666 - val_auc: 0.7750 - val_binary_accuracy: 0.9047 - val_loss: 0.2712\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9079 - loss: 0.2623 - val_auc: 0.7807 - val_binary_accuracy: 0.9056 - val_loss: 0.2686\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9093 - loss: 0.2587 - val_auc: 0.7848 - val_binary_accuracy: 0.9059 - val_loss: 0.2674\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9096 - loss: 0.2566 - val_auc: 0.7860 - val_binary_accuracy: 0.9066 - val_loss: 0.2668\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9096 - loss: 0.2544 - val_auc: 0.7871 - val_binary_accuracy: 0.9069 - val_loss: 0.2668\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8017 - binary_accuracy: 0.9107 - loss: 0.2529 - val_auc: 0.7890 - val_binary_accuracy: 0.9068 - val_loss: 0.2661\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9107 - loss: 0.2526 - val_auc: 0.7918 - val_binary_accuracy: 0.9075 - val_loss: 0.2652\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9111 - loss: 0.2512 - val_auc: 0.7935 - val_binary_accuracy: 0.9079 - val_loss: 0.2638\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8081 - binary_accuracy: 0.9116 - loss: 0.2500 - val_auc: 0.7935 - val_binary_accuracy: 0.9085 - val_loss: 0.2631\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9120 - loss: 0.2536\n",
            "Fold 1 Metrics: Loss = 0.2631, Accuracy = 0.9085, AUC = 0.7935\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6902 - binary_accuracy: 0.8972 - loss: 0.3136 - val_auc: 0.7918 - val_binary_accuracy: 0.9079 - val_loss: 0.2654\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9049 - loss: 0.2730 - val_auc: 0.7993 - val_binary_accuracy: 0.9096 - val_loss: 0.2639\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9067 - loss: 0.2697 - val_auc: 0.8037 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9065 - loss: 0.2693 - val_auc: 0.8056 - val_binary_accuracy: 0.9106 - val_loss: 0.2598\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9073 - loss: 0.2667 - val_auc: 0.8046 - val_binary_accuracy: 0.9072 - val_loss: 0.2676\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9075 - loss: 0.2645 - val_auc: 0.8046 - val_binary_accuracy: 0.9073 - val_loss: 0.2627\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9075 - loss: 0.2636 - val_auc: 0.8023 - val_binary_accuracy: 0.9090 - val_loss: 0.2621\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9084 - loss: 0.2623 - val_auc: 0.8102 - val_binary_accuracy: 0.9102 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8023 - val_binary_accuracy: 0.9090 - val_loss: 0.2625\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9083 - loss: 0.2611 - val_auc: 0.8094 - val_binary_accuracy: 0.9087 - val_loss: 0.2577\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.9118 - loss: 0.2485\n",
            "Fold 2 Metrics: Loss = 0.2577, Accuracy = 0.9087, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6536 - binary_accuracy: 0.8522 - loss: 0.7490 - val_auc: 0.7771 - val_binary_accuracy: 0.9056 - val_loss: 0.2699\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7580 - binary_accuracy: 0.9071 - loss: 0.2740 - val_auc: 0.7829 - val_binary_accuracy: 0.9075 - val_loss: 0.2692\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7664 - binary_accuracy: 0.9071 - loss: 0.2707 - val_auc: 0.7879 - val_binary_accuracy: 0.9084 - val_loss: 0.2675\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9067 - loss: 0.2691 - val_auc: 0.7899 - val_binary_accuracy: 0.9087 - val_loss: 0.2670\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.7923 - val_binary_accuracy: 0.9059 - val_loss: 0.2672\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9075 - loss: 0.2664 - val_auc: 0.7951 - val_binary_accuracy: 0.9097 - val_loss: 0.2641\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9078 - loss: 0.2666 - val_auc: 0.7944 - val_binary_accuracy: 0.9103 - val_loss: 0.2628\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9081 - loss: 0.2658 - val_auc: 0.7962 - val_binary_accuracy: 0.9079 - val_loss: 0.2634\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9081 - loss: 0.2657 - val_auc: 0.7973 - val_binary_accuracy: 0.9099 - val_loss: 0.2622\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9082 - loss: 0.2648 - val_auc: 0.7984 - val_binary_accuracy: 0.9102 - val_loss: 0.2601\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7943 - binary_accuracy: 0.9107 - loss: 0.2599\n",
            "Fold 3 Metrics: Loss = 0.2601, Accuracy = 0.9102, AUC = 0.7984\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - auc: 0.6610 - binary_accuracy: 0.9044 - loss: 0.3356 - val_auc: 0.7807 - val_binary_accuracy: 0.9048 - val_loss: 0.2690\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9063 - loss: 0.2737 - val_auc: 0.7888 - val_binary_accuracy: 0.9070 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9070 - loss: 0.2696 - val_auc: 0.7962 - val_binary_accuracy: 0.9053 - val_loss: 0.2630\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9063 - loss: 0.2666 - val_auc: 0.7984 - val_binary_accuracy: 0.9023 - val_loss: 0.2622\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2643 - val_auc: 0.8011 - val_binary_accuracy: 0.9062 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9076 - loss: 0.2632 - val_auc: 0.8021 - val_binary_accuracy: 0.9035 - val_loss: 0.2602\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9086 - loss: 0.2624 - val_auc: 0.8032 - val_binary_accuracy: 0.9032 - val_loss: 0.2599\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.8072 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9094 - loss: 0.2603 - val_auc: 0.8086 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8094 - val_binary_accuracy: 0.9090 - val_loss: 0.2546\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7896 - binary_accuracy: 0.9082 - loss: 0.2620\n",
            "Fold 4 Metrics: Loss = 0.2546, Accuracy = 0.9090, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5903 - binary_accuracy: 0.8426 - loss: 0.8164 - val_auc: 0.7801 - val_binary_accuracy: 0.9066 - val_loss: 0.2782\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7524 - binary_accuracy: 0.9046 - loss: 0.2796 - val_auc: 0.7909 - val_binary_accuracy: 0.9069 - val_loss: 0.2708\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9046 - loss: 0.2746 - val_auc: 0.7965 - val_binary_accuracy: 0.9073 - val_loss: 0.2656\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9044 - loss: 0.2720 - val_auc: 0.8004 - val_binary_accuracy: 0.9069 - val_loss: 0.2650\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9039 - loss: 0.2702 - val_auc: 0.8023 - val_binary_accuracy: 0.9059 - val_loss: 0.2651\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9054 - loss: 0.2685 - val_auc: 0.8046 - val_binary_accuracy: 0.9066 - val_loss: 0.2666\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9065 - loss: 0.2671 - val_auc: 0.8059 - val_binary_accuracy: 0.9075 - val_loss: 0.2641\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9071 - loss: 0.2656 - val_auc: 0.8055 - val_binary_accuracy: 0.9053 - val_loss: 0.2659\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.8081 - val_binary_accuracy: 0.9063 - val_loss: 0.2657\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8076 - val_binary_accuracy: 0.9066 - val_loss: 0.2638\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9092 - loss: 0.2615\n",
            "Fold 5 Metrics: Loss = 0.2638, Accuracy = 0.9066, AUC = 0.8076\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2599\n",
            "Average Accuracy: 0.9086\n",
            "Average AUC: 0.8037\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 4, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6601 - binary_accuracy: 0.8901 - loss: 0.3777 - val_auc: 0.7766 - val_binary_accuracy: 0.9072 - val_loss: 0.2873\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9085 - loss: 0.2657 - val_auc: 0.7797 - val_binary_accuracy: 0.9054 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9094 - loss: 0.2584 - val_auc: 0.7858 - val_binary_accuracy: 0.9071 - val_loss: 0.2628\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9100 - loss: 0.2566 - val_auc: 0.7885 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9112 - loss: 0.2537 - val_auc: 0.7880 - val_binary_accuracy: 0.9073 - val_loss: 0.2634\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9117 - loss: 0.2526 - val_auc: 0.7910 - val_binary_accuracy: 0.9082 - val_loss: 0.2622\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9122 - loss: 0.2506 - val_auc: 0.7872 - val_binary_accuracy: 0.9066 - val_loss: 0.2642\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9123 - loss: 0.2502 - val_auc: 0.7878 - val_binary_accuracy: 0.9082 - val_loss: 0.2619\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9120 - loss: 0.2493 - val_auc: 0.7917 - val_binary_accuracy: 0.9076 - val_loss: 0.2609\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9129 - loss: 0.2482 - val_auc: 0.7920 - val_binary_accuracy: 0.9079 - val_loss: 0.2604\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7921 - binary_accuracy: 0.9108 - loss: 0.2517\n",
            "Fold 1 Metrics: Loss = 0.2604, Accuracy = 0.9079, AUC = 0.7920\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6860 - binary_accuracy: 0.8952 - loss: 0.3456 - val_auc: 0.7974 - val_binary_accuracy: 0.9045 - val_loss: 0.2650\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9038 - loss: 0.2723 - val_auc: 0.7958 - val_binary_accuracy: 0.9047 - val_loss: 0.2685\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9048 - loss: 0.2687 - val_auc: 0.8071 - val_binary_accuracy: 0.9065 - val_loss: 0.2631\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9066 - loss: 0.2662 - val_auc: 0.8038 - val_binary_accuracy: 0.9069 - val_loss: 0.2612\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9052 - loss: 0.2657 - val_auc: 0.8051 - val_binary_accuracy: 0.9087 - val_loss: 0.2634\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9080 - loss: 0.2622 - val_auc: 0.8095 - val_binary_accuracy: 0.9091 - val_loss: 0.2595\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9083 - loss: 0.2616 - val_auc: 0.8078 - val_binary_accuracy: 0.9085 - val_loss: 0.2598\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9082 - loss: 0.2610 - val_auc: 0.8081 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9082 - loss: 0.2608 - val_auc: 0.8132 - val_binary_accuracy: 0.9088 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9089 - loss: 0.2603 - val_auc: 0.8115 - val_binary_accuracy: 0.9093 - val_loss: 0.2583\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9126 - loss: 0.2503\n",
            "Fold 2 Metrics: Loss = 0.2583, Accuracy = 0.9093, AUC = 0.8115\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6137 - binary_accuracy: 0.8627 - loss: 0.8741 - val_auc: 0.7711 - val_binary_accuracy: 0.9042 - val_loss: 0.2741\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7423 - binary_accuracy: 0.9036 - loss: 0.2834 - val_auc: 0.7781 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9035 - loss: 0.2775 - val_auc: 0.7866 - val_binary_accuracy: 0.9069 - val_loss: 0.2650\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9054 - loss: 0.2721 - val_auc: 0.7931 - val_binary_accuracy: 0.9094 - val_loss: 0.2615\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9066 - loss: 0.2678 - val_auc: 0.7949 - val_binary_accuracy: 0.9093 - val_loss: 0.2676\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9082 - loss: 0.2646 - val_auc: 0.7980 - val_binary_accuracy: 0.9094 - val_loss: 0.2644\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9094 - loss: 0.2627 - val_auc: 0.7995 - val_binary_accuracy: 0.9075 - val_loss: 0.2640\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9092 - loss: 0.2619 - val_auc: 0.8025 - val_binary_accuracy: 0.9112 - val_loss: 0.2585\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9097 - loss: 0.2623 - val_auc: 0.8021 - val_binary_accuracy: 0.9091 - val_loss: 0.2627\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9099 - loss: 0.2620 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2578\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9121 - loss: 0.2586\n",
            "Fold 3 Metrics: Loss = 0.2578, Accuracy = 0.9107, AUC = 0.8026\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6741 - binary_accuracy: 0.8865 - loss: 0.3803 - val_auc: 0.7838 - val_binary_accuracy: 0.9053 - val_loss: 0.2682\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9059 - loss: 0.2740 - val_auc: 0.7923 - val_binary_accuracy: 0.9076 - val_loss: 0.2632\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9071 - loss: 0.2697 - val_auc: 0.7957 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9076 - loss: 0.2674 - val_auc: 0.7989 - val_binary_accuracy: 0.9062 - val_loss: 0.2605\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9080 - loss: 0.2638 - val_auc: 0.8016 - val_binary_accuracy: 0.9084 - val_loss: 0.2594\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9081 - loss: 0.2630 - val_auc: 0.8025 - val_binary_accuracy: 0.9084 - val_loss: 0.2579\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.8034 - val_binary_accuracy: 0.9062 - val_loss: 0.2580\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9098 - loss: 0.2608 - val_auc: 0.8053 - val_binary_accuracy: 0.9073 - val_loss: 0.2575\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.8054 - val_binary_accuracy: 0.9082 - val_loss: 0.2572\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9096 - loss: 0.2602 - val_auc: 0.8062 - val_binary_accuracy: 0.9088 - val_loss: 0.2559\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7868 - binary_accuracy: 0.9074 - loss: 0.2634\n",
            "Fold 4 Metrics: Loss = 0.2559, Accuracy = 0.9088, AUC = 0.8062\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7049 - binary_accuracy: 0.9019 - loss: 0.3049 - val_auc: 0.7936 - val_binary_accuracy: 0.8948 - val_loss: 0.2847\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7451 - binary_accuracy: 0.9022 - loss: 0.2836 - val_auc: 0.7960 - val_binary_accuracy: 0.9064 - val_loss: 0.2609\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7600 - binary_accuracy: 0.9063 - loss: 0.2748 - val_auc: 0.7998 - val_binary_accuracy: 0.9091 - val_loss: 0.2580\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9075 - loss: 0.2697 - val_auc: 0.8023 - val_binary_accuracy: 0.9014 - val_loss: 0.2655\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9061 - loss: 0.2675 - val_auc: 0.8047 - val_binary_accuracy: 0.9063 - val_loss: 0.2620\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9078 - loss: 0.2658 - val_auc: 0.8059 - val_binary_accuracy: 0.9045 - val_loss: 0.2639\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9081 - loss: 0.2652 - val_auc: 0.8069 - val_binary_accuracy: 0.9064 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9090 - loss: 0.2639 - val_auc: 0.8075 - val_binary_accuracy: 0.9075 - val_loss: 0.2598\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8081 - val_binary_accuracy: 0.9078 - val_loss: 0.2599\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9095 - loss: 0.2635 - val_auc: 0.8076 - val_binary_accuracy: 0.9094 - val_loss: 0.2566\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9087 - loss: 0.2541\n",
            "Fold 5 Metrics: Loss = 0.2566, Accuracy = 0.9094, AUC = 0.8076\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2578\n",
            "Average Accuracy: 0.9092\n",
            "Average AUC: 0.8040\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 4, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6876 - binary_accuracy: 0.8980 - loss: 0.3569 - val_auc: 0.7743 - val_binary_accuracy: 0.9050 - val_loss: 0.2731\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9083 - loss: 0.2651 - val_auc: 0.7793 - val_binary_accuracy: 0.9094 - val_loss: 0.2753\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9097 - loss: 0.2597 - val_auc: 0.7853 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9115 - loss: 0.2556 - val_auc: 0.7903 - val_binary_accuracy: 0.9069 - val_loss: 0.2635\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9118 - loss: 0.2535 - val_auc: 0.7921 - val_binary_accuracy: 0.9088 - val_loss: 0.2603\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8005 - binary_accuracy: 0.9122 - loss: 0.2525 - val_auc: 0.7940 - val_binary_accuracy: 0.9096 - val_loss: 0.2593\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9118 - loss: 0.2508 - val_auc: 0.7942 - val_binary_accuracy: 0.9094 - val_loss: 0.2607\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9121 - loss: 0.2510 - val_auc: 0.7926 - val_binary_accuracy: 0.9075 - val_loss: 0.2641\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8068 - binary_accuracy: 0.9132 - loss: 0.2497 - val_auc: 0.7980 - val_binary_accuracy: 0.9081 - val_loss: 0.2589\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8098 - binary_accuracy: 0.9131 - loss: 0.2479 - val_auc: 0.7973 - val_binary_accuracy: 0.9076 - val_loss: 0.2613\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7942 - binary_accuracy: 0.9109 - loss: 0.2531\n",
            "Fold 1 Metrics: Loss = 0.2613, Accuracy = 0.9076, AUC = 0.7973\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6711 - binary_accuracy: 0.8797 - loss: 0.5018 - val_auc: 0.8015 - val_binary_accuracy: 0.9056 - val_loss: 0.2718\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9027 - loss: 0.2744 - val_auc: 0.7999 - val_binary_accuracy: 0.9076 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9057 - loss: 0.2688 - val_auc: 0.8042 - val_binary_accuracy: 0.9076 - val_loss: 0.2603\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9064 - loss: 0.2659 - val_auc: 0.8051 - val_binary_accuracy: 0.9072 - val_loss: 0.2614\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9075 - loss: 0.2641 - val_auc: 0.8066 - val_binary_accuracy: 0.9091 - val_loss: 0.2605\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.8084 - val_binary_accuracy: 0.9091 - val_loss: 0.2640\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9075 - loss: 0.2617 - val_auc: 0.8021 - val_binary_accuracy: 0.9091 - val_loss: 0.2644\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8089 - val_binary_accuracy: 0.9099 - val_loss: 0.2613\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9089 - loss: 0.2604 - val_auc: 0.8110 - val_binary_accuracy: 0.9094 - val_loss: 0.2597\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8002 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.8073 - val_binary_accuracy: 0.9091 - val_loss: 0.2639\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8134 - binary_accuracy: 0.9130 - loss: 0.2549\n",
            "Fold 2 Metrics: Loss = 0.2639, Accuracy = 0.9091, AUC = 0.8073\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7087 - binary_accuracy: 0.8943 - loss: 0.3278 - val_auc: 0.7834 - val_binary_accuracy: 0.9068 - val_loss: 0.2663\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7614 - binary_accuracy: 0.9058 - loss: 0.2729 - val_auc: 0.7872 - val_binary_accuracy: 0.9088 - val_loss: 0.2684\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9084 - loss: 0.2662 - val_auc: 0.7947 - val_binary_accuracy: 0.9094 - val_loss: 0.2662\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9085 - loss: 0.2653 - val_auc: 0.7956 - val_binary_accuracy: 0.9097 - val_loss: 0.2623\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9079 - loss: 0.2651 - val_auc: 0.7958 - val_binary_accuracy: 0.9104 - val_loss: 0.2619\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9075 - loss: 0.2632 - val_auc: 0.8008 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9079 - loss: 0.2642 - val_auc: 0.7996 - val_binary_accuracy: 0.9106 - val_loss: 0.2593\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9090 - loss: 0.2615 - val_auc: 0.8014 - val_binary_accuracy: 0.9104 - val_loss: 0.2591\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9094 - loss: 0.2607 - val_auc: 0.8003 - val_binary_accuracy: 0.9110 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2612 - val_auc: 0.8013 - val_binary_accuracy: 0.9115 - val_loss: 0.2585\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7944 - binary_accuracy: 0.9129 - loss: 0.2589\n",
            "Fold 3 Metrics: Loss = 0.2585, Accuracy = 0.9115, AUC = 0.8013\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6414 - binary_accuracy: 0.8837 - loss: 0.4603 - val_auc: 0.7865 - val_binary_accuracy: 0.9048 - val_loss: 0.2691\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9071 - loss: 0.2743 - val_auc: 0.7921 - val_binary_accuracy: 0.9079 - val_loss: 0.2627\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9080 - loss: 0.2686 - val_auc: 0.7938 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9084 - loss: 0.2649 - val_auc: 0.7994 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.8044 - val_binary_accuracy: 0.9051 - val_loss: 0.2585\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9092 - loss: 0.2629 - val_auc: 0.8044 - val_binary_accuracy: 0.9075 - val_loss: 0.2573\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9098 - loss: 0.2614 - val_auc: 0.8047 - val_binary_accuracy: 0.9078 - val_loss: 0.2575\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.8072 - val_binary_accuracy: 0.9078 - val_loss: 0.2569\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9102 - loss: 0.2600 - val_auc: 0.8093 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8093 - val_binary_accuracy: 0.9079 - val_loss: 0.2554\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7897 - binary_accuracy: 0.9071 - loss: 0.2634\n",
            "Fold 4 Metrics: Loss = 0.2554, Accuracy = 0.9079, AUC = 0.8093\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6406 - binary_accuracy: 0.8849 - loss: 0.5232 - val_auc: 0.7915 - val_binary_accuracy: 0.9003 - val_loss: 0.2699\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7510 - binary_accuracy: 0.9013 - loss: 0.2806 - val_auc: 0.7973 - val_binary_accuracy: 0.9063 - val_loss: 0.2584\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7659 - binary_accuracy: 0.9040 - loss: 0.2732 - val_auc: 0.7997 - val_binary_accuracy: 0.9057 - val_loss: 0.2617\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9050 - loss: 0.2706 - val_auc: 0.8024 - val_binary_accuracy: 0.9075 - val_loss: 0.2551\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9059 - loss: 0.2685 - val_auc: 0.8049 - val_binary_accuracy: 0.9103 - val_loss: 0.2586\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9077 - loss: 0.2651 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2591\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9088 - loss: 0.2643 - val_auc: 0.8056 - val_binary_accuracy: 0.9110 - val_loss: 0.2556\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9072 - loss: 0.2652 - val_auc: 0.8070 - val_binary_accuracy: 0.9110 - val_loss: 0.2575\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8089 - val_binary_accuracy: 0.9112 - val_loss: 0.2575\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9096 - loss: 0.2636 - val_auc: 0.8088 - val_binary_accuracy: 0.9110 - val_loss: 0.2563\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9095 - loss: 0.2553\n",
            "Fold 5 Metrics: Loss = 0.2563, Accuracy = 0.9110, AUC = 0.8088\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2591\n",
            "Average Accuracy: 0.9094\n",
            "Average AUC: 0.8048\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 4, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6483 - binary_accuracy: 0.8755 - loss: 0.5879 - val_auc: 0.7742 - val_binary_accuracy: 0.9085 - val_loss: 0.2753\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.7806 - val_binary_accuracy: 0.9102 - val_loss: 0.2640\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9105 - loss: 0.2580 - val_auc: 0.7864 - val_binary_accuracy: 0.9104 - val_loss: 0.2625\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9110 - loss: 0.2549 - val_auc: 0.7909 - val_binary_accuracy: 0.9113 - val_loss: 0.2664\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9119 - loss: 0.2535 - val_auc: 0.7925 - val_binary_accuracy: 0.9100 - val_loss: 0.2614\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9126 - loss: 0.2514 - val_auc: 0.7936 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9129 - loss: 0.2511 - val_auc: 0.7957 - val_binary_accuracy: 0.9090 - val_loss: 0.2599\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8064 - binary_accuracy: 0.9132 - loss: 0.2499 - val_auc: 0.7953 - val_binary_accuracy: 0.9099 - val_loss: 0.2581\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9126 - loss: 0.2502 - val_auc: 0.7961 - val_binary_accuracy: 0.9082 - val_loss: 0.2605\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8092 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7959 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9107 - loss: 0.2537\n",
            "Fold 1 Metrics: Loss = 0.2621, Accuracy = 0.9078, AUC = 0.7959\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6642 - binary_accuracy: 0.8735 - loss: 0.5663 - val_auc: 0.7947 - val_binary_accuracy: 0.9085 - val_loss: 0.2929\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9033 - loss: 0.2770 - val_auc: 0.8037 - val_binary_accuracy: 0.9054 - val_loss: 0.2659\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.8057 - val_binary_accuracy: 0.9063 - val_loss: 0.2629\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9059 - loss: 0.2669 - val_auc: 0.7991 - val_binary_accuracy: 0.9079 - val_loss: 0.2624\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9068 - loss: 0.2656 - val_auc: 0.8044 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9083 - loss: 0.2644 - val_auc: 0.8036 - val_binary_accuracy: 0.9076 - val_loss: 0.2645\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9085 - loss: 0.2627 - val_auc: 0.8062 - val_binary_accuracy: 0.9088 - val_loss: 0.2634\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9090 - loss: 0.2620 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2604\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9091 - loss: 0.2608 - val_auc: 0.8073 - val_binary_accuracy: 0.9097 - val_loss: 0.2639\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9085 - loss: 0.2611 - val_auc: 0.8074 - val_binary_accuracy: 0.9087 - val_loss: 0.2623\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8090 - binary_accuracy: 0.9128 - loss: 0.2549\n",
            "Fold 2 Metrics: Loss = 0.2623, Accuracy = 0.9087, AUC = 0.8074\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6402 - binary_accuracy: 0.8750 - loss: 0.6017 - val_auc: 0.7788 - val_binary_accuracy: 0.9072 - val_loss: 0.2750\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9053 - loss: 0.2736 - val_auc: 0.7840 - val_binary_accuracy: 0.9087 - val_loss: 0.2655\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9067 - loss: 0.2696 - val_auc: 0.7891 - val_binary_accuracy: 0.9093 - val_loss: 0.2649\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9084 - loss: 0.2669 - val_auc: 0.7925 - val_binary_accuracy: 0.9096 - val_loss: 0.2627\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9084 - loss: 0.2645 - val_auc: 0.7955 - val_binary_accuracy: 0.9104 - val_loss: 0.2603\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.7969 - val_binary_accuracy: 0.9106 - val_loss: 0.2606\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9087 - loss: 0.2636 - val_auc: 0.8000 - val_binary_accuracy: 0.9110 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9090 - loss: 0.2628 - val_auc: 0.8008 - val_binary_accuracy: 0.9107 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.8026 - val_binary_accuracy: 0.9112 - val_loss: 0.2593\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8026 - val_binary_accuracy: 0.9107 - val_loss: 0.2581\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9112 - loss: 0.2587\n",
            "Fold 3 Metrics: Loss = 0.2581, Accuracy = 0.9107, AUC = 0.8026\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6449 - binary_accuracy: 0.8701 - loss: 0.8217 - val_auc: 0.7858 - val_binary_accuracy: 0.9053 - val_loss: 0.2684\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7600 - binary_accuracy: 0.9066 - loss: 0.2741 - val_auc: 0.7921 - val_binary_accuracy: 0.9082 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9084 - loss: 0.2681 - val_auc: 0.7965 - val_binary_accuracy: 0.9069 - val_loss: 0.2615\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9081 - loss: 0.2654 - val_auc: 0.8006 - val_binary_accuracy: 0.9088 - val_loss: 0.2594\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8035 - val_binary_accuracy: 0.9095 - val_loss: 0.2571\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9103 - loss: 0.2614 - val_auc: 0.8059 - val_binary_accuracy: 0.9098 - val_loss: 0.2557\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9104 - loss: 0.2604 - val_auc: 0.8073 - val_binary_accuracy: 0.9097 - val_loss: 0.2552\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9107 - loss: 0.2595 - val_auc: 0.8074 - val_binary_accuracy: 0.9100 - val_loss: 0.2550\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9104 - loss: 0.2598 - val_auc: 0.8083 - val_binary_accuracy: 0.9094 - val_loss: 0.2547\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9109 - loss: 0.2590 - val_auc: 0.8102 - val_binary_accuracy: 0.9095 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9089 - loss: 0.2623\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9095, AUC = 0.8102\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6608 - binary_accuracy: 0.8902 - loss: 0.4149 - val_auc: 0.7908 - val_binary_accuracy: 0.8977 - val_loss: 0.2746\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7512 - binary_accuracy: 0.9027 - loss: 0.2799 - val_auc: 0.7955 - val_binary_accuracy: 0.9032 - val_loss: 0.2625\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9039 - loss: 0.2754 - val_auc: 0.7993 - val_binary_accuracy: 0.9107 - val_loss: 0.2599\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7739 - binary_accuracy: 0.9060 - loss: 0.2696 - val_auc: 0.8012 - val_binary_accuracy: 0.9098 - val_loss: 0.2597\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9080 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9097 - val_loss: 0.2635\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9084 - loss: 0.2662 - val_auc: 0.8046 - val_binary_accuracy: 0.9084 - val_loss: 0.2644\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9076 - loss: 0.2654 - val_auc: 0.8065 - val_binary_accuracy: 0.9121 - val_loss: 0.2636\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9084 - loss: 0.2641 - val_auc: 0.8061 - val_binary_accuracy: 0.9106 - val_loss: 0.2647\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9086 - loss: 0.2640 - val_auc: 0.8081 - val_binary_accuracy: 0.9112 - val_loss: 0.2596\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9091 - loss: 0.2622 - val_auc: 0.8080 - val_binary_accuracy: 0.9116 - val_loss: 0.2602\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9115 - loss: 0.2588\n",
            "Fold 5 Metrics: Loss = 0.2602, Accuracy = 0.9116, AUC = 0.8080\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2596\n",
            "Average Accuracy: 0.9097\n",
            "Average AUC: 0.8048\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 5, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7407 - binary_accuracy: 0.9073 - loss: 0.2764 - val_auc: 0.7709 - val_binary_accuracy: 0.9047 - val_loss: 0.2712\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9094 - loss: 0.2598 - val_auc: 0.7768 - val_binary_accuracy: 0.9069 - val_loss: 0.2681\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9099 - loss: 0.2563 - val_auc: 0.7825 - val_binary_accuracy: 0.9065 - val_loss: 0.2662\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9106 - loss: 0.2545 - val_auc: 0.7853 - val_binary_accuracy: 0.9078 - val_loss: 0.2640\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9117 - loss: 0.2531 - val_auc: 0.7872 - val_binary_accuracy: 0.9088 - val_loss: 0.2630\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9120 - loss: 0.2518 - val_auc: 0.7887 - val_binary_accuracy: 0.9090 - val_loss: 0.2622\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7905 - val_binary_accuracy: 0.9094 - val_loss: 0.2618\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8069 - binary_accuracy: 0.9127 - loss: 0.2499 - val_auc: 0.7915 - val_binary_accuracy: 0.9099 - val_loss: 0.2613\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8082 - binary_accuracy: 0.9133 - loss: 0.2488 - val_auc: 0.7916 - val_binary_accuracy: 0.9093 - val_loss: 0.2611\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8092 - binary_accuracy: 0.9135 - loss: 0.2479 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2607\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9125 - loss: 0.2542\n",
            "Fold 1 Metrics: Loss = 0.2607, Accuracy = 0.9093, AUC = 0.7919\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5360 - binary_accuracy: 0.6777 - loss: 2.9505 - val_auc: 0.7771 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9029 - loss: 0.2784 - val_auc: 0.7787 - val_binary_accuracy: 0.9047 - val_loss: 0.2716\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9032 - loss: 0.2736 - val_auc: 0.7911 - val_binary_accuracy: 0.9056 - val_loss: 0.2646\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9049 - loss: 0.2709 - val_auc: 0.7938 - val_binary_accuracy: 0.9072 - val_loss: 0.2632\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9066 - loss: 0.2694 - val_auc: 0.7963 - val_binary_accuracy: 0.9078 - val_loss: 0.2622\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9065 - loss: 0.2683 - val_auc: 0.7986 - val_binary_accuracy: 0.9079 - val_loss: 0.2607\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9072 - loss: 0.2669 - val_auc: 0.8014 - val_binary_accuracy: 0.9078 - val_loss: 0.2594\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9078 - loss: 0.2658 - val_auc: 0.8025 - val_binary_accuracy: 0.9075 - val_loss: 0.2588\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9080 - loss: 0.2650 - val_auc: 0.8050 - val_binary_accuracy: 0.9073 - val_loss: 0.2586\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9082 - loss: 0.2644 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2574\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8085 - binary_accuracy: 0.9125 - loss: 0.2485\n",
            "Fold 2 Metrics: Loss = 0.2574, Accuracy = 0.9078, AUC = 0.8073\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4992 - binary_accuracy: 0.8095 - loss: 0.6973 - val_auc: 0.7599 - val_binary_accuracy: 0.9042 - val_loss: 0.2772\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9051 - loss: 0.2758 - val_auc: 0.7685 - val_binary_accuracy: 0.9042 - val_loss: 0.2740\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9054 - loss: 0.2724 - val_auc: 0.7766 - val_binary_accuracy: 0.9041 - val_loss: 0.2729\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9060 - loss: 0.2703 - val_auc: 0.7790 - val_binary_accuracy: 0.9045 - val_loss: 0.2711\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9061 - loss: 0.2688 - val_auc: 0.7822 - val_binary_accuracy: 0.9054 - val_loss: 0.2697\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.7842 - val_binary_accuracy: 0.9072 - val_loss: 0.2678\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9071 - loss: 0.2675 - val_auc: 0.7862 - val_binary_accuracy: 0.9087 - val_loss: 0.2669\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9073 - loss: 0.2668 - val_auc: 0.7873 - val_binary_accuracy: 0.9094 - val_loss: 0.2664\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9078 - loss: 0.2661 - val_auc: 0.7886 - val_binary_accuracy: 0.9102 - val_loss: 0.2654\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9082 - loss: 0.2655 - val_auc: 0.7896 - val_binary_accuracy: 0.9103 - val_loss: 0.2650\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7849 - binary_accuracy: 0.9110 - loss: 0.2645\n",
            "Fold 3 Metrics: Loss = 0.2650, Accuracy = 0.9103, AUC = 0.7896\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6278 - binary_accuracy: 0.8020 - loss: 0.4701 - val_auc: 0.7498 - val_binary_accuracy: 0.9044 - val_loss: 0.2810\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7508 - binary_accuracy: 0.9047 - loss: 0.2777 - val_auc: 0.7720 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9057 - loss: 0.2705 - val_auc: 0.7820 - val_binary_accuracy: 0.9060 - val_loss: 0.2687\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9083 - loss: 0.2678 - val_auc: 0.7870 - val_binary_accuracy: 0.9069 - val_loss: 0.2682\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9088 - loss: 0.2652 - val_auc: 0.7895 - val_binary_accuracy: 0.9069 - val_loss: 0.2663\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9094 - loss: 0.2636 - val_auc: 0.7913 - val_binary_accuracy: 0.9078 - val_loss: 0.2656\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9093 - loss: 0.2625 - val_auc: 0.7928 - val_binary_accuracy: 0.9078 - val_loss: 0.2651\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9094 - loss: 0.2617 - val_auc: 0.7946 - val_binary_accuracy: 0.9081 - val_loss: 0.2644\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2610 - val_auc: 0.7955 - val_binary_accuracy: 0.9081 - val_loss: 0.2647\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9096 - loss: 0.2601 - val_auc: 0.7969 - val_binary_accuracy: 0.9081 - val_loss: 0.2640\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7745 - binary_accuracy: 0.9073 - loss: 0.2713\n",
            "Fold 4 Metrics: Loss = 0.2640, Accuracy = 0.9081, AUC = 0.7969\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7206 - binary_accuracy: 0.9042 - loss: 0.2886 - val_auc: 0.7822 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7582 - binary_accuracy: 0.9044 - loss: 0.2772 - val_auc: 0.7893 - val_binary_accuracy: 0.9057 - val_loss: 0.2700\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9049 - loss: 0.2742 - val_auc: 0.7929 - val_binary_accuracy: 0.9062 - val_loss: 0.2663\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9060 - loss: 0.2720 - val_auc: 0.7953 - val_binary_accuracy: 0.9072 - val_loss: 0.2619\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9071 - loss: 0.2701 - val_auc: 0.7964 - val_binary_accuracy: 0.9076 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9072 - loss: 0.2692 - val_auc: 0.7965 - val_binary_accuracy: 0.9078 - val_loss: 0.2588\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9075 - loss: 0.2673 - val_auc: 0.7999 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9075 - loss: 0.2661 - val_auc: 0.8008 - val_binary_accuracy: 0.9098 - val_loss: 0.2570\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9086 - loss: 0.2659 - val_auc: 0.8012 - val_binary_accuracy: 0.9100 - val_loss: 0.2566\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9082 - loss: 0.2651 - val_auc: 0.8018 - val_binary_accuracy: 0.9109 - val_loss: 0.2557\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8119 - binary_accuracy: 0.9096 - loss: 0.2539\n",
            "Fold 5 Metrics: Loss = 0.2557, Accuracy = 0.9109, AUC = 0.8018\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2606\n",
            "Average Accuracy: 0.9093\n",
            "Average AUC: 0.7975\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 5, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6768 - binary_accuracy: 0.9012 - loss: 0.3083 - val_auc: 0.7721 - val_binary_accuracy: 0.9045 - val_loss: 0.2709\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9083 - loss: 0.2637 - val_auc: 0.7824 - val_binary_accuracy: 0.9053 - val_loss: 0.2659\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2583 - val_auc: 0.7853 - val_binary_accuracy: 0.9078 - val_loss: 0.2627\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9106 - loss: 0.2559 - val_auc: 0.7875 - val_binary_accuracy: 0.9087 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9118 - loss: 0.2540 - val_auc: 0.7889 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9116 - loss: 0.2527 - val_auc: 0.7904 - val_binary_accuracy: 0.9069 - val_loss: 0.2629\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9119 - loss: 0.2515 - val_auc: 0.7939 - val_binary_accuracy: 0.9088 - val_loss: 0.2604\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9119 - loss: 0.2500 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9123 - loss: 0.2497 - val_auc: 0.7948 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8091 - binary_accuracy: 0.9122 - loss: 0.2490 - val_auc: 0.7953 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7938 - binary_accuracy: 0.9118 - loss: 0.2518\n",
            "Fold 1 Metrics: Loss = 0.2594, Accuracy = 0.9085, AUC = 0.7953\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7273 - binary_accuracy: 0.9029 - loss: 0.2894 - val_auc: 0.7957 - val_binary_accuracy: 0.9044 - val_loss: 0.2647\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9034 - loss: 0.2712 - val_auc: 0.8002 - val_binary_accuracy: 0.9071 - val_loss: 0.2608\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9047 - loss: 0.2676 - val_auc: 0.8050 - val_binary_accuracy: 0.9066 - val_loss: 0.2592\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7906 - binary_accuracy: 0.9060 - loss: 0.2656 - val_auc: 0.8074 - val_binary_accuracy: 0.9081 - val_loss: 0.2573\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9077 - loss: 0.2643 - val_auc: 0.8084 - val_binary_accuracy: 0.9088 - val_loss: 0.2566\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9084 - loss: 0.2630 - val_auc: 0.8108 - val_binary_accuracy: 0.9090 - val_loss: 0.2543\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8112 - val_binary_accuracy: 0.9099 - val_loss: 0.2539\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9082 - loss: 0.2605 - val_auc: 0.8111 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8006 - binary_accuracy: 0.9083 - loss: 0.2604 - val_auc: 0.8108 - val_binary_accuracy: 0.9100 - val_loss: 0.2532\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9086 - loss: 0.2593 - val_auc: 0.8105 - val_binary_accuracy: 0.9099 - val_loss: 0.2544\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9137 - loss: 0.2452\n",
            "Fold 2 Metrics: Loss = 0.2544, Accuracy = 0.9099, AUC = 0.8105\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6220 - binary_accuracy: 0.8580 - loss: 0.4961 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7602 - binary_accuracy: 0.9052 - loss: 0.2745 - val_auc: 0.7819 - val_binary_accuracy: 0.9048 - val_loss: 0.2688\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7672 - binary_accuracy: 0.9063 - loss: 0.2710 - val_auc: 0.7895 - val_binary_accuracy: 0.9091 - val_loss: 0.2644\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9057 - loss: 0.2686 - val_auc: 0.7913 - val_binary_accuracy: 0.9085 - val_loss: 0.2633\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9065 - loss: 0.2667 - val_auc: 0.7919 - val_binary_accuracy: 0.9096 - val_loss: 0.2624\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9067 - loss: 0.2656 - val_auc: 0.7946 - val_binary_accuracy: 0.9097 - val_loss: 0.2612\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9080 - loss: 0.2635 - val_auc: 0.7939 - val_binary_accuracy: 0.9102 - val_loss: 0.2604\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9080 - loss: 0.2637 - val_auc: 0.7963 - val_binary_accuracy: 0.9103 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9082 - loss: 0.2612 - val_auc: 0.7947 - val_binary_accuracy: 0.9082 - val_loss: 0.2605\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9081 - loss: 0.2621 - val_auc: 0.7952 - val_binary_accuracy: 0.9097 - val_loss: 0.2594\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7884 - binary_accuracy: 0.9120 - loss: 0.2604\n",
            "Fold 3 Metrics: Loss = 0.2594, Accuracy = 0.9097, AUC = 0.7952\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6633 - binary_accuracy: 0.9040 - loss: 0.3229 - val_auc: 0.7850 - val_binary_accuracy: 0.9048 - val_loss: 0.2676\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9048 - loss: 0.2722 - val_auc: 0.7925 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9057 - loss: 0.2683 - val_auc: 0.7943 - val_binary_accuracy: 0.9050 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7988 - val_binary_accuracy: 0.9051 - val_loss: 0.2609\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9077 - loss: 0.2638 - val_auc: 0.8002 - val_binary_accuracy: 0.9057 - val_loss: 0.2599\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2619 - val_auc: 0.8020 - val_binary_accuracy: 0.9011 - val_loss: 0.2632\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9082 - loss: 0.2624 - val_auc: 0.8046 - val_binary_accuracy: 0.9022 - val_loss: 0.2611\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9090 - loss: 0.2608 - val_auc: 0.8046 - val_binary_accuracy: 0.9070 - val_loss: 0.2576\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9103 - loss: 0.2591 - val_auc: 0.8067 - val_binary_accuracy: 0.9059 - val_loss: 0.2580\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8067 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7872 - binary_accuracy: 0.9074 - loss: 0.2640\n",
            "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9087, AUC = 0.8067\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6249 - binary_accuracy: 0.8291 - loss: 0.4671 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9043 - loss: 0.2747 - val_auc: 0.7917 - val_binary_accuracy: 0.9003 - val_loss: 0.2738\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9041 - loss: 0.2734 - val_auc: 0.7943 - val_binary_accuracy: 0.8995 - val_loss: 0.2674\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7991 - val_binary_accuracy: 0.9067 - val_loss: 0.2655\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9060 - loss: 0.2693 - val_auc: 0.8004 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9080 - loss: 0.2660 - val_auc: 0.8007 - val_binary_accuracy: 0.9067 - val_loss: 0.2611\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9074 - loss: 0.2656 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2577\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9088 - loss: 0.2633 - val_auc: 0.8051 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8058 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9088 - loss: 0.2624 - val_auc: 0.8067 - val_binary_accuracy: 0.9103 - val_loss: 0.2563\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9101 - loss: 0.2536\n",
            "Fold 5 Metrics: Loss = 0.2563, Accuracy = 0.9103, AUC = 0.8067\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2571\n",
            "Average Accuracy: 0.9094\n",
            "Average AUC: 0.8029\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 5, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7065 - binary_accuracy: 0.9066 - loss: 0.2945 - val_auc: 0.7741 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9077 - loss: 0.2617 - val_auc: 0.7815 - val_binary_accuracy: 0.9050 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9095 - loss: 0.2581 - val_auc: 0.7843 - val_binary_accuracy: 0.9072 - val_loss: 0.2643\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9112 - loss: 0.2549 - val_auc: 0.7880 - val_binary_accuracy: 0.9072 - val_loss: 0.2635\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9112 - loss: 0.2535 - val_auc: 0.7885 - val_binary_accuracy: 0.9069 - val_loss: 0.2627\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9110 - loss: 0.2514 - val_auc: 0.7901 - val_binary_accuracy: 0.9094 - val_loss: 0.2613\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9117 - loss: 0.2508 - val_auc: 0.7918 - val_binary_accuracy: 0.9088 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9120 - loss: 0.2498 - val_auc: 0.7914 - val_binary_accuracy: 0.9081 - val_loss: 0.2612\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8099 - binary_accuracy: 0.9129 - loss: 0.2480 - val_auc: 0.7918 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8098 - binary_accuracy: 0.9131 - loss: 0.2480 - val_auc: 0.7914 - val_binary_accuracy: 0.9072 - val_loss: 0.2619\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7918 - binary_accuracy: 0.9114 - loss: 0.2528\n",
            "Fold 1 Metrics: Loss = 0.2619, Accuracy = 0.9072, AUC = 0.7914\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - auc: 0.6525 - binary_accuracy: 0.8688 - loss: 0.5184 - val_auc: 0.7926 - val_binary_accuracy: 0.9040 - val_loss: 0.2703\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9032 - loss: 0.2726 - val_auc: 0.7990 - val_binary_accuracy: 0.9047 - val_loss: 0.2685\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9047 - loss: 0.2679 - val_auc: 0.8014 - val_binary_accuracy: 0.9068 - val_loss: 0.2666\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9075 - loss: 0.2670 - val_auc: 0.8016 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9071 - loss: 0.2652 - val_auc: 0.8024 - val_binary_accuracy: 0.9069 - val_loss: 0.2633\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9076 - loss: 0.2636 - val_auc: 0.8017 - val_binary_accuracy: 0.9088 - val_loss: 0.2628\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9071 - loss: 0.2625 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2598\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9081 - loss: 0.2615 - val_auc: 0.8113 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9085 - loss: 0.2608 - val_auc: 0.8099 - val_binary_accuracy: 0.9093 - val_loss: 0.2587\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9091 - loss: 0.2603 - val_auc: 0.8159 - val_binary_accuracy: 0.9087 - val_loss: 0.2553\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8209 - binary_accuracy: 0.9127 - loss: 0.2465\n",
            "Fold 2 Metrics: Loss = 0.2553, Accuracy = 0.9087, AUC = 0.8159\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6395 - binary_accuracy: 0.8448 - loss: 0.8657 - val_auc: 0.7829 - val_binary_accuracy: 0.9059 - val_loss: 0.2744\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9073 - loss: 0.2715 - val_auc: 0.7891 - val_binary_accuracy: 0.9081 - val_loss: 0.2712\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9073 - loss: 0.2683 - val_auc: 0.7922 - val_binary_accuracy: 0.9050 - val_loss: 0.2667\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9076 - loss: 0.2681 - val_auc: 0.7940 - val_binary_accuracy: 0.9085 - val_loss: 0.2638\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9079 - loss: 0.2663 - val_auc: 0.7974 - val_binary_accuracy: 0.9084 - val_loss: 0.2618\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9078 - loss: 0.2643 - val_auc: 0.7991 - val_binary_accuracy: 0.9091 - val_loss: 0.2622\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9082 - loss: 0.2631 - val_auc: 0.8007 - val_binary_accuracy: 0.9090 - val_loss: 0.2607\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9089 - loss: 0.2625 - val_auc: 0.8027 - val_binary_accuracy: 0.9090 - val_loss: 0.2601\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9088 - loss: 0.2617 - val_auc: 0.8039 - val_binary_accuracy: 0.9073 - val_loss: 0.2604\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9095 - loss: 0.2615 - val_auc: 0.8035 - val_binary_accuracy: 0.9096 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7963 - binary_accuracy: 0.9118 - loss: 0.2593\n",
            "Fold 3 Metrics: Loss = 0.2587, Accuracy = 0.9096, AUC = 0.8035\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7178 - binary_accuracy: 0.9054 - loss: 0.2938 - val_auc: 0.7950 - val_binary_accuracy: 0.9076 - val_loss: 0.2615\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9079 - loss: 0.2668 - val_auc: 0.7960 - val_binary_accuracy: 0.9064 - val_loss: 0.2606\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9075 - loss: 0.2651 - val_auc: 0.7994 - val_binary_accuracy: 0.9053 - val_loss: 0.2609\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8033 - val_binary_accuracy: 0.9067 - val_loss: 0.2581\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9089 - loss: 0.2615 - val_auc: 0.8032 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9096 - loss: 0.2606 - val_auc: 0.7999 - val_binary_accuracy: 0.9088 - val_loss: 0.2583\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9105 - loss: 0.2601 - val_auc: 0.8074 - val_binary_accuracy: 0.9094 - val_loss: 0.2552\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8089 - val_binary_accuracy: 0.9087 - val_loss: 0.2560\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9107 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9107 - loss: 0.2571 - val_auc: 0.8107 - val_binary_accuracy: 0.9093 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7915 - binary_accuracy: 0.9094 - loss: 0.2624\n",
            "Fold 4 Metrics: Loss = 0.2551, Accuracy = 0.9093, AUC = 0.8107\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6953 - binary_accuracy: 0.9039 - loss: 0.2980 - val_auc: 0.7916 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9037 - loss: 0.2771 - val_auc: 0.7958 - val_binary_accuracy: 0.9053 - val_loss: 0.2638\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9051 - loss: 0.2717 - val_auc: 0.8012 - val_binary_accuracy: 0.9093 - val_loss: 0.2614\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.8033 - val_binary_accuracy: 0.9093 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9081 - loss: 0.2666 - val_auc: 0.8053 - val_binary_accuracy: 0.9104 - val_loss: 0.2614\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9084 - loss: 0.2659 - val_auc: 0.8059 - val_binary_accuracy: 0.9093 - val_loss: 0.2613\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9076 - loss: 0.2644 - val_auc: 0.8071 - val_binary_accuracy: 0.9101 - val_loss: 0.2575\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.8085 - val_binary_accuracy: 0.9103 - val_loss: 0.2564\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9099 - loss: 0.2622 - val_auc: 0.8092 - val_binary_accuracy: 0.9107 - val_loss: 0.2549\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9100 - loss: 0.2624 - val_auc: 0.8099 - val_binary_accuracy: 0.9098 - val_loss: 0.2529\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9086 - loss: 0.2514\n",
            "Fold 5 Metrics: Loss = 0.2529, Accuracy = 0.9098, AUC = 0.8099\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2568\n",
            "Average Accuracy: 0.9089\n",
            "Average AUC: 0.8063\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 5, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6974 - binary_accuracy: 0.9006 - loss: 0.3307 - val_auc: 0.7742 - val_binary_accuracy: 0.9084 - val_loss: 0.2769\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9089 - loss: 0.2635 - val_auc: 0.7827 - val_binary_accuracy: 0.9085 - val_loss: 0.2661\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9103 - loss: 0.2595 - val_auc: 0.7857 - val_binary_accuracy: 0.9091 - val_loss: 0.2629\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9110 - loss: 0.2545 - val_auc: 0.7854 - val_binary_accuracy: 0.9115 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7979 - binary_accuracy: 0.9113 - loss: 0.2533 - val_auc: 0.7902 - val_binary_accuracy: 0.9088 - val_loss: 0.2597\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7908 - val_binary_accuracy: 0.9079 - val_loss: 0.2609\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9125 - loss: 0.2505 - val_auc: 0.7908 - val_binary_accuracy: 0.9084 - val_loss: 0.2633\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9130 - loss: 0.2494 - val_auc: 0.7945 - val_binary_accuracy: 0.9063 - val_loss: 0.2647\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9125 - loss: 0.2491 - val_auc: 0.7944 - val_binary_accuracy: 0.9072 - val_loss: 0.2648\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9126 - loss: 0.2485 - val_auc: 0.7941 - val_binary_accuracy: 0.9073 - val_loss: 0.2626\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7940 - binary_accuracy: 0.9106 - loss: 0.2539\n",
            "Fold 1 Metrics: Loss = 0.2626, Accuracy = 0.9073, AUC = 0.7941\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6998 - binary_accuracy: 0.8838 - loss: 0.3609 - val_auc: 0.7953 - val_binary_accuracy: 0.9045 - val_loss: 0.2826\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7627 - binary_accuracy: 0.9035 - loss: 0.2775 - val_auc: 0.7992 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9049 - loss: 0.2698 - val_auc: 0.8042 - val_binary_accuracy: 0.9066 - val_loss: 0.2631\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9058 - loss: 0.2670 - val_auc: 0.8063 - val_binary_accuracy: 0.9081 - val_loss: 0.2642\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9070 - loss: 0.2663 - val_auc: 0.8062 - val_binary_accuracy: 0.9073 - val_loss: 0.2653\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9077 - loss: 0.2641 - val_auc: 0.8034 - val_binary_accuracy: 0.9075 - val_loss: 0.2677\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8074 - val_binary_accuracy: 0.9093 - val_loss: 0.2652\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9081 - loss: 0.2617 - val_auc: 0.8063 - val_binary_accuracy: 0.9085 - val_loss: 0.2641\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9086 - loss: 0.2614 - val_auc: 0.8058 - val_binary_accuracy: 0.9091 - val_loss: 0.2637\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9082 - loss: 0.2606 - val_auc: 0.8082 - val_binary_accuracy: 0.9079 - val_loss: 0.2628\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8096 - binary_accuracy: 0.9121 - loss: 0.2547\n",
            "Fold 2 Metrics: Loss = 0.2628, Accuracy = 0.9079, AUC = 0.8082\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6591 - binary_accuracy: 0.8839 - loss: 0.5042 - val_auc: 0.7756 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7546 - binary_accuracy: 0.9049 - loss: 0.2768 - val_auc: 0.7852 - val_binary_accuracy: 0.9096 - val_loss: 0.2672\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9076 - loss: 0.2673 - val_auc: 0.7930 - val_binary_accuracy: 0.9103 - val_loss: 0.2622\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9080 - loss: 0.2657 - val_auc: 0.7946 - val_binary_accuracy: 0.9081 - val_loss: 0.2625\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9087 - loss: 0.2637 - val_auc: 0.7972 - val_binary_accuracy: 0.9102 - val_loss: 0.2609\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9084 - loss: 0.2633 - val_auc: 0.7994 - val_binary_accuracy: 0.9103 - val_loss: 0.2604\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9089 - loss: 0.2623 - val_auc: 0.8015 - val_binary_accuracy: 0.9110 - val_loss: 0.2616\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.8018 - val_binary_accuracy: 0.9107 - val_loss: 0.2612\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9088 - loss: 0.2616 - val_auc: 0.8027 - val_binary_accuracy: 0.9112 - val_loss: 0.2596\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8039 - val_binary_accuracy: 0.9109 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7971 - binary_accuracy: 0.9118 - loss: 0.2592\n",
            "Fold 3 Metrics: Loss = 0.2586, Accuracy = 0.9109, AUC = 0.8039\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6802 - binary_accuracy: 0.8869 - loss: 0.3484 - val_auc: 0.7851 - val_binary_accuracy: 0.9075 - val_loss: 0.2662\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9065 - loss: 0.2705 - val_auc: 0.7932 - val_binary_accuracy: 0.9038 - val_loss: 0.2647\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9072 - loss: 0.2670 - val_auc: 0.7967 - val_binary_accuracy: 0.9076 - val_loss: 0.2605\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.8005 - val_binary_accuracy: 0.9085 - val_loss: 0.2580\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9089 - loss: 0.2626 - val_auc: 0.8009 - val_binary_accuracy: 0.9098 - val_loss: 0.2574\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9097 - loss: 0.2617 - val_auc: 0.8040 - val_binary_accuracy: 0.9094 - val_loss: 0.2563\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9102 - loss: 0.2614 - val_auc: 0.8055 - val_binary_accuracy: 0.9097 - val_loss: 0.2563\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9101 - loss: 0.2600 - val_auc: 0.8064 - val_binary_accuracy: 0.9095 - val_loss: 0.2564\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9100 - loss: 0.2593 - val_auc: 0.8075 - val_binary_accuracy: 0.9098 - val_loss: 0.2562\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9106 - loss: 0.2585 - val_auc: 0.8080 - val_binary_accuracy: 0.9093 - val_loss: 0.2556\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9082 - loss: 0.2633\n",
            "Fold 4 Metrics: Loss = 0.2556, Accuracy = 0.9093, AUC = 0.8080\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6713 - binary_accuracy: 0.8885 - loss: 0.3562 - val_auc: 0.7881 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7560 - binary_accuracy: 0.9039 - loss: 0.2776 - val_auc: 0.7947 - val_binary_accuracy: 0.9079 - val_loss: 0.2627\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9065 - loss: 0.2729 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9060 - loss: 0.2705 - val_auc: 0.8007 - val_binary_accuracy: 0.9112 - val_loss: 0.2633\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9067 - loss: 0.2687 - val_auc: 0.8021 - val_binary_accuracy: 0.9104 - val_loss: 0.2590\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9071 - loss: 0.2674 - val_auc: 0.8048 - val_binary_accuracy: 0.9104 - val_loss: 0.2580\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.8060 - val_binary_accuracy: 0.9104 - val_loss: 0.2581\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9091 - loss: 0.2634 - val_auc: 0.8072 - val_binary_accuracy: 0.9113 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9094 - loss: 0.2623 - val_auc: 0.8063 - val_binary_accuracy: 0.9110 - val_loss: 0.2551\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9087 - loss: 0.2620 - val_auc: 0.8075 - val_binary_accuracy: 0.9113 - val_loss: 0.2542\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8159 - binary_accuracy: 0.9098 - loss: 0.2532\n",
            "Fold 5 Metrics: Loss = 0.2542, Accuracy = 0.9113, AUC = 0.8075\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2588\n",
            "Average Accuracy: 0.9093\n",
            "Average AUC: 0.8043\n",
            "----------------------------------------\n",
            "Performing training for: ('relu', 5, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6604 - binary_accuracy: 0.8799 - loss: 0.4752 - val_auc: 0.7722 - val_binary_accuracy: 0.9071 - val_loss: 0.2713\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9091 - loss: 0.2630 - val_auc: 0.7802 - val_binary_accuracy: 0.9078 - val_loss: 0.2715\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2572 - val_auc: 0.7870 - val_binary_accuracy: 0.9093 - val_loss: 0.2636\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9117 - loss: 0.2553 - val_auc: 0.7902 - val_binary_accuracy: 0.9099 - val_loss: 0.2630\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7981 - binary_accuracy: 0.9121 - loss: 0.2537 - val_auc: 0.7928 - val_binary_accuracy: 0.9090 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9131 - loss: 0.2514 - val_auc: 0.7936 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9127 - loss: 0.2506 - val_auc: 0.7947 - val_binary_accuracy: 0.9088 - val_loss: 0.2592\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9133 - loss: 0.2493 - val_auc: 0.7947 - val_binary_accuracy: 0.9087 - val_loss: 0.2591\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8062 - binary_accuracy: 0.9130 - loss: 0.2492 - val_auc: 0.7944 - val_binary_accuracy: 0.9075 - val_loss: 0.2643\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9130 - loss: 0.2478 - val_auc: 0.7967 - val_binary_accuracy: 0.9075 - val_loss: 0.2624\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9105 - loss: 0.2539\n",
            "Fold 1 Metrics: Loss = 0.2624, Accuracy = 0.9075, AUC = 0.7967\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6583 - binary_accuracy: 0.8823 - loss: 0.5256 - val_auc: 0.7975 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9035 - loss: 0.2733 - val_auc: 0.8036 - val_binary_accuracy: 0.9063 - val_loss: 0.2675\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9057 - loss: 0.2684 - val_auc: 0.8062 - val_binary_accuracy: 0.9081 - val_loss: 0.2629\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9063 - loss: 0.2668 - val_auc: 0.8093 - val_binary_accuracy: 0.9062 - val_loss: 0.2619\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9068 - loss: 0.2650 - val_auc: 0.8026 - val_binary_accuracy: 0.9073 - val_loss: 0.2651\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9079 - loss: 0.2645 - val_auc: 0.8084 - val_binary_accuracy: 0.9071 - val_loss: 0.2659\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9067 - loss: 0.2632 - val_auc: 0.8118 - val_binary_accuracy: 0.9071 - val_loss: 0.2634\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9079 - loss: 0.2620 - val_auc: 0.8119 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9078 - loss: 0.2617 - val_auc: 0.8081 - val_binary_accuracy: 0.9082 - val_loss: 0.2628\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9088 - loss: 0.2612 - val_auc: 0.8066 - val_binary_accuracy: 0.9082 - val_loss: 0.2651\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8135 - binary_accuracy: 0.9126 - loss: 0.2562\n",
            "Fold 2 Metrics: Loss = 0.2651, Accuracy = 0.9082, AUC = 0.8066\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6539 - binary_accuracy: 0.8703 - loss: 0.4389 - val_auc: 0.7834 - val_binary_accuracy: 0.9063 - val_loss: 0.2737\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9068 - loss: 0.2708 - val_auc: 0.7899 - val_binary_accuracy: 0.9051 - val_loss: 0.2677\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9077 - loss: 0.2666 - val_auc: 0.7933 - val_binary_accuracy: 0.9053 - val_loss: 0.2636\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9085 - loss: 0.2650 - val_auc: 0.7966 - val_binary_accuracy: 0.9071 - val_loss: 0.2616\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9083 - loss: 0.2644 - val_auc: 0.7991 - val_binary_accuracy: 0.9054 - val_loss: 0.2626\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9095 - loss: 0.2624 - val_auc: 0.8015 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8019 - val_binary_accuracy: 0.9102 - val_loss: 0.2598\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8035 - val_binary_accuracy: 0.9109 - val_loss: 0.2575\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9096 - loss: 0.2620 - val_auc: 0.8041 - val_binary_accuracy: 0.9071 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9093 - loss: 0.2600 - val_auc: 0.8056 - val_binary_accuracy: 0.9097 - val_loss: 0.2588\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7988 - binary_accuracy: 0.9097 - loss: 0.2595\n",
            "Fold 3 Metrics: Loss = 0.2588, Accuracy = 0.9097, AUC = 0.8056\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6627 - binary_accuracy: 0.8852 - loss: 0.4744 - val_auc: 0.7887 - val_binary_accuracy: 0.9050 - val_loss: 0.2751\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9071 - loss: 0.2727 - val_auc: 0.7961 - val_binary_accuracy: 0.9069 - val_loss: 0.2627\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.8004 - val_binary_accuracy: 0.9081 - val_loss: 0.2597\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8025 - val_binary_accuracy: 0.9079 - val_loss: 0.2594\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9091 - loss: 0.2633 - val_auc: 0.8055 - val_binary_accuracy: 0.9093 - val_loss: 0.2563\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9095 - loss: 0.2620 - val_auc: 0.8067 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9103 - loss: 0.2612 - val_auc: 0.8094 - val_binary_accuracy: 0.9104 - val_loss: 0.2542\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9103 - loss: 0.2606 - val_auc: 0.8108 - val_binary_accuracy: 0.9097 - val_loss: 0.2539\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9103 - loss: 0.2600 - val_auc: 0.8101 - val_binary_accuracy: 0.9095 - val_loss: 0.2542\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9105 - loss: 0.2591 - val_auc: 0.8119 - val_binary_accuracy: 0.9097 - val_loss: 0.2532\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7929 - binary_accuracy: 0.9092 - loss: 0.2601\n",
            "Fold 4 Metrics: Loss = 0.2532, Accuracy = 0.9097, AUC = 0.8119\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6627 - binary_accuracy: 0.8900 - loss: 0.3801 - val_auc: 0.7908 - val_binary_accuracy: 0.9064 - val_loss: 0.2643\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9036 - loss: 0.2766 - val_auc: 0.7966 - val_binary_accuracy: 0.9022 - val_loss: 0.2604\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9040 - loss: 0.2731 - val_auc: 0.8000 - val_binary_accuracy: 0.9026 - val_loss: 0.2655\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9050 - loss: 0.2698 - val_auc: 0.8031 - val_binary_accuracy: 0.9098 - val_loss: 0.2657\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9076 - loss: 0.2673 - val_auc: 0.8038 - val_binary_accuracy: 0.9103 - val_loss: 0.2662\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9067 - loss: 0.2667 - val_auc: 0.8061 - val_binary_accuracy: 0.9101 - val_loss: 0.2626\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8078 - val_binary_accuracy: 0.9109 - val_loss: 0.2629\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9085 - loss: 0.2637 - val_auc: 0.8088 - val_binary_accuracy: 0.9113 - val_loss: 0.2612\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8093 - val_binary_accuracy: 0.9112 - val_loss: 0.2606\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9089 - loss: 0.2621 - val_auc: 0.8105 - val_binary_accuracy: 0.9110 - val_loss: 0.2592\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8180 - binary_accuracy: 0.9095 - loss: 0.2583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|      | 1/3 [27:29<54:58, 1649.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 Metrics: Loss = 0.2592, Accuracy = 0.9110, AUC = 0.8105\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2597\n",
            "Average Accuracy: 0.9092\n",
            "Average AUC: 0.8063\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 1, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5407 - binary_accuracy: 0.8881 - loss: 0.4453 - val_auc: 0.7252 - val_binary_accuracy: 0.9044 - val_loss: 0.2942\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7504 - binary_accuracy: 0.9069 - loss: 0.2838 - val_auc: 0.7611 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9069 - loss: 0.2731 - val_auc: 0.7639 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9069 - loss: 0.2694 - val_auc: 0.7680 - val_binary_accuracy: 0.9044 - val_loss: 0.2769\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.7680 - val_binary_accuracy: 0.9044 - val_loss: 0.2740\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9069 - loss: 0.2637 - val_auc: 0.7704 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7703 - val_binary_accuracy: 0.9044 - val_loss: 0.2711\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9069 - loss: 0.2606 - val_auc: 0.7728 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2597 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9069 - loss: 0.2591 - val_auc: 0.7754 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7695 - binary_accuracy: 0.9084 - loss: 0.2623\n",
            "Fold 1 Metrics: Loss = 0.2693, Accuracy = 0.9044, AUC = 0.7754\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5431 - binary_accuracy: 0.6690 - loss: 0.5823 - val_auc: 0.7283 - val_binary_accuracy: 0.9042 - val_loss: 0.2975\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7313 - binary_accuracy: 0.9029 - loss: 0.2964 - val_auc: 0.7698 - val_binary_accuracy: 0.9042 - val_loss: 0.2864\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7585 - binary_accuracy: 0.9029 - loss: 0.2881 - val_auc: 0.7775 - val_binary_accuracy: 0.9042 - val_loss: 0.2786\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9029 - loss: 0.2803 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2724\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2756 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9029 - loss: 0.2730 - val_auc: 0.7930 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9029 - loss: 0.2714 - val_auc: 0.7936 - val_binary_accuracy: 0.9042 - val_loss: 0.2647\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9029 - loss: 0.2702 - val_auc: 0.7938 - val_binary_accuracy: 0.9042 - val_loss: 0.2635\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9029 - loss: 0.2692 - val_auc: 0.7980 - val_binary_accuracy: 0.9042 - val_loss: 0.2621\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9029 - loss: 0.2683 - val_auc: 0.7988 - val_binary_accuracy: 0.9042 - val_loss: 0.2610\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7984 - binary_accuracy: 0.9092 - loss: 0.2522\n",
            "Fold 2 Metrics: Loss = 0.2610, Accuracy = 0.9042, AUC = 0.7988\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5566 - binary_accuracy: 0.8404 - loss: 0.4183 - val_auc: 0.7434 - val_binary_accuracy: 0.9042 - val_loss: 0.2893\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7448 - binary_accuracy: 0.9051 - loss: 0.2850 - val_auc: 0.7576 - val_binary_accuracy: 0.9042 - val_loss: 0.2785\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9051 - loss: 0.2765 - val_auc: 0.7733 - val_binary_accuracy: 0.9042 - val_loss: 0.2735\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9051 - loss: 0.2715 - val_auc: 0.7771 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9051 - loss: 0.2685 - val_auc: 0.7793 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7828 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9051 - loss: 0.2654 - val_auc: 0.7842 - val_binary_accuracy: 0.9042 - val_loss: 0.2678\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9051 - loss: 0.2646 - val_auc: 0.7856 - val_binary_accuracy: 0.9042 - val_loss: 0.2673\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9051 - loss: 0.2636 - val_auc: 0.7896 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7821 - binary_accuracy: 0.9046 - loss: 0.2672\n",
            "Fold 3 Metrics: Loss = 0.2663, Accuracy = 0.9042, AUC = 0.7896\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5240 - binary_accuracy: 0.7788 - loss: 0.5157 - val_auc: 0.7256 - val_binary_accuracy: 0.9044 - val_loss: 0.3122\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7287 - binary_accuracy: 0.9047 - loss: 0.3036 - val_auc: 0.7630 - val_binary_accuracy: 0.9044 - val_loss: 0.2779\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7619 - binary_accuracy: 0.9047 - loss: 0.2764 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9047 - loss: 0.2717 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7742 - binary_accuracy: 0.9047 - loss: 0.2695 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9047 - loss: 0.2683 - val_auc: 0.7825 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9047 - loss: 0.2676 - val_auc: 0.7815 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9047 - loss: 0.2670 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9047 - loss: 0.2665 - val_auc: 0.7827 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9047 - loss: 0.2660 - val_auc: 0.7825 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7576 - binary_accuracy: 0.9049 - loss: 0.2724\n",
            "Fold 4 Metrics: Loss = 0.2665, Accuracy = 0.9044, AUC = 0.7825\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5757 - binary_accuracy: 0.8772 - loss: 0.3729 - val_auc: 0.7388 - val_binary_accuracy: 0.9044 - val_loss: 0.2870\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7411 - binary_accuracy: 0.9040 - loss: 0.2862 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7650 - binary_accuracy: 0.9040 - loss: 0.2755 - val_auc: 0.7852 - val_binary_accuracy: 0.9044 - val_loss: 0.2646\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7720 - binary_accuracy: 0.9049 - loss: 0.2702 - val_auc: 0.7873 - val_binary_accuracy: 0.9067 - val_loss: 0.2615\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9062 - loss: 0.2676 - val_auc: 0.7915 - val_binary_accuracy: 0.9076 - val_loss: 0.2600\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9077 - loss: 0.2660 - val_auc: 0.7935 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7824 - binary_accuracy: 0.9084 - loss: 0.2650 - val_auc: 0.7944 - val_binary_accuracy: 0.9097 - val_loss: 0.2582\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9085 - loss: 0.2643 - val_auc: 0.7955 - val_binary_accuracy: 0.9100 - val_loss: 0.2578\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9086 - loss: 0.2637 - val_auc: 0.7962 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7852 - binary_accuracy: 0.9084 - loss: 0.2633 - val_auc: 0.7966 - val_binary_accuracy: 0.9100 - val_loss: 0.2568\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8049 - binary_accuracy: 0.9085 - loss: 0.2565\n",
            "Fold 5 Metrics: Loss = 0.2568, Accuracy = 0.9100, AUC = 0.7966\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2640\n",
            "Average Accuracy: 0.9055\n",
            "Average AUC: 0.7886\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 1, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5814 - binary_accuracy: 0.6433 - loss: 0.6112 - val_auc: 0.7338 - val_binary_accuracy: 0.9044 - val_loss: 0.2928\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7551 - binary_accuracy: 0.9069 - loss: 0.2785 - val_auc: 0.7602 - val_binary_accuracy: 0.9044 - val_loss: 0.2753\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9069 - loss: 0.2657 - val_auc: 0.7694 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7941 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7769 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7977 - binary_accuracy: 0.9069 - loss: 0.2567 - val_auc: 0.7788 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7992 - binary_accuracy: 0.9070 - loss: 0.2558 - val_auc: 0.7803 - val_binary_accuracy: 0.9060 - val_loss: 0.2648\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8003 - binary_accuracy: 0.9084 - loss: 0.2548 - val_auc: 0.7815 - val_binary_accuracy: 0.9071 - val_loss: 0.2641\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8019 - binary_accuracy: 0.9096 - loss: 0.2540 - val_auc: 0.7836 - val_binary_accuracy: 0.9076 - val_loss: 0.2635\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8027 - binary_accuracy: 0.9106 - loss: 0.2534 - val_auc: 0.7855 - val_binary_accuracy: 0.9088 - val_loss: 0.2629\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7808 - binary_accuracy: 0.9122 - loss: 0.2566\n",
            "Fold 1 Metrics: Loss = 0.2629, Accuracy = 0.9088, AUC = 0.7855\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5741 - binary_accuracy: 0.7016 - loss: 0.5321 - val_auc: 0.7599 - val_binary_accuracy: 0.9042 - val_loss: 0.2855\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7551 - binary_accuracy: 0.9029 - loss: 0.2834 - val_auc: 0.7829 - val_binary_accuracy: 0.9042 - val_loss: 0.2736\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9029 - loss: 0.2756 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7805 - binary_accuracy: 0.9029 - loss: 0.2717 - val_auc: 0.7976 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9029 - loss: 0.2694 - val_auc: 0.8017 - val_binary_accuracy: 0.9042 - val_loss: 0.2658\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9029 - loss: 0.2679 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2636\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9045 - loss: 0.2666 - val_auc: 0.8037 - val_binary_accuracy: 0.9048 - val_loss: 0.2610\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9054 - loss: 0.2651 - val_auc: 0.8046 - val_binary_accuracy: 0.9057 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9065 - loss: 0.2641 - val_auc: 0.8073 - val_binary_accuracy: 0.9066 - val_loss: 0.2590\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9070 - loss: 0.2632 - val_auc: 0.8092 - val_binary_accuracy: 0.9069 - val_loss: 0.2584\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8106 - binary_accuracy: 0.9109 - loss: 0.2493\n",
            "Fold 2 Metrics: Loss = 0.2584, Accuracy = 0.9069, AUC = 0.8092\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6599 - binary_accuracy: 0.9042 - loss: 0.3330 - val_auc: 0.7664 - val_binary_accuracy: 0.9042 - val_loss: 0.2731\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9051 - loss: 0.2704 - val_auc: 0.7746 - val_binary_accuracy: 0.9042 - val_loss: 0.2704\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9051 - loss: 0.2674 - val_auc: 0.7760 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9051 - loss: 0.2659 - val_auc: 0.7795 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7805 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2641 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2665\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9053 - loss: 0.2633 - val_auc: 0.7856 - val_binary_accuracy: 0.9057 - val_loss: 0.2654\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7857 - binary_accuracy: 0.9065 - loss: 0.2623 - val_auc: 0.7881 - val_binary_accuracy: 0.9069 - val_loss: 0.2643\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7871 - binary_accuracy: 0.9072 - loss: 0.2613 - val_auc: 0.7913 - val_binary_accuracy: 0.9090 - val_loss: 0.2630\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9075 - loss: 0.2604 - val_auc: 0.7932 - val_binary_accuracy: 0.9093 - val_loss: 0.2620\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7855 - binary_accuracy: 0.9099 - loss: 0.2633\n",
            "Fold 3 Metrics: Loss = 0.2620, Accuracy = 0.9093, AUC = 0.7932\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5827 - binary_accuracy: 0.6991 - loss: 0.5044 - val_auc: 0.7478 - val_binary_accuracy: 0.9044 - val_loss: 0.2858\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7446 - binary_accuracy: 0.9047 - loss: 0.2826 - val_auc: 0.7729 - val_binary_accuracy: 0.9044 - val_loss: 0.2749\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9047 - loss: 0.2730 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9047 - loss: 0.2686 - val_auc: 0.7858 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9047 - loss: 0.2663 - val_auc: 0.7884 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9048 - loss: 0.2643 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7868 - binary_accuracy: 0.9052 - loss: 0.2632 - val_auc: 0.7899 - val_binary_accuracy: 0.9047 - val_loss: 0.2660\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9070 - loss: 0.2623 - val_auc: 0.7910 - val_binary_accuracy: 0.9056 - val_loss: 0.2654\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9087 - loss: 0.2615 - val_auc: 0.7925 - val_binary_accuracy: 0.9070 - val_loss: 0.2648\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9089 - loss: 0.2606 - val_auc: 0.7934 - val_binary_accuracy: 0.9076 - val_loss: 0.2642\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7696 - binary_accuracy: 0.9062 - loss: 0.2695\n",
            "Fold 4 Metrics: Loss = 0.2642, Accuracy = 0.9076, AUC = 0.7934\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6358 - binary_accuracy: 0.9040 - loss: 0.3280 - val_auc: 0.7817 - val_binary_accuracy: 0.9044 - val_loss: 0.2685\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9040 - loss: 0.2742 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7746 - binary_accuracy: 0.9040 - loss: 0.2710 - val_auc: 0.7913 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.7956 - val_binary_accuracy: 0.9044 - val_loss: 0.2601\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7818 - binary_accuracy: 0.9040 - loss: 0.2679 - val_auc: 0.7975 - val_binary_accuracy: 0.9044 - val_loss: 0.2589\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9042 - loss: 0.2666 - val_auc: 0.7992 - val_binary_accuracy: 0.9048 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7997 - val_binary_accuracy: 0.9053 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7870 - binary_accuracy: 0.9065 - loss: 0.2647 - val_auc: 0.8003 - val_binary_accuracy: 0.9073 - val_loss: 0.2565\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9070 - loss: 0.2638 - val_auc: 0.8006 - val_binary_accuracy: 0.9085 - val_loss: 0.2558\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9080 - loss: 0.2630 - val_auc: 0.8014 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8118 - binary_accuracy: 0.9068 - loss: 0.2537\n",
            "Fold 5 Metrics: Loss = 0.2550, Accuracy = 0.9090, AUC = 0.8014\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2605\n",
            "Average Accuracy: 0.9083\n",
            "Average AUC: 0.7965\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 1, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6186 - binary_accuracy: 0.8966 - loss: 0.3419 - val_auc: 0.7591 - val_binary_accuracy: 0.9044 - val_loss: 0.2778\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9069 - loss: 0.2665 - val_auc: 0.7716 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9070 - loss: 0.2587 - val_auc: 0.7766 - val_binary_accuracy: 0.9060 - val_loss: 0.2672\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9098 - loss: 0.2561 - val_auc: 0.7801 - val_binary_accuracy: 0.9073 - val_loss: 0.2654\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9113 - loss: 0.2543 - val_auc: 0.7829 - val_binary_accuracy: 0.9088 - val_loss: 0.2639\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9120 - loss: 0.2527 - val_auc: 0.7854 - val_binary_accuracy: 0.9099 - val_loss: 0.2624\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9123 - loss: 0.2513 - val_auc: 0.7874 - val_binary_accuracy: 0.9094 - val_loss: 0.2613\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9123 - loss: 0.2503 - val_auc: 0.7893 - val_binary_accuracy: 0.9093 - val_loss: 0.2608\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8094 - binary_accuracy: 0.9129 - loss: 0.2494 - val_auc: 0.7898 - val_binary_accuracy: 0.9091 - val_loss: 0.2603\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9128 - loss: 0.2486 - val_auc: 0.7912 - val_binary_accuracy: 0.9096 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7863 - binary_accuracy: 0.9139 - loss: 0.2541\n",
            "Fold 1 Metrics: Loss = 0.2599, Accuracy = 0.9096, AUC = 0.7912\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6473 - binary_accuracy: 0.9029 - loss: 0.3159 - val_auc: 0.7858 - val_binary_accuracy: 0.9042 - val_loss: 0.2720\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9029 - loss: 0.2745 - val_auc: 0.7967 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.7998 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9031 - loss: 0.2680 - val_auc: 0.8024 - val_binary_accuracy: 0.9044 - val_loss: 0.2627\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9045 - loss: 0.2662 - val_auc: 0.8050 - val_binary_accuracy: 0.9057 - val_loss: 0.2602\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9060 - loss: 0.2646 - val_auc: 0.8058 - val_binary_accuracy: 0.9060 - val_loss: 0.2592\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9070 - loss: 0.2627 - val_auc: 0.8070 - val_binary_accuracy: 0.9062 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9073 - loss: 0.2615 - val_auc: 0.8076 - val_binary_accuracy: 0.9071 - val_loss: 0.2590\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9080 - loss: 0.2604 - val_auc: 0.8090 - val_binary_accuracy: 0.9078 - val_loss: 0.2587\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8017 - binary_accuracy: 0.9078 - loss: 0.2596 - val_auc: 0.8100 - val_binary_accuracy: 0.9081 - val_loss: 0.2583\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8147 - binary_accuracy: 0.9118 - loss: 0.2477\n",
            "Fold 2 Metrics: Loss = 0.2583, Accuracy = 0.9081, AUC = 0.8100\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7156 - binary_accuracy: 0.9051 - loss: 0.2877 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7728 - binary_accuracy: 0.9051 - loss: 0.2691 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7798 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7847 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7834 - binary_accuracy: 0.9053 - loss: 0.2639 - val_auc: 0.7893 - val_binary_accuracy: 0.9048 - val_loss: 0.2648\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7860 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.7926 - val_binary_accuracy: 0.9076 - val_loss: 0.2628\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9076 - loss: 0.2611 - val_auc: 0.7957 - val_binary_accuracy: 0.9094 - val_loss: 0.2615\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7907 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.7979 - val_binary_accuracy: 0.9100 - val_loss: 0.2604\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7916 - binary_accuracy: 0.9094 - loss: 0.2593 - val_auc: 0.7993 - val_binary_accuracy: 0.9102 - val_loss: 0.2594\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7931 - binary_accuracy: 0.9095 - loss: 0.2587 - val_auc: 0.8006 - val_binary_accuracy: 0.9103 - val_loss: 0.2587\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7939 - binary_accuracy: 0.9098 - loss: 0.2582 - val_auc: 0.8025 - val_binary_accuracy: 0.9104 - val_loss: 0.2580\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9120 - loss: 0.2587\n",
            "Fold 3 Metrics: Loss = 0.2580, Accuracy = 0.9104, AUC = 0.8025\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5983 - binary_accuracy: 0.7126 - loss: 0.5437 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2777\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7606 - binary_accuracy: 0.9047 - loss: 0.2754 - val_auc: 0.7823 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9047 - loss: 0.2678 - val_auc: 0.7875 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7826 - binary_accuracy: 0.9050 - loss: 0.2653 - val_auc: 0.7899 - val_binary_accuracy: 0.9045 - val_loss: 0.2673\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9062 - loss: 0.2637 - val_auc: 0.7929 - val_binary_accuracy: 0.9057 - val_loss: 0.2662\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9083 - loss: 0.2622 - val_auc: 0.7957 - val_binary_accuracy: 0.9070 - val_loss: 0.2653\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.7975 - val_binary_accuracy: 0.9079 - val_loss: 0.2640\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9091 - loss: 0.2601 - val_auc: 0.7994 - val_binary_accuracy: 0.9085 - val_loss: 0.2632\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9096 - loss: 0.2593 - val_auc: 0.8001 - val_binary_accuracy: 0.9091 - val_loss: 0.2626\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9100 - loss: 0.2586 - val_auc: 0.8017 - val_binary_accuracy: 0.9094 - val_loss: 0.2622\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7809 - binary_accuracy: 0.9092 - loss: 0.2677\n",
            "Fold 4 Metrics: Loss = 0.2622, Accuracy = 0.9094, AUC = 0.8017\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6977 - binary_accuracy: 0.9040 - loss: 0.2969 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9040 - loss: 0.2689 - val_auc: 0.7955 - val_binary_accuracy: 0.9047 - val_loss: 0.2596\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9045 - loss: 0.2668 - val_auc: 0.7981 - val_binary_accuracy: 0.9060 - val_loss: 0.2578\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9057 - loss: 0.2653 - val_auc: 0.8018 - val_binary_accuracy: 0.9087 - val_loss: 0.2560\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.8029 - val_binary_accuracy: 0.9087 - val_loss: 0.2553\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9084 - loss: 0.2627 - val_auc: 0.8040 - val_binary_accuracy: 0.9093 - val_loss: 0.2545\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9087 - loss: 0.2618 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2537\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9094 - loss: 0.2611 - val_auc: 0.8062 - val_binary_accuracy: 0.9104 - val_loss: 0.2530\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9100 - loss: 0.2602 - val_auc: 0.8068 - val_binary_accuracy: 0.9104 - val_loss: 0.2525\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9084 - loss: 0.2513\n",
            "Fold 5 Metrics: Loss = 0.2525, Accuracy = 0.9104, AUC = 0.8068\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2582\n",
            "Average Accuracy: 0.9096\n",
            "Average AUC: 0.8025\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 1, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6868 - binary_accuracy: 0.9069 - loss: 0.2956 - val_auc: 0.7720 - val_binary_accuracy: 0.9044 - val_loss: 0.2714\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9075 - loss: 0.2586 - val_auc: 0.7812 - val_binary_accuracy: 0.9069 - val_loss: 0.2663\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9093 - loss: 0.2549 - val_auc: 0.7856 - val_binary_accuracy: 0.9082 - val_loss: 0.2640\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9118 - loss: 0.2526 - val_auc: 0.7884 - val_binary_accuracy: 0.9079 - val_loss: 0.2622\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9130 - loss: 0.2509 - val_auc: 0.7903 - val_binary_accuracy: 0.9085 - val_loss: 0.2610\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9129 - loss: 0.2493 - val_auc: 0.7918 - val_binary_accuracy: 0.9085 - val_loss: 0.2604\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9128 - loss: 0.2484 - val_auc: 0.7930 - val_binary_accuracy: 0.9085 - val_loss: 0.2600\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9127 - loss: 0.2475 - val_auc: 0.7938 - val_binary_accuracy: 0.9087 - val_loss: 0.2597\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8133 - binary_accuracy: 0.9127 - loss: 0.2469 - val_auc: 0.7941 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9126 - loss: 0.2463 - val_auc: 0.7949 - val_binary_accuracy: 0.9090 - val_loss: 0.2591\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7946 - binary_accuracy: 0.9128 - loss: 0.2521\n",
            "Fold 1 Metrics: Loss = 0.2591, Accuracy = 0.9090, AUC = 0.7949\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6517 - binary_accuracy: 0.8179 - loss: 0.3826 - val_auc: 0.7930 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8002 - val_binary_accuracy: 0.9042 - val_loss: 0.2628\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9042 - loss: 0.2661 - val_auc: 0.8058 - val_binary_accuracy: 0.9048 - val_loss: 0.2597\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9064 - loss: 0.2636 - val_auc: 0.8082 - val_binary_accuracy: 0.9060 - val_loss: 0.2586\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9069 - loss: 0.2619 - val_auc: 0.8095 - val_binary_accuracy: 0.9062 - val_loss: 0.2579\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.8110 - val_binary_accuracy: 0.9072 - val_loss: 0.2570\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9081 - loss: 0.2598 - val_auc: 0.8115 - val_binary_accuracy: 0.9073 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9080 - loss: 0.2591 - val_auc: 0.8116 - val_binary_accuracy: 0.9076 - val_loss: 0.2568\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9079 - loss: 0.2584 - val_auc: 0.8129 - val_binary_accuracy: 0.9082 - val_loss: 0.2565\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9083 - loss: 0.2578 - val_auc: 0.8133 - val_binary_accuracy: 0.9084 - val_loss: 0.2565\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8198 - binary_accuracy: 0.9127 - loss: 0.2454\n",
            "Fold 2 Metrics: Loss = 0.2565, Accuracy = 0.9084, AUC = 0.8133\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6423 - binary_accuracy: 0.8182 - loss: 0.3870 - val_auc: 0.7731 - val_binary_accuracy: 0.9042 - val_loss: 0.2711\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9052 - loss: 0.2688 - val_auc: 0.7804 - val_binary_accuracy: 0.9045 - val_loss: 0.2677\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9071 - loss: 0.2651 - val_auc: 0.7852 - val_binary_accuracy: 0.9079 - val_loss: 0.2652\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9081 - loss: 0.2633 - val_auc: 0.7890 - val_binary_accuracy: 0.9102 - val_loss: 0.2631\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9090 - loss: 0.2618 - val_auc: 0.7941 - val_binary_accuracy: 0.9099 - val_loss: 0.2611\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9095 - loss: 0.2605 - val_auc: 0.7981 - val_binary_accuracy: 0.9103 - val_loss: 0.2593\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9094 - loss: 0.2595 - val_auc: 0.8009 - val_binary_accuracy: 0.9113 - val_loss: 0.2581\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9096 - loss: 0.2587 - val_auc: 0.8031 - val_binary_accuracy: 0.9113 - val_loss: 0.2570\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9094 - loss: 0.2581 - val_auc: 0.8049 - val_binary_accuracy: 0.9115 - val_loss: 0.2562\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9096 - loss: 0.2576 - val_auc: 0.8059 - val_binary_accuracy: 0.9113 - val_loss: 0.2557\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9125 - loss: 0.2569\n",
            "Fold 3 Metrics: Loss = 0.2557, Accuracy = 0.9113, AUC = 0.8059\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6984 - binary_accuracy: 0.9049 - loss: 0.2910 - val_auc: 0.7864 - val_binary_accuracy: 0.9051 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7942 - val_binary_accuracy: 0.9066 - val_loss: 0.2623\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.7989 - val_binary_accuracy: 0.9078 - val_loss: 0.2601\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9095 - loss: 0.2601 - val_auc: 0.8015 - val_binary_accuracy: 0.9084 - val_loss: 0.2583\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9104 - loss: 0.2586 - val_auc: 0.8059 - val_binary_accuracy: 0.9087 - val_loss: 0.2570\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9109 - loss: 0.2575 - val_auc: 0.8062 - val_binary_accuracy: 0.9093 - val_loss: 0.2563\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9107 - loss: 0.2567 - val_auc: 0.8087 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7990 - binary_accuracy: 0.9108 - loss: 0.2559 - val_auc: 0.8093 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9110 - loss: 0.2555 - val_auc: 0.8103 - val_binary_accuracy: 0.9095 - val_loss: 0.2552\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9113 - loss: 0.2550 - val_auc: 0.8101 - val_binary_accuracy: 0.9095 - val_loss: 0.2549\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7899 - binary_accuracy: 0.9090 - loss: 0.2617\n",
            "Fold 4 Metrics: Loss = 0.2549, Accuracy = 0.9095, AUC = 0.8101\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6479 - binary_accuracy: 0.8353 - loss: 0.3740 - val_auc: 0.7840 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9040 - loss: 0.2720 - val_auc: 0.7910 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9044 - loss: 0.2683 - val_auc: 0.7960 - val_binary_accuracy: 0.9067 - val_loss: 0.2589\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9064 - loss: 0.2662 - val_auc: 0.7995 - val_binary_accuracy: 0.9079 - val_loss: 0.2572\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7868 - binary_accuracy: 0.9084 - loss: 0.2645 - val_auc: 0.8025 - val_binary_accuracy: 0.9095 - val_loss: 0.2556\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7902 - binary_accuracy: 0.9086 - loss: 0.2630 - val_auc: 0.8039 - val_binary_accuracy: 0.9100 - val_loss: 0.2545\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7913 - binary_accuracy: 0.9089 - loss: 0.2617 - val_auc: 0.8054 - val_binary_accuracy: 0.9101 - val_loss: 0.2537\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7936 - binary_accuracy: 0.9093 - loss: 0.2608 - val_auc: 0.8058 - val_binary_accuracy: 0.9107 - val_loss: 0.2531\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9098 - loss: 0.2600 - val_auc: 0.8060 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9102 - loss: 0.2594 - val_auc: 0.8069 - val_binary_accuracy: 0.9107 - val_loss: 0.2522\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8153 - binary_accuracy: 0.9089 - loss: 0.2510\n",
            "Fold 5 Metrics: Loss = 0.2522, Accuracy = 0.9107, AUC = 0.8069\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2557\n",
            "Average Accuracy: 0.9098\n",
            "Average AUC: 0.8062\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 1, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6850 - binary_accuracy: 0.8710 - loss: 0.3234 - val_auc: 0.7733 - val_binary_accuracy: 0.9051 - val_loss: 0.2710\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.7813 - val_binary_accuracy: 0.9076 - val_loss: 0.2667\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9107 - loss: 0.2548 - val_auc: 0.7862 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9126 - loss: 0.2522 - val_auc: 0.7903 - val_binary_accuracy: 0.9088 - val_loss: 0.2613\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9128 - loss: 0.2501 - val_auc: 0.7922 - val_binary_accuracy: 0.9087 - val_loss: 0.2602\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8095 - binary_accuracy: 0.9126 - loss: 0.2488 - val_auc: 0.7933 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9127 - loss: 0.2477 - val_auc: 0.7948 - val_binary_accuracy: 0.9088 - val_loss: 0.2590\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8135 - binary_accuracy: 0.9127 - loss: 0.2469 - val_auc: 0.7953 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8146 - binary_accuracy: 0.9128 - loss: 0.2462 - val_auc: 0.7952 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8154 - binary_accuracy: 0.9127 - loss: 0.2457 - val_auc: 0.7962 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7961 - binary_accuracy: 0.9129 - loss: 0.2514\n",
            "Fold 1 Metrics: Loss = 0.2586, Accuracy = 0.9088, AUC = 0.7962\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6677 - binary_accuracy: 0.8441 - loss: 0.3601 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2654\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9036 - loss: 0.2691 - val_auc: 0.8037 - val_binary_accuracy: 0.9054 - val_loss: 0.2597\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9055 - loss: 0.2651 - val_auc: 0.8071 - val_binary_accuracy: 0.9068 - val_loss: 0.2577\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9074 - loss: 0.2630 - val_auc: 0.8099 - val_binary_accuracy: 0.9073 - val_loss: 0.2569\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9077 - loss: 0.2616 - val_auc: 0.8116 - val_binary_accuracy: 0.9078 - val_loss: 0.2558\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9078 - loss: 0.2605 - val_auc: 0.8123 - val_binary_accuracy: 0.9079 - val_loss: 0.2555\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9085 - loss: 0.2597 - val_auc: 0.8131 - val_binary_accuracy: 0.9081 - val_loss: 0.2549\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9084 - loss: 0.2589 - val_auc: 0.8136 - val_binary_accuracy: 0.9084 - val_loss: 0.2546\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9085 - loss: 0.2582 - val_auc: 0.8140 - val_binary_accuracy: 0.9090 - val_loss: 0.2543\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9084 - loss: 0.2576 - val_auc: 0.8145 - val_binary_accuracy: 0.9088 - val_loss: 0.2541\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8208 - binary_accuracy: 0.9133 - loss: 0.2435\n",
            "Fold 2 Metrics: Loss = 0.2541, Accuracy = 0.9088, AUC = 0.8145\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6643 - binary_accuracy: 0.8778 - loss: 0.3242 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9067 - loss: 0.2680 - val_auc: 0.7863 - val_binary_accuracy: 0.9075 - val_loss: 0.2657\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9081 - loss: 0.2653 - val_auc: 0.7920 - val_binary_accuracy: 0.9097 - val_loss: 0.2632\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9085 - loss: 0.2632 - val_auc: 0.7953 - val_binary_accuracy: 0.9100 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9092 - loss: 0.2618 - val_auc: 0.7988 - val_binary_accuracy: 0.9107 - val_loss: 0.2594\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9092 - loss: 0.2609 - val_auc: 0.8003 - val_binary_accuracy: 0.9110 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9096 - loss: 0.2600 - val_auc: 0.8029 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9099 - loss: 0.2594 - val_auc: 0.8035 - val_binary_accuracy: 0.9112 - val_loss: 0.2564\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9098 - loss: 0.2589 - val_auc: 0.8053 - val_binary_accuracy: 0.9110 - val_loss: 0.2557\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7922 - binary_accuracy: 0.9098 - loss: 0.2585 - val_auc: 0.8063 - val_binary_accuracy: 0.9109 - val_loss: 0.2553\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7980 - binary_accuracy: 0.9118 - loss: 0.2562\n",
            "Fold 3 Metrics: Loss = 0.2553, Accuracy = 0.9109, AUC = 0.8063\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7242 - binary_accuracy: 0.9052 - loss: 0.2848 - val_auc: 0.7915 - val_binary_accuracy: 0.9070 - val_loss: 0.2633\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9078 - loss: 0.2645 - val_auc: 0.7983 - val_binary_accuracy: 0.9081 - val_loss: 0.2597\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9098 - loss: 0.2612 - val_auc: 0.8017 - val_binary_accuracy: 0.9094 - val_loss: 0.2577\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9100 - loss: 0.2594 - val_auc: 0.8051 - val_binary_accuracy: 0.9098 - val_loss: 0.2564\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9106 - loss: 0.2580 - val_auc: 0.8077 - val_binary_accuracy: 0.9097 - val_loss: 0.2554\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9111 - loss: 0.2572 - val_auc: 0.8084 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9109 - loss: 0.2566 - val_auc: 0.8094 - val_binary_accuracy: 0.9091 - val_loss: 0.2543\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9109 - loss: 0.2561 - val_auc: 0.8105 - val_binary_accuracy: 0.9093 - val_loss: 0.2539\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9111 - loss: 0.2557 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2536\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9110 - loss: 0.2553 - val_auc: 0.8117 - val_binary_accuracy: 0.9093 - val_loss: 0.2535\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7926 - binary_accuracy: 0.9089 - loss: 0.2605\n",
            "Fold 4 Metrics: Loss = 0.2535, Accuracy = 0.9093, AUC = 0.8117\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6878 - binary_accuracy: 0.8724 - loss: 0.3236 - val_auc: 0.7872 - val_binary_accuracy: 0.9045 - val_loss: 0.2643\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9059 - loss: 0.2700 - val_auc: 0.7952 - val_binary_accuracy: 0.9081 - val_loss: 0.2600\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9086 - loss: 0.2667 - val_auc: 0.7990 - val_binary_accuracy: 0.9090 - val_loss: 0.2569\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9090 - loss: 0.2644 - val_auc: 0.8026 - val_binary_accuracy: 0.9098 - val_loss: 0.2549\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9092 - loss: 0.2627 - val_auc: 0.8057 - val_binary_accuracy: 0.9103 - val_loss: 0.2531\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9095 - loss: 0.2615 - val_auc: 0.8067 - val_binary_accuracy: 0.9106 - val_loss: 0.2527\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9097 - loss: 0.2605 - val_auc: 0.8076 - val_binary_accuracy: 0.9109 - val_loss: 0.2521\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9102 - loss: 0.2598 - val_auc: 0.8080 - val_binary_accuracy: 0.9109 - val_loss: 0.2519\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9105 - loss: 0.2593 - val_auc: 0.8081 - val_binary_accuracy: 0.9112 - val_loss: 0.2518\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9105 - loss: 0.2589 - val_auc: 0.8085 - val_binary_accuracy: 0.9112 - val_loss: 0.2518\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9094 - loss: 0.2510\n",
            "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9112, AUC = 0.8085\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2547\n",
            "Average Accuracy: 0.9098\n",
            "Average AUC: 0.8074\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 2, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5174 - binary_accuracy: 0.5824 - loss: 0.6365 - val_auc: 0.7352 - val_binary_accuracy: 0.9044 - val_loss: 0.3114\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7387 - binary_accuracy: 0.9069 - loss: 0.2987 - val_auc: 0.7471 - val_binary_accuracy: 0.9044 - val_loss: 0.2900\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9069 - loss: 0.2792 - val_auc: 0.7612 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9069 - loss: 0.2687 - val_auc: 0.7653 - val_binary_accuracy: 0.9044 - val_loss: 0.2737\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.7718 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9069 - loss: 0.2593 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9069 - loss: 0.2575 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9069 - loss: 0.2563 - val_auc: 0.7763 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7955 - binary_accuracy: 0.9069 - loss: 0.2556 - val_auc: 0.7774 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9070 - loss: 0.2550 - val_auc: 0.7796 - val_binary_accuracy: 0.9045 - val_loss: 0.2656\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7781 - binary_accuracy: 0.9086 - loss: 0.2584\n",
            "Fold 1 Metrics: Loss = 0.2656, Accuracy = 0.9045, AUC = 0.7796\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.4830 - binary_accuracy: 0.8103 - loss: 0.4890 - val_auc: 0.6652 - val_binary_accuracy: 0.9042 - val_loss: 0.3137\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.6821 - binary_accuracy: 0.9029 - loss: 0.3148 - val_auc: 0.7370 - val_binary_accuracy: 0.9042 - val_loss: 0.3088\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7247 - binary_accuracy: 0.9029 - loss: 0.3110 - val_auc: 0.7555 - val_binary_accuracy: 0.9042 - val_loss: 0.3041\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7427 - binary_accuracy: 0.9029 - loss: 0.3017 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2867\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9029 - loss: 0.2871 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2750\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9029 - loss: 0.2775 - val_auc: 0.7827 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9029 - loss: 0.2730 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2709 - val_auc: 0.7922 - val_binary_accuracy: 0.9042 - val_loss: 0.2637\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9029 - loss: 0.2699 - val_auc: 0.7948 - val_binary_accuracy: 0.9042 - val_loss: 0.2627\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9029 - loss: 0.2693 - val_auc: 0.8002 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7975 - binary_accuracy: 0.9092 - loss: 0.2542\n",
            "Fold 2 Metrics: Loss = 0.2623, Accuracy = 0.9042, AUC = 0.8002\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.5581 - binary_accuracy: 0.6994 - loss: 0.5267 - val_auc: 0.7585 - val_binary_accuracy: 0.9042 - val_loss: 0.2914\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7546 - binary_accuracy: 0.9051 - loss: 0.2867 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2786\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9051 - loss: 0.2750 - val_auc: 0.7714 - val_binary_accuracy: 0.9042 - val_loss: 0.2728\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9051 - loss: 0.2698 - val_auc: 0.7789 - val_binary_accuracy: 0.9042 - val_loss: 0.2709\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7759 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9051 - loss: 0.2662 - val_auc: 0.7798 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9051 - loss: 0.2650 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7838 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9051 - loss: 0.2629 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9051 - loss: 0.2620 - val_auc: 0.7877 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7815 - binary_accuracy: 0.9046 - loss: 0.2655\n",
            "Fold 3 Metrics: Loss = 0.2652, Accuracy = 0.9042, AUC = 0.7877\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5508 - binary_accuracy: 0.8437 - loss: 0.4380 - val_auc: 0.7529 - val_binary_accuracy: 0.9044 - val_loss: 0.2950\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7393 - binary_accuracy: 0.9047 - loss: 0.2905 - val_auc: 0.7674 - val_binary_accuracy: 0.9044 - val_loss: 0.2799\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9047 - loss: 0.2774 - val_auc: 0.7800 - val_binary_accuracy: 0.9044 - val_loss: 0.2739\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9047 - loss: 0.2707 - val_auc: 0.7860 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9047 - loss: 0.2674 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9047 - loss: 0.2660 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9047 - loss: 0.2650 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9047 - loss: 0.2643 - val_auc: 0.7931 - val_binary_accuracy: 0.9044 - val_loss: 0.2653\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9047 - loss: 0.2636 - val_auc: 0.7944 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9047 - loss: 0.2630 - val_auc: 0.7947 - val_binary_accuracy: 0.9044 - val_loss: 0.2644\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7729 - binary_accuracy: 0.9049 - loss: 0.2691\n",
            "Fold 4 Metrics: Loss = 0.2644, Accuracy = 0.9044, AUC = 0.7947\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5074 - binary_accuracy: 0.7590 - loss: 0.4816 - val_auc: 0.7335 - val_binary_accuracy: 0.9044 - val_loss: 0.3036\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7281 - binary_accuracy: 0.9040 - loss: 0.3030 - val_auc: 0.7601 - val_binary_accuracy: 0.9044 - val_loss: 0.2946\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7483 - binary_accuracy: 0.9040 - loss: 0.2945 - val_auc: 0.7685 - val_binary_accuracy: 0.9044 - val_loss: 0.2823\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9040 - loss: 0.2834 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2738\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9040 - loss: 0.2769 - val_auc: 0.7779 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9040 - loss: 0.2725 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9040 - loss: 0.2719 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7885 - val_binary_accuracy: 0.9044 - val_loss: 0.2632\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9040 - loss: 0.2711 - val_auc: 0.7895 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7987 - binary_accuracy: 0.9013 - loss: 0.2630\n",
            "Fold 5 Metrics: Loss = 0.2626, Accuracy = 0.9044, AUC = 0.7895\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2640\n",
            "Average Accuracy: 0.9044\n",
            "Average AUC: 0.7904\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 2, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - auc: 0.5151 - binary_accuracy: 0.6644 - loss: 0.5768 - val_auc: 0.7096 - val_binary_accuracy: 0.9044 - val_loss: 0.3085\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7242 - binary_accuracy: 0.9069 - loss: 0.2999 - val_auc: 0.7472 - val_binary_accuracy: 0.9044 - val_loss: 0.2943\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9069 - loss: 0.2826 - val_auc: 0.7603 - val_binary_accuracy: 0.9044 - val_loss: 0.2804\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9069 - loss: 0.2683 - val_auc: 0.7607 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9069 - loss: 0.2616 - val_auc: 0.7689 - val_binary_accuracy: 0.9044 - val_loss: 0.2704\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2596 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2696\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9069 - loss: 0.2587 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9069 - loss: 0.2581 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9069 - loss: 0.2576 - val_auc: 0.7752 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9069 - loss: 0.2571 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7735 - binary_accuracy: 0.9084 - loss: 0.2604\n",
            "Fold 1 Metrics: Loss = 0.2680, Accuracy = 0.9044, AUC = 0.7751\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5828 - binary_accuracy: 0.9020 - loss: 0.3681 - val_auc: 0.7650 - val_binary_accuracy: 0.9042 - val_loss: 0.2861\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9029 - loss: 0.2832 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2711 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2650\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9029 - loss: 0.2675 - val_auc: 0.8000 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9048 - loss: 0.2648 - val_auc: 0.8026 - val_binary_accuracy: 0.9047 - val_loss: 0.2616\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9063 - loss: 0.2628 - val_auc: 0.8053 - val_binary_accuracy: 0.9062 - val_loss: 0.2609\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.8073 - val_binary_accuracy: 0.9069 - val_loss: 0.2602\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9075 - loss: 0.2603 - val_auc: 0.8085 - val_binary_accuracy: 0.9075 - val_loss: 0.2595\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9078 - loss: 0.2594 - val_auc: 0.8092 - val_binary_accuracy: 0.9079 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.8113 - val_binary_accuracy: 0.9082 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8159 - binary_accuracy: 0.9121 - loss: 0.2488\n",
            "Fold 2 Metrics: Loss = 0.2587, Accuracy = 0.9082, AUC = 0.8113\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5187 - binary_accuracy: 0.7906 - loss: 0.4414 - val_auc: 0.7587 - val_binary_accuracy: 0.9042 - val_loss: 0.2873\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9051 - loss: 0.2828 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7817 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9051 - loss: 0.2665 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2673\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9051 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9051 - loss: 0.2635 - val_auc: 0.7881 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9051 - loss: 0.2629 - val_auc: 0.7891 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9051 - loss: 0.2624 - val_auc: 0.7904 - val_binary_accuracy: 0.9042 - val_loss: 0.2649\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9058 - loss: 0.2616 - val_auc: 0.7917 - val_binary_accuracy: 0.9079 - val_loss: 0.2639\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9074 - loss: 0.2644\n",
            "Fold 3 Metrics: Loss = 0.2639, Accuracy = 0.9079, AUC = 0.7917\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5575 - binary_accuracy: 0.9047 - loss: 0.3670 - val_auc: 0.7704 - val_binary_accuracy: 0.9044 - val_loss: 0.2877\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7604 - binary_accuracy: 0.9047 - loss: 0.2814 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9047 - loss: 0.2677 - val_auc: 0.7826 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9047 - loss: 0.2653 - val_auc: 0.7867 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9050 - loss: 0.2641 - val_auc: 0.7887 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9066 - loss: 0.2633 - val_auc: 0.7932 - val_binary_accuracy: 0.9053 - val_loss: 0.2648\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9083 - loss: 0.2622 - val_auc: 0.7934 - val_binary_accuracy: 0.9067 - val_loss: 0.2640\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9091 - loss: 0.2612 - val_auc: 0.7963 - val_binary_accuracy: 0.9070 - val_loss: 0.2631\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9094 - loss: 0.2602 - val_auc: 0.7984 - val_binary_accuracy: 0.9078 - val_loss: 0.2622\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9097 - loss: 0.2593 - val_auc: 0.8003 - val_binary_accuracy: 0.9088 - val_loss: 0.2612\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7793 - binary_accuracy: 0.9080 - loss: 0.2669\n",
            "Fold 4 Metrics: Loss = 0.2612, Accuracy = 0.9088, AUC = 0.8003\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5635 - binary_accuracy: 0.8763 - loss: 0.3911 - val_auc: 0.7609 - val_binary_accuracy: 0.9044 - val_loss: 0.2932\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7480 - binary_accuracy: 0.9040 - loss: 0.2910 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2742\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9040 - loss: 0.2766 - val_auc: 0.7842 - val_binary_accuracy: 0.9044 - val_loss: 0.2644\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9040 - loss: 0.2706 - val_auc: 0.7881 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9040 - loss: 0.2687 - val_auc: 0.7936 - val_binary_accuracy: 0.9044 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9040 - loss: 0.2671 - val_auc: 0.7967 - val_binary_accuracy: 0.9060 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9058 - loss: 0.2654 - val_auc: 0.7970 - val_binary_accuracy: 0.9084 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9079 - loss: 0.2640 - val_auc: 0.7987 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9083 - loss: 0.2627 - val_auc: 0.7978 - val_binary_accuracy: 0.9097 - val_loss: 0.2558\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9090 - loss: 0.2615 - val_auc: 0.7997 - val_binary_accuracy: 0.9101 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8093 - binary_accuracy: 0.9079 - loss: 0.2532\n",
            "Fold 5 Metrics: Loss = 0.2552, Accuracy = 0.9101, AUC = 0.7997\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2614\n",
            "Average Accuracy: 0.9079\n",
            "Average AUC: 0.7956\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 2, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6283 - binary_accuracy: 0.9033 - loss: 0.3333 - val_auc: 0.7664 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9069 - loss: 0.2620 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9069 - loss: 0.2575 - val_auc: 0.7791 - val_binary_accuracy: 0.9041 - val_loss: 0.2672\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9072 - loss: 0.2550 - val_auc: 0.7825 - val_binary_accuracy: 0.9065 - val_loss: 0.2653\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9093 - loss: 0.2530 - val_auc: 0.7846 - val_binary_accuracy: 0.9079 - val_loss: 0.2638\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9110 - loss: 0.2512 - val_auc: 0.7873 - val_binary_accuracy: 0.9088 - val_loss: 0.2625\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9120 - loss: 0.2498 - val_auc: 0.7885 - val_binary_accuracy: 0.9084 - val_loss: 0.2616\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9123 - loss: 0.2487 - val_auc: 0.7895 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8114 - binary_accuracy: 0.9124 - loss: 0.2480 - val_auc: 0.7895 - val_binary_accuracy: 0.9090 - val_loss: 0.2608\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8123 - binary_accuracy: 0.9124 - loss: 0.2473 - val_auc: 0.7904 - val_binary_accuracy: 0.9085 - val_loss: 0.2603\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7897 - binary_accuracy: 0.9113 - loss: 0.2530\n",
            "Fold 1 Metrics: Loss = 0.2603, Accuracy = 0.9085, AUC = 0.7904\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6523 - binary_accuracy: 0.9029 - loss: 0.3193 - val_auc: 0.7889 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9029 - loss: 0.2714 - val_auc: 0.7968 - val_binary_accuracy: 0.9042 - val_loss: 0.2625\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9038 - loss: 0.2674 - val_auc: 0.8027 - val_binary_accuracy: 0.9045 - val_loss: 0.2602\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9052 - loss: 0.2644 - val_auc: 0.8057 - val_binary_accuracy: 0.9065 - val_loss: 0.2578\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9068 - loss: 0.2623 - val_auc: 0.8072 - val_binary_accuracy: 0.9071 - val_loss: 0.2577\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9074 - loss: 0.2611 - val_auc: 0.8076 - val_binary_accuracy: 0.9078 - val_loss: 0.2574\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9079 - loss: 0.2602 - val_auc: 0.8087 - val_binary_accuracy: 0.9078 - val_loss: 0.2569\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9081 - loss: 0.2595 - val_auc: 0.8086 - val_binary_accuracy: 0.9084 - val_loss: 0.2570\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9087 - loss: 0.2589 - val_auc: 0.8100 - val_binary_accuracy: 0.9082 - val_loss: 0.2566\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9088 - loss: 0.2582 - val_auc: 0.8098 - val_binary_accuracy: 0.9087 - val_loss: 0.2568\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8164 - binary_accuracy: 0.9116 - loss: 0.2460\n",
            "Fold 2 Metrics: Loss = 0.2568, Accuracy = 0.9087, AUC = 0.8098\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6286 - binary_accuracy: 0.8816 - loss: 0.3469 - val_auc: 0.7731 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9051 - loss: 0.2696 - val_auc: 0.7800 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9059 - loss: 0.2659 - val_auc: 0.7851 - val_binary_accuracy: 0.9072 - val_loss: 0.2658\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9076 - loss: 0.2641 - val_auc: 0.7897 - val_binary_accuracy: 0.9093 - val_loss: 0.2637\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9081 - loss: 0.2629 - val_auc: 0.7945 - val_binary_accuracy: 0.9100 - val_loss: 0.2616\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9088 - loss: 0.2613 - val_auc: 0.7986 - val_binary_accuracy: 0.9109 - val_loss: 0.2597\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9091 - loss: 0.2604 - val_auc: 0.8017 - val_binary_accuracy: 0.9109 - val_loss: 0.2583\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9094 - loss: 0.2597 - val_auc: 0.8042 - val_binary_accuracy: 0.9113 - val_loss: 0.2573\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9094 - loss: 0.2591 - val_auc: 0.8054 - val_binary_accuracy: 0.9113 - val_loss: 0.2566\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9099 - loss: 0.2587 - val_auc: 0.8057 - val_binary_accuracy: 0.9113 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7978 - binary_accuracy: 0.9127 - loss: 0.2572\n",
            "Fold 3 Metrics: Loss = 0.2561, Accuracy = 0.9113, AUC = 0.8057\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6091 - binary_accuracy: 0.8293 - loss: 0.3819 - val_auc: 0.7752 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9047 - loss: 0.2691 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9050 - loss: 0.2652 - val_auc: 0.7943 - val_binary_accuracy: 0.9047 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9079 - loss: 0.2629 - val_auc: 0.7995 - val_binary_accuracy: 0.9070 - val_loss: 0.2615\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9097 - loss: 0.2606 - val_auc: 0.8024 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9105 - loss: 0.2594 - val_auc: 0.8044 - val_binary_accuracy: 0.9082 - val_loss: 0.2582\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9111 - loss: 0.2584 - val_auc: 0.8060 - val_binary_accuracy: 0.9084 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9114 - loss: 0.2575 - val_auc: 0.8074 - val_binary_accuracy: 0.9084 - val_loss: 0.2569\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9113 - loss: 0.2567 - val_auc: 0.8085 - val_binary_accuracy: 0.9081 - val_loss: 0.2567\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9112 - loss: 0.2562 - val_auc: 0.8098 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9084 - loss: 0.2616\n",
            "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9087, AUC = 0.8098\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6192 - binary_accuracy: 0.9038 - loss: 0.3399 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9040 - loss: 0.2737 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2611\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9048 - loss: 0.2690 - val_auc: 0.7961 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7984 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9087 - loss: 0.2644 - val_auc: 0.8018 - val_binary_accuracy: 0.9101 - val_loss: 0.2547\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9089 - loss: 0.2628 - val_auc: 0.8031 - val_binary_accuracy: 0.9107 - val_loss: 0.2539\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9092 - loss: 0.2617 - val_auc: 0.8042 - val_binary_accuracy: 0.9107 - val_loss: 0.2533\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9094 - loss: 0.2609 - val_auc: 0.8044 - val_binary_accuracy: 0.9106 - val_loss: 0.2532\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8049 - val_binary_accuracy: 0.9109 - val_loss: 0.2530\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8049 - val_binary_accuracy: 0.9110 - val_loss: 0.2528\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8138 - binary_accuracy: 0.9091 - loss: 0.2512\n",
            "Fold 5 Metrics: Loss = 0.2528, Accuracy = 0.9110, AUC = 0.8049\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2564\n",
            "Average Accuracy: 0.9096\n",
            "Average AUC: 0.8041\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 2, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6988 - binary_accuracy: 0.9069 - loss: 0.2914 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9072 - loss: 0.2590 - val_auc: 0.7819 - val_binary_accuracy: 0.9048 - val_loss: 0.2660\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9094 - loss: 0.2551 - val_auc: 0.7877 - val_binary_accuracy: 0.9060 - val_loss: 0.2628\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8045 - binary_accuracy: 0.9112 - loss: 0.2520 - val_auc: 0.7907 - val_binary_accuracy: 0.9076 - val_loss: 0.2610\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9123 - loss: 0.2499 - val_auc: 0.7921 - val_binary_accuracy: 0.9078 - val_loss: 0.2601\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9125 - loss: 0.2485 - val_auc: 0.7936 - val_binary_accuracy: 0.9087 - val_loss: 0.2592\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8116 - binary_accuracy: 0.9124 - loss: 0.2475 - val_auc: 0.7944 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8131 - binary_accuracy: 0.9128 - loss: 0.2468 - val_auc: 0.7945 - val_binary_accuracy: 0.9091 - val_loss: 0.2586\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9129 - loss: 0.2462 - val_auc: 0.7945 - val_binary_accuracy: 0.9093 - val_loss: 0.2586\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8148 - binary_accuracy: 0.9125 - loss: 0.2457 - val_auc: 0.7951 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7937 - binary_accuracy: 0.9128 - loss: 0.2518\n",
            "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9091, AUC = 0.7951\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6524 - binary_accuracy: 0.8633 - loss: 0.3412 - val_auc: 0.7960 - val_binary_accuracy: 0.9042 - val_loss: 0.2636\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9040 - loss: 0.2687 - val_auc: 0.8037 - val_binary_accuracy: 0.9056 - val_loss: 0.2591\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9053 - loss: 0.2643 - val_auc: 0.8077 - val_binary_accuracy: 0.9068 - val_loss: 0.2571\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9072 - loss: 0.2621 - val_auc: 0.8092 - val_binary_accuracy: 0.9076 - val_loss: 0.2560\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9077 - loss: 0.2607 - val_auc: 0.8105 - val_binary_accuracy: 0.9079 - val_loss: 0.2554\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8005 - binary_accuracy: 0.9079 - loss: 0.2598 - val_auc: 0.8100 - val_binary_accuracy: 0.9085 - val_loss: 0.2552\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8020 - binary_accuracy: 0.9083 - loss: 0.2592 - val_auc: 0.8104 - val_binary_accuracy: 0.9085 - val_loss: 0.2550\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9081 - loss: 0.2587 - val_auc: 0.8103 - val_binary_accuracy: 0.9085 - val_loss: 0.2549\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9080 - loss: 0.2581 - val_auc: 0.8106 - val_binary_accuracy: 0.9087 - val_loss: 0.2548\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9083 - loss: 0.2576 - val_auc: 0.8106 - val_binary_accuracy: 0.9085 - val_loss: 0.2550\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9121 - loss: 0.2445\n",
            "Fold 2 Metrics: Loss = 0.2550, Accuracy = 0.9085, AUC = 0.8106\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6260 - binary_accuracy: 0.8325 - loss: 0.3854 - val_auc: 0.7763 - val_binary_accuracy: 0.9042 - val_loss: 0.2705\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9055 - loss: 0.2685 - val_auc: 0.7850 - val_binary_accuracy: 0.9053 - val_loss: 0.2663\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9072 - loss: 0.2656 - val_auc: 0.7905 - val_binary_accuracy: 0.9087 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9079 - loss: 0.2643 - val_auc: 0.7946 - val_binary_accuracy: 0.9106 - val_loss: 0.2615\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9090 - loss: 0.2634 - val_auc: 0.7972 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9094 - loss: 0.2625 - val_auc: 0.7997 - val_binary_accuracy: 0.9110 - val_loss: 0.2584\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9096 - loss: 0.2619 - val_auc: 0.8014 - val_binary_accuracy: 0.9113 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9101 - loss: 0.2614 - val_auc: 0.8029 - val_binary_accuracy: 0.9116 - val_loss: 0.2568\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9103 - loss: 0.2609 - val_auc: 0.8046 - val_binary_accuracy: 0.9116 - val_loss: 0.2563\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9103 - loss: 0.2603 - val_auc: 0.8062 - val_binary_accuracy: 0.9115 - val_loss: 0.2559\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7977 - binary_accuracy: 0.9130 - loss: 0.2568\n",
            "Fold 3 Metrics: Loss = 0.2559, Accuracy = 0.9115, AUC = 0.8062\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6158 - binary_accuracy: 0.8419 - loss: 0.3678 - val_auc: 0.7857 - val_binary_accuracy: 0.9048 - val_loss: 0.2655\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9065 - loss: 0.2662 - val_auc: 0.7949 - val_binary_accuracy: 0.9087 - val_loss: 0.2609\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9083 - loss: 0.2627 - val_auc: 0.8004 - val_binary_accuracy: 0.9088 - val_loss: 0.2583\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9098 - loss: 0.2606 - val_auc: 0.8030 - val_binary_accuracy: 0.9095 - val_loss: 0.2569\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9103 - loss: 0.2594 - val_auc: 0.8044 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7929 - binary_accuracy: 0.9106 - loss: 0.2585 - val_auc: 0.8063 - val_binary_accuracy: 0.9093 - val_loss: 0.2554\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9112 - loss: 0.2577 - val_auc: 0.8084 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7957 - binary_accuracy: 0.9118 - loss: 0.2571 - val_auc: 0.8090 - val_binary_accuracy: 0.9097 - val_loss: 0.2542\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9117 - loss: 0.2568 - val_auc: 0.8098 - val_binary_accuracy: 0.9097 - val_loss: 0.2539\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9119 - loss: 0.2564 - val_auc: 0.8104 - val_binary_accuracy: 0.9097 - val_loss: 0.2537\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7914 - binary_accuracy: 0.9099 - loss: 0.2603\n",
            "Fold 4 Metrics: Loss = 0.2537, Accuracy = 0.9097, AUC = 0.8104\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6509 - binary_accuracy: 0.8786 - loss: 0.3291 - val_auc: 0.7903 - val_binary_accuracy: 0.9045 - val_loss: 0.2618\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.7960 - val_binary_accuracy: 0.9082 - val_loss: 0.2584\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9070 - loss: 0.2680 - val_auc: 0.7986 - val_binary_accuracy: 0.9084 - val_loss: 0.2561\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9087 - loss: 0.2659 - val_auc: 0.8028 - val_binary_accuracy: 0.9094 - val_loss: 0.2543\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9091 - loss: 0.2642 - val_auc: 0.8048 - val_binary_accuracy: 0.9101 - val_loss: 0.2530\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9091 - loss: 0.2629 - val_auc: 0.8060 - val_binary_accuracy: 0.9109 - val_loss: 0.2522\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8063 - val_binary_accuracy: 0.9109 - val_loss: 0.2517\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9098 - loss: 0.2611 - val_auc: 0.8072 - val_binary_accuracy: 0.9110 - val_loss: 0.2515\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9103 - loss: 0.2605 - val_auc: 0.8070 - val_binary_accuracy: 0.9112 - val_loss: 0.2513\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9100 - loss: 0.2600 - val_auc: 0.8078 - val_binary_accuracy: 0.9110 - val_loss: 0.2511\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9094 - loss: 0.2501\n",
            "Fold 5 Metrics: Loss = 0.2511, Accuracy = 0.9110, AUC = 0.8078\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2549\n",
            "Average Accuracy: 0.9100\n",
            "Average AUC: 0.8060\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 2, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7176 - binary_accuracy: 0.9069 - loss: 0.2854 - val_auc: 0.7773 - val_binary_accuracy: 0.9048 - val_loss: 0.2695\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9097 - loss: 0.2587 - val_auc: 0.7868 - val_binary_accuracy: 0.9066 - val_loss: 0.2653\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9119 - loss: 0.2544 - val_auc: 0.7917 - val_binary_accuracy: 0.9078 - val_loss: 0.2632\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9115 - loss: 0.2520 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2631\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9121 - loss: 0.2503 - val_auc: 0.7946 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8084 - binary_accuracy: 0.9123 - loss: 0.2491 - val_auc: 0.7955 - val_binary_accuracy: 0.9078 - val_loss: 0.2616\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8101 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7961 - val_binary_accuracy: 0.9082 - val_loss: 0.2606\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9127 - loss: 0.2474 - val_auc: 0.7959 - val_binary_accuracy: 0.9082 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8131 - binary_accuracy: 0.9123 - loss: 0.2468 - val_auc: 0.7962 - val_binary_accuracy: 0.9082 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8138 - binary_accuracy: 0.9127 - loss: 0.2464 - val_auc: 0.7964 - val_binary_accuracy: 0.9082 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7964 - binary_accuracy: 0.9118 - loss: 0.2504\n",
            "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9082, AUC = 0.7964\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6800 - binary_accuracy: 0.8850 - loss: 0.3162 - val_auc: 0.7986 - val_binary_accuracy: 0.9047 - val_loss: 0.2627\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9045 - loss: 0.2695 - val_auc: 0.8064 - val_binary_accuracy: 0.9060 - val_loss: 0.2596\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9060 - loss: 0.2654 - val_auc: 0.8089 - val_binary_accuracy: 0.9082 - val_loss: 0.2580\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9076 - loss: 0.2627 - val_auc: 0.8092 - val_binary_accuracy: 0.9096 - val_loss: 0.2566\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9085 - loss: 0.2609 - val_auc: 0.8099 - val_binary_accuracy: 0.9103 - val_loss: 0.2556\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9087 - loss: 0.2600 - val_auc: 0.8100 - val_binary_accuracy: 0.9099 - val_loss: 0.2546\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9081 - loss: 0.2592 - val_auc: 0.8112 - val_binary_accuracy: 0.9103 - val_loss: 0.2539\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9078 - loss: 0.2586 - val_auc: 0.8109 - val_binary_accuracy: 0.9102 - val_loss: 0.2535\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9079 - loss: 0.2581 - val_auc: 0.8131 - val_binary_accuracy: 0.9103 - val_loss: 0.2529\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8050 - binary_accuracy: 0.9078 - loss: 0.2577 - val_auc: 0.8121 - val_binary_accuracy: 0.9100 - val_loss: 0.2533\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8181 - binary_accuracy: 0.9130 - loss: 0.2431\n",
            "Fold 2 Metrics: Loss = 0.2533, Accuracy = 0.9100, AUC = 0.8121\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6425 - binary_accuracy: 0.8758 - loss: 0.3350 - val_auc: 0.7791 - val_binary_accuracy: 0.9051 - val_loss: 0.2682\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7620 - binary_accuracy: 0.9071 - loss: 0.2725 - val_auc: 0.7861 - val_binary_accuracy: 0.9082 - val_loss: 0.2651\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7685 - binary_accuracy: 0.9073 - loss: 0.2692 - val_auc: 0.7920 - val_binary_accuracy: 0.9102 - val_loss: 0.2624\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9085 - loss: 0.2666 - val_auc: 0.7964 - val_binary_accuracy: 0.9104 - val_loss: 0.2602\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9090 - loss: 0.2646 - val_auc: 0.7996 - val_binary_accuracy: 0.9112 - val_loss: 0.2583\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9096 - loss: 0.2639 - val_auc: 0.8011 - val_binary_accuracy: 0.9115 - val_loss: 0.2571\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9097 - loss: 0.2631 - val_auc: 0.8029 - val_binary_accuracy: 0.9116 - val_loss: 0.2562\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9100 - loss: 0.2625 - val_auc: 0.8047 - val_binary_accuracy: 0.9115 - val_loss: 0.2556\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9110 - loss: 0.2618 - val_auc: 0.8052 - val_binary_accuracy: 0.9116 - val_loss: 0.2553\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9108 - loss: 0.2612 - val_auc: 0.8055 - val_binary_accuracy: 0.9116 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7976 - binary_accuracy: 0.9134 - loss: 0.2556\n",
            "Fold 3 Metrics: Loss = 0.2551, Accuracy = 0.9116, AUC = 0.8055\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6487 - binary_accuracy: 0.8869 - loss: 0.3241 - val_auc: 0.7897 - val_binary_accuracy: 0.9063 - val_loss: 0.2639\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9071 - loss: 0.2666 - val_auc: 0.7988 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9088 - loss: 0.2630 - val_auc: 0.8036 - val_binary_accuracy: 0.9087 - val_loss: 0.2572\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9097 - loss: 0.2610 - val_auc: 0.8060 - val_binary_accuracy: 0.9081 - val_loss: 0.2559\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9102 - loss: 0.2597 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2552\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9106 - loss: 0.2588 - val_auc: 0.8088 - val_binary_accuracy: 0.9091 - val_loss: 0.2546\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9107 - loss: 0.2581 - val_auc: 0.8095 - val_binary_accuracy: 0.9093 - val_loss: 0.2543\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9109 - loss: 0.2575 - val_auc: 0.8100 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9110 - loss: 0.2570 - val_auc: 0.8105 - val_binary_accuracy: 0.9094 - val_loss: 0.2539\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9113 - loss: 0.2566 - val_auc: 0.8113 - val_binary_accuracy: 0.9091 - val_loss: 0.2538\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9083 - loss: 0.2609\n",
            "Fold 4 Metrics: Loss = 0.2538, Accuracy = 0.9091, AUC = 0.8113\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6596 - binary_accuracy: 0.8855 - loss: 0.3214 - val_auc: 0.7902 - val_binary_accuracy: 0.9041 - val_loss: 0.2671\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9043 - loss: 0.2730 - val_auc: 0.7974 - val_binary_accuracy: 0.9053 - val_loss: 0.2647\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9062 - loss: 0.2696 - val_auc: 0.8024 - val_binary_accuracy: 0.9090 - val_loss: 0.2619\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9069 - loss: 0.2669 - val_auc: 0.8047 - val_binary_accuracy: 0.9094 - val_loss: 0.2594\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8062 - val_binary_accuracy: 0.9107 - val_loss: 0.2573\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9083 - loss: 0.2640 - val_auc: 0.8075 - val_binary_accuracy: 0.9116 - val_loss: 0.2554\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2630 - val_auc: 0.8076 - val_binary_accuracy: 0.9115 - val_loss: 0.2539\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8082 - val_binary_accuracy: 0.9113 - val_loss: 0.2529\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8086 - val_binary_accuracy: 0.9115 - val_loss: 0.2519\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9093 - loss: 0.2607 - val_auc: 0.8095 - val_binary_accuracy: 0.9118 - val_loss: 0.2515\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9096 - loss: 0.2499\n",
            "Fold 5 Metrics: Loss = 0.2515, Accuracy = 0.9118, AUC = 0.8095\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2545\n",
            "Average Accuracy: 0.9101\n",
            "Average AUC: 0.8070\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 3, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5016 - binary_accuracy: 0.6917 - loss: 0.5461 - val_auc: 0.7261 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6942 - binary_accuracy: 0.9069 - loss: 0.3066 - val_auc: 0.7271 - val_binary_accuracy: 0.9044 - val_loss: 0.3083\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7550 - binary_accuracy: 0.9069 - loss: 0.3004 - val_auc: 0.7529 - val_binary_accuracy: 0.9044 - val_loss: 0.2989\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9069 - loss: 0.2879 - val_auc: 0.7558 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9069 - loss: 0.2709 - val_auc: 0.7661 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7747 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7944 - binary_accuracy: 0.9069 - loss: 0.2585 - val_auc: 0.7771 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9069 - loss: 0.2570 - val_auc: 0.7775 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9069 - loss: 0.2563 - val_auc: 0.7803 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9069 - loss: 0.2557 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7775 - binary_accuracy: 0.9084 - loss: 0.2589\n",
            "Fold 1 Metrics: Loss = 0.2662, Accuracy = 0.9044, AUC = 0.7814\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5037 - binary_accuracy: 0.5797 - loss: 0.6377 - val_auc: 0.6403 - val_binary_accuracy: 0.9042 - val_loss: 0.3163\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6298 - binary_accuracy: 0.9029 - loss: 0.3170 - val_auc: 0.7354 - val_binary_accuracy: 0.9042 - val_loss: 0.3102\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7345 - binary_accuracy: 0.9029 - loss: 0.3117 - val_auc: 0.7564 - val_binary_accuracy: 0.9042 - val_loss: 0.3024\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7552 - binary_accuracy: 0.9029 - loss: 0.3026 - val_auc: 0.7788 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9029 - loss: 0.2889 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2743\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9029 - loss: 0.2769 - val_auc: 0.7942 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2729 - val_auc: 0.7966 - val_binary_accuracy: 0.9042 - val_loss: 0.2640\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9029 - loss: 0.2695 - val_auc: 0.7981 - val_binary_accuracy: 0.9042 - val_loss: 0.2620\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9029 - loss: 0.2679 - val_auc: 0.8014 - val_binary_accuracy: 0.9042 - val_loss: 0.2612\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9029 - loss: 0.2666 - val_auc: 0.8023 - val_binary_accuracy: 0.9042 - val_loss: 0.2609\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8054 - binary_accuracy: 0.9092 - loss: 0.2511\n",
            "Fold 2 Metrics: Loss = 0.2609, Accuracy = 0.9042, AUC = 0.8023\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5094 - binary_accuracy: 0.9051 - loss: 0.4287 - val_auc: 0.7078 - val_binary_accuracy: 0.9042 - val_loss: 0.3112\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7050 - binary_accuracy: 0.9051 - loss: 0.3059 - val_auc: 0.7609 - val_binary_accuracy: 0.9042 - val_loss: 0.2882\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7575 - binary_accuracy: 0.9051 - loss: 0.2824 - val_auc: 0.7727 - val_binary_accuracy: 0.9042 - val_loss: 0.2735\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7709 - binary_accuracy: 0.9051 - loss: 0.2706 - val_auc: 0.7745 - val_binary_accuracy: 0.9042 - val_loss: 0.2705\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9051 - loss: 0.2681 - val_auc: 0.7803 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9051 - loss: 0.2664 - val_auc: 0.7845 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7839 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9051 - loss: 0.2650 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2670\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9051 - loss: 0.2643 - val_auc: 0.7866 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9051 - loss: 0.2635 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7821 - binary_accuracy: 0.9046 - loss: 0.2655\n",
            "Fold 3 Metrics: Loss = 0.2657, Accuracy = 0.9042, AUC = 0.7876\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5206 - binary_accuracy: 0.9047 - loss: 0.3544 - val_auc: 0.7491 - val_binary_accuracy: 0.9044 - val_loss: 0.3113\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7073 - binary_accuracy: 0.9047 - loss: 0.3089 - val_auc: 0.7533 - val_binary_accuracy: 0.9044 - val_loss: 0.3009\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7386 - binary_accuracy: 0.9047 - loss: 0.2960 - val_auc: 0.7657 - val_binary_accuracy: 0.9044 - val_loss: 0.2825\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9047 - loss: 0.2777 - val_auc: 0.7776 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9047 - loss: 0.2692 - val_auc: 0.7773 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9047 - loss: 0.2675 - val_auc: 0.7821 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9047 - loss: 0.2670 - val_auc: 0.7812 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9047 - loss: 0.2666 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9047 - loss: 0.2659 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7650 - binary_accuracy: 0.9049 - loss: 0.2728\n",
            "Fold 4 Metrics: Loss = 0.2692, Accuracy = 0.9044, AUC = 0.7828\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5026 - binary_accuracy: 0.6269 - loss: 0.5922 - val_auc: 0.7004 - val_binary_accuracy: 0.9044 - val_loss: 0.3140\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6943 - binary_accuracy: 0.9040 - loss: 0.3128 - val_auc: 0.7520 - val_binary_accuracy: 0.9044 - val_loss: 0.3028\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7483 - binary_accuracy: 0.9040 - loss: 0.3011 - val_auc: 0.7717 - val_binary_accuracy: 0.9044 - val_loss: 0.2867\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7598 - binary_accuracy: 0.9040 - loss: 0.2865 - val_auc: 0.7743 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2758 - val_auc: 0.7890 - val_binary_accuracy: 0.9044 - val_loss: 0.2651\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7925 - val_binary_accuracy: 0.9044 - val_loss: 0.2629\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9040 - loss: 0.2702 - val_auc: 0.7928 - val_binary_accuracy: 0.9044 - val_loss: 0.2619\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9040 - loss: 0.2694 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2612\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9040 - loss: 0.2688 - val_auc: 0.7941 - val_binary_accuracy: 0.9044 - val_loss: 0.2605\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9040 - loss: 0.2681 - val_auc: 0.7955 - val_binary_accuracy: 0.9044 - val_loss: 0.2600\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8072 - binary_accuracy: 0.9013 - loss: 0.2585\n",
            "Fold 5 Metrics: Loss = 0.2600, Accuracy = 0.9044, AUC = 0.7955\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2644\n",
            "Average Accuracy: 0.9043\n",
            "Average AUC: 0.7899\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 3, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5001 - binary_accuracy: 0.6835 - loss: 0.5494 - val_auc: 0.6707 - val_binary_accuracy: 0.9044 - val_loss: 0.3132\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6898 - binary_accuracy: 0.9069 - loss: 0.3056 - val_auc: 0.7449 - val_binary_accuracy: 0.9044 - val_loss: 0.3041\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7515 - binary_accuracy: 0.9069 - loss: 0.2922 - val_auc: 0.7589 - val_binary_accuracy: 0.9044 - val_loss: 0.2818\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9069 - loss: 0.2695 - val_auc: 0.7672 - val_binary_accuracy: 0.9044 - val_loss: 0.2728\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9069 - loss: 0.2617 - val_auc: 0.7753 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9069 - loss: 0.2589 - val_auc: 0.7799 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9069 - loss: 0.2572 - val_auc: 0.7831 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9069 - loss: 0.2562 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2648\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9069 - loss: 0.2551 - val_auc: 0.7882 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8045 - binary_accuracy: 0.9069 - loss: 0.2539 - val_auc: 0.7895 - val_binary_accuracy: 0.9044 - val_loss: 0.2628\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9084 - loss: 0.2555\n",
            "Fold 1 Metrics: Loss = 0.2628, Accuracy = 0.9044, AUC = 0.7895\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5494 - binary_accuracy: 0.8115 - loss: 0.4208 - val_auc: 0.7633 - val_binary_accuracy: 0.9042 - val_loss: 0.2972\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7539 - binary_accuracy: 0.9029 - loss: 0.2931 - val_auc: 0.7887 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9029 - loss: 0.2732 - val_auc: 0.7956 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8009 - val_binary_accuracy: 0.9042 - val_loss: 0.2638\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9029 - loss: 0.2683 - val_auc: 0.8026 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9029 - loss: 0.2668 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9036 - loss: 0.2652 - val_auc: 0.8050 - val_binary_accuracy: 0.9042 - val_loss: 0.2616\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9052 - loss: 0.2638 - val_auc: 0.8064 - val_binary_accuracy: 0.9051 - val_loss: 0.2616\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9063 - loss: 0.2625 - val_auc: 0.8069 - val_binary_accuracy: 0.9059 - val_loss: 0.2612\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9075 - loss: 0.2614 - val_auc: 0.8078 - val_binary_accuracy: 0.9068 - val_loss: 0.2607\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8112 - binary_accuracy: 0.9104 - loss: 0.2513\n",
            "Fold 2 Metrics: Loss = 0.2607, Accuracy = 0.9068, AUC = 0.8078\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5586 - binary_accuracy: 0.9051 - loss: 0.3586 - val_auc: 0.7628 - val_binary_accuracy: 0.9042 - val_loss: 0.2854\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7576 - binary_accuracy: 0.9051 - loss: 0.2787 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9051 - loss: 0.2676 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9051 - loss: 0.2660 - val_auc: 0.7837 - val_binary_accuracy: 0.9042 - val_loss: 0.2676\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9051 - loss: 0.2648 - val_auc: 0.7870 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9051 - loss: 0.2636 - val_auc: 0.7890 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9053 - loss: 0.2624 - val_auc: 0.7912 - val_binary_accuracy: 0.9042 - val_loss: 0.2644\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9070 - loss: 0.2615 - val_auc: 0.7935 - val_binary_accuracy: 0.9090 - val_loss: 0.2633\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9086 - loss: 0.2608 - val_auc: 0.7945 - val_binary_accuracy: 0.9093 - val_loss: 0.2621\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9095 - loss: 0.2600 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2609\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9100 - loss: 0.2619\n",
            "Fold 3 Metrics: Loss = 0.2609, Accuracy = 0.9094, AUC = 0.7978\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5424 - binary_accuracy: 0.9047 - loss: 0.3808 - val_auc: 0.7546 - val_binary_accuracy: 0.9044 - val_loss: 0.2978\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7434 - binary_accuracy: 0.9047 - loss: 0.2896 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9047 - loss: 0.2698 - val_auc: 0.7893 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9047 - loss: 0.2653 - val_auc: 0.7930 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9047 - loss: 0.2639 - val_auc: 0.7951 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9048 - loss: 0.2629 - val_auc: 0.7961 - val_binary_accuracy: 0.9044 - val_loss: 0.2652\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9059 - loss: 0.2616 - val_auc: 0.7985 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9086 - loss: 0.2603 - val_auc: 0.8002 - val_binary_accuracy: 0.9060 - val_loss: 0.2621\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9100 - loss: 0.2592 - val_auc: 0.8014 - val_binary_accuracy: 0.9081 - val_loss: 0.2608\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9101 - loss: 0.2583 - val_auc: 0.8034 - val_binary_accuracy: 0.9088 - val_loss: 0.2598\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7852 - binary_accuracy: 0.9078 - loss: 0.2646\n",
            "Fold 4 Metrics: Loss = 0.2598, Accuracy = 0.9088, AUC = 0.8034\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5186 - binary_accuracy: 0.6762 - loss: 0.5585 - val_auc: 0.7575 - val_binary_accuracy: 0.9044 - val_loss: 0.3071\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7405 - binary_accuracy: 0.9040 - loss: 0.3036 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2812\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9040 - loss: 0.2809 - val_auc: 0.7861 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9040 - loss: 0.2711 - val_auc: 0.7940 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9040 - loss: 0.2684 - val_auc: 0.7970 - val_binary_accuracy: 0.9044 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9040 - loss: 0.2667 - val_auc: 0.7980 - val_binary_accuracy: 0.9044 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9043 - loss: 0.2650 - val_auc: 0.7993 - val_binary_accuracy: 0.9084 - val_loss: 0.2575\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9073 - loss: 0.2638 - val_auc: 0.8002 - val_binary_accuracy: 0.9100 - val_loss: 0.2566\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9082 - loss: 0.2628 - val_auc: 0.8002 - val_binary_accuracy: 0.9101 - val_loss: 0.2559\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9088 - loss: 0.2622 - val_auc: 0.8009 - val_binary_accuracy: 0.9094 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8121 - binary_accuracy: 0.9078 - loss: 0.2525\n",
            "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9094, AUC = 0.8009\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2598\n",
            "Average Accuracy: 0.9078\n",
            "Average AUC: 0.7999\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 3, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6031 - binary_accuracy: 0.9069 - loss: 0.3197 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2756\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9069 - loss: 0.2629 - val_auc: 0.7730 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9070 - loss: 0.2584 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9072 - loss: 0.2563 - val_auc: 0.7797 - val_binary_accuracy: 0.9062 - val_loss: 0.2662\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9104 - loss: 0.2543 - val_auc: 0.7826 - val_binary_accuracy: 0.9075 - val_loss: 0.2648\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8034 - binary_accuracy: 0.9123 - loss: 0.2523 - val_auc: 0.7852 - val_binary_accuracy: 0.9078 - val_loss: 0.2636\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7873 - val_binary_accuracy: 0.9087 - val_loss: 0.2624\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9124 - loss: 0.2491 - val_auc: 0.7896 - val_binary_accuracy: 0.9085 - val_loss: 0.2614\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8104 - binary_accuracy: 0.9127 - loss: 0.2482 - val_auc: 0.7899 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8115 - binary_accuracy: 0.9130 - loss: 0.2474 - val_auc: 0.7907 - val_binary_accuracy: 0.9088 - val_loss: 0.2606\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9132 - loss: 0.2533\n",
            "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9088, AUC = 0.7907\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5975 - binary_accuracy: 0.8692 - loss: 0.3589 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9029 - loss: 0.2736 - val_auc: 0.7979 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9030 - loss: 0.2682 - val_auc: 0.8016 - val_binary_accuracy: 0.9042 - val_loss: 0.2607\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9038 - loss: 0.2656 - val_auc: 0.8044 - val_binary_accuracy: 0.9050 - val_loss: 0.2588\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9063 - loss: 0.2629 - val_auc: 0.8071 - val_binary_accuracy: 0.9066 - val_loss: 0.2583\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9070 - loss: 0.2611 - val_auc: 0.8083 - val_binary_accuracy: 0.9073 - val_loss: 0.2578\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9075 - loss: 0.2599 - val_auc: 0.8082 - val_binary_accuracy: 0.9078 - val_loss: 0.2577\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9077 - loss: 0.2591 - val_auc: 0.8086 - val_binary_accuracy: 0.9078 - val_loss: 0.2578\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9079 - loss: 0.2585 - val_auc: 0.8084 - val_binary_accuracy: 0.9085 - val_loss: 0.2580\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9078 - loss: 0.2579 - val_auc: 0.8094 - val_binary_accuracy: 0.9087 - val_loss: 0.2580\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8141 - binary_accuracy: 0.9121 - loss: 0.2476\n",
            "Fold 2 Metrics: Loss = 0.2580, Accuracy = 0.9087, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5699 - binary_accuracy: 0.8448 - loss: 0.3757 - val_auc: 0.7576 - val_binary_accuracy: 0.9042 - val_loss: 0.2835\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9051 - loss: 0.2760 - val_auc: 0.7803 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9052 - loss: 0.2670 - val_auc: 0.7852 - val_binary_accuracy: 0.9048 - val_loss: 0.2661\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9068 - loss: 0.2648 - val_auc: 0.7893 - val_binary_accuracy: 0.9088 - val_loss: 0.2642\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.7928 - val_binary_accuracy: 0.9099 - val_loss: 0.2626\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9090 - loss: 0.2623 - val_auc: 0.7958 - val_binary_accuracy: 0.9104 - val_loss: 0.2610\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9095 - loss: 0.2614 - val_auc: 0.7977 - val_binary_accuracy: 0.9104 - val_loss: 0.2598\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9092 - loss: 0.2607 - val_auc: 0.7994 - val_binary_accuracy: 0.9109 - val_loss: 0.2586\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9094 - loss: 0.2600 - val_auc: 0.8016 - val_binary_accuracy: 0.9110 - val_loss: 0.2575\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9095 - loss: 0.2595 - val_auc: 0.8036 - val_binary_accuracy: 0.9112 - val_loss: 0.2567\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7953 - binary_accuracy: 0.9127 - loss: 0.2575\n",
            "Fold 3 Metrics: Loss = 0.2567, Accuracy = 0.9112, AUC = 0.8036\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5847 - binary_accuracy: 0.8714 - loss: 0.3584 - val_auc: 0.7733 - val_binary_accuracy: 0.9044 - val_loss: 0.2755\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9047 - loss: 0.2713 - val_auc: 0.7870 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9049 - loss: 0.2652 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9068 - loss: 0.2631 - val_auc: 0.7971 - val_binary_accuracy: 0.9056 - val_loss: 0.2607\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9090 - loss: 0.2613 - val_auc: 0.8003 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9090 - loss: 0.2599 - val_auc: 0.8023 - val_binary_accuracy: 0.9082 - val_loss: 0.2579\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9096 - loss: 0.2589 - val_auc: 0.8048 - val_binary_accuracy: 0.9087 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9100 - loss: 0.2583 - val_auc: 0.8058 - val_binary_accuracy: 0.9094 - val_loss: 0.2569\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7958 - binary_accuracy: 0.9097 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9100 - loss: 0.2572 - val_auc: 0.8083 - val_binary_accuracy: 0.9093 - val_loss: 0.2562\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7889 - binary_accuracy: 0.9088 - loss: 0.2624\n",
            "Fold 4 Metrics: Loss = 0.2562, Accuracy = 0.9093, AUC = 0.8083\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6027 - binary_accuracy: 0.8854 - loss: 0.3512 - val_auc: 0.7779 - val_binary_accuracy: 0.9044 - val_loss: 0.2725\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9040 - loss: 0.2747 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9040 - loss: 0.2703 - val_auc: 0.7929 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9040 - loss: 0.2686 - val_auc: 0.7954 - val_binary_accuracy: 0.9044 - val_loss: 0.2588\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9047 - loss: 0.2667 - val_auc: 0.7974 - val_binary_accuracy: 0.9085 - val_loss: 0.2572\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9078 - loss: 0.2652 - val_auc: 0.8014 - val_binary_accuracy: 0.9093 - val_loss: 0.2560\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8041 - val_binary_accuracy: 0.9093 - val_loss: 0.2548\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9094 - loss: 0.2625 - val_auc: 0.8067 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9094 - loss: 0.2615 - val_auc: 0.8085 - val_binary_accuracy: 0.9100 - val_loss: 0.2525\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9096 - loss: 0.2606 - val_auc: 0.8098 - val_binary_accuracy: 0.9103 - val_loss: 0.2516\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8184 - binary_accuracy: 0.9086 - loss: 0.2501\n",
            "Fold 5 Metrics: Loss = 0.2516, Accuracy = 0.9103, AUC = 0.8098\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2566\n",
            "Average Accuracy: 0.9096\n",
            "Average AUC: 0.8044\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 3, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6540 - binary_accuracy: 0.9069 - loss: 0.3076 - val_auc: 0.7724 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9071 - loss: 0.2598 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9089 - loss: 0.2558 - val_auc: 0.7864 - val_binary_accuracy: 0.9051 - val_loss: 0.2639\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9105 - loss: 0.2528 - val_auc: 0.7896 - val_binary_accuracy: 0.9068 - val_loss: 0.2623\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9116 - loss: 0.2507 - val_auc: 0.7923 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9119 - loss: 0.2493 - val_auc: 0.7935 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9126 - loss: 0.2482 - val_auc: 0.7942 - val_binary_accuracy: 0.9084 - val_loss: 0.2594\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9125 - loss: 0.2474 - val_auc: 0.7944 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8133 - binary_accuracy: 0.9127 - loss: 0.2466 - val_auc: 0.7948 - val_binary_accuracy: 0.9088 - val_loss: 0.2588\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8141 - binary_accuracy: 0.9129 - loss: 0.2461 - val_auc: 0.7951 - val_binary_accuracy: 0.9085 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7937 - binary_accuracy: 0.9122 - loss: 0.2515\n",
            "Fold 1 Metrics: Loss = 0.2587, Accuracy = 0.9085, AUC = 0.7951\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6455 - binary_accuracy: 0.9029 - loss: 0.3099 - val_auc: 0.7958 - val_binary_accuracy: 0.9042 - val_loss: 0.2653\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9040 - loss: 0.2706 - val_auc: 0.8024 - val_binary_accuracy: 0.9053 - val_loss: 0.2601\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9055 - loss: 0.2660 - val_auc: 0.8055 - val_binary_accuracy: 0.9065 - val_loss: 0.2584\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9069 - loss: 0.2634 - val_auc: 0.8074 - val_binary_accuracy: 0.9072 - val_loss: 0.2561\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8087 - val_binary_accuracy: 0.9087 - val_loss: 0.2550\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9082 - loss: 0.2602 - val_auc: 0.8090 - val_binary_accuracy: 0.9088 - val_loss: 0.2547\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9082 - loss: 0.2594 - val_auc: 0.8096 - val_binary_accuracy: 0.9088 - val_loss: 0.2548\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9085 - loss: 0.2587 - val_auc: 0.8089 - val_binary_accuracy: 0.9087 - val_loss: 0.2550\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9085 - loss: 0.2582 - val_auc: 0.8093 - val_binary_accuracy: 0.9087 - val_loss: 0.2549\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9087 - loss: 0.2578 - val_auc: 0.8095 - val_binary_accuracy: 0.9088 - val_loss: 0.2548\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8161 - binary_accuracy: 0.9127 - loss: 0.2442\n",
            "Fold 2 Metrics: Loss = 0.2548, Accuracy = 0.9088, AUC = 0.8095\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6080 - binary_accuracy: 0.8568 - loss: 0.3631 - val_auc: 0.7791 - val_binary_accuracy: 0.9042 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9053 - loss: 0.2690 - val_auc: 0.7862 - val_binary_accuracy: 0.9050 - val_loss: 0.2660\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9073 - loss: 0.2666 - val_auc: 0.7899 - val_binary_accuracy: 0.9088 - val_loss: 0.2636\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9081 - loss: 0.2650 - val_auc: 0.7936 - val_binary_accuracy: 0.9096 - val_loss: 0.2615\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.7955 - val_binary_accuracy: 0.9103 - val_loss: 0.2599\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9090 - loss: 0.2633 - val_auc: 0.7979 - val_binary_accuracy: 0.9107 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9094 - loss: 0.2626 - val_auc: 0.7990 - val_binary_accuracy: 0.9109 - val_loss: 0.2578\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9095 - loss: 0.2619 - val_auc: 0.8009 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9096 - loss: 0.2613 - val_auc: 0.8020 - val_binary_accuracy: 0.9115 - val_loss: 0.2565\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.8031 - val_binary_accuracy: 0.9115 - val_loss: 0.2560\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9134 - loss: 0.2566\n",
            "Fold 3 Metrics: Loss = 0.2560, Accuracy = 0.9115, AUC = 0.8031\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5836 - binary_accuracy: 0.8179 - loss: 0.4140 - val_auc: 0.7830 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9047 - loss: 0.2675 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9065 - loss: 0.2640 - val_auc: 0.7958 - val_binary_accuracy: 0.9064 - val_loss: 0.2612\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2618 - val_auc: 0.7993 - val_binary_accuracy: 0.9088 - val_loss: 0.2591\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9094 - loss: 0.2601 - val_auc: 0.8026 - val_binary_accuracy: 0.9091 - val_loss: 0.2571\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9103 - loss: 0.2588 - val_auc: 0.8045 - val_binary_accuracy: 0.9095 - val_loss: 0.2560\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9107 - loss: 0.2580 - val_auc: 0.8057 - val_binary_accuracy: 0.9094 - val_loss: 0.2554\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9108 - loss: 0.2573 - val_auc: 0.8067 - val_binary_accuracy: 0.9098 - val_loss: 0.2551\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.8079 - val_binary_accuracy: 0.9097 - val_loss: 0.2547\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9115 - loss: 0.2564 - val_auc: 0.8084 - val_binary_accuracy: 0.9095 - val_loss: 0.2544\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7896 - binary_accuracy: 0.9085 - loss: 0.2608\n",
            "Fold 4 Metrics: Loss = 0.2544, Accuracy = 0.9095, AUC = 0.8084\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6257 - binary_accuracy: 0.9040 - loss: 0.3208 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9043 - loss: 0.2727 - val_auc: 0.7930 - val_binary_accuracy: 0.9079 - val_loss: 0.2598\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9061 - loss: 0.2698 - val_auc: 0.7960 - val_binary_accuracy: 0.9081 - val_loss: 0.2577\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9084 - loss: 0.2675 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2560\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9086 - loss: 0.2656 - val_auc: 0.8022 - val_binary_accuracy: 0.9094 - val_loss: 0.2547\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9092 - loss: 0.2641 - val_auc: 0.8050 - val_binary_accuracy: 0.9100 - val_loss: 0.2536\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9092 - loss: 0.2628 - val_auc: 0.8059 - val_binary_accuracy: 0.9106 - val_loss: 0.2528\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9094 - loss: 0.2619 - val_auc: 0.8069 - val_binary_accuracy: 0.9107 - val_loss: 0.2521\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9095 - loss: 0.2611 - val_auc: 0.8078 - val_binary_accuracy: 0.9113 - val_loss: 0.2516\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8084 - val_binary_accuracy: 0.9115 - val_loss: 0.2513\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9096 - loss: 0.2489\n",
            "Fold 5 Metrics: Loss = 0.2513, Accuracy = 0.9115, AUC = 0.8084\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2551\n",
            "Average Accuracy: 0.9100\n",
            "Average AUC: 0.8049\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 3, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6561 - binary_accuracy: 0.8901 - loss: 0.3053 - val_auc: 0.7742 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9076 - loss: 0.2608 - val_auc: 0.7809 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9097 - loss: 0.2570 - val_auc: 0.7871 - val_binary_accuracy: 0.9054 - val_loss: 0.2666\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9108 - loss: 0.2539 - val_auc: 0.7910 - val_binary_accuracy: 0.9069 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8040 - binary_accuracy: 0.9117 - loss: 0.2515 - val_auc: 0.7933 - val_binary_accuracy: 0.9075 - val_loss: 0.2631\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9119 - loss: 0.2498 - val_auc: 0.7942 - val_binary_accuracy: 0.9081 - val_loss: 0.2620\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8095 - binary_accuracy: 0.9125 - loss: 0.2486 - val_auc: 0.7946 - val_binary_accuracy: 0.9087 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8115 - binary_accuracy: 0.9128 - loss: 0.2476 - val_auc: 0.7958 - val_binary_accuracy: 0.9087 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8130 - binary_accuracy: 0.9132 - loss: 0.2468 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2593\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8140 - binary_accuracy: 0.9131 - loss: 0.2462 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2589\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7956 - binary_accuracy: 0.9118 - loss: 0.2508\n",
            "Fold 1 Metrics: Loss = 0.2589, Accuracy = 0.9084, AUC = 0.7962\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6743 - binary_accuracy: 0.9031 - loss: 0.3031 - val_auc: 0.7991 - val_binary_accuracy: 0.9042 - val_loss: 0.2653\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9043 - loss: 0.2697 - val_auc: 0.8052 - val_binary_accuracy: 0.9060 - val_loss: 0.2627\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9065 - loss: 0.2656 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2609\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9079 - loss: 0.2630 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2599\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8083 - val_binary_accuracy: 0.9090 - val_loss: 0.2589\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7987 - binary_accuracy: 0.9082 - loss: 0.2606 - val_auc: 0.8086 - val_binary_accuracy: 0.9093 - val_loss: 0.2580\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8008 - binary_accuracy: 0.9084 - loss: 0.2599 - val_auc: 0.8092 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9083 - loss: 0.2593 - val_auc: 0.8100 - val_binary_accuracy: 0.9094 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9083 - loss: 0.2587 - val_auc: 0.8103 - val_binary_accuracy: 0.9093 - val_loss: 0.2555\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9083 - loss: 0.2583 - val_auc: 0.8105 - val_binary_accuracy: 0.9093 - val_loss: 0.2550\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9124 - loss: 0.2453\n",
            "Fold 2 Metrics: Loss = 0.2550, Accuracy = 0.9093, AUC = 0.8105\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6393 - binary_accuracy: 0.8865 - loss: 0.3228 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7624 - binary_accuracy: 0.9060 - loss: 0.2722 - val_auc: 0.7872 - val_binary_accuracy: 0.9073 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9076 - loss: 0.2690 - val_auc: 0.7918 - val_binary_accuracy: 0.9102 - val_loss: 0.2628\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9085 - loss: 0.2667 - val_auc: 0.7959 - val_binary_accuracy: 0.9110 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9090 - loss: 0.2650 - val_auc: 0.7991 - val_binary_accuracy: 0.9113 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9093 - loss: 0.2638 - val_auc: 0.8011 - val_binary_accuracy: 0.9113 - val_loss: 0.2582\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9094 - loss: 0.2629 - val_auc: 0.8033 - val_binary_accuracy: 0.9113 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9099 - loss: 0.2621 - val_auc: 0.8050 - val_binary_accuracy: 0.9115 - val_loss: 0.2563\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9100 - loss: 0.2615 - val_auc: 0.8059 - val_binary_accuracy: 0.9118 - val_loss: 0.2557\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9098 - loss: 0.2609 - val_auc: 0.8069 - val_binary_accuracy: 0.9115 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7990 - binary_accuracy: 0.9130 - loss: 0.2559\n",
            "Fold 3 Metrics: Loss = 0.2552, Accuracy = 0.9115, AUC = 0.8069\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6251 - binary_accuracy: 0.8866 - loss: 0.3383 - val_auc: 0.7882 - val_binary_accuracy: 0.9051 - val_loss: 0.2648\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9059 - loss: 0.2676 - val_auc: 0.7959 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9081 - loss: 0.2646 - val_auc: 0.8012 - val_binary_accuracy: 0.9085 - val_loss: 0.2582\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9090 - loss: 0.2622 - val_auc: 0.8046 - val_binary_accuracy: 0.9085 - val_loss: 0.2566\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9100 - loss: 0.2605 - val_auc: 0.8065 - val_binary_accuracy: 0.9087 - val_loss: 0.2557\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9100 - loss: 0.2595 - val_auc: 0.8072 - val_binary_accuracy: 0.9085 - val_loss: 0.2551\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9104 - loss: 0.2587 - val_auc: 0.8085 - val_binary_accuracy: 0.9093 - val_loss: 0.2547\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9107 - loss: 0.2580 - val_auc: 0.8092 - val_binary_accuracy: 0.9093 - val_loss: 0.2544\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9107 - loss: 0.2575 - val_auc: 0.8100 - val_binary_accuracy: 0.9091 - val_loss: 0.2542\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7954 - binary_accuracy: 0.9109 - loss: 0.2571 - val_auc: 0.8101 - val_binary_accuracy: 0.9093 - val_loss: 0.2540\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7920 - binary_accuracy: 0.9086 - loss: 0.2607\n",
            "Fold 4 Metrics: Loss = 0.2540, Accuracy = 0.9093, AUC = 0.8101\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6250 - binary_accuracy: 0.8698 - loss: 0.3534 - val_auc: 0.7891 - val_binary_accuracy: 0.9075 - val_loss: 0.2658\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9045 - loss: 0.2732 - val_auc: 0.7945 - val_binary_accuracy: 0.9082 - val_loss: 0.2639\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9057 - loss: 0.2704 - val_auc: 0.7990 - val_binary_accuracy: 0.9081 - val_loss: 0.2625\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9074 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9085 - val_loss: 0.2616\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9082 - loss: 0.2662 - val_auc: 0.8042 - val_binary_accuracy: 0.9087 - val_loss: 0.2600\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9085 - loss: 0.2648 - val_auc: 0.8050 - val_binary_accuracy: 0.9101 - val_loss: 0.2582\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9087 - loss: 0.2638 - val_auc: 0.8062 - val_binary_accuracy: 0.9103 - val_loss: 0.2564\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9092 - loss: 0.2630 - val_auc: 0.8072 - val_binary_accuracy: 0.9115 - val_loss: 0.2547\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9092 - loss: 0.2622 - val_auc: 0.8072 - val_binary_accuracy: 0.9121 - val_loss: 0.2537\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9096 - loss: 0.2615 - val_auc: 0.8083 - val_binary_accuracy: 0.9116 - val_loss: 0.2527\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9095 - loss: 0.2509\n",
            "Fold 5 Metrics: Loss = 0.2527, Accuracy = 0.9116, AUC = 0.8083\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2552\n",
            "Average Accuracy: 0.9100\n",
            "Average AUC: 0.8064\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 4, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4969 - binary_accuracy: 0.3356 - loss: 1.0198 - val_auc: 0.4997 - val_binary_accuracy: 0.9044 - val_loss: 0.3583\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4961 - binary_accuracy: 0.9069 - loss: 0.3372 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3189\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5076 - binary_accuracy: 0.9069 - loss: 0.3124 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3155\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5098 - binary_accuracy: 0.9069 - loss: 0.3099 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3151\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5093 - binary_accuracy: 0.9069 - loss: 0.3095 - val_auc: 0.4999 - val_binary_accuracy: 0.9044 - val_loss: 0.3150\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5691 - binary_accuracy: 0.9069 - loss: 0.3093 - val_auc: 0.4998 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5973 - binary_accuracy: 0.9069 - loss: 0.3088 - val_auc: 0.7049 - val_binary_accuracy: 0.9044 - val_loss: 0.3133\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7355 - binary_accuracy: 0.9069 - loss: 0.3064 - val_auc: 0.7475 - val_binary_accuracy: 0.9044 - val_loss: 0.3039\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9069 - loss: 0.2901 - val_auc: 0.7627 - val_binary_accuracy: 0.9044 - val_loss: 0.2786\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7697 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7680 - binary_accuracy: 0.9084 - loss: 0.2622\n",
            "Fold 1 Metrics: Loss = 0.2700, Accuracy = 0.9044, AUC = 0.7697\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5046 - binary_accuracy: 0.9029 - loss: 0.3812 - val_auc: 0.6797 - val_binary_accuracy: 0.9042 - val_loss: 0.3142\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6695 - binary_accuracy: 0.9029 - loss: 0.3158 - val_auc: 0.7519 - val_binary_accuracy: 0.9042 - val_loss: 0.3039\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7421 - binary_accuracy: 0.9029 - loss: 0.2995 - val_auc: 0.7911 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2751 - val_auc: 0.7948 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9029 - loss: 0.2696 - val_auc: 0.8021 - val_binary_accuracy: 0.9042 - val_loss: 0.2644\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9029 - loss: 0.2673 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2635\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9029 - loss: 0.2657 - val_auc: 0.8057 - val_binary_accuracy: 0.9042 - val_loss: 0.2629\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9030 - loss: 0.2643 - val_auc: 0.8063 - val_binary_accuracy: 0.9042 - val_loss: 0.2622\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7975 - binary_accuracy: 0.9047 - loss: 0.2632 - val_auc: 0.8064 - val_binary_accuracy: 0.9051 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9061 - loss: 0.2622 - val_auc: 0.8080 - val_binary_accuracy: 0.9056 - val_loss: 0.2609\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8113 - binary_accuracy: 0.9099 - loss: 0.2505\n",
            "Fold 2 Metrics: Loss = 0.2609, Accuracy = 0.9056, AUC = 0.8080\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5037 - binary_accuracy: 0.8728 - loss: 0.4521 - val_auc: 0.6925 - val_binary_accuracy: 0.9042 - val_loss: 0.3140\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6814 - binary_accuracy: 0.9051 - loss: 0.3107 - val_auc: 0.7450 - val_binary_accuracy: 0.9042 - val_loss: 0.3009\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7463 - binary_accuracy: 0.9051 - loss: 0.2936 - val_auc: 0.7699 - val_binary_accuracy: 0.9042 - val_loss: 0.2784\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9051 - loss: 0.2740 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9051 - loss: 0.2682 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7799 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7802 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9051 - loss: 0.2645 - val_auc: 0.7831 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9051 - loss: 0.2639 - val_auc: 0.7844 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7804 - binary_accuracy: 0.9046 - loss: 0.2672\n",
            "Fold 3 Metrics: Loss = 0.2674, Accuracy = 0.9042, AUC = 0.7844\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - auc: 0.4974 - binary_accuracy: 0.6128 - loss: 0.6017 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3166\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4971 - binary_accuracy: 0.9047 - loss: 0.3151 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3153\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5004 - binary_accuracy: 0.9047 - loss: 0.3146 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3152\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5160 - binary_accuracy: 0.9047 - loss: 0.3144 - val_auc: 0.6853 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6210 - binary_accuracy: 0.9047 - loss: 0.3129 - val_auc: 0.7450 - val_binary_accuracy: 0.9044 - val_loss: 0.3091\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7349 - binary_accuracy: 0.9047 - loss: 0.3057 - val_auc: 0.7712 - val_binary_accuracy: 0.9044 - val_loss: 0.2949\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7509 - binary_accuracy: 0.9047 - loss: 0.2897 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2800\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7627 - binary_accuracy: 0.9047 - loss: 0.2754 - val_auc: 0.7768 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9047 - loss: 0.2701 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2726\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9047 - loss: 0.2681 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7635 - binary_accuracy: 0.9049 - loss: 0.2743\n",
            "Fold 4 Metrics: Loss = 0.2712, Accuracy = 0.9044, AUC = 0.7828\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5041 - binary_accuracy: 0.7764 - loss: 0.4915 - val_auc: 0.6729 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5882 - binary_accuracy: 0.9040 - loss: 0.3149 - val_auc: 0.7296 - val_binary_accuracy: 0.9044 - val_loss: 0.3122\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7166 - binary_accuracy: 0.9040 - loss: 0.3122 - val_auc: 0.7463 - val_binary_accuracy: 0.9044 - val_loss: 0.3044\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7387 - binary_accuracy: 0.9040 - loss: 0.3013 - val_auc: 0.7674 - val_binary_accuracy: 0.9044 - val_loss: 0.2817\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7552 - binary_accuracy: 0.9040 - loss: 0.2832 - val_auc: 0.7707 - val_binary_accuracy: 0.9044 - val_loss: 0.2714\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7643 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9040 - loss: 0.2729 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2655\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9040 - loss: 0.2717 - val_auc: 0.7822 - val_binary_accuracy: 0.9044 - val_loss: 0.2646\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9040 - loss: 0.2710 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2640\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9040 - loss: 0.2705 - val_auc: 0.7897 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8000 - binary_accuracy: 0.9013 - loss: 0.2621\n",
            "Fold 5 Metrics: Loss = 0.2635, Accuracy = 0.9044, AUC = 0.7897\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2666\n",
            "Average Accuracy: 0.9046\n",
            "Average AUC: 0.7869\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 4, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4990 - binary_accuracy: 0.7259 - loss: 0.4959 - val_auc: 0.6752 - val_binary_accuracy: 0.9044 - val_loss: 0.3144\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6313 - binary_accuracy: 0.9069 - loss: 0.3070 - val_auc: 0.7469 - val_binary_accuracy: 0.9044 - val_loss: 0.2975\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9069 - loss: 0.2813 - val_auc: 0.7646 - val_binary_accuracy: 0.9044 - val_loss: 0.2733\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9069 - loss: 0.2623 - val_auc: 0.7768 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9069 - loss: 0.2584 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9069 - loss: 0.2567 - val_auc: 0.7826 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7997 - binary_accuracy: 0.9069 - loss: 0.2556 - val_auc: 0.7866 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9069 - loss: 0.2546 - val_auc: 0.7901 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9070 - loss: 0.2536 - val_auc: 0.7907 - val_binary_accuracy: 0.9044 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9078 - loss: 0.2525 - val_auc: 0.7926 - val_binary_accuracy: 0.9069 - val_loss: 0.2607\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7934 - binary_accuracy: 0.9111 - loss: 0.2528\n",
            "Fold 1 Metrics: Loss = 0.2607, Accuracy = 0.9069, AUC = 0.7926\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5150 - binary_accuracy: 0.9029 - loss: 0.3443 - val_auc: 0.7261 - val_binary_accuracy: 0.9042 - val_loss: 0.3104\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7228 - binary_accuracy: 0.9029 - loss: 0.3022 - val_auc: 0.7919 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9029 - loss: 0.2716 - val_auc: 0.8001 - val_binary_accuracy: 0.9042 - val_loss: 0.2641\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9029 - loss: 0.2686 - val_auc: 0.8026 - val_binary_accuracy: 0.9042 - val_loss: 0.2631\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9037 - loss: 0.2671 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9046 - loss: 0.2655 - val_auc: 0.8045 - val_binary_accuracy: 0.9056 - val_loss: 0.2614\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9066 - loss: 0.2639 - val_auc: 0.8050 - val_binary_accuracy: 0.9063 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9069 - loss: 0.2624 - val_auc: 0.8069 - val_binary_accuracy: 0.9069 - val_loss: 0.2594\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9075 - loss: 0.2612 - val_auc: 0.8076 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9078 - loss: 0.2604 - val_auc: 0.8076 - val_binary_accuracy: 0.9082 - val_loss: 0.2588\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8108 - binary_accuracy: 0.9118 - loss: 0.2494\n",
            "Fold 2 Metrics: Loss = 0.2588, Accuracy = 0.9082, AUC = 0.8076\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5068 - binary_accuracy: 0.8865 - loss: 0.3881 - val_auc: 0.7022 - val_binary_accuracy: 0.9042 - val_loss: 0.3133\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6946 - binary_accuracy: 0.9051 - loss: 0.3082 - val_auc: 0.7682 - val_binary_accuracy: 0.9042 - val_loss: 0.2854\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7616 - binary_accuracy: 0.9051 - loss: 0.2770 - val_auc: 0.7730 - val_binary_accuracy: 0.9042 - val_loss: 0.2713\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9051 - loss: 0.2686 - val_auc: 0.7775 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7823 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9051 - loss: 0.2659 - val_auc: 0.7843 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9059 - loss: 0.2647 - val_auc: 0.7862 - val_binary_accuracy: 0.9082 - val_loss: 0.2654\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9079 - loss: 0.2636 - val_auc: 0.7873 - val_binary_accuracy: 0.9097 - val_loss: 0.2646\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9084 - loss: 0.2631 - val_auc: 0.7884 - val_binary_accuracy: 0.9102 - val_loss: 0.2638\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7847 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.7900 - val_binary_accuracy: 0.9103 - val_loss: 0.2632\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7847 - binary_accuracy: 0.9115 - loss: 0.2633\n",
            "Fold 3 Metrics: Loss = 0.2632, Accuracy = 0.9103, AUC = 0.7900\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5048 - binary_accuracy: 0.6734 - loss: 0.5628 - val_auc: 0.7008 - val_binary_accuracy: 0.9044 - val_loss: 0.3131\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6866 - binary_accuracy: 0.9047 - loss: 0.3106 - val_auc: 0.7548 - val_binary_accuracy: 0.9044 - val_loss: 0.2990\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7447 - binary_accuracy: 0.9047 - loss: 0.2920 - val_auc: 0.7681 - val_binary_accuracy: 0.9044 - val_loss: 0.2774\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7653 - binary_accuracy: 0.9047 - loss: 0.2733 - val_auc: 0.7790 - val_binary_accuracy: 0.9044 - val_loss: 0.2729\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9047 - loss: 0.2688 - val_auc: 0.7789 - val_binary_accuracy: 0.9044 - val_loss: 0.2734\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9047 - loss: 0.2679 - val_auc: 0.7866 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9047 - loss: 0.2674 - val_auc: 0.7851 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9047 - loss: 0.2665 - val_auc: 0.7878 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9047 - loss: 0.2658 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9047 - loss: 0.2650 - val_auc: 0.7924 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7716 - binary_accuracy: 0.9049 - loss: 0.2734\n",
            "Fold 4 Metrics: Loss = 0.2680, Accuracy = 0.9044, AUC = 0.7924\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5250 - binary_accuracy: 0.9040 - loss: 0.3465 - val_auc: 0.7361 - val_binary_accuracy: 0.9044 - val_loss: 0.3061\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7318 - binary_accuracy: 0.9040 - loss: 0.2972 - val_auc: 0.7815 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7854 - val_binary_accuracy: 0.9044 - val_loss: 0.2632\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9040 - loss: 0.2719 - val_auc: 0.7871 - val_binary_accuracy: 0.9044 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9040 - loss: 0.2690 - val_auc: 0.7925 - val_binary_accuracy: 0.9044 - val_loss: 0.2590\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9041 - loss: 0.2673 - val_auc: 0.7960 - val_binary_accuracy: 0.9072 - val_loss: 0.2575\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.7983 - val_binary_accuracy: 0.9093 - val_loss: 0.2560\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2642 - val_auc: 0.8011 - val_binary_accuracy: 0.9100 - val_loss: 0.2547\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9087 - loss: 0.2630 - val_auc: 0.8025 - val_binary_accuracy: 0.9107 - val_loss: 0.2537\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8133 - binary_accuracy: 0.9093 - loss: 0.2513\n",
            "Fold 5 Metrics: Loss = 0.2537, Accuracy = 0.9107, AUC = 0.8025\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2609\n",
            "Average Accuracy: 0.9081\n",
            "Average AUC: 0.7970\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 4, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5312 - binary_accuracy: 0.8037 - loss: 0.4185 - val_auc: 0.7559 - val_binary_accuracy: 0.9044 - val_loss: 0.2886\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9069 - loss: 0.2722 - val_auc: 0.7699 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7748 - val_binary_accuracy: 0.9044 - val_loss: 0.2693\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9070 - loss: 0.2568 - val_auc: 0.7811 - val_binary_accuracy: 0.9044 - val_loss: 0.2661\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9078 - loss: 0.2548 - val_auc: 0.7855 - val_binary_accuracy: 0.9071 - val_loss: 0.2647\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8024 - binary_accuracy: 0.9101 - loss: 0.2532 - val_auc: 0.7873 - val_binary_accuracy: 0.9085 - val_loss: 0.2635\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9121 - loss: 0.2518 - val_auc: 0.7886 - val_binary_accuracy: 0.9096 - val_loss: 0.2626\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8066 - binary_accuracy: 0.9125 - loss: 0.2506 - val_auc: 0.7890 - val_binary_accuracy: 0.9100 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9131 - loss: 0.2495 - val_auc: 0.7893 - val_binary_accuracy: 0.9099 - val_loss: 0.2610\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7880 - binary_accuracy: 0.9131 - loss: 0.2545\n",
            "Fold 1 Metrics: Loss = 0.2610, Accuracy = 0.9099, AUC = 0.7893\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5575 - binary_accuracy: 0.9029 - loss: 0.3253 - val_auc: 0.7887 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9029 - loss: 0.2727 - val_auc: 0.8010 - val_binary_accuracy: 0.9042 - val_loss: 0.2620\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9036 - loss: 0.2681 - val_auc: 0.8052 - val_binary_accuracy: 0.9042 - val_loss: 0.2599\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9044 - loss: 0.2652 - val_auc: 0.8097 - val_binary_accuracy: 0.9051 - val_loss: 0.2574\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9052 - loss: 0.2629 - val_auc: 0.8098 - val_binary_accuracy: 0.9065 - val_loss: 0.2565\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9065 - loss: 0.2613 - val_auc: 0.8099 - val_binary_accuracy: 0.9071 - val_loss: 0.2560\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9067 - loss: 0.2602 - val_auc: 0.8104 - val_binary_accuracy: 0.9076 - val_loss: 0.2560\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9078 - loss: 0.2595 - val_auc: 0.8109 - val_binary_accuracy: 0.9084 - val_loss: 0.2557\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9073 - loss: 0.2589 - val_auc: 0.8114 - val_binary_accuracy: 0.9087 - val_loss: 0.2561\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8035 - binary_accuracy: 0.9075 - loss: 0.2584 - val_auc: 0.8107 - val_binary_accuracy: 0.9090 - val_loss: 0.2563\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8160 - binary_accuracy: 0.9130 - loss: 0.2456\n",
            "Fold 2 Metrics: Loss = 0.2563, Accuracy = 0.9090, AUC = 0.8107\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5587 - binary_accuracy: 0.8865 - loss: 0.3486 - val_auc: 0.7627 - val_binary_accuracy: 0.9042 - val_loss: 0.2795\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9051 - loss: 0.2726 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2690\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9051 - loss: 0.2673 - val_auc: 0.7875 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9052 - loss: 0.2654 - val_auc: 0.7923 - val_binary_accuracy: 0.9059 - val_loss: 0.2640\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9061 - loss: 0.2636 - val_auc: 0.7946 - val_binary_accuracy: 0.9097 - val_loss: 0.2620\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9085 - loss: 0.2626 - val_auc: 0.7963 - val_binary_accuracy: 0.9100 - val_loss: 0.2603\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9089 - loss: 0.2616 - val_auc: 0.7992 - val_binary_accuracy: 0.9102 - val_loss: 0.2591\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9091 - loss: 0.2610 - val_auc: 0.7993 - val_binary_accuracy: 0.9115 - val_loss: 0.2584\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9098 - loss: 0.2607 - val_auc: 0.7996 - val_binary_accuracy: 0.9113 - val_loss: 0.2578\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9101 - loss: 0.2599 - val_auc: 0.8005 - val_binary_accuracy: 0.9110 - val_loss: 0.2574\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7935 - binary_accuracy: 0.9123 - loss: 0.2578\n",
            "Fold 3 Metrics: Loss = 0.2574, Accuracy = 0.9110, AUC = 0.8005\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5406 - binary_accuracy: 0.9043 - loss: 0.3519 - val_auc: 0.7755 - val_binary_accuracy: 0.9044 - val_loss: 0.2751\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9047 - loss: 0.2710 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7918 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9060 - loss: 0.2643 - val_auc: 0.7959 - val_binary_accuracy: 0.9072 - val_loss: 0.2626\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9085 - loss: 0.2623 - val_auc: 0.7982 - val_binary_accuracy: 0.9076 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9097 - loss: 0.2608 - val_auc: 0.8011 - val_binary_accuracy: 0.9085 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9104 - loss: 0.2596 - val_auc: 0.8037 - val_binary_accuracy: 0.9097 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9110 - loss: 0.2586 - val_auc: 0.8063 - val_binary_accuracy: 0.9104 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9112 - loss: 0.2579 - val_auc: 0.8073 - val_binary_accuracy: 0.9106 - val_loss: 0.2554\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9114 - loss: 0.2573 - val_auc: 0.8079 - val_binary_accuracy: 0.9104 - val_loss: 0.2549\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7903 - binary_accuracy: 0.9099 - loss: 0.2603\n",
            "Fold 4 Metrics: Loss = 0.2549, Accuracy = 0.9104, AUC = 0.8079\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5695 - binary_accuracy: 0.9040 - loss: 0.3262 - val_auc: 0.7827 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.7938 - val_binary_accuracy: 0.9044 - val_loss: 0.2604\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9041 - loss: 0.2694 - val_auc: 0.7970 - val_binary_accuracy: 0.9073 - val_loss: 0.2585\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9066 - loss: 0.2670 - val_auc: 0.7983 - val_binary_accuracy: 0.9081 - val_loss: 0.2575\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9079 - loss: 0.2656 - val_auc: 0.8006 - val_binary_accuracy: 0.9094 - val_loss: 0.2557\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8025 - val_binary_accuracy: 0.9095 - val_loss: 0.2547\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8033 - val_binary_accuracy: 0.9104 - val_loss: 0.2539\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9089 - loss: 0.2623 - val_auc: 0.8048 - val_binary_accuracy: 0.9107 - val_loss: 0.2533\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9088 - loss: 0.2617 - val_auc: 0.8058 - val_binary_accuracy: 0.9109 - val_loss: 0.2529\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9087 - loss: 0.2611 - val_auc: 0.8069 - val_binary_accuracy: 0.9109 - val_loss: 0.2526\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8163 - binary_accuracy: 0.9092 - loss: 0.2503\n",
            "Fold 5 Metrics: Loss = 0.2526, Accuracy = 0.9109, AUC = 0.8069\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2565\n",
            "Average Accuracy: 0.9102\n",
            "Average AUC: 0.8031\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 4, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6197 - binary_accuracy: 0.9069 - loss: 0.3147 - val_auc: 0.7702 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9069 - loss: 0.2611 - val_auc: 0.7781 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9071 - loss: 0.2578 - val_auc: 0.7843 - val_binary_accuracy: 0.9044 - val_loss: 0.2651\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9092 - loss: 0.2548 - val_auc: 0.7886 - val_binary_accuracy: 0.9062 - val_loss: 0.2639\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8041 - binary_accuracy: 0.9116 - loss: 0.2522 - val_auc: 0.7908 - val_binary_accuracy: 0.9081 - val_loss: 0.2624\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8073 - binary_accuracy: 0.9117 - loss: 0.2502 - val_auc: 0.7922 - val_binary_accuracy: 0.9085 - val_loss: 0.2612\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9122 - loss: 0.2488 - val_auc: 0.7934 - val_binary_accuracy: 0.9084 - val_loss: 0.2602\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8111 - binary_accuracy: 0.9129 - loss: 0.2479 - val_auc: 0.7930 - val_binary_accuracy: 0.9082 - val_loss: 0.2595\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9133 - loss: 0.2472 - val_auc: 0.7943 - val_binary_accuracy: 0.9084 - val_loss: 0.2590\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8130 - binary_accuracy: 0.9133 - loss: 0.2466 - val_auc: 0.7937 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7931 - binary_accuracy: 0.9124 - loss: 0.2511\n",
            "Fold 1 Metrics: Loss = 0.2588, Accuracy = 0.9085, AUC = 0.7937\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5774 - binary_accuracy: 0.8554 - loss: 0.3685 - val_auc: 0.7944 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2710 - val_auc: 0.8030 - val_binary_accuracy: 0.9042 - val_loss: 0.2600\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9040 - loss: 0.2665 - val_auc: 0.8060 - val_binary_accuracy: 0.9050 - val_loss: 0.2584\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9055 - loss: 0.2638 - val_auc: 0.8064 - val_binary_accuracy: 0.9066 - val_loss: 0.2574\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9068 - loss: 0.2621 - val_auc: 0.8075 - val_binary_accuracy: 0.9075 - val_loss: 0.2561\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9075 - loss: 0.2608 - val_auc: 0.8077 - val_binary_accuracy: 0.9082 - val_loss: 0.2557\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9075 - loss: 0.2600 - val_auc: 0.8078 - val_binary_accuracy: 0.9081 - val_loss: 0.2555\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9077 - loss: 0.2593 - val_auc: 0.8079 - val_binary_accuracy: 0.9081 - val_loss: 0.2552\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8031 - binary_accuracy: 0.9082 - loss: 0.2587 - val_auc: 0.8088 - val_binary_accuracy: 0.9084 - val_loss: 0.2550\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9080 - loss: 0.2582 - val_auc: 0.8093 - val_binary_accuracy: 0.9085 - val_loss: 0.2549\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9118 - loss: 0.2445\n",
            "Fold 2 Metrics: Loss = 0.2549, Accuracy = 0.9085, AUC = 0.8093\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6086 - binary_accuracy: 0.9051 - loss: 0.3213 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9051 - loss: 0.2719 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9057 - loss: 0.2687 - val_auc: 0.7903 - val_binary_accuracy: 0.9060 - val_loss: 0.2641\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9075 - loss: 0.2669 - val_auc: 0.7944 - val_binary_accuracy: 0.9093 - val_loss: 0.2616\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9084 - loss: 0.2655 - val_auc: 0.7978 - val_binary_accuracy: 0.9094 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9088 - loss: 0.2644 - val_auc: 0.8006 - val_binary_accuracy: 0.9102 - val_loss: 0.2583\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9094 - loss: 0.2633 - val_auc: 0.8016 - val_binary_accuracy: 0.9109 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9098 - loss: 0.2625 - val_auc: 0.8036 - val_binary_accuracy: 0.9107 - val_loss: 0.2564\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9096 - loss: 0.2618 - val_auc: 0.8048 - val_binary_accuracy: 0.9109 - val_loss: 0.2558\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8052 - val_binary_accuracy: 0.9112 - val_loss: 0.2554\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7985 - binary_accuracy: 0.9124 - loss: 0.2559\n",
            "Fold 3 Metrics: Loss = 0.2554, Accuracy = 0.9112, AUC = 0.8052\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5807 - binary_accuracy: 0.9047 - loss: 0.3278 - val_auc: 0.7863 - val_binary_accuracy: 0.9044 - val_loss: 0.2667\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9050 - loss: 0.2676 - val_auc: 0.7948 - val_binary_accuracy: 0.9057 - val_loss: 0.2624\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9071 - loss: 0.2640 - val_auc: 0.7995 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9095 - loss: 0.2618 - val_auc: 0.8028 - val_binary_accuracy: 0.9097 - val_loss: 0.2571\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9104 - loss: 0.2604 - val_auc: 0.8042 - val_binary_accuracy: 0.9097 - val_loss: 0.2562\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9106 - loss: 0.2595 - val_auc: 0.8053 - val_binary_accuracy: 0.9095 - val_loss: 0.2558\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9108 - loss: 0.2588 - val_auc: 0.8070 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9110 - loss: 0.2582 - val_auc: 0.8077 - val_binary_accuracy: 0.9091 - val_loss: 0.2552\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9112 - loss: 0.2578 - val_auc: 0.8083 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9113 - loss: 0.2574 - val_auc: 0.8093 - val_binary_accuracy: 0.9090 - val_loss: 0.2547\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7916 - binary_accuracy: 0.9077 - loss: 0.2608\n",
            "Fold 4 Metrics: Loss = 0.2547, Accuracy = 0.9090, AUC = 0.8093\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5985 - binary_accuracy: 0.9040 - loss: 0.3231 - val_auc: 0.7888 - val_binary_accuracy: 0.9044 - val_loss: 0.2640\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9041 - loss: 0.2728 - val_auc: 0.7949 - val_binary_accuracy: 0.9079 - val_loss: 0.2604\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9053 - loss: 0.2700 - val_auc: 0.7979 - val_binary_accuracy: 0.9082 - val_loss: 0.2588\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9075 - loss: 0.2680 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9080 - loss: 0.2666 - val_auc: 0.8024 - val_binary_accuracy: 0.9106 - val_loss: 0.2561\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.8038 - val_binary_accuracy: 0.9104 - val_loss: 0.2549\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9088 - loss: 0.2640 - val_auc: 0.8046 - val_binary_accuracy: 0.9112 - val_loss: 0.2540\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9093 - loss: 0.2630 - val_auc: 0.8059 - val_binary_accuracy: 0.9104 - val_loss: 0.2532\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9096 - loss: 0.2621 - val_auc: 0.8061 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9093 - loss: 0.2615 - val_auc: 0.8066 - val_binary_accuracy: 0.9109 - val_loss: 0.2522\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9086 - loss: 0.2498\n",
            "Fold 5 Metrics: Loss = 0.2522, Accuracy = 0.9109, AUC = 0.8066\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2552\n",
            "Average Accuracy: 0.9096\n",
            "Average AUC: 0.8048\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 4, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6381 - binary_accuracy: 0.8901 - loss: 0.3081 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9076 - loss: 0.2585 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9098 - loss: 0.2556 - val_auc: 0.7888 - val_binary_accuracy: 0.9062 - val_loss: 0.2658\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9115 - loss: 0.2531 - val_auc: 0.7911 - val_binary_accuracy: 0.9075 - val_loss: 0.2642\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9120 - loss: 0.2511 - val_auc: 0.7925 - val_binary_accuracy: 0.9078 - val_loss: 0.2633\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8077 - binary_accuracy: 0.9122 - loss: 0.2497 - val_auc: 0.7945 - val_binary_accuracy: 0.9084 - val_loss: 0.2617\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9128 - loss: 0.2485 - val_auc: 0.7945 - val_binary_accuracy: 0.9084 - val_loss: 0.2607\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8114 - binary_accuracy: 0.9130 - loss: 0.2476 - val_auc: 0.7954 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8122 - binary_accuracy: 0.9129 - loss: 0.2470 - val_auc: 0.7955 - val_binary_accuracy: 0.9081 - val_loss: 0.2596\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7946 - binary_accuracy: 0.9114 - loss: 0.2515\n",
            "Fold 1 Metrics: Loss = 0.2596, Accuracy = 0.9081, AUC = 0.7955\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5940 - binary_accuracy: 0.8692 - loss: 0.3557 - val_auc: 0.7984 - val_binary_accuracy: 0.9042 - val_loss: 0.2655\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9033 - loss: 0.2711 - val_auc: 0.8041 - val_binary_accuracy: 0.9044 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9048 - loss: 0.2683 - val_auc: 0.8066 - val_binary_accuracy: 0.9062 - val_loss: 0.2617\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9061 - loss: 0.2657 - val_auc: 0.8072 - val_binary_accuracy: 0.9069 - val_loss: 0.2608\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8071 - val_binary_accuracy: 0.9075 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9081 - loss: 0.2622 - val_auc: 0.8075 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9085 - loss: 0.2611 - val_auc: 0.8068 - val_binary_accuracy: 0.9085 - val_loss: 0.2600\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9088 - loss: 0.2603 - val_auc: 0.8077 - val_binary_accuracy: 0.9087 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8014 - binary_accuracy: 0.9089 - loss: 0.2596 - val_auc: 0.8080 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9091 - loss: 0.2591 - val_auc: 0.8089 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9129 - loss: 0.2485\n",
            "Fold 2 Metrics: Loss = 0.2582, Accuracy = 0.9091, AUC = 0.8089\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6086 - binary_accuracy: 0.8865 - loss: 0.3291 - val_auc: 0.7805 - val_binary_accuracy: 0.9042 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9051 - loss: 0.2737 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7660 - binary_accuracy: 0.9052 - loss: 0.2709 - val_auc: 0.7893 - val_binary_accuracy: 0.9057 - val_loss: 0.2650\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7692 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.7923 - val_binary_accuracy: 0.9097 - val_loss: 0.2637\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9076 - loss: 0.2675 - val_auc: 0.7948 - val_binary_accuracy: 0.9102 - val_loss: 0.2625\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9085 - loss: 0.2661 - val_auc: 0.7970 - val_binary_accuracy: 0.9106 - val_loss: 0.2612\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9089 - loss: 0.2650 - val_auc: 0.7995 - val_binary_accuracy: 0.9110 - val_loss: 0.2600\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9093 - loss: 0.2640 - val_auc: 0.8004 - val_binary_accuracy: 0.9109 - val_loss: 0.2589\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9093 - loss: 0.2633 - val_auc: 0.8019 - val_binary_accuracy: 0.9109 - val_loss: 0.2580\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9096 - loss: 0.2628 - val_auc: 0.8033 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7952 - binary_accuracy: 0.9124 - loss: 0.2578\n",
            "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9109, AUC = 0.8033\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5841 - binary_accuracy: 0.8714 - loss: 0.3610 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7735 - binary_accuracy: 0.9055 - loss: 0.2683 - val_auc: 0.7940 - val_binary_accuracy: 0.9070 - val_loss: 0.2619\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9078 - loss: 0.2653 - val_auc: 0.7998 - val_binary_accuracy: 0.9085 - val_loss: 0.2591\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9090 - loss: 0.2630 - val_auc: 0.8024 - val_binary_accuracy: 0.9094 - val_loss: 0.2571\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9099 - loss: 0.2615 - val_auc: 0.8052 - val_binary_accuracy: 0.9082 - val_loss: 0.2561\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9099 - loss: 0.2604 - val_auc: 0.8064 - val_binary_accuracy: 0.9088 - val_loss: 0.2554\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9103 - loss: 0.2597 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2550\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9107 - loss: 0.2590 - val_auc: 0.8081 - val_binary_accuracy: 0.9090 - val_loss: 0.2547\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9108 - loss: 0.2585 - val_auc: 0.8087 - val_binary_accuracy: 0.9091 - val_loss: 0.2545\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9108 - loss: 0.2580 - val_auc: 0.8094 - val_binary_accuracy: 0.9091 - val_loss: 0.2543\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7911 - binary_accuracy: 0.9087 - loss: 0.2614\n",
            "Fold 4 Metrics: Loss = 0.2543, Accuracy = 0.9091, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6132 - binary_accuracy: 0.9040 - loss: 0.3212 - val_auc: 0.7890 - val_binary_accuracy: 0.9048 - val_loss: 0.2685\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9041 - loss: 0.2740 - val_auc: 0.7950 - val_binary_accuracy: 0.9078 - val_loss: 0.2656\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9052 - loss: 0.2709 - val_auc: 0.7987 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9073 - loss: 0.2684 - val_auc: 0.8017 - val_binary_accuracy: 0.9076 - val_loss: 0.2627\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9078 - loss: 0.2667 - val_auc: 0.8041 - val_binary_accuracy: 0.9087 - val_loss: 0.2610\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9084 - loss: 0.2653 - val_auc: 0.8053 - val_binary_accuracy: 0.9091 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9089 - loss: 0.2641 - val_auc: 0.8064 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9098 - loss: 0.2631 - val_auc: 0.8077 - val_binary_accuracy: 0.9106 - val_loss: 0.2553\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9096 - loss: 0.2622 - val_auc: 0.8074 - val_binary_accuracy: 0.9112 - val_loss: 0.2541\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9098 - loss: 0.2615 - val_auc: 0.8082 - val_binary_accuracy: 0.9113 - val_loss: 0.2531\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8169 - binary_accuracy: 0.9092 - loss: 0.2512\n",
            "Fold 5 Metrics: Loss = 0.2531, Accuracy = 0.9113, AUC = 0.8082\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2564\n",
            "Average Accuracy: 0.9097\n",
            "Average AUC: 0.8051\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 5, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4973 - binary_accuracy: 0.7440 - loss: 0.5121 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3162\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5044 - binary_accuracy: 0.9069 - loss: 0.3101 - val_auc: 0.4999 - val_binary_accuracy: 0.9044 - val_loss: 0.3150\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5662 - binary_accuracy: 0.9069 - loss: 0.3091 - val_auc: 0.7259 - val_binary_accuracy: 0.9044 - val_loss: 0.3125\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7352 - binary_accuracy: 0.9069 - loss: 0.3041 - val_auc: 0.7583 - val_binary_accuracy: 0.9044 - val_loss: 0.2982\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7614 - binary_accuracy: 0.9069 - loss: 0.2857 - val_auc: 0.7465 - val_binary_accuracy: 0.9044 - val_loss: 0.2798\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9069 - loss: 0.2678 - val_auc: 0.7755 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9069 - loss: 0.2613 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9069 - loss: 0.2595 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7960 - binary_accuracy: 0.9069 - loss: 0.2578 - val_auc: 0.7835 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9069 - loss: 0.2569 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7856 - binary_accuracy: 0.9084 - loss: 0.2585\n",
            "Fold 1 Metrics: Loss = 0.2671, Accuracy = 0.9044, AUC = 0.7839\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5018 - binary_accuracy: 0.9029 - loss: 0.4375 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3155\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5285 - binary_accuracy: 0.9029 - loss: 0.3185 - val_auc: 0.7104 - val_binary_accuracy: 0.9042 - val_loss: 0.3150\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6496 - binary_accuracy: 0.9029 - loss: 0.3174 - val_auc: 0.7353 - val_binary_accuracy: 0.9042 - val_loss: 0.3104\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7362 - binary_accuracy: 0.9029 - loss: 0.3084 - val_auc: 0.7837 - val_binary_accuracy: 0.9042 - val_loss: 0.2815\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9029 - loss: 0.2819 - val_auc: 0.7820 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7776 - binary_accuracy: 0.9029 - loss: 0.2731 - val_auc: 0.7931 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9029 - loss: 0.2711 - val_auc: 0.7961 - val_binary_accuracy: 0.9042 - val_loss: 0.2643\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9029 - loss: 0.2700 - val_auc: 0.7974 - val_binary_accuracy: 0.9042 - val_loss: 0.2632\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2689 - val_auc: 0.7995 - val_binary_accuracy: 0.9042 - val_loss: 0.2621\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9029 - loss: 0.2681 - val_auc: 0.8006 - val_binary_accuracy: 0.9042 - val_loss: 0.2611\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8018 - binary_accuracy: 0.9092 - loss: 0.2522\n",
            "Fold 2 Metrics: Loss = 0.2611, Accuracy = 0.9042, AUC = 0.8006\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4998 - binary_accuracy: 0.7474 - loss: 0.4956 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3158\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.4981 - binary_accuracy: 0.9051 - loss: 0.3138 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3155\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5111 - binary_accuracy: 0.9051 - loss: 0.3136 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3153\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5305 - binary_accuracy: 0.9051 - loss: 0.3133 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3146\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5968 - binary_accuracy: 0.9051 - loss: 0.3124 - val_auc: 0.7238 - val_binary_accuracy: 0.9042 - val_loss: 0.3115\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7208 - binary_accuracy: 0.9051 - loss: 0.3061 - val_auc: 0.7651 - val_binary_accuracy: 0.9042 - val_loss: 0.2848\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7559 - binary_accuracy: 0.9051 - loss: 0.2801 - val_auc: 0.7686 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9051 - loss: 0.2730 - val_auc: 0.7718 - val_binary_accuracy: 0.9042 - val_loss: 0.2725\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7622 - binary_accuracy: 0.9051 - loss: 0.2707 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2725\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9051 - loss: 0.2691 - val_auc: 0.7719 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7689 - binary_accuracy: 0.9046 - loss: 0.2724\n",
            "Fold 3 Metrics: Loss = 0.2723, Accuracy = 0.9042, AUC = 0.7719\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4987 - binary_accuracy: 0.9047 - loss: 0.3930 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3146\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5932 - binary_accuracy: 0.9047 - loss: 0.3133 - val_auc: 0.7478 - val_binary_accuracy: 0.9044 - val_loss: 0.3086\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7324 - binary_accuracy: 0.9047 - loss: 0.3026 - val_auc: 0.7721 - val_binary_accuracy: 0.9044 - val_loss: 0.2833\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9047 - loss: 0.2778 - val_auc: 0.7746 - val_binary_accuracy: 0.9044 - val_loss: 0.2757\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9047 - loss: 0.2697 - val_auc: 0.7784 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9047 - loss: 0.2678 - val_auc: 0.7677 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7756 - binary_accuracy: 0.9047 - loss: 0.2673 - val_auc: 0.7790 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9047 - loss: 0.2662 - val_auc: 0.7833 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2655 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2678\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9047 - loss: 0.2652 - val_auc: 0.7777 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7564 - binary_accuracy: 0.9049 - loss: 0.2730\n",
            "Fold 4 Metrics: Loss = 0.2683, Accuracy = 0.9044, AUC = 0.7777\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5013 - binary_accuracy: 0.9040 - loss: 0.4339 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3152\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5197 - binary_accuracy: 0.9040 - loss: 0.3159 - val_auc: 0.5000 - val_binary_accuracy: 0.9044 - val_loss: 0.3143\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6066 - binary_accuracy: 0.9040 - loss: 0.3148 - val_auc: 0.7457 - val_binary_accuracy: 0.9044 - val_loss: 0.3095\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7343 - binary_accuracy: 0.9040 - loss: 0.3048 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2764\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7652 - binary_accuracy: 0.9040 - loss: 0.2780 - val_auc: 0.7844 - val_binary_accuracy: 0.9044 - val_loss: 0.2654\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9040 - loss: 0.2727 - val_auc: 0.7884 - val_binary_accuracy: 0.9044 - val_loss: 0.2636\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9040 - loss: 0.2714 - val_auc: 0.7879 - val_binary_accuracy: 0.9044 - val_loss: 0.2630\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7779 - binary_accuracy: 0.9040 - loss: 0.2703 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2625\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9040 - loss: 0.2696 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2625\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9040 - loss: 0.2692 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2619\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8004 - binary_accuracy: 0.9013 - loss: 0.2606\n",
            "Fold 5 Metrics: Loss = 0.2619, Accuracy = 0.9044, AUC = 0.7917\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2662\n",
            "Average Accuracy: 0.9043\n",
            "Average AUC: 0.7852\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 5, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5026 - binary_accuracy: 0.9069 - loss: 0.3597 - val_auc: 0.6572 - val_binary_accuracy: 0.9044 - val_loss: 0.3142\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6451 - binary_accuracy: 0.9069 - loss: 0.3047 - val_auc: 0.7599 - val_binary_accuracy: 0.9044 - val_loss: 0.2794\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9069 - loss: 0.2663 - val_auc: 0.7708 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9069 - loss: 0.2602 - val_auc: 0.7748 - val_binary_accuracy: 0.9044 - val_loss: 0.2694\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7922 - binary_accuracy: 0.9069 - loss: 0.2587 - val_auc: 0.7762 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7946 - binary_accuracy: 0.9069 - loss: 0.2579 - val_auc: 0.7780 - val_binary_accuracy: 0.9044 - val_loss: 0.2682\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9069 - loss: 0.2572 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7978 - binary_accuracy: 0.9069 - loss: 0.2566 - val_auc: 0.7803 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9069 - loss: 0.2560 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2660\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9069 - loss: 0.2551 - val_auc: 0.7861 - val_binary_accuracy: 0.9044 - val_loss: 0.2649\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7829 - binary_accuracy: 0.9084 - loss: 0.2585\n",
            "Fold 1 Metrics: Loss = 0.2649, Accuracy = 0.9044, AUC = 0.7861\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5047 - binary_accuracy: 0.9029 - loss: 0.3619 - val_auc: 0.7054 - val_binary_accuracy: 0.9042 - val_loss: 0.3143\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6909 - binary_accuracy: 0.9029 - loss: 0.3084 - val_auc: 0.7925 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9029 - loss: 0.2722 - val_auc: 0.7999 - val_binary_accuracy: 0.9042 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9029 - loss: 0.2690 - val_auc: 0.8028 - val_binary_accuracy: 0.9042 - val_loss: 0.2633\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9029 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9042 - val_loss: 0.2633\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9029 - loss: 0.2669 - val_auc: 0.8054 - val_binary_accuracy: 0.9042 - val_loss: 0.2627\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9029 - loss: 0.2664 - val_auc: 0.8052 - val_binary_accuracy: 0.9042 - val_loss: 0.2626\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7906 - binary_accuracy: 0.9035 - loss: 0.2658 - val_auc: 0.8054 - val_binary_accuracy: 0.9042 - val_loss: 0.2625\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9049 - loss: 0.2650 - val_auc: 0.8058 - val_binary_accuracy: 0.9050 - val_loss: 0.2620\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9062 - loss: 0.2642 - val_auc: 0.8061 - val_binary_accuracy: 0.9062 - val_loss: 0.2615\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8058 - binary_accuracy: 0.9101 - loss: 0.2528\n",
            "Fold 2 Metrics: Loss = 0.2615, Accuracy = 0.9062, AUC = 0.8061\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5010 - binary_accuracy: 0.7300 - loss: 0.4890 - val_auc: 0.5000 - val_binary_accuracy: 0.9042 - val_loss: 0.3154\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5254 - binary_accuracy: 0.9051 - loss: 0.3129 - val_auc: 0.7501 - val_binary_accuracy: 0.9042 - val_loss: 0.3068\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7356 - binary_accuracy: 0.9051 - loss: 0.2949 - val_auc: 0.7756 - val_binary_accuracy: 0.9042 - val_loss: 0.2748\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7726 - binary_accuracy: 0.9051 - loss: 0.2704 - val_auc: 0.7812 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9051 - loss: 0.2673 - val_auc: 0.7856 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2676\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9051 - loss: 0.2654 - val_auc: 0.7883 - val_binary_accuracy: 0.9042 - val_loss: 0.2666\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9051 - loss: 0.2651 - val_auc: 0.7908 - val_binary_accuracy: 0.9042 - val_loss: 0.2652\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9052 - loss: 0.2643 - val_auc: 0.7913 - val_binary_accuracy: 0.9063 - val_loss: 0.2643\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9062 - loss: 0.2637 - val_auc: 0.7925 - val_binary_accuracy: 0.9100 - val_loss: 0.2632\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7864 - binary_accuracy: 0.9103 - loss: 0.2638\n",
            "Fold 3 Metrics: Loss = 0.2632, Accuracy = 0.9100, AUC = 0.7925\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.4988 - binary_accuracy: 0.8179 - loss: 0.4269 - val_auc: 0.6953 - val_binary_accuracy: 0.9044 - val_loss: 0.3144\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6380 - binary_accuracy: 0.9047 - loss: 0.3116 - val_auc: 0.7670 - val_binary_accuracy: 0.9044 - val_loss: 0.2962\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7441 - binary_accuracy: 0.9047 - loss: 0.2865 - val_auc: 0.7732 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9047 - loss: 0.2683 - val_auc: 0.7796 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9047 - loss: 0.2664 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9050 - loss: 0.2640 - val_auc: 0.7880 - val_binary_accuracy: 0.9045 - val_loss: 0.2640\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9076 - loss: 0.2622 - val_auc: 0.7892 - val_binary_accuracy: 0.9073 - val_loss: 0.2642\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9091 - loss: 0.2608 - val_auc: 0.7937 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9097 - loss: 0.2598 - val_auc: 0.7958 - val_binary_accuracy: 0.9082 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.7973 - val_binary_accuracy: 0.9088 - val_loss: 0.2603\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7782 - binary_accuracy: 0.9085 - loss: 0.2655\n",
            "Fold 4 Metrics: Loss = 0.2603, Accuracy = 0.9088, AUC = 0.7973\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5080 - binary_accuracy: 0.7764 - loss: 0.4473 - val_auc: 0.6901 - val_binary_accuracy: 0.9044 - val_loss: 0.3133\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6971 - binary_accuracy: 0.9040 - loss: 0.3102 - val_auc: 0.7698 - val_binary_accuracy: 0.9044 - val_loss: 0.2806\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7589 - binary_accuracy: 0.9040 - loss: 0.2803 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2645\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9040 - loss: 0.2713 - val_auc: 0.7898 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9040 - loss: 0.2694 - val_auc: 0.7942 - val_binary_accuracy: 0.9044 - val_loss: 0.2606\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9040 - loss: 0.2682 - val_auc: 0.7950 - val_binary_accuracy: 0.9044 - val_loss: 0.2599\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9040 - loss: 0.2674 - val_auc: 0.7961 - val_binary_accuracy: 0.9044 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9040 - loss: 0.2667 - val_auc: 0.7972 - val_binary_accuracy: 0.9044 - val_loss: 0.2589\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9040 - loss: 0.2659 - val_auc: 0.7993 - val_binary_accuracy: 0.9044 - val_loss: 0.2581\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9044 - loss: 0.2653 - val_auc: 0.7986 - val_binary_accuracy: 0.9081 - val_loss: 0.2576\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8077 - binary_accuracy: 0.9069 - loss: 0.2551\n",
            "Fold 5 Metrics: Loss = 0.2576, Accuracy = 0.9081, AUC = 0.7986\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2615\n",
            "Average Accuracy: 0.9075\n",
            "Average AUC: 0.7961\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 5, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5420 - binary_accuracy: 0.9069 - loss: 0.3254 - val_auc: 0.7619 - val_binary_accuracy: 0.9044 - val_loss: 0.2807\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9069 - loss: 0.2660 - val_auc: 0.7734 - val_binary_accuracy: 0.9044 - val_loss: 0.2726\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9069 - loss: 0.2603 - val_auc: 0.7774 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9069 - loss: 0.2581 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2683\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9071 - loss: 0.2562 - val_auc: 0.7832 - val_binary_accuracy: 0.9056 - val_loss: 0.2658\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8002 - binary_accuracy: 0.9091 - loss: 0.2545 - val_auc: 0.7851 - val_binary_accuracy: 0.9078 - val_loss: 0.2641\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9118 - loss: 0.2532 - val_auc: 0.7867 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8042 - binary_accuracy: 0.9122 - loss: 0.2518 - val_auc: 0.7875 - val_binary_accuracy: 0.9090 - val_loss: 0.2609\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9129 - loss: 0.2507 - val_auc: 0.7894 - val_binary_accuracy: 0.9091 - val_loss: 0.2602\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9132 - loss: 0.2496 - val_auc: 0.7899 - val_binary_accuracy: 0.9088 - val_loss: 0.2597\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7861 - binary_accuracy: 0.9128 - loss: 0.2532\n",
            "Fold 1 Metrics: Loss = 0.2597, Accuracy = 0.9088, AUC = 0.7899\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5275 - binary_accuracy: 0.8436 - loss: 0.3803 - val_auc: 0.7777 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9029 - loss: 0.2805 - val_auc: 0.7999 - val_binary_accuracy: 0.9042 - val_loss: 0.2628\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2687 - val_auc: 0.8031 - val_binary_accuracy: 0.9042 - val_loss: 0.2598\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9031 - loss: 0.2663 - val_auc: 0.8063 - val_binary_accuracy: 0.9042 - val_loss: 0.2588\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9057 - loss: 0.2644 - val_auc: 0.8079 - val_binary_accuracy: 0.9066 - val_loss: 0.2587\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9068 - loss: 0.2629 - val_auc: 0.8081 - val_binary_accuracy: 0.9075 - val_loss: 0.2586\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9076 - loss: 0.2617 - val_auc: 0.8057 - val_binary_accuracy: 0.9072 - val_loss: 0.2591\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9083 - loss: 0.2609 - val_auc: 0.8058 - val_binary_accuracy: 0.9072 - val_loss: 0.2594\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9083 - loss: 0.2603 - val_auc: 0.8066 - val_binary_accuracy: 0.9075 - val_loss: 0.2598\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9084 - loss: 0.2597 - val_auc: 0.8069 - val_binary_accuracy: 0.9082 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8129 - binary_accuracy: 0.9128 - loss: 0.2491\n",
            "Fold 2 Metrics: Loss = 0.2599, Accuracy = 0.9082, AUC = 0.8069\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5089 - binary_accuracy: 0.7474 - loss: 0.4985 - val_auc: 0.7218 - val_binary_accuracy: 0.9042 - val_loss: 0.3102\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7207 - binary_accuracy: 0.9051 - loss: 0.2970 - val_auc: 0.7743 - val_binary_accuracy: 0.9042 - val_loss: 0.2752\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9051 - loss: 0.2705 - val_auc: 0.7817 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7897 - val_binary_accuracy: 0.9042 - val_loss: 0.2657\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7802 - binary_accuracy: 0.9059 - loss: 0.2653 - val_auc: 0.7896 - val_binary_accuracy: 0.9097 - val_loss: 0.2642\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.7916 - val_binary_accuracy: 0.9099 - val_loss: 0.2625\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9088 - loss: 0.2635 - val_auc: 0.7947 - val_binary_accuracy: 0.9104 - val_loss: 0.2607\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7970 - val_binary_accuracy: 0.9112 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9090 - loss: 0.2620 - val_auc: 0.7987 - val_binary_accuracy: 0.9116 - val_loss: 0.2582\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7922 - binary_accuracy: 0.9134 - loss: 0.2586\n",
            "Fold 3 Metrics: Loss = 0.2582, Accuracy = 0.9116, AUC = 0.7987\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5045 - binary_accuracy: 0.9047 - loss: 0.3483 - val_auc: 0.7596 - val_binary_accuracy: 0.9044 - val_loss: 0.2908\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7565 - binary_accuracy: 0.9047 - loss: 0.2779 - val_auc: 0.7874 - val_binary_accuracy: 0.9044 - val_loss: 0.2658\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7793 - binary_accuracy: 0.9047 - loss: 0.2657 - val_auc: 0.7916 - val_binary_accuracy: 0.9044 - val_loss: 0.2642\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9049 - loss: 0.2636 - val_auc: 0.7943 - val_binary_accuracy: 0.9044 - val_loss: 0.2626\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9064 - loss: 0.2620 - val_auc: 0.7993 - val_binary_accuracy: 0.9066 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9089 - loss: 0.2606 - val_auc: 0.8023 - val_binary_accuracy: 0.9082 - val_loss: 0.2580\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9098 - loss: 0.2597 - val_auc: 0.8035 - val_binary_accuracy: 0.9085 - val_loss: 0.2568\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9093 - loss: 0.2589 - val_auc: 0.8057 - val_binary_accuracy: 0.9087 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9098 - loss: 0.2586 - val_auc: 0.8056 - val_binary_accuracy: 0.9088 - val_loss: 0.2560\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9102 - loss: 0.2577 - val_auc: 0.8071 - val_binary_accuracy: 0.9091 - val_loss: 0.2557\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9087 - loss: 0.2614\n",
            "Fold 4 Metrics: Loss = 0.2557, Accuracy = 0.9091, AUC = 0.8071\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5529 - binary_accuracy: 0.9040 - loss: 0.3187 - val_auc: 0.7836 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9040 - loss: 0.2735 - val_auc: 0.7918 - val_binary_accuracy: 0.9044 - val_loss: 0.2614\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9040 - loss: 0.2702 - val_auc: 0.7938 - val_binary_accuracy: 0.9045 - val_loss: 0.2605\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9047 - loss: 0.2684 - val_auc: 0.7953 - val_binary_accuracy: 0.9079 - val_loss: 0.2590\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9073 - loss: 0.2670 - val_auc: 0.7974 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9083 - loss: 0.2658 - val_auc: 0.7999 - val_binary_accuracy: 0.9091 - val_loss: 0.2565\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9083 - loss: 0.2648 - val_auc: 0.8004 - val_binary_accuracy: 0.9090 - val_loss: 0.2555\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8026 - val_binary_accuracy: 0.9091 - val_loss: 0.2548\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9089 - loss: 0.2631 - val_auc: 0.8036 - val_binary_accuracy: 0.9098 - val_loss: 0.2541\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9092 - loss: 0.2624 - val_auc: 0.8037 - val_binary_accuracy: 0.9103 - val_loss: 0.2536\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8138 - binary_accuracy: 0.9081 - loss: 0.2509\n",
            "Fold 5 Metrics: Loss = 0.2536, Accuracy = 0.9103, AUC = 0.8037\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2574\n",
            "Average Accuracy: 0.9096\n",
            "Average AUC: 0.8013\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 5, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5788 - binary_accuracy: 0.8757 - loss: 0.3350 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9069 - loss: 0.2623 - val_auc: 0.7760 - val_binary_accuracy: 0.9044 - val_loss: 0.2686\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9069 - loss: 0.2591 - val_auc: 0.7807 - val_binary_accuracy: 0.9044 - val_loss: 0.2662\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9071 - loss: 0.2567 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9089 - loss: 0.2543 - val_auc: 0.7881 - val_binary_accuracy: 0.9065 - val_loss: 0.2633\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8040 - binary_accuracy: 0.9113 - loss: 0.2522 - val_auc: 0.7906 - val_binary_accuracy: 0.9079 - val_loss: 0.2618\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9121 - loss: 0.2505 - val_auc: 0.7912 - val_binary_accuracy: 0.9087 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8085 - binary_accuracy: 0.9120 - loss: 0.2494 - val_auc: 0.7919 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8105 - binary_accuracy: 0.9127 - loss: 0.2484 - val_auc: 0.7918 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8116 - binary_accuracy: 0.9131 - loss: 0.2476 - val_auc: 0.7925 - val_binary_accuracy: 0.9090 - val_loss: 0.2592\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7916 - binary_accuracy: 0.9130 - loss: 0.2516\n",
            "Fold 1 Metrics: Loss = 0.2592, Accuracy = 0.9090, AUC = 0.7925\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5215 - binary_accuracy: 0.8554 - loss: 0.3773 - val_auc: 0.7895 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9029 - loss: 0.2742 - val_auc: 0.7998 - val_binary_accuracy: 0.9042 - val_loss: 0.2623\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.8044 - val_binary_accuracy: 0.9042 - val_loss: 0.2604\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9030 - loss: 0.2676 - val_auc: 0.8065 - val_binary_accuracy: 0.9042 - val_loss: 0.2592\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9052 - loss: 0.2652 - val_auc: 0.8082 - val_binary_accuracy: 0.9062 - val_loss: 0.2580\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9064 - loss: 0.2632 - val_auc: 0.8087 - val_binary_accuracy: 0.9075 - val_loss: 0.2570\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9075 - loss: 0.2616 - val_auc: 0.8086 - val_binary_accuracy: 0.9078 - val_loss: 0.2564\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9081 - loss: 0.2606 - val_auc: 0.8084 - val_binary_accuracy: 0.9078 - val_loss: 0.2559\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9080 - loss: 0.2598 - val_auc: 0.8092 - val_binary_accuracy: 0.9084 - val_loss: 0.2555\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9084 - loss: 0.2592 - val_auc: 0.8089 - val_binary_accuracy: 0.9084 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8162 - binary_accuracy: 0.9123 - loss: 0.2447\n",
            "Fold 2 Metrics: Loss = 0.2551, Accuracy = 0.9084, AUC = 0.8089\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5237 - binary_accuracy: 0.8325 - loss: 0.4001 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2727\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7596 - binary_accuracy: 0.9051 - loss: 0.2740 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2702 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2665\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9053 - loss: 0.2684 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9068 - loss: 0.2673 - val_auc: 0.7928 - val_binary_accuracy: 0.9100 - val_loss: 0.2627\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7952 - val_binary_accuracy: 0.9103 - val_loss: 0.2610\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9083 - loss: 0.2653 - val_auc: 0.7984 - val_binary_accuracy: 0.9110 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9085 - loss: 0.2646 - val_auc: 0.8002 - val_binary_accuracy: 0.9113 - val_loss: 0.2585\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8018 - val_binary_accuracy: 0.9112 - val_loss: 0.2576\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9089 - loss: 0.2632 - val_auc: 0.8034 - val_binary_accuracy: 0.9112 - val_loss: 0.2570\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7960 - binary_accuracy: 0.9128 - loss: 0.2577\n",
            "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9112, AUC = 0.8034\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5373 - binary_accuracy: 0.8714 - loss: 0.3583 - val_auc: 0.7820 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9047 - loss: 0.2687 - val_auc: 0.7899 - val_binary_accuracy: 0.9044 - val_loss: 0.2635\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9065 - loss: 0.2651 - val_auc: 0.7940 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9094 - loss: 0.2631 - val_auc: 0.7965 - val_binary_accuracy: 0.9090 - val_loss: 0.2596\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9093 - loss: 0.2616 - val_auc: 0.7982 - val_binary_accuracy: 0.9093 - val_loss: 0.2586\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9099 - loss: 0.2606 - val_auc: 0.8004 - val_binary_accuracy: 0.9097 - val_loss: 0.2578\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9106 - loss: 0.2599 - val_auc: 0.8022 - val_binary_accuracy: 0.9095 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9106 - loss: 0.2593 - val_auc: 0.8034 - val_binary_accuracy: 0.9098 - val_loss: 0.2566\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7904 - binary_accuracy: 0.9110 - loss: 0.2589 - val_auc: 0.8048 - val_binary_accuracy: 0.9095 - val_loss: 0.2562\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9112 - loss: 0.2584 - val_auc: 0.8057 - val_binary_accuracy: 0.9097 - val_loss: 0.2557\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7869 - binary_accuracy: 0.9091 - loss: 0.2618\n",
            "Fold 4 Metrics: Loss = 0.2557, Accuracy = 0.9097, AUC = 0.8057\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5867 - binary_accuracy: 0.9040 - loss: 0.3168 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9041 - loss: 0.2742 - val_auc: 0.7943 - val_binary_accuracy: 0.9073 - val_loss: 0.2612\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9042 - loss: 0.2710 - val_auc: 0.7981 - val_binary_accuracy: 0.9069 - val_loss: 0.2596\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9065 - loss: 0.2689 - val_auc: 0.8007 - val_binary_accuracy: 0.9091 - val_loss: 0.2583\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9083 - loss: 0.2673 - val_auc: 0.8028 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9082 - loss: 0.2659 - val_auc: 0.8045 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9090 - loss: 0.2647 - val_auc: 0.8057 - val_binary_accuracy: 0.9106 - val_loss: 0.2546\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9094 - loss: 0.2637 - val_auc: 0.8075 - val_binary_accuracy: 0.9110 - val_loss: 0.2534\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9094 - loss: 0.2629 - val_auc: 0.8077 - val_binary_accuracy: 0.9115 - val_loss: 0.2524\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9095 - loss: 0.2620 - val_auc: 0.8085 - val_binary_accuracy: 0.9121 - val_loss: 0.2518\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8180 - binary_accuracy: 0.9102 - loss: 0.2490\n",
            "Fold 5 Metrics: Loss = 0.2518, Accuracy = 0.9121, AUC = 0.8085\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2558\n",
            "Average Accuracy: 0.9101\n",
            "Average AUC: 0.8038\n",
            "----------------------------------------\n",
            "Performing training for: ('sigmoid', 5, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5900 - binary_accuracy: 0.8901 - loss: 0.3228 - val_auc: 0.7708 - val_binary_accuracy: 0.9044 - val_loss: 0.2719\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7782 - val_binary_accuracy: 0.9044 - val_loss: 0.2701\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9069 - loss: 0.2596 - val_auc: 0.7834 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7947 - binary_accuracy: 0.9072 - loss: 0.2571 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7988 - binary_accuracy: 0.9102 - loss: 0.2549 - val_auc: 0.7906 - val_binary_accuracy: 0.9065 - val_loss: 0.2654\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9115 - loss: 0.2530 - val_auc: 0.7923 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8049 - binary_accuracy: 0.9119 - loss: 0.2514 - val_auc: 0.7938 - val_binary_accuracy: 0.9088 - val_loss: 0.2632\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9124 - loss: 0.2502 - val_auc: 0.7938 - val_binary_accuracy: 0.9087 - val_loss: 0.2623\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9131 - loss: 0.2493 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2613\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8103 - binary_accuracy: 0.9128 - loss: 0.2484 - val_auc: 0.7945 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7941 - binary_accuracy: 0.9117 - loss: 0.2521\n",
            "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9085, AUC = 0.7945\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5756 - binary_accuracy: 0.8847 - loss: 0.3358 - val_auc: 0.7968 - val_binary_accuracy: 0.9042 - val_loss: 0.2679\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.8036 - val_binary_accuracy: 0.9042 - val_loss: 0.2654\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9041 - loss: 0.2690 - val_auc: 0.8057 - val_binary_accuracy: 0.9047 - val_loss: 0.2633\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9062 - loss: 0.2658 - val_auc: 0.8066 - val_binary_accuracy: 0.9066 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9066 - loss: 0.2637 - val_auc: 0.8076 - val_binary_accuracy: 0.9068 - val_loss: 0.2605\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9075 - loss: 0.2621 - val_auc: 0.8079 - val_binary_accuracy: 0.9078 - val_loss: 0.2603\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9077 - loss: 0.2610 - val_auc: 0.8076 - val_binary_accuracy: 0.9078 - val_loss: 0.2602\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8003 - binary_accuracy: 0.9080 - loss: 0.2603 - val_auc: 0.8082 - val_binary_accuracy: 0.9079 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8012 - binary_accuracy: 0.9078 - loss: 0.2597 - val_auc: 0.8088 - val_binary_accuracy: 0.9079 - val_loss: 0.2595\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8021 - binary_accuracy: 0.9080 - loss: 0.2593 - val_auc: 0.8085 - val_binary_accuracy: 0.9078 - val_loss: 0.2590\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9116 - loss: 0.2494\n",
            "Fold 2 Metrics: Loss = 0.2590, Accuracy = 0.9078, AUC = 0.8085\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - auc: 0.5779 - binary_accuracy: 0.8865 - loss: 0.3352 - val_auc: 0.7785 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7545 - binary_accuracy: 0.9051 - loss: 0.2757 - val_auc: 0.7834 - val_binary_accuracy: 0.9042 - val_loss: 0.2678\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9051 - loss: 0.2719 - val_auc: 0.7873 - val_binary_accuracy: 0.9042 - val_loss: 0.2664\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9051 - loss: 0.2700 - val_auc: 0.7896 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9054 - loss: 0.2687 - val_auc: 0.7923 - val_binary_accuracy: 0.9090 - val_loss: 0.2638\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9068 - loss: 0.2675 - val_auc: 0.7952 - val_binary_accuracy: 0.9099 - val_loss: 0.2624\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9082 - loss: 0.2664 - val_auc: 0.7980 - val_binary_accuracy: 0.9109 - val_loss: 0.2612\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9087 - loss: 0.2653 - val_auc: 0.7999 - val_binary_accuracy: 0.9107 - val_loss: 0.2601\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9091 - loss: 0.2644 - val_auc: 0.8019 - val_binary_accuracy: 0.9107 - val_loss: 0.2591\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8037 - val_binary_accuracy: 0.9112 - val_loss: 0.2580\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9126 - loss: 0.2589\n",
            "Fold 3 Metrics: Loss = 0.2580, Accuracy = 0.9112, AUC = 0.8037\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5519 - binary_accuracy: 0.8866 - loss: 0.3507 - val_auc: 0.7860 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9047 - loss: 0.2698 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2636\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9054 - loss: 0.2668 - val_auc: 0.7966 - val_binary_accuracy: 0.9081 - val_loss: 0.2608\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9080 - loss: 0.2648 - val_auc: 0.7992 - val_binary_accuracy: 0.9094 - val_loss: 0.2593\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9090 - loss: 0.2632 - val_auc: 0.8004 - val_binary_accuracy: 0.9090 - val_loss: 0.2582\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9098 - loss: 0.2620 - val_auc: 0.8016 - val_binary_accuracy: 0.9090 - val_loss: 0.2577\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9104 - loss: 0.2611 - val_auc: 0.8030 - val_binary_accuracy: 0.9084 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9107 - loss: 0.2603 - val_auc: 0.8049 - val_binary_accuracy: 0.9091 - val_loss: 0.2563\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9109 - loss: 0.2596 - val_auc: 0.8061 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9112 - loss: 0.2591 - val_auc: 0.8070 - val_binary_accuracy: 0.9093 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7882 - binary_accuracy: 0.9092 - loss: 0.2622\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9093, AUC = 0.8070\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5931 - binary_accuracy: 0.9040 - loss: 0.3197 - val_auc: 0.7878 - val_binary_accuracy: 0.9044 - val_loss: 0.2665\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7631 - binary_accuracy: 0.9040 - loss: 0.2748 - val_auc: 0.7934 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9041 - loss: 0.2720 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2633\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9048 - loss: 0.2699 - val_auc: 0.7999 - val_binary_accuracy: 0.9093 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9070 - loss: 0.2679 - val_auc: 0.8018 - val_binary_accuracy: 0.9091 - val_loss: 0.2620\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9085 - loss: 0.2664 - val_auc: 0.8035 - val_binary_accuracy: 0.9097 - val_loss: 0.2618\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9081 - loss: 0.2652 - val_auc: 0.8056 - val_binary_accuracy: 0.9097 - val_loss: 0.2613\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9090 - loss: 0.2642 - val_auc: 0.8070 - val_binary_accuracy: 0.9101 - val_loss: 0.2605\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9092 - loss: 0.2633 - val_auc: 0.8072 - val_binary_accuracy: 0.9097 - val_loss: 0.2595\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9093 - loss: 0.2627 - val_auc: 0.8085 - val_binary_accuracy: 0.9103 - val_loss: 0.2583\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8171 - binary_accuracy: 0.9119 - loss: 0.2560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|   | 2/3 [55:17<27:40, 1660.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 Metrics: Loss = 0.2583, Accuracy = 0.9103, AUC = 0.8085\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2582\n",
            "Average Accuracy: 0.9094\n",
            "Average AUC: 0.8044\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 1, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5266 - binary_accuracy: 0.6977 - loss: 0.5188 - val_auc: 0.6882 - val_binary_accuracy: 0.9041 - val_loss: 0.2958\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7066 - binary_accuracy: 0.9069 - loss: 0.2843 - val_auc: 0.7156 - val_binary_accuracy: 0.9044 - val_loss: 0.2857\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7444 - binary_accuracy: 0.9069 - loss: 0.2756 - val_auc: 0.7374 - val_binary_accuracy: 0.9042 - val_loss: 0.2824\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7606 - binary_accuracy: 0.9069 - loss: 0.2714 - val_auc: 0.7393 - val_binary_accuracy: 0.9044 - val_loss: 0.2792\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9069 - loss: 0.2688 - val_auc: 0.7333 - val_binary_accuracy: 0.9044 - val_loss: 0.2777\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7395 - val_binary_accuracy: 0.9044 - val_loss: 0.2770\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9069 - loss: 0.2660 - val_auc: 0.7345 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9069 - loss: 0.2652 - val_auc: 0.7471 - val_binary_accuracy: 0.9041 - val_loss: 0.2758\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9069 - loss: 0.2645 - val_auc: 0.7442 - val_binary_accuracy: 0.9041 - val_loss: 0.2753\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9069 - loss: 0.2639 - val_auc: 0.7444 - val_binary_accuracy: 0.9041 - val_loss: 0.2749\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7428 - binary_accuracy: 0.9081 - loss: 0.2662\n",
            "Fold 1 Metrics: Loss = 0.2749, Accuracy = 0.9041, AUC = 0.7444\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5584 - binary_accuracy: 0.7373 - loss: 0.5031 - val_auc: 0.7282 - val_binary_accuracy: 0.9042 - val_loss: 0.2890\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7379 - binary_accuracy: 0.9029 - loss: 0.2878 - val_auc: 0.7527 - val_binary_accuracy: 0.9042 - val_loss: 0.2819\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7542 - binary_accuracy: 0.9029 - loss: 0.2822 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7659 - binary_accuracy: 0.9029 - loss: 0.2775 - val_auc: 0.7833 - val_binary_accuracy: 0.9042 - val_loss: 0.2716\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2734 - val_auc: 0.7852 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7802 - binary_accuracy: 0.9029 - loss: 0.2704 - val_auc: 0.7926 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7842 - binary_accuracy: 0.9029 - loss: 0.2685 - val_auc: 0.7953 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7872 - binary_accuracy: 0.9043 - loss: 0.2676 - val_auc: 0.7943 - val_binary_accuracy: 0.9053 - val_loss: 0.2657\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9072 - loss: 0.2666 - val_auc: 0.7934 - val_binary_accuracy: 0.9065 - val_loss: 0.2658\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9079 - loss: 0.2665 - val_auc: 0.7911 - val_binary_accuracy: 0.9076 - val_loss: 0.2662\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9112 - loss: 0.2568\n",
            "Fold 2 Metrics: Loss = 0.2662, Accuracy = 0.9076, AUC = 0.7911\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5662 - binary_accuracy: 0.8890 - loss: 0.3588 - val_auc: 0.7475 - val_binary_accuracy: 0.9042 - val_loss: 0.2856\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7347 - binary_accuracy: 0.9051 - loss: 0.2849 - val_auc: 0.7552 - val_binary_accuracy: 0.9042 - val_loss: 0.2783\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7453 - binary_accuracy: 0.9051 - loss: 0.2784 - val_auc: 0.7623 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7551 - binary_accuracy: 0.9051 - loss: 0.2734 - val_auc: 0.7645 - val_binary_accuracy: 0.9042 - val_loss: 0.2715\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7613 - binary_accuracy: 0.9051 - loss: 0.2702 - val_auc: 0.7666 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7656 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7695 - val_binary_accuracy: 0.9042 - val_loss: 0.2701\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2667 - val_auc: 0.7708 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9051 - loss: 0.2656 - val_auc: 0.7716 - val_binary_accuracy: 0.9042 - val_loss: 0.2688\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9051 - loss: 0.2645 - val_auc: 0.7711 - val_binary_accuracy: 0.9042 - val_loss: 0.2687\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7742 - binary_accuracy: 0.9051 - loss: 0.2637 - val_auc: 0.7710 - val_binary_accuracy: 0.9042 - val_loss: 0.2683\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7722 - binary_accuracy: 0.9046 - loss: 0.2666\n",
            "Fold 3 Metrics: Loss = 0.2683, Accuracy = 0.9042, AUC = 0.7710\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6024 - binary_accuracy: 0.9021 - loss: 0.3401 - val_auc: 0.7602 - val_binary_accuracy: 0.9044 - val_loss: 0.2823\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7582 - binary_accuracy: 0.9047 - loss: 0.2790 - val_auc: 0.7630 - val_binary_accuracy: 0.9044 - val_loss: 0.2767\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7649 - binary_accuracy: 0.9047 - loss: 0.2731 - val_auc: 0.7760 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9047 - loss: 0.2720 - val_auc: 0.7770 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7708 - binary_accuracy: 0.9047 - loss: 0.2704 - val_auc: 0.7792 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7707 - binary_accuracy: 0.9047 - loss: 0.2693 - val_auc: 0.7816 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9047 - loss: 0.2689 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2709\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9047 - loss: 0.2682 - val_auc: 0.7795 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9048 - loss: 0.2670 - val_auc: 0.7808 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9074 - loss: 0.2667 - val_auc: 0.7824 - val_binary_accuracy: 0.9048 - val_loss: 0.2698\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7642 - binary_accuracy: 0.9049 - loss: 0.2719\n",
            "Fold 4 Metrics: Loss = 0.2698, Accuracy = 0.9048, AUC = 0.7824\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5597 - binary_accuracy: 0.8180 - loss: 0.4326 - val_auc: 0.7197 - val_binary_accuracy: 0.9044 - val_loss: 0.2887\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7302 - binary_accuracy: 0.9040 - loss: 0.2872 - val_auc: 0.7675 - val_binary_accuracy: 0.9044 - val_loss: 0.2741\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7609 - binary_accuracy: 0.9040 - loss: 0.2770 - val_auc: 0.7802 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9040 - loss: 0.2736 - val_auc: 0.7830 - val_binary_accuracy: 0.9044 - val_loss: 0.2677\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9049 - loss: 0.2708 - val_auc: 0.7877 - val_binary_accuracy: 0.9060 - val_loss: 0.2647\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7752 - binary_accuracy: 0.9062 - loss: 0.2690 - val_auc: 0.7919 - val_binary_accuracy: 0.9075 - val_loss: 0.2610\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9074 - loss: 0.2680 - val_auc: 0.7888 - val_binary_accuracy: 0.9078 - val_loss: 0.2629\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9072 - loss: 0.2666 - val_auc: 0.7949 - val_binary_accuracy: 0.9094 - val_loss: 0.2591\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9082 - loss: 0.2663 - val_auc: 0.7945 - val_binary_accuracy: 0.9097 - val_loss: 0.2593\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9084 - loss: 0.2655 - val_auc: 0.7912 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8006 - binary_accuracy: 0.9073 - loss: 0.2610\n",
            "Fold 5 Metrics: Loss = 0.2611, Accuracy = 0.9094, AUC = 0.7912\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2680\n",
            "Average Accuracy: 0.9060\n",
            "Average AUC: 0.7760\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 1, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6618 - binary_accuracy: 0.7700 - loss: 0.4375 - val_auc: 0.7479 - val_binary_accuracy: 0.9044 - val_loss: 0.2784\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9069 - loss: 0.2648 - val_auc: 0.7617 - val_binary_accuracy: 0.9068 - val_loss: 0.2727\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9091 - loss: 0.2596 - val_auc: 0.7696 - val_binary_accuracy: 0.9079 - val_loss: 0.2694\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9095 - loss: 0.2574 - val_auc: 0.7734 - val_binary_accuracy: 0.9081 - val_loss: 0.2678\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9104 - loss: 0.2564 - val_auc: 0.7732 - val_binary_accuracy: 0.9087 - val_loss: 0.2672\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9107 - loss: 0.2558 - val_auc: 0.7736 - val_binary_accuracy: 0.9090 - val_loss: 0.2666\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9107 - loss: 0.2551 - val_auc: 0.7745 - val_binary_accuracy: 0.9088 - val_loss: 0.2660\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7958 - binary_accuracy: 0.9107 - loss: 0.2548 - val_auc: 0.7762 - val_binary_accuracy: 0.9091 - val_loss: 0.2655\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9113 - loss: 0.2546 - val_auc: 0.7766 - val_binary_accuracy: 0.9091 - val_loss: 0.2650\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9121 - loss: 0.2540 - val_auc: 0.7768 - val_binary_accuracy: 0.9093 - val_loss: 0.2646\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7754 - binary_accuracy: 0.9131 - loss: 0.2572\n",
            "Fold 1 Metrics: Loss = 0.2646, Accuracy = 0.9093, AUC = 0.7768\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6894 - binary_accuracy: 0.9016 - loss: 0.3190 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7709 - binary_accuracy: 0.9029 - loss: 0.2740 - val_auc: 0.7883 - val_binary_accuracy: 0.9042 - val_loss: 0.2680\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7771 - binary_accuracy: 0.9037 - loss: 0.2711 - val_auc: 0.7929 - val_binary_accuracy: 0.9042 - val_loss: 0.2669\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7804 - binary_accuracy: 0.9057 - loss: 0.2695 - val_auc: 0.7960 - val_binary_accuracy: 0.9050 - val_loss: 0.2655\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9069 - loss: 0.2677 - val_auc: 0.7993 - val_binary_accuracy: 0.9056 - val_loss: 0.2648\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7862 - binary_accuracy: 0.9070 - loss: 0.2667 - val_auc: 0.8006 - val_binary_accuracy: 0.9065 - val_loss: 0.2644\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9062 - loss: 0.2661 - val_auc: 0.8025 - val_binary_accuracy: 0.9065 - val_loss: 0.2614\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9066 - loss: 0.2653 - val_auc: 0.8017 - val_binary_accuracy: 0.9071 - val_loss: 0.2617\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9068 - loss: 0.2647 - val_auc: 0.8018 - val_binary_accuracy: 0.9078 - val_loss: 0.2604\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9070 - loss: 0.2630 - val_auc: 0.8031 - val_binary_accuracy: 0.9078 - val_loss: 0.2610\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8067 - binary_accuracy: 0.9119 - loss: 0.2508\n",
            "Fold 2 Metrics: Loss = 0.2610, Accuracy = 0.9078, AUC = 0.8031\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6874 - binary_accuracy: 0.8978 - loss: 0.3120 - val_auc: 0.7725 - val_binary_accuracy: 0.9042 - val_loss: 0.2732\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7691 - binary_accuracy: 0.9051 - loss: 0.2703 - val_auc: 0.7753 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7731 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7778 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7750 - binary_accuracy: 0.9051 - loss: 0.2667 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7767 - binary_accuracy: 0.9051 - loss: 0.2655 - val_auc: 0.7801 - val_binary_accuracy: 0.9047 - val_loss: 0.2676\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7792 - binary_accuracy: 0.9063 - loss: 0.2644 - val_auc: 0.7807 - val_binary_accuracy: 0.9069 - val_loss: 0.2670\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7811 - binary_accuracy: 0.9069 - loss: 0.2635 - val_auc: 0.7826 - val_binary_accuracy: 0.9075 - val_loss: 0.2663\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9071 - loss: 0.2626 - val_auc: 0.7835 - val_binary_accuracy: 0.9081 - val_loss: 0.2658\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7845 - binary_accuracy: 0.9075 - loss: 0.2619 - val_auc: 0.7850 - val_binary_accuracy: 0.9087 - val_loss: 0.2658\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7841 - binary_accuracy: 0.9077 - loss: 0.2616 - val_auc: 0.7867 - val_binary_accuracy: 0.9087 - val_loss: 0.2646\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7809 - binary_accuracy: 0.9096 - loss: 0.2653\n",
            "Fold 3 Metrics: Loss = 0.2646, Accuracy = 0.9087, AUC = 0.7867\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6057 - binary_accuracy: 0.6792 - loss: 0.5916 - val_auc: 0.7379 - val_binary_accuracy: 0.9044 - val_loss: 0.2846\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7347 - binary_accuracy: 0.9047 - loss: 0.2840 - val_auc: 0.7619 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7603 - binary_accuracy: 0.9048 - loss: 0.2746 - val_auc: 0.7738 - val_binary_accuracy: 0.9053 - val_loss: 0.2711\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7704 - binary_accuracy: 0.9059 - loss: 0.2706 - val_auc: 0.7752 - val_binary_accuracy: 0.9050 - val_loss: 0.2708\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7742 - binary_accuracy: 0.9068 - loss: 0.2688 - val_auc: 0.7797 - val_binary_accuracy: 0.9059 - val_loss: 0.2690\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7792 - binary_accuracy: 0.9080 - loss: 0.2661 - val_auc: 0.7833 - val_binary_accuracy: 0.9072 - val_loss: 0.2668\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9075 - loss: 0.2648 - val_auc: 0.7847 - val_binary_accuracy: 0.9085 - val_loss: 0.2656\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9080 - loss: 0.2639 - val_auc: 0.7862 - val_binary_accuracy: 0.9081 - val_loss: 0.2653\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9091 - loss: 0.2630 - val_auc: 0.7871 - val_binary_accuracy: 0.9082 - val_loss: 0.2657\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7859 - binary_accuracy: 0.9091 - loss: 0.2625 - val_auc: 0.7867 - val_binary_accuracy: 0.9082 - val_loss: 0.2664\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7648 - binary_accuracy: 0.9080 - loss: 0.2720\n",
            "Fold 4 Metrics: Loss = 0.2664, Accuracy = 0.9082, AUC = 0.7867\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6366 - binary_accuracy: 0.8897 - loss: 0.3399 - val_auc: 0.7799 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7632 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7812 - val_binary_accuracy: 0.9044 - val_loss: 0.2659\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7665 - binary_accuracy: 0.9043 - loss: 0.2737 - val_auc: 0.7878 - val_binary_accuracy: 0.9048 - val_loss: 0.2625\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7714 - binary_accuracy: 0.9061 - loss: 0.2713 - val_auc: 0.7884 - val_binary_accuracy: 0.9054 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7717 - binary_accuracy: 0.9065 - loss: 0.2710 - val_auc: 0.7891 - val_binary_accuracy: 0.9057 - val_loss: 0.2612\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2707 - val_auc: 0.7896 - val_binary_accuracy: 0.9066 - val_loss: 0.2603\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9072 - loss: 0.2694 - val_auc: 0.7900 - val_binary_accuracy: 0.9067 - val_loss: 0.2599\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9074 - loss: 0.2688 - val_auc: 0.7916 - val_binary_accuracy: 0.9084 - val_loss: 0.2593\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7759 - binary_accuracy: 0.9073 - loss: 0.2686 - val_auc: 0.7900 - val_binary_accuracy: 0.9088 - val_loss: 0.2590\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7779 - binary_accuracy: 0.9075 - loss: 0.2680 - val_auc: 0.7930 - val_binary_accuracy: 0.9084 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8015 - binary_accuracy: 0.9076 - loss: 0.2594\n",
            "Fold 5 Metrics: Loss = 0.2586, Accuracy = 0.9084, AUC = 0.7930\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2630\n",
            "Average Accuracy: 0.9085\n",
            "Average AUC: 0.7892\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 1, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7272 - binary_accuracy: 0.9069 - loss: 0.2821 - val_auc: 0.7683 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9069 - loss: 0.2599 - val_auc: 0.7758 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9073 - loss: 0.2565 - val_auc: 0.7821 - val_binary_accuracy: 0.9044 - val_loss: 0.2668\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9078 - loss: 0.2540 - val_auc: 0.7857 - val_binary_accuracy: 0.9044 - val_loss: 0.2650\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8057 - binary_accuracy: 0.9090 - loss: 0.2519 - val_auc: 0.7861 - val_binary_accuracy: 0.9072 - val_loss: 0.2627\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8070 - binary_accuracy: 0.9106 - loss: 0.2507 - val_auc: 0.7890 - val_binary_accuracy: 0.9079 - val_loss: 0.2617\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8086 - binary_accuracy: 0.9114 - loss: 0.2500 - val_auc: 0.7901 - val_binary_accuracy: 0.9088 - val_loss: 0.2606\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8097 - binary_accuracy: 0.9125 - loss: 0.2490 - val_auc: 0.7901 - val_binary_accuracy: 0.9103 - val_loss: 0.2601\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9131 - loss: 0.2481 - val_auc: 0.7910 - val_binary_accuracy: 0.9100 - val_loss: 0.2597\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8108 - binary_accuracy: 0.9127 - loss: 0.2478 - val_auc: 0.7913 - val_binary_accuracy: 0.9104 - val_loss: 0.2595\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7898 - binary_accuracy: 0.9133 - loss: 0.2522\n",
            "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9104, AUC = 0.7913\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6781 - binary_accuracy: 0.9029 - loss: 0.3073 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7778 - binary_accuracy: 0.9029 - loss: 0.2719 - val_auc: 0.7997 - val_binary_accuracy: 0.9042 - val_loss: 0.2645\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9035 - loss: 0.2684 - val_auc: 0.8021 - val_binary_accuracy: 0.9045 - val_loss: 0.2634\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9052 - loss: 0.2665 - val_auc: 0.8043 - val_binary_accuracy: 0.9057 - val_loss: 0.2623\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9057 - loss: 0.2656 - val_auc: 0.8046 - val_binary_accuracy: 0.9069 - val_loss: 0.2592\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7906 - binary_accuracy: 0.9071 - loss: 0.2644 - val_auc: 0.8049 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7923 - binary_accuracy: 0.9077 - loss: 0.2635 - val_auc: 0.8068 - val_binary_accuracy: 0.9081 - val_loss: 0.2588\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7944 - binary_accuracy: 0.9078 - loss: 0.2625 - val_auc: 0.8068 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7956 - binary_accuracy: 0.9087 - loss: 0.2621 - val_auc: 0.8081 - val_binary_accuracy: 0.9088 - val_loss: 0.2593\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9082 - loss: 0.2617 - val_auc: 0.8089 - val_binary_accuracy: 0.9094 - val_loss: 0.2576\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8161 - binary_accuracy: 0.9124 - loss: 0.2463\n",
            "Fold 2 Metrics: Loss = 0.2576, Accuracy = 0.9094, AUC = 0.8089\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7279 - binary_accuracy: 0.9051 - loss: 0.2831 - val_auc: 0.7758 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9055 - loss: 0.2684 - val_auc: 0.7836 - val_binary_accuracy: 0.9063 - val_loss: 0.2677\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9068 - loss: 0.2654 - val_auc: 0.7907 - val_binary_accuracy: 0.9088 - val_loss: 0.2641\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9079 - loss: 0.2637 - val_auc: 0.7966 - val_binary_accuracy: 0.9096 - val_loss: 0.2616\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9080 - loss: 0.2620 - val_auc: 0.8013 - val_binary_accuracy: 0.9102 - val_loss: 0.2596\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9091 - loss: 0.2613 - val_auc: 0.8036 - val_binary_accuracy: 0.9100 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9089 - loss: 0.2605 - val_auc: 0.8052 - val_binary_accuracy: 0.9109 - val_loss: 0.2573\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7884 - binary_accuracy: 0.9092 - loss: 0.2602 - val_auc: 0.8060 - val_binary_accuracy: 0.9112 - val_loss: 0.2567\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9095 - loss: 0.2596 - val_auc: 0.8072 - val_binary_accuracy: 0.9112 - val_loss: 0.2562\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9095 - loss: 0.2590 - val_auc: 0.8076 - val_binary_accuracy: 0.9113 - val_loss: 0.2559\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8000 - binary_accuracy: 0.9124 - loss: 0.2562\n",
            "Fold 3 Metrics: Loss = 0.2559, Accuracy = 0.9113, AUC = 0.8076\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6208 - binary_accuracy: 0.7267 - loss: 0.6144 - val_auc: 0.7587 - val_binary_accuracy: 0.9044 - val_loss: 0.2768\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7610 - binary_accuracy: 0.9047 - loss: 0.2750 - val_auc: 0.7804 - val_binary_accuracy: 0.9045 - val_loss: 0.2693\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9057 - loss: 0.2667 - val_auc: 0.7873 - val_binary_accuracy: 0.9050 - val_loss: 0.2670\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9066 - loss: 0.2642 - val_auc: 0.7935 - val_binary_accuracy: 0.9057 - val_loss: 0.2660\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7865 - binary_accuracy: 0.9071 - loss: 0.2629 - val_auc: 0.7933 - val_binary_accuracy: 0.9079 - val_loss: 0.2636\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9075 - loss: 0.2619 - val_auc: 0.7934 - val_binary_accuracy: 0.9069 - val_loss: 0.2662\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9088 - loss: 0.2614 - val_auc: 0.7942 - val_binary_accuracy: 0.9078 - val_loss: 0.2659\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9093 - loss: 0.2606 - val_auc: 0.7964 - val_binary_accuracy: 0.9082 - val_loss: 0.2642\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9094 - loss: 0.2599 - val_auc: 0.7970 - val_binary_accuracy: 0.9085 - val_loss: 0.2636\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7927 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.7980 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7776 - binary_accuracy: 0.9085 - loss: 0.2684\n",
            "Fold 4 Metrics: Loss = 0.2631, Accuracy = 0.9082, AUC = 0.7980\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7277 - binary_accuracy: 0.9040 - loss: 0.2875 - val_auc: 0.7910 - val_binary_accuracy: 0.9057 - val_loss: 0.2616\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9043 - loss: 0.2694 - val_auc: 0.7962 - val_binary_accuracy: 0.9054 - val_loss: 0.2582\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9063 - loss: 0.2659 - val_auc: 0.7976 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9069 - loss: 0.2637 - val_auc: 0.8015 - val_binary_accuracy: 0.9081 - val_loss: 0.2557\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9072 - loss: 0.2636 - val_auc: 0.8047 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9082 - loss: 0.2616 - val_auc: 0.8041 - val_binary_accuracy: 0.9094 - val_loss: 0.2534\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9085 - loss: 0.2607 - val_auc: 0.8050 - val_binary_accuracy: 0.9097 - val_loss: 0.2531\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7957 - binary_accuracy: 0.9087 - loss: 0.2601 - val_auc: 0.8056 - val_binary_accuracy: 0.9103 - val_loss: 0.2528\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7969 - binary_accuracy: 0.9093 - loss: 0.2594 - val_auc: 0.8049 - val_binary_accuracy: 0.9103 - val_loss: 0.2527\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7966 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.8069 - val_binary_accuracy: 0.9110 - val_loss: 0.2523\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9089 - loss: 0.2508\n",
            "Fold 5 Metrics: Loss = 0.2523, Accuracy = 0.9110, AUC = 0.8069\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2577\n",
            "Average Accuracy: 0.9101\n",
            "Average AUC: 0.8025\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 1, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7450 - binary_accuracy: 0.9069 - loss: 0.2758 - val_auc: 0.7784 - val_binary_accuracy: 0.9056 - val_loss: 0.2687\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7951 - binary_accuracy: 0.9083 - loss: 0.2566 - val_auc: 0.7872 - val_binary_accuracy: 0.9053 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9087 - loss: 0.2532 - val_auc: 0.7890 - val_binary_accuracy: 0.9069 - val_loss: 0.2620\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8047 - binary_accuracy: 0.9116 - loss: 0.2515 - val_auc: 0.7903 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9125 - loss: 0.2502 - val_auc: 0.7907 - val_binary_accuracy: 0.9084 - val_loss: 0.2609\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8094 - binary_accuracy: 0.9126 - loss: 0.2490 - val_auc: 0.7918 - val_binary_accuracy: 0.9096 - val_loss: 0.2603\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8102 - binary_accuracy: 0.9125 - loss: 0.2482 - val_auc: 0.7943 - val_binary_accuracy: 0.9094 - val_loss: 0.2590\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8120 - binary_accuracy: 0.9126 - loss: 0.2471 - val_auc: 0.7947 - val_binary_accuracy: 0.9097 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8136 - binary_accuracy: 0.9134 - loss: 0.2463 - val_auc: 0.7955 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8152 - binary_accuracy: 0.9136 - loss: 0.2457 - val_auc: 0.7972 - val_binary_accuracy: 0.9094 - val_loss: 0.2584\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7958 - binary_accuracy: 0.9130 - loss: 0.2519\n",
            "Fold 1 Metrics: Loss = 0.2584, Accuracy = 0.9094, AUC = 0.7972\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6504 - binary_accuracy: 0.7876 - loss: 0.4939 - val_auc: 0.7916 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7828 - binary_accuracy: 0.9029 - loss: 0.2700 - val_auc: 0.8022 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7915 - binary_accuracy: 0.9042 - loss: 0.2653 - val_auc: 0.8065 - val_binary_accuracy: 0.9045 - val_loss: 0.2610\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9061 - loss: 0.2631 - val_auc: 0.8095 - val_binary_accuracy: 0.9056 - val_loss: 0.2591\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9067 - loss: 0.2620 - val_auc: 0.8092 - val_binary_accuracy: 0.9063 - val_loss: 0.2585\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7985 - binary_accuracy: 0.9075 - loss: 0.2608 - val_auc: 0.8089 - val_binary_accuracy: 0.9069 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7989 - binary_accuracy: 0.9084 - loss: 0.2606 - val_auc: 0.8106 - val_binary_accuracy: 0.9073 - val_loss: 0.2573\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8010 - binary_accuracy: 0.9082 - loss: 0.2597 - val_auc: 0.8104 - val_binary_accuracy: 0.9078 - val_loss: 0.2573\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8011 - binary_accuracy: 0.9086 - loss: 0.2596 - val_auc: 0.8090 - val_binary_accuracy: 0.9075 - val_loss: 0.2577\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.8022 - binary_accuracy: 0.9076 - loss: 0.2593 - val_auc: 0.8099 - val_binary_accuracy: 0.9081 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8163 - binary_accuracy: 0.9121 - loss: 0.2474\n",
            "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9081, AUC = 0.8099\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6593 - binary_accuracy: 0.8358 - loss: 0.3686 - val_auc: 0.7730 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9056 - loss: 0.2678 - val_auc: 0.7836 - val_binary_accuracy: 0.9072 - val_loss: 0.2660\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9079 - loss: 0.2644 - val_auc: 0.7903 - val_binary_accuracy: 0.9090 - val_loss: 0.2631\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9084 - loss: 0.2629 - val_auc: 0.7951 - val_binary_accuracy: 0.9094 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9092 - loss: 0.2618 - val_auc: 0.7962 - val_binary_accuracy: 0.9097 - val_loss: 0.2599\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9095 - loss: 0.2610 - val_auc: 0.7950 - val_binary_accuracy: 0.9096 - val_loss: 0.2597\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9091 - loss: 0.2602 - val_auc: 0.7995 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9096 - loss: 0.2593 - val_auc: 0.8022 - val_binary_accuracy: 0.9106 - val_loss: 0.2576\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7903 - binary_accuracy: 0.9098 - loss: 0.2591 - val_auc: 0.8015 - val_binary_accuracy: 0.9109 - val_loss: 0.2574\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7908 - binary_accuracy: 0.9093 - loss: 0.2590 - val_auc: 0.8032 - val_binary_accuracy: 0.9113 - val_loss: 0.2575\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7936 - binary_accuracy: 0.9123 - loss: 0.2592\n",
            "Fold 3 Metrics: Loss = 0.2575, Accuracy = 0.9113, AUC = 0.8032\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7258 - binary_accuracy: 0.9049 - loss: 0.2833 - val_auc: 0.7871 - val_binary_accuracy: 0.9054 - val_loss: 0.2654\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9080 - loss: 0.2650 - val_auc: 0.7945 - val_binary_accuracy: 0.9079 - val_loss: 0.2623\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7878 - binary_accuracy: 0.9099 - loss: 0.2616 - val_auc: 0.7993 - val_binary_accuracy: 0.9078 - val_loss: 0.2598\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9104 - loss: 0.2595 - val_auc: 0.7999 - val_binary_accuracy: 0.9079 - val_loss: 0.2598\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7929 - binary_accuracy: 0.9102 - loss: 0.2587 - val_auc: 0.8000 - val_binary_accuracy: 0.9090 - val_loss: 0.2591\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9101 - loss: 0.2590 - val_auc: 0.8015 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7938 - binary_accuracy: 0.9104 - loss: 0.2579 - val_auc: 0.8010 - val_binary_accuracy: 0.9091 - val_loss: 0.2589\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9102 - loss: 0.2578 - val_auc: 0.8010 - val_binary_accuracy: 0.9091 - val_loss: 0.2586\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7952 - binary_accuracy: 0.9102 - loss: 0.2577 - val_auc: 0.8026 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7966 - binary_accuracy: 0.9102 - loss: 0.2569 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2589\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7858 - binary_accuracy: 0.9084 - loss: 0.2648\n",
            "Fold 4 Metrics: Loss = 0.2589, Accuracy = 0.9087, AUC = 0.8037\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7170 - binary_accuracy: 0.9007 - loss: 0.2948 - val_auc: 0.7877 - val_binary_accuracy: 0.9045 - val_loss: 0.2642\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7721 - binary_accuracy: 0.9062 - loss: 0.2709 - val_auc: 0.7960 - val_binary_accuracy: 0.9063 - val_loss: 0.2594\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9072 - loss: 0.2680 - val_auc: 0.7969 - val_binary_accuracy: 0.9082 - val_loss: 0.2571\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9080 - loss: 0.2658 - val_auc: 0.8007 - val_binary_accuracy: 0.9090 - val_loss: 0.2556\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9079 - loss: 0.2643 - val_auc: 0.8047 - val_binary_accuracy: 0.9095 - val_loss: 0.2544\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9085 - loss: 0.2628 - val_auc: 0.8059 - val_binary_accuracy: 0.9100 - val_loss: 0.2533\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9089 - loss: 0.2621 - val_auc: 0.8063 - val_binary_accuracy: 0.9106 - val_loss: 0.2530\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9094 - loss: 0.2615 - val_auc: 0.8069 - val_binary_accuracy: 0.9106 - val_loss: 0.2523\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7933 - binary_accuracy: 0.9098 - loss: 0.2609 - val_auc: 0.8058 - val_binary_accuracy: 0.9100 - val_loss: 0.2532\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8063 - val_binary_accuracy: 0.9098 - val_loss: 0.2536\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8166 - binary_accuracy: 0.9075 - loss: 0.2519\n",
            "Fold 5 Metrics: Loss = 0.2536, Accuracy = 0.9098, AUC = 0.8063\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2574\n",
            "Average Accuracy: 0.9095\n",
            "Average AUC: 0.8041\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 1, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7411 - binary_accuracy: 0.9076 - loss: 0.2779 - val_auc: 0.7812 - val_binary_accuracy: 0.9053 - val_loss: 0.2688\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7976 - binary_accuracy: 0.9103 - loss: 0.2552 - val_auc: 0.7894 - val_binary_accuracy: 0.9066 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8026 - binary_accuracy: 0.9114 - loss: 0.2526 - val_auc: 0.7911 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8064 - binary_accuracy: 0.9118 - loss: 0.2506 - val_auc: 0.7926 - val_binary_accuracy: 0.9079 - val_loss: 0.2629\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8080 - binary_accuracy: 0.9121 - loss: 0.2496 - val_auc: 0.7926 - val_binary_accuracy: 0.9076 - val_loss: 0.2626\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8100 - binary_accuracy: 0.9125 - loss: 0.2487 - val_auc: 0.7943 - val_binary_accuracy: 0.9078 - val_loss: 0.2618\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8107 - binary_accuracy: 0.9130 - loss: 0.2482 - val_auc: 0.7932 - val_binary_accuracy: 0.9082 - val_loss: 0.2620\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8119 - binary_accuracy: 0.9131 - loss: 0.2475 - val_auc: 0.7942 - val_binary_accuracy: 0.9084 - val_loss: 0.2607\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8129 - binary_accuracy: 0.9130 - loss: 0.2470 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2600\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8142 - binary_accuracy: 0.9132 - loss: 0.2463 - val_auc: 0.7956 - val_binary_accuracy: 0.9081 - val_loss: 0.2602\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9114 - loss: 0.2519\n",
            "Fold 1 Metrics: Loss = 0.2602, Accuracy = 0.9081, AUC = 0.7956\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6722 - binary_accuracy: 0.8454 - loss: 0.3876 - val_auc: 0.7945 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9038 - loss: 0.2691 - val_auc: 0.8036 - val_binary_accuracy: 0.9060 - val_loss: 0.2605\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9059 - loss: 0.2651 - val_auc: 0.8067 - val_binary_accuracy: 0.9065 - val_loss: 0.2591\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9063 - loss: 0.2635 - val_auc: 0.8077 - val_binary_accuracy: 0.9068 - val_loss: 0.2582\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7963 - binary_accuracy: 0.9077 - loss: 0.2620 - val_auc: 0.8086 - val_binary_accuracy: 0.9071 - val_loss: 0.2570\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7978 - binary_accuracy: 0.9075 - loss: 0.2610 - val_auc: 0.8077 - val_binary_accuracy: 0.9075 - val_loss: 0.2579\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7976 - binary_accuracy: 0.9081 - loss: 0.2607 - val_auc: 0.8073 - val_binary_accuracy: 0.9078 - val_loss: 0.2573\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7990 - binary_accuracy: 0.9084 - loss: 0.2602 - val_auc: 0.8079 - val_binary_accuracy: 0.9079 - val_loss: 0.2567\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8006 - binary_accuracy: 0.9082 - loss: 0.2595 - val_auc: 0.8077 - val_binary_accuracy: 0.9079 - val_loss: 0.2573\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9081 - loss: 0.2593 - val_auc: 0.8085 - val_binary_accuracy: 0.9082 - val_loss: 0.2571\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8184 - binary_accuracy: 0.9118 - loss: 0.2458\n",
            "Fold 2 Metrics: Loss = 0.2571, Accuracy = 0.9082, AUC = 0.8085\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7200 - binary_accuracy: 0.9013 - loss: 0.2934 - val_auc: 0.7870 - val_binary_accuracy: 0.9059 - val_loss: 0.2656\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9067 - loss: 0.2680 - val_auc: 0.7945 - val_binary_accuracy: 0.9078 - val_loss: 0.2621\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9078 - loss: 0.2657 - val_auc: 0.7981 - val_binary_accuracy: 0.9090 - val_loss: 0.2602\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9078 - loss: 0.2643 - val_auc: 0.7971 - val_binary_accuracy: 0.9099 - val_loss: 0.2597\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7822 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8005 - val_binary_accuracy: 0.9100 - val_loss: 0.2582\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9090 - loss: 0.2627 - val_auc: 0.8011 - val_binary_accuracy: 0.9102 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9092 - loss: 0.2621 - val_auc: 0.8014 - val_binary_accuracy: 0.9106 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9098 - loss: 0.2614 - val_auc: 0.8027 - val_binary_accuracy: 0.9107 - val_loss: 0.2570\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9100 - loss: 0.2608 - val_auc: 0.8022 - val_binary_accuracy: 0.9102 - val_loss: 0.2578\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9096 - loss: 0.2605 - val_auc: 0.8036 - val_binary_accuracy: 0.9106 - val_loss: 0.2570\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7954 - binary_accuracy: 0.9112 - loss: 0.2577\n",
            "Fold 3 Metrics: Loss = 0.2570, Accuracy = 0.9106, AUC = 0.8036\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7369 - binary_accuracy: 0.9059 - loss: 0.2818 - val_auc: 0.7948 - val_binary_accuracy: 0.9082 - val_loss: 0.2608\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9097 - loss: 0.2631 - val_auc: 0.7997 - val_binary_accuracy: 0.9088 - val_loss: 0.2580\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9110 - loss: 0.2609 - val_auc: 0.8008 - val_binary_accuracy: 0.9082 - val_loss: 0.2578\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9107 - loss: 0.2596 - val_auc: 0.8025 - val_binary_accuracy: 0.9085 - val_loss: 0.2570\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9107 - loss: 0.2587 - val_auc: 0.8047 - val_binary_accuracy: 0.9093 - val_loss: 0.2564\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9109 - loss: 0.2581 - val_auc: 0.8047 - val_binary_accuracy: 0.9091 - val_loss: 0.2562\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9107 - loss: 0.2573 - val_auc: 0.8056 - val_binary_accuracy: 0.9090 - val_loss: 0.2560\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9110 - loss: 0.2574 - val_auc: 0.8054 - val_binary_accuracy: 0.9090 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7958 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2552\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9110 - loss: 0.2564 - val_auc: 0.8072 - val_binary_accuracy: 0.9081 - val_loss: 0.2552\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7874 - binary_accuracy: 0.9081 - loss: 0.2626\n",
            "Fold 4 Metrics: Loss = 0.2552, Accuracy = 0.9081, AUC = 0.8072\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7378 - binary_accuracy: 0.9045 - loss: 0.2839 - val_auc: 0.7956 - val_binary_accuracy: 0.9073 - val_loss: 0.2611\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9069 - loss: 0.2696 - val_auc: 0.8026 - val_binary_accuracy: 0.9088 - val_loss: 0.2601\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9073 - loss: 0.2684 - val_auc: 0.8037 - val_binary_accuracy: 0.9088 - val_loss: 0.2564\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9081 - loss: 0.2660 - val_auc: 0.8060 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.8079 - val_binary_accuracy: 0.9093 - val_loss: 0.2534\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8073 - val_binary_accuracy: 0.9098 - val_loss: 0.2531\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9087 - loss: 0.2626 - val_auc: 0.8084 - val_binary_accuracy: 0.9095 - val_loss: 0.2527\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9087 - loss: 0.2621 - val_auc: 0.8082 - val_binary_accuracy: 0.9093 - val_loss: 0.2522\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7919 - binary_accuracy: 0.9084 - loss: 0.2617 - val_auc: 0.8076 - val_binary_accuracy: 0.9098 - val_loss: 0.2519\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9090 - loss: 0.2609 - val_auc: 0.8089 - val_binary_accuracy: 0.9101 - val_loss: 0.2515\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9084 - loss: 0.2504\n",
            "Fold 5 Metrics: Loss = 0.2515, Accuracy = 0.9101, AUC = 0.8089\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2562\n",
            "Average Accuracy: 0.9090\n",
            "Average AUC: 0.8047\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 2, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6182 - binary_accuracy: 0.7984 - loss: 0.4154 - val_auc: 0.7467 - val_binary_accuracy: 0.9044 - val_loss: 0.2788\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7663 - binary_accuracy: 0.9069 - loss: 0.2674 - val_auc: 0.7560 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9069 - loss: 0.2627 - val_auc: 0.7626 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9092 - loss: 0.2606 - val_auc: 0.7673 - val_binary_accuracy: 0.9059 - val_loss: 0.2701\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.7688 - val_binary_accuracy: 0.9059 - val_loss: 0.2698\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9106 - loss: 0.2581 - val_auc: 0.7702 - val_binary_accuracy: 0.9069 - val_loss: 0.2683\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9111 - loss: 0.2574 - val_auc: 0.7720 - val_binary_accuracy: 0.9072 - val_loss: 0.2674\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9111 - loss: 0.2568 - val_auc: 0.7714 - val_binary_accuracy: 0.9073 - val_loss: 0.2673\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9111 - loss: 0.2571 - val_auc: 0.7740 - val_binary_accuracy: 0.9076 - val_loss: 0.2669\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9122 - loss: 0.2564 - val_auc: 0.7748 - val_binary_accuracy: 0.9078 - val_loss: 0.2669\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7723 - binary_accuracy: 0.9104 - loss: 0.2597\n",
            "Fold 1 Metrics: Loss = 0.2669, Accuracy = 0.9078, AUC = 0.7748\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5405 - binary_accuracy: 0.9022 - loss: 0.3564 - val_auc: 0.7345 - val_binary_accuracy: 0.9042 - val_loss: 0.2920\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7368 - binary_accuracy: 0.9029 - loss: 0.2893 - val_auc: 0.7651 - val_binary_accuracy: 0.9042 - val_loss: 0.2800\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7604 - binary_accuracy: 0.9029 - loss: 0.2777 - val_auc: 0.7794 - val_binary_accuracy: 0.9042 - val_loss: 0.2739\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7654 - binary_accuracy: 0.9029 - loss: 0.2757 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9029 - loss: 0.2744 - val_auc: 0.7915 - val_binary_accuracy: 0.9042 - val_loss: 0.2700\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9029 - loss: 0.2738 - val_auc: 0.7861 - val_binary_accuracy: 0.9042 - val_loss: 0.2696\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9029 - loss: 0.2735 - val_auc: 0.7868 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9029 - loss: 0.2732 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9029 - loss: 0.2729 - val_auc: 0.7914 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.7974 - val_binary_accuracy: 0.9042 - val_loss: 0.2669\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7991 - binary_accuracy: 0.9092 - loss: 0.2580\n",
            "Fold 2 Metrics: Loss = 0.2669, Accuracy = 0.9042, AUC = 0.7974\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6537 - binary_accuracy: 0.8582 - loss: 0.3662 - val_auc: 0.7539 - val_binary_accuracy: 0.9042 - val_loss: 0.2782\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9051 - loss: 0.2736 - val_auc: 0.7799 - val_binary_accuracy: 0.9042 - val_loss: 0.2692\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9051 - loss: 0.2683 - val_auc: 0.7812 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9051 - loss: 0.2671 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2686\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7860 - val_binary_accuracy: 0.9042 - val_loss: 0.2681\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9051 - loss: 0.2656 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9051 - loss: 0.2652 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2685\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7801 - binary_accuracy: 0.9051 - loss: 0.2646 - val_auc: 0.7864 - val_binary_accuracy: 0.9042 - val_loss: 0.2682\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9051 - loss: 0.2642 - val_auc: 0.7865 - val_binary_accuracy: 0.9042 - val_loss: 0.2679\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9051 - loss: 0.2638 - val_auc: 0.7863 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7823 - binary_accuracy: 0.9046 - loss: 0.2684\n",
            "Fold 3 Metrics: Loss = 0.2677, Accuracy = 0.9042, AUC = 0.7863\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6045 - binary_accuracy: 0.8124 - loss: 0.4151 - val_auc: 0.7433 - val_binary_accuracy: 0.9044 - val_loss: 0.2850\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7468 - binary_accuracy: 0.9047 - loss: 0.2800 - val_auc: 0.7575 - val_binary_accuracy: 0.9044 - val_loss: 0.2764\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9047 - loss: 0.2709 - val_auc: 0.7677 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9050 - loss: 0.2684 - val_auc: 0.7764 - val_binary_accuracy: 0.9050 - val_loss: 0.2710\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9058 - loss: 0.2669 - val_auc: 0.7786 - val_binary_accuracy: 0.9056 - val_loss: 0.2689\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9064 - loss: 0.2661 - val_auc: 0.7781 - val_binary_accuracy: 0.9059 - val_loss: 0.2681\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7784 - binary_accuracy: 0.9072 - loss: 0.2651 - val_auc: 0.7782 - val_binary_accuracy: 0.9064 - val_loss: 0.2687\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9081 - loss: 0.2644 - val_auc: 0.7836 - val_binary_accuracy: 0.9072 - val_loss: 0.2689\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9085 - loss: 0.2639 - val_auc: 0.7846 - val_binary_accuracy: 0.9079 - val_loss: 0.2688\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9081 - loss: 0.2634 - val_auc: 0.7845 - val_binary_accuracy: 0.9081 - val_loss: 0.2687\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7650 - binary_accuracy: 0.9084 - loss: 0.2739\n",
            "Fold 4 Metrics: Loss = 0.2687, Accuracy = 0.9081, AUC = 0.7845\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5155 - binary_accuracy: 0.7282 - loss: 0.5179 - val_auc: 0.6883 - val_binary_accuracy: 0.9044 - val_loss: 0.3035\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6826 - binary_accuracy: 0.9039 - loss: 0.3017 - val_auc: 0.7339 - val_binary_accuracy: 0.9044 - val_loss: 0.2869\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7254 - binary_accuracy: 0.9039 - loss: 0.2886 - val_auc: 0.7520 - val_binary_accuracy: 0.9044 - val_loss: 0.2769\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7356 - binary_accuracy: 0.9039 - loss: 0.2813 - val_auc: 0.7600 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7478 - binary_accuracy: 0.9039 - loss: 0.2801 - val_auc: 0.7637 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7571 - binary_accuracy: 0.9039 - loss: 0.2771 - val_auc: 0.7667 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9039 - loss: 0.2764 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7566 - binary_accuracy: 0.9039 - loss: 0.2760 - val_auc: 0.7682 - val_binary_accuracy: 0.9044 - val_loss: 0.2676\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7574 - binary_accuracy: 0.9039 - loss: 0.2757 - val_auc: 0.7691 - val_binary_accuracy: 0.9044 - val_loss: 0.2673\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9039 - loss: 0.2754 - val_auc: 0.7700 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7850 - binary_accuracy: 0.9013 - loss: 0.2659\n",
            "Fold 5 Metrics: Loss = 0.2671, Accuracy = 0.9044, AUC = 0.7700\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2675\n",
            "Average Accuracy: 0.9057\n",
            "Average AUC: 0.7826\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 2, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6210 - binary_accuracy: 0.8316 - loss: 0.3766 - val_auc: 0.7564 - val_binary_accuracy: 0.9044 - val_loss: 0.2802\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9069 - loss: 0.2693 - val_auc: 0.7684 - val_binary_accuracy: 0.9044 - val_loss: 0.2736\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9069 - loss: 0.2634 - val_auc: 0.7719 - val_binary_accuracy: 0.9044 - val_loss: 0.2706\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9069 - loss: 0.2588 - val_auc: 0.7793 - val_binary_accuracy: 0.9044 - val_loss: 0.2680\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9069 - loss: 0.2574 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9069 - loss: 0.2565 - val_auc: 0.7785 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9069 - loss: 0.2559 - val_auc: 0.7813 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8022 - binary_accuracy: 0.9069 - loss: 0.2552 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9069 - loss: 0.2545 - val_auc: 0.7845 - val_binary_accuracy: 0.9044 - val_loss: 0.2672\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7878 - binary_accuracy: 0.9084 - loss: 0.2590\n",
            "Fold 1 Metrics: Loss = 0.2672, Accuracy = 0.9044, AUC = 0.7845\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6579 - binary_accuracy: 0.8703 - loss: 0.3423 - val_auc: 0.7854 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7698 - binary_accuracy: 0.9029 - loss: 0.2735 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2734\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9034 - loss: 0.2714 - val_auc: 0.7927 - val_binary_accuracy: 0.9042 - val_loss: 0.2691\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9034 - loss: 0.2691 - val_auc: 0.7955 - val_binary_accuracy: 0.9048 - val_loss: 0.2655\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9051 - loss: 0.2676 - val_auc: 0.7972 - val_binary_accuracy: 0.9051 - val_loss: 0.2669\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9049 - loss: 0.2666 - val_auc: 0.8002 - val_binary_accuracy: 0.9062 - val_loss: 0.2674\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9057 - loss: 0.2654 - val_auc: 0.7997 - val_binary_accuracy: 0.9063 - val_loss: 0.2652\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9066 - loss: 0.2645 - val_auc: 0.8026 - val_binary_accuracy: 0.9059 - val_loss: 0.2649\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9064 - loss: 0.2640 - val_auc: 0.8047 - val_binary_accuracy: 0.9066 - val_loss: 0.2629\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9071 - loss: 0.2631 - val_auc: 0.8060 - val_binary_accuracy: 0.9071 - val_loss: 0.2616\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8109 - binary_accuracy: 0.9111 - loss: 0.2509\n",
            "Fold 2 Metrics: Loss = 0.2616, Accuracy = 0.9071, AUC = 0.8060\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.5777 - binary_accuracy: 0.8146 - loss: 0.4277 - val_auc: 0.7277 - val_binary_accuracy: 0.9042 - val_loss: 0.2887\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7181 - binary_accuracy: 0.9051 - loss: 0.2872 - val_auc: 0.7590 - val_binary_accuracy: 0.9042 - val_loss: 0.2760\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7548 - binary_accuracy: 0.9051 - loss: 0.2739 - val_auc: 0.7703 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7679 - binary_accuracy: 0.9051 - loss: 0.2695 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2721\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7689 - binary_accuracy: 0.9051 - loss: 0.2681 - val_auc: 0.7765 - val_binary_accuracy: 0.9042 - val_loss: 0.2714\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7710 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7782 - val_binary_accuracy: 0.9042 - val_loss: 0.2710\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7717 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7795 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9051 - loss: 0.2680 - val_auc: 0.7807 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7723 - binary_accuracy: 0.9051 - loss: 0.2679 - val_auc: 0.7821 - val_binary_accuracy: 0.9042 - val_loss: 0.2702\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7848 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7783 - binary_accuracy: 0.9046 - loss: 0.2700\n",
            "Fold 3 Metrics: Loss = 0.2694, Accuracy = 0.9042, AUC = 0.7848\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6428 - binary_accuracy: 0.8646 - loss: 0.3499 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7727 - binary_accuracy: 0.9048 - loss: 0.2689 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2691\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9049 - loss: 0.2668 - val_auc: 0.7831 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9062 - loss: 0.2653 - val_auc: 0.7865 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7850 - binary_accuracy: 0.9060 - loss: 0.2640 - val_auc: 0.7878 - val_binary_accuracy: 0.9064 - val_loss: 0.2660\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9068 - loss: 0.2631 - val_auc: 0.7898 - val_binary_accuracy: 0.9070 - val_loss: 0.2658\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9081 - loss: 0.2624 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2640\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9081 - loss: 0.2617 - val_auc: 0.7935 - val_binary_accuracy: 0.9081 - val_loss: 0.2637\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9084 - loss: 0.2609 - val_auc: 0.7947 - val_binary_accuracy: 0.9078 - val_loss: 0.2637\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9085 - loss: 0.2604 - val_auc: 0.7917 - val_binary_accuracy: 0.9084 - val_loss: 0.2649\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7694 - binary_accuracy: 0.9074 - loss: 0.2708\n",
            "Fold 4 Metrics: Loss = 0.2649, Accuracy = 0.9084, AUC = 0.7917\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6287 - binary_accuracy: 0.8434 - loss: 0.3650 - val_auc: 0.7751 - val_binary_accuracy: 0.9044 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7647 - binary_accuracy: 0.9040 - loss: 0.2751 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2643\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9040 - loss: 0.2722 - val_auc: 0.7903 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.7912 - val_binary_accuracy: 0.9044 - val_loss: 0.2613\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9040 - loss: 0.2701 - val_auc: 0.7929 - val_binary_accuracy: 0.9044 - val_loss: 0.2607\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.7891 - val_binary_accuracy: 0.9044 - val_loss: 0.2610\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9041 - loss: 0.2688 - val_auc: 0.7926 - val_binary_accuracy: 0.9044 - val_loss: 0.2596\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9046 - loss: 0.2674 - val_auc: 0.7946 - val_binary_accuracy: 0.9054 - val_loss: 0.2588\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9053 - loss: 0.2668 - val_auc: 0.7965 - val_binary_accuracy: 0.9044 - val_loss: 0.2580\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9042 - loss: 0.2663 - val_auc: 0.7954 - val_binary_accuracy: 0.9078 - val_loss: 0.2580\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8084 - binary_accuracy: 0.9055 - loss: 0.2550\n",
            "Fold 5 Metrics: Loss = 0.2580, Accuracy = 0.9078, AUC = 0.7954\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2642\n",
            "Average Accuracy: 0.9064\n",
            "Average AUC: 0.7925\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 2, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7302 - binary_accuracy: 0.9069 - loss: 0.2803 - val_auc: 0.7687 - val_binary_accuracy: 0.9044 - val_loss: 0.2716\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9079 - loss: 0.2593 - val_auc: 0.7789 - val_binary_accuracy: 0.9069 - val_loss: 0.2654\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7968 - binary_accuracy: 0.9100 - loss: 0.2550 - val_auc: 0.7823 - val_binary_accuracy: 0.9068 - val_loss: 0.2640\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9106 - loss: 0.2526 - val_auc: 0.7833 - val_binary_accuracy: 0.9073 - val_loss: 0.2637\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8049 - binary_accuracy: 0.9118 - loss: 0.2509 - val_auc: 0.7853 - val_binary_accuracy: 0.9075 - val_loss: 0.2625\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8066 - binary_accuracy: 0.9122 - loss: 0.2496 - val_auc: 0.7853 - val_binary_accuracy: 0.9084 - val_loss: 0.2628\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8084 - binary_accuracy: 0.9125 - loss: 0.2487 - val_auc: 0.7856 - val_binary_accuracy: 0.9091 - val_loss: 0.2626\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8093 - binary_accuracy: 0.9130 - loss: 0.2485 - val_auc: 0.7869 - val_binary_accuracy: 0.9096 - val_loss: 0.2618\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8111 - binary_accuracy: 0.9126 - loss: 0.2473 - val_auc: 0.7876 - val_binary_accuracy: 0.9094 - val_loss: 0.2616\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8124 - binary_accuracy: 0.9130 - loss: 0.2466 - val_auc: 0.7878 - val_binary_accuracy: 0.9094 - val_loss: 0.2616\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7879 - binary_accuracy: 0.9129 - loss: 0.2539\n",
            "Fold 1 Metrics: Loss = 0.2616, Accuracy = 0.9094, AUC = 0.7878\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.7044 - binary_accuracy: 0.8960 - loss: 0.3059 - val_auc: 0.7818 - val_binary_accuracy: 0.9051 - val_loss: 0.2685\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7738 - binary_accuracy: 0.9045 - loss: 0.2723 - val_auc: 0.7957 - val_binary_accuracy: 0.9057 - val_loss: 0.2623\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9050 - loss: 0.2676 - val_auc: 0.8027 - val_binary_accuracy: 0.9054 - val_loss: 0.2587\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9061 - loss: 0.2645 - val_auc: 0.8040 - val_binary_accuracy: 0.9059 - val_loss: 0.2576\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9062 - loss: 0.2628 - val_auc: 0.8042 - val_binary_accuracy: 0.9062 - val_loss: 0.2574\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7971 - binary_accuracy: 0.9073 - loss: 0.2617 - val_auc: 0.8032 - val_binary_accuracy: 0.9065 - val_loss: 0.2574\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7982 - binary_accuracy: 0.9070 - loss: 0.2612 - val_auc: 0.8021 - val_binary_accuracy: 0.9069 - val_loss: 0.2572\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9074 - loss: 0.2604 - val_auc: 0.8037 - val_binary_accuracy: 0.9068 - val_loss: 0.2576\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9072 - loss: 0.2599 - val_auc: 0.8041 - val_binary_accuracy: 0.9066 - val_loss: 0.2578\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8020 - binary_accuracy: 0.9071 - loss: 0.2595 - val_auc: 0.8032 - val_binary_accuracy: 0.9066 - val_loss: 0.2582\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8091 - binary_accuracy: 0.9102 - loss: 0.2482\n",
            "Fold 2 Metrics: Loss = 0.2582, Accuracy = 0.9066, AUC = 0.8032\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7223 - binary_accuracy: 0.9053 - loss: 0.2857 - val_auc: 0.7872 - val_binary_accuracy: 0.9051 - val_loss: 0.2662\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9063 - loss: 0.2711 - val_auc: 0.7939 - val_binary_accuracy: 0.9075 - val_loss: 0.2626\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.7959 - val_binary_accuracy: 0.9065 - val_loss: 0.2615\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7769 - binary_accuracy: 0.9081 - loss: 0.2654 - val_auc: 0.7966 - val_binary_accuracy: 0.9088 - val_loss: 0.2607\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9086 - loss: 0.2641 - val_auc: 0.7980 - val_binary_accuracy: 0.9096 - val_loss: 0.2597\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9089 - loss: 0.2630 - val_auc: 0.7982 - val_binary_accuracy: 0.9100 - val_loss: 0.2590\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8013 - val_binary_accuracy: 0.9103 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7854 - binary_accuracy: 0.9090 - loss: 0.2614 - val_auc: 0.8016 - val_binary_accuracy: 0.9107 - val_loss: 0.2584\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9096 - loss: 0.2612 - val_auc: 0.8015 - val_binary_accuracy: 0.9110 - val_loss: 0.2577\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2574\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7950 - binary_accuracy: 0.9123 - loss: 0.2580\n",
            "Fold 3 Metrics: Loss = 0.2574, Accuracy = 0.9107, AUC = 0.8029\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6472 - binary_accuracy: 0.8780 - loss: 0.3309 - val_auc: 0.7821 - val_binary_accuracy: 0.9048 - val_loss: 0.2671\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9063 - loss: 0.2671 - val_auc: 0.7907 - val_binary_accuracy: 0.9073 - val_loss: 0.2628\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9084 - loss: 0.2652 - val_auc: 0.7940 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9089 - loss: 0.2633 - val_auc: 0.7953 - val_binary_accuracy: 0.9082 - val_loss: 0.2607\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9099 - loss: 0.2627 - val_auc: 0.7957 - val_binary_accuracy: 0.9093 - val_loss: 0.2595\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.7978 - val_binary_accuracy: 0.9097 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9104 - loss: 0.2598 - val_auc: 0.8003 - val_binary_accuracy: 0.9100 - val_loss: 0.2579\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9102 - loss: 0.2595 - val_auc: 0.8008 - val_binary_accuracy: 0.9109 - val_loss: 0.2585\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9106 - loss: 0.2586 - val_auc: 0.8022 - val_binary_accuracy: 0.9104 - val_loss: 0.2578\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9103 - loss: 0.2583 - val_auc: 0.8015 - val_binary_accuracy: 0.9101 - val_loss: 0.2577\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7813 - binary_accuracy: 0.9099 - loss: 0.2636\n",
            "Fold 4 Metrics: Loss = 0.2577, Accuracy = 0.9101, AUC = 0.8015\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6722 - binary_accuracy: 0.9038 - loss: 0.3049 - val_auc: 0.7820 - val_binary_accuracy: 0.9050 - val_loss: 0.2658\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9042 - loss: 0.2749 - val_auc: 0.7932 - val_binary_accuracy: 0.9045 - val_loss: 0.2604\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9060 - loss: 0.2704 - val_auc: 0.7930 - val_binary_accuracy: 0.9059 - val_loss: 0.2605\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9070 - loss: 0.2689 - val_auc: 0.7959 - val_binary_accuracy: 0.9097 - val_loss: 0.2572\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7815 - binary_accuracy: 0.9082 - loss: 0.2667 - val_auc: 0.7991 - val_binary_accuracy: 0.9091 - val_loss: 0.2567\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9083 - loss: 0.2654 - val_auc: 0.8011 - val_binary_accuracy: 0.9107 - val_loss: 0.2552\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9086 - loss: 0.2640 - val_auc: 0.8025 - val_binary_accuracy: 0.9113 - val_loss: 0.2546\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9093 - loss: 0.2632 - val_auc: 0.8036 - val_binary_accuracy: 0.9113 - val_loss: 0.2538\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9095 - loss: 0.2625 - val_auc: 0.8044 - val_binary_accuracy: 0.9113 - val_loss: 0.2534\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9096 - loss: 0.2624 - val_auc: 0.8062 - val_binary_accuracy: 0.9118 - val_loss: 0.2528\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8150 - binary_accuracy: 0.9100 - loss: 0.2509\n",
            "Fold 5 Metrics: Loss = 0.2528, Accuracy = 0.9118, AUC = 0.8062\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2576\n",
            "Average Accuracy: 0.9097\n",
            "Average AUC: 0.8003\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 2, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.7228 - binary_accuracy: 0.9067 - loss: 0.2842 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2688\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9083 - loss: 0.2595 - val_auc: 0.7859 - val_binary_accuracy: 0.9069 - val_loss: 0.2660\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9104 - loss: 0.2555 - val_auc: 0.7893 - val_binary_accuracy: 0.9062 - val_loss: 0.2652\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8012 - binary_accuracy: 0.9113 - loss: 0.2529 - val_auc: 0.7898 - val_binary_accuracy: 0.9072 - val_loss: 0.2645\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8052 - binary_accuracy: 0.9122 - loss: 0.2506 - val_auc: 0.7907 - val_binary_accuracy: 0.9082 - val_loss: 0.2632\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8087 - binary_accuracy: 0.9121 - loss: 0.2489 - val_auc: 0.7918 - val_binary_accuracy: 0.9081 - val_loss: 0.2616\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8102 - binary_accuracy: 0.9129 - loss: 0.2478 - val_auc: 0.7920 - val_binary_accuracy: 0.9079 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8118 - binary_accuracy: 0.9126 - loss: 0.2468 - val_auc: 0.7926 - val_binary_accuracy: 0.9081 - val_loss: 0.2603\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8135 - binary_accuracy: 0.9131 - loss: 0.2461 - val_auc: 0.7921 - val_binary_accuracy: 0.9091 - val_loss: 0.2598\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8144 - binary_accuracy: 0.9131 - loss: 0.2455 - val_auc: 0.7924 - val_binary_accuracy: 0.9094 - val_loss: 0.2595\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7912 - binary_accuracy: 0.9129 - loss: 0.2519\n",
            "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9094, AUC = 0.7924\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6794 - binary_accuracy: 0.8797 - loss: 0.3308 - val_auc: 0.8003 - val_binary_accuracy: 0.9057 - val_loss: 0.2620\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9054 - loss: 0.2680 - val_auc: 0.8019 - val_binary_accuracy: 0.9065 - val_loss: 0.2609\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9066 - loss: 0.2656 - val_auc: 0.8038 - val_binary_accuracy: 0.9075 - val_loss: 0.2594\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7914 - binary_accuracy: 0.9075 - loss: 0.2639 - val_auc: 0.8055 - val_binary_accuracy: 0.9082 - val_loss: 0.2584\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9080 - loss: 0.2621 - val_auc: 0.8062 - val_binary_accuracy: 0.9068 - val_loss: 0.2581\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9085 - loss: 0.2610 - val_auc: 0.8077 - val_binary_accuracy: 0.9081 - val_loss: 0.2569\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7986 - binary_accuracy: 0.9083 - loss: 0.2601 - val_auc: 0.8082 - val_binary_accuracy: 0.9082 - val_loss: 0.2564\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8004 - binary_accuracy: 0.9083 - loss: 0.2594 - val_auc: 0.8093 - val_binary_accuracy: 0.9081 - val_loss: 0.2555\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9081 - loss: 0.2591 - val_auc: 0.8086 - val_binary_accuracy: 0.9085 - val_loss: 0.2558\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9081 - loss: 0.2588 - val_auc: 0.8088 - val_binary_accuracy: 0.9079 - val_loss: 0.2557\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9115 - loss: 0.2464\n",
            "Fold 2 Metrics: Loss = 0.2557, Accuracy = 0.9079, AUC = 0.8088\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7255 - binary_accuracy: 0.8980 - loss: 0.2938 - val_auc: 0.7890 - val_binary_accuracy: 0.9068 - val_loss: 0.2669\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7668 - binary_accuracy: 0.9067 - loss: 0.2703 - val_auc: 0.7921 - val_binary_accuracy: 0.9068 - val_loss: 0.2653\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9071 - loss: 0.2683 - val_auc: 0.7951 - val_binary_accuracy: 0.9082 - val_loss: 0.2626\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9080 - loss: 0.2667 - val_auc: 0.7981 - val_binary_accuracy: 0.9090 - val_loss: 0.2613\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9082 - loss: 0.2653 - val_auc: 0.7986 - val_binary_accuracy: 0.9091 - val_loss: 0.2612\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8002 - val_binary_accuracy: 0.9093 - val_loss: 0.2607\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9085 - loss: 0.2640 - val_auc: 0.8004 - val_binary_accuracy: 0.9094 - val_loss: 0.2593\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9087 - loss: 0.2630 - val_auc: 0.8005 - val_binary_accuracy: 0.9096 - val_loss: 0.2589\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.8017 - val_binary_accuracy: 0.9099 - val_loss: 0.2582\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9093 - loss: 0.2614 - val_auc: 0.8029 - val_binary_accuracy: 0.9107 - val_loss: 0.2572\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7949 - binary_accuracy: 0.9116 - loss: 0.2581\n",
            "Fold 3 Metrics: Loss = 0.2572, Accuracy = 0.9107, AUC = 0.8029\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6892 - binary_accuracy: 0.8896 - loss: 0.3105 - val_auc: 0.7928 - val_binary_accuracy: 0.9087 - val_loss: 0.2617\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9066 - loss: 0.2673 - val_auc: 0.7984 - val_binary_accuracy: 0.9073 - val_loss: 0.2590\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7824 - binary_accuracy: 0.9078 - loss: 0.2639 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2586\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9083 - loss: 0.2625 - val_auc: 0.8014 - val_binary_accuracy: 0.9091 - val_loss: 0.2569\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9088 - loss: 0.2611 - val_auc: 0.8038 - val_binary_accuracy: 0.9098 - val_loss: 0.2565\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9087 - loss: 0.2606 - val_auc: 0.8011 - val_binary_accuracy: 0.9088 - val_loss: 0.2571\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7913 - binary_accuracy: 0.9090 - loss: 0.2596 - val_auc: 0.8024 - val_binary_accuracy: 0.9094 - val_loss: 0.2563\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7917 - binary_accuracy: 0.9099 - loss: 0.2591 - val_auc: 0.8035 - val_binary_accuracy: 0.9094 - val_loss: 0.2559\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9098 - loss: 0.2588 - val_auc: 0.8040 - val_binary_accuracy: 0.9094 - val_loss: 0.2556\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9097 - loss: 0.2584 - val_auc: 0.8060 - val_binary_accuracy: 0.9097 - val_loss: 0.2550\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7860 - binary_accuracy: 0.9088 - loss: 0.2620\n",
            "Fold 4 Metrics: Loss = 0.2550, Accuracy = 0.9097, AUC = 0.8060\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - auc: 0.6383 - binary_accuracy: 0.8697 - loss: 0.3769 - val_auc: 0.7925 - val_binary_accuracy: 0.9090 - val_loss: 0.2635\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9050 - loss: 0.2729 - val_auc: 0.7996 - val_binary_accuracy: 0.9085 - val_loss: 0.2635\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9046 - loss: 0.2706 - val_auc: 0.8026 - val_binary_accuracy: 0.9103 - val_loss: 0.2606\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7766 - binary_accuracy: 0.9076 - loss: 0.2680 - val_auc: 0.8032 - val_binary_accuracy: 0.9101 - val_loss: 0.2565\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9089 - loss: 0.2664 - val_auc: 0.8036 - val_binary_accuracy: 0.9109 - val_loss: 0.2557\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9091 - loss: 0.2654 - val_auc: 0.8045 - val_binary_accuracy: 0.9107 - val_loss: 0.2539\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9094 - loss: 0.2643 - val_auc: 0.8040 - val_binary_accuracy: 0.9104 - val_loss: 0.2533\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9103 - loss: 0.2633 - val_auc: 0.8042 - val_binary_accuracy: 0.9110 - val_loss: 0.2530\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9106 - loss: 0.2627 - val_auc: 0.8051 - val_binary_accuracy: 0.9106 - val_loss: 0.2526\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9101 - loss: 0.2621 - val_auc: 0.8061 - val_binary_accuracy: 0.9113 - val_loss: 0.2527\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8172 - binary_accuracy: 0.9094 - loss: 0.2504\n",
            "Fold 5 Metrics: Loss = 0.2527, Accuracy = 0.9113, AUC = 0.8061\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2560\n",
            "Average Accuracy: 0.9098\n",
            "Average AUC: 0.8032\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 2, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7019 - binary_accuracy: 0.8908 - loss: 0.3147 - val_auc: 0.7819 - val_binary_accuracy: 0.9054 - val_loss: 0.2656\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9098 - loss: 0.2581 - val_auc: 0.7872 - val_binary_accuracy: 0.9078 - val_loss: 0.2634\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7967 - binary_accuracy: 0.9109 - loss: 0.2548 - val_auc: 0.7884 - val_binary_accuracy: 0.9078 - val_loss: 0.2646\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8000 - binary_accuracy: 0.9115 - loss: 0.2530 - val_auc: 0.7906 - val_binary_accuracy: 0.9079 - val_loss: 0.2642\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8037 - binary_accuracy: 0.9119 - loss: 0.2513 - val_auc: 0.7908 - val_binary_accuracy: 0.9078 - val_loss: 0.2635\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9120 - loss: 0.2501 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2625\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8075 - binary_accuracy: 0.9122 - loss: 0.2493 - val_auc: 0.7936 - val_binary_accuracy: 0.9087 - val_loss: 0.2618\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8088 - binary_accuracy: 0.9124 - loss: 0.2486 - val_auc: 0.7933 - val_binary_accuracy: 0.9087 - val_loss: 0.2611\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8096 - binary_accuracy: 0.9129 - loss: 0.2479 - val_auc: 0.7941 - val_binary_accuracy: 0.9085 - val_loss: 0.2607\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8105 - binary_accuracy: 0.9131 - loss: 0.2475 - val_auc: 0.7947 - val_binary_accuracy: 0.9084 - val_loss: 0.2606\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9108 - loss: 0.2526\n",
            "Fold 1 Metrics: Loss = 0.2606, Accuracy = 0.9084, AUC = 0.7947\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7231 - binary_accuracy: 0.9035 - loss: 0.2977 - val_auc: 0.7994 - val_binary_accuracy: 0.9056 - val_loss: 0.2685\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9050 - loss: 0.2684 - val_auc: 0.8049 - val_binary_accuracy: 0.9065 - val_loss: 0.2631\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9059 - loss: 0.2655 - val_auc: 0.8050 - val_binary_accuracy: 0.9072 - val_loss: 0.2612\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7934 - binary_accuracy: 0.9073 - loss: 0.2636 - val_auc: 0.8075 - val_binary_accuracy: 0.9081 - val_loss: 0.2599\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9071 - loss: 0.2624 - val_auc: 0.8096 - val_binary_accuracy: 0.9082 - val_loss: 0.2594\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9081 - loss: 0.2612 - val_auc: 0.8101 - val_binary_accuracy: 0.9079 - val_loss: 0.2591\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9087 - loss: 0.2605 - val_auc: 0.8096 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8010 - binary_accuracy: 0.9084 - loss: 0.2598 - val_auc: 0.8099 - val_binary_accuracy: 0.9084 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9092 - loss: 0.2593 - val_auc: 0.8106 - val_binary_accuracy: 0.9085 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8016 - binary_accuracy: 0.9092 - loss: 0.2592 - val_auc: 0.8111 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8190 - binary_accuracy: 0.9134 - loss: 0.2492\n",
            "Fold 2 Metrics: Loss = 0.2587, Accuracy = 0.9091, AUC = 0.8111\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.7099 - binary_accuracy: 0.9052 - loss: 0.2995 - val_auc: 0.7868 - val_binary_accuracy: 0.9085 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7685 - binary_accuracy: 0.9083 - loss: 0.2690 - val_auc: 0.7927 - val_binary_accuracy: 0.9104 - val_loss: 0.2645\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7732 - binary_accuracy: 0.9086 - loss: 0.2666 - val_auc: 0.7960 - val_binary_accuracy: 0.9106 - val_loss: 0.2623\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9080 - loss: 0.2658 - val_auc: 0.7983 - val_binary_accuracy: 0.9107 - val_loss: 0.2614\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.8003 - val_binary_accuracy: 0.9107 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9084 - loss: 0.2646 - val_auc: 0.8008 - val_binary_accuracy: 0.9112 - val_loss: 0.2601\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7775 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8021 - val_binary_accuracy: 0.9110 - val_loss: 0.2592\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7786 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8037 - val_binary_accuracy: 0.9112 - val_loss: 0.2590\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9087 - loss: 0.2631 - val_auc: 0.8038 - val_binary_accuracy: 0.9112 - val_loss: 0.2590\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - auc: 0.7796 - binary_accuracy: 0.9094 - loss: 0.2631 - val_auc: 0.8050 - val_binary_accuracy: 0.9110 - val_loss: 0.2576\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7977 - binary_accuracy: 0.9121 - loss: 0.2584\n",
            "Fold 3 Metrics: Loss = 0.2576, Accuracy = 0.9110, AUC = 0.8050\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6967 - binary_accuracy: 0.8868 - loss: 0.3252 - val_auc: 0.7942 - val_binary_accuracy: 0.9087 - val_loss: 0.2616\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9065 - loss: 0.2666 - val_auc: 0.7995 - val_binary_accuracy: 0.9085 - val_loss: 0.2588\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7825 - binary_accuracy: 0.9084 - loss: 0.2642 - val_auc: 0.8013 - val_binary_accuracy: 0.9067 - val_loss: 0.2587\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7852 - binary_accuracy: 0.9085 - loss: 0.2625 - val_auc: 0.8037 - val_binary_accuracy: 0.9066 - val_loss: 0.2576\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8041 - val_binary_accuracy: 0.9085 - val_loss: 0.2569\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7884 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8054 - val_binary_accuracy: 0.9094 - val_loss: 0.2558\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9104 - loss: 0.2599 - val_auc: 0.8067 - val_binary_accuracy: 0.9094 - val_loss: 0.2551\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9105 - loss: 0.2594 - val_auc: 0.8090 - val_binary_accuracy: 0.9093 - val_loss: 0.2540\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9105 - loss: 0.2590 - val_auc: 0.8088 - val_binary_accuracy: 0.9093 - val_loss: 0.2541\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7910 - binary_accuracy: 0.9107 - loss: 0.2586 - val_auc: 0.8094 - val_binary_accuracy: 0.9093 - val_loss: 0.2539\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7899 - binary_accuracy: 0.9091 - loss: 0.2620\n",
            "Fold 4 Metrics: Loss = 0.2539, Accuracy = 0.9093, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - auc: 0.6883 - binary_accuracy: 0.8934 - loss: 0.3195 - val_auc: 0.7951 - val_binary_accuracy: 0.9087 - val_loss: 0.2591\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9060 - loss: 0.2712 - val_auc: 0.8000 - val_binary_accuracy: 0.9057 - val_loss: 0.2620\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9072 - loss: 0.2677 - val_auc: 0.8027 - val_binary_accuracy: 0.9088 - val_loss: 0.2615\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9079 - loss: 0.2657 - val_auc: 0.8038 - val_binary_accuracy: 0.9094 - val_loss: 0.2619\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7819 - binary_accuracy: 0.9081 - loss: 0.2650 - val_auc: 0.8050 - val_binary_accuracy: 0.9095 - val_loss: 0.2609\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9082 - loss: 0.2643 - val_auc: 0.8055 - val_binary_accuracy: 0.9091 - val_loss: 0.2598\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9085 - loss: 0.2635 - val_auc: 0.8056 - val_binary_accuracy: 0.9091 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8069 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.8066 - val_binary_accuracy: 0.9095 - val_loss: 0.2588\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9086 - loss: 0.2624 - val_auc: 0.8070 - val_binary_accuracy: 0.9079 - val_loss: 0.2591\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8157 - binary_accuracy: 0.9088 - loss: 0.2563\n",
            "Fold 5 Metrics: Loss = 0.2591, Accuracy = 0.9079, AUC = 0.8070\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2580\n",
            "Average Accuracy: 0.9091\n",
            "Average AUC: 0.8054\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 3, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6231 - binary_accuracy: 0.9069 - loss: 0.3285 - val_auc: 0.7382 - val_binary_accuracy: 0.9044 - val_loss: 0.2813\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9069 - loss: 0.2674 - val_auc: 0.7482 - val_binary_accuracy: 0.9044 - val_loss: 0.2780\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9070 - loss: 0.2644 - val_auc: 0.7539 - val_binary_accuracy: 0.9044 - val_loss: 0.2757\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9070 - loss: 0.2631 - val_auc: 0.7634 - val_binary_accuracy: 0.9044 - val_loss: 0.2730\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9070 - loss: 0.2620 - val_auc: 0.7639 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9070 - loss: 0.2618 - val_auc: 0.7644 - val_binary_accuracy: 0.9044 - val_loss: 0.2721\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9069 - loss: 0.2615 - val_auc: 0.7645 - val_binary_accuracy: 0.9044 - val_loss: 0.2715\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9070 - loss: 0.2613 - val_auc: 0.7656 - val_binary_accuracy: 0.9044 - val_loss: 0.2715\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9069 - loss: 0.2610 - val_auc: 0.7660 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9069 - loss: 0.2608 - val_auc: 0.7669 - val_binary_accuracy: 0.9042 - val_loss: 0.2712\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7601 - binary_accuracy: 0.9082 - loss: 0.2640\n",
            "Fold 1 Metrics: Loss = 0.2712, Accuracy = 0.9042, AUC = 0.7669\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6295 - binary_accuracy: 0.8972 - loss: 0.3282 - val_auc: 0.7588 - val_binary_accuracy: 0.9042 - val_loss: 0.2822\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7492 - binary_accuracy: 0.9029 - loss: 0.2815 - val_auc: 0.7734 - val_binary_accuracy: 0.9042 - val_loss: 0.2742\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9029 - loss: 0.2763 - val_auc: 0.7790 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7646 - binary_accuracy: 0.9029 - loss: 0.2744 - val_auc: 0.7830 - val_binary_accuracy: 0.9042 - val_loss: 0.2704\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7691 - binary_accuracy: 0.9029 - loss: 0.2728 - val_auc: 0.7898 - val_binary_accuracy: 0.9042 - val_loss: 0.2663\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9029 - loss: 0.2707 - val_auc: 0.7922 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9029 - loss: 0.2701 - val_auc: 0.7952 - val_binary_accuracy: 0.9042 - val_loss: 0.2651\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9029 - loss: 0.2695 - val_auc: 0.7962 - val_binary_accuracy: 0.9042 - val_loss: 0.2647\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9029 - loss: 0.2691 - val_auc: 0.7973 - val_binary_accuracy: 0.9042 - val_loss: 0.2643\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9029 - loss: 0.2689 - val_auc: 0.7991 - val_binary_accuracy: 0.9042 - val_loss: 0.2642\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7969 - binary_accuracy: 0.9092 - loss: 0.2540\n",
            "Fold 2 Metrics: Loss = 0.2642, Accuracy = 0.9042, AUC = 0.7991\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5201 - binary_accuracy: 0.9051 - loss: 0.3335 - val_auc: 0.7416 - val_binary_accuracy: 0.9042 - val_loss: 0.2879\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7409 - binary_accuracy: 0.9051 - loss: 0.2804 - val_auc: 0.7647 - val_binary_accuracy: 0.9042 - val_loss: 0.2747\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7680 - binary_accuracy: 0.9051 - loss: 0.2696 - val_auc: 0.7767 - val_binary_accuracy: 0.9042 - val_loss: 0.2728\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9061 - loss: 0.2685 - val_auc: 0.7792 - val_binary_accuracy: 0.9066 - val_loss: 0.2711\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9066 - loss: 0.2674 - val_auc: 0.7848 - val_binary_accuracy: 0.9075 - val_loss: 0.2694\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7767 - binary_accuracy: 0.9075 - loss: 0.2666 - val_auc: 0.7859 - val_binary_accuracy: 0.9076 - val_loss: 0.2671\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7772 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7886 - val_binary_accuracy: 0.9087 - val_loss: 0.2653\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7785 - binary_accuracy: 0.9083 - loss: 0.2654 - val_auc: 0.7886 - val_binary_accuracy: 0.9099 - val_loss: 0.2642\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9089 - loss: 0.2650 - val_auc: 0.7896 - val_binary_accuracy: 0.9104 - val_loss: 0.2635\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9085 - loss: 0.2645 - val_auc: 0.7904 - val_binary_accuracy: 0.9100 - val_loss: 0.2631\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7841 - binary_accuracy: 0.9098 - loss: 0.2643\n",
            "Fold 3 Metrics: Loss = 0.2631, Accuracy = 0.9100, AUC = 0.7904\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5469 - binary_accuracy: 0.9047 - loss: 0.3493 - val_auc: 0.7014 - val_binary_accuracy: 0.9044 - val_loss: 0.2931\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7048 - binary_accuracy: 0.9047 - loss: 0.2899 - val_auc: 0.7433 - val_binary_accuracy: 0.9044 - val_loss: 0.2826\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7378 - binary_accuracy: 0.9047 - loss: 0.2812 - val_auc: 0.7586 - val_binary_accuracy: 0.9044 - val_loss: 0.2754\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7527 - binary_accuracy: 0.9047 - loss: 0.2763 - val_auc: 0.7696 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9047 - loss: 0.2738 - val_auc: 0.7721 - val_binary_accuracy: 0.9044 - val_loss: 0.2711\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9047 - loss: 0.2711 - val_auc: 0.7778 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9047 - loss: 0.2684 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2666\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9047 - loss: 0.2656 - val_auc: 0.7881 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9047 - loss: 0.2644 - val_auc: 0.7869 - val_binary_accuracy: 0.9044 - val_loss: 0.2674\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9047 - loss: 0.2640 - val_auc: 0.7872 - val_binary_accuracy: 0.9044 - val_loss: 0.2675\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7729 - binary_accuracy: 0.9049 - loss: 0.2698\n",
            "Fold 4 Metrics: Loss = 0.2675, Accuracy = 0.9044, AUC = 0.7872\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5982 - binary_accuracy: 0.9036 - loss: 0.3237 - val_auc: 0.7556 - val_binary_accuracy: 0.9044 - val_loss: 0.2723\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7469 - binary_accuracy: 0.9037 - loss: 0.2794 - val_auc: 0.7687 - val_binary_accuracy: 0.9044 - val_loss: 0.2672\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7578 - binary_accuracy: 0.9039 - loss: 0.2767 - val_auc: 0.7793 - val_binary_accuracy: 0.9044 - val_loss: 0.2652\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7633 - binary_accuracy: 0.9039 - loss: 0.2742 - val_auc: 0.7822 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9040 - loss: 0.2730 - val_auc: 0.7838 - val_binary_accuracy: 0.9044 - val_loss: 0.2631\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7683 - binary_accuracy: 0.9040 - loss: 0.2721 - val_auc: 0.7850 - val_binary_accuracy: 0.9044 - val_loss: 0.2627\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9040 - loss: 0.2715 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2623\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.7856 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2704 - val_auc: 0.7875 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9040 - loss: 0.2698 - val_auc: 0.7885 - val_binary_accuracy: 0.9044 - val_loss: 0.2615\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8049 - binary_accuracy: 0.9013 - loss: 0.2585\n",
            "Fold 5 Metrics: Loss = 0.2615, Accuracy = 0.9044, AUC = 0.7885\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2655\n",
            "Average Accuracy: 0.9055\n",
            "Average AUC: 0.7864\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 3, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5706 - binary_accuracy: 0.9066 - loss: 0.3155 - val_auc: 0.7594 - val_binary_accuracy: 0.9044 - val_loss: 0.2817\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9069 - loss: 0.2672 - val_auc: 0.7713 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9069 - loss: 0.2621 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2698\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7872 - binary_accuracy: 0.9071 - loss: 0.2591 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9083 - loss: 0.2572 - val_auc: 0.7832 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7943 - binary_accuracy: 0.9089 - loss: 0.2557 - val_auc: 0.7820 - val_binary_accuracy: 0.9088 - val_loss: 0.2669\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7969 - binary_accuracy: 0.9096 - loss: 0.2547 - val_auc: 0.7833 - val_binary_accuracy: 0.9082 - val_loss: 0.2650\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7983 - binary_accuracy: 0.9111 - loss: 0.2537 - val_auc: 0.7852 - val_binary_accuracy: 0.9099 - val_loss: 0.2645\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9124 - loss: 0.2530 - val_auc: 0.7863 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8032 - binary_accuracy: 0.9119 - loss: 0.2516 - val_auc: 0.7849 - val_binary_accuracy: 0.9090 - val_loss: 0.2644\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7846 - binary_accuracy: 0.9112 - loss: 0.2573\n",
            "Fold 1 Metrics: Loss = 0.2644, Accuracy = 0.9090, AUC = 0.7849\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6661 - binary_accuracy: 0.8577 - loss: 0.3449 - val_auc: 0.7872 - val_binary_accuracy: 0.9042 - val_loss: 0.2699\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9043 - loss: 0.2716 - val_auc: 0.7932 - val_binary_accuracy: 0.9053 - val_loss: 0.2657\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9052 - loss: 0.2673 - val_auc: 0.7994 - val_binary_accuracy: 0.9065 - val_loss: 0.2612\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9059 - loss: 0.2646 - val_auc: 0.8019 - val_binary_accuracy: 0.9084 - val_loss: 0.2586\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9071 - loss: 0.2633 - val_auc: 0.8000 - val_binary_accuracy: 0.9094 - val_loss: 0.2589\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7956 - binary_accuracy: 0.9072 - loss: 0.2620 - val_auc: 0.7998 - val_binary_accuracy: 0.9093 - val_loss: 0.2592\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9082 - loss: 0.2609 - val_auc: 0.7977 - val_binary_accuracy: 0.9079 - val_loss: 0.2615\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9081 - loss: 0.2608 - val_auc: 0.7983 - val_binary_accuracy: 0.9078 - val_loss: 0.2618\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9087 - loss: 0.2607 - val_auc: 0.7985 - val_binary_accuracy: 0.9076 - val_loss: 0.2618\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9098 - loss: 0.2605 - val_auc: 0.7985 - val_binary_accuracy: 0.9078 - val_loss: 0.2620\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8050 - binary_accuracy: 0.9118 - loss: 0.2514\n",
            "Fold 2 Metrics: Loss = 0.2620, Accuracy = 0.9078, AUC = 0.7985\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6525 - binary_accuracy: 0.8428 - loss: 0.3592 - val_auc: 0.7640 - val_binary_accuracy: 0.9048 - val_loss: 0.2753\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7597 - binary_accuracy: 0.9058 - loss: 0.2722 - val_auc: 0.7723 - val_binary_accuracy: 0.9053 - val_loss: 0.2711\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7656 - binary_accuracy: 0.9063 - loss: 0.2700 - val_auc: 0.7733 - val_binary_accuracy: 0.9065 - val_loss: 0.2698\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9078 - loss: 0.2686 - val_auc: 0.7787 - val_binary_accuracy: 0.9082 - val_loss: 0.2690\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9086 - loss: 0.2673 - val_auc: 0.7782 - val_binary_accuracy: 0.9084 - val_loss: 0.2691\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9087 - loss: 0.2662 - val_auc: 0.7768 - val_binary_accuracy: 0.9084 - val_loss: 0.2689\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9085 - loss: 0.2655 - val_auc: 0.7776 - val_binary_accuracy: 0.9087 - val_loss: 0.2687\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9092 - loss: 0.2650 - val_auc: 0.7792 - val_binary_accuracy: 0.9088 - val_loss: 0.2685\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9094 - loss: 0.2646 - val_auc: 0.7790 - val_binary_accuracy: 0.9097 - val_loss: 0.2682\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9096 - loss: 0.2641 - val_auc: 0.7801 - val_binary_accuracy: 0.9093 - val_loss: 0.2679\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7731 - binary_accuracy: 0.9104 - loss: 0.2692\n",
            "Fold 3 Metrics: Loss = 0.2679, Accuracy = 0.9093, AUC = 0.7801\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6619 - binary_accuracy: 0.8546 - loss: 0.3482 - val_auc: 0.7817 - val_binary_accuracy: 0.9044 - val_loss: 0.2696\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9051 - loss: 0.2686 - val_auc: 0.7863 - val_binary_accuracy: 0.9047 - val_loss: 0.2671\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9069 - loss: 0.2656 - val_auc: 0.7906 - val_binary_accuracy: 0.9066 - val_loss: 0.2644\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.7924 - val_binary_accuracy: 0.9078 - val_loss: 0.2624\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9085 - loss: 0.2618 - val_auc: 0.7962 - val_binary_accuracy: 0.9084 - val_loss: 0.2613\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2610 - val_auc: 0.7961 - val_binary_accuracy: 0.9085 - val_loss: 0.2609\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9095 - loss: 0.2603 - val_auc: 0.7966 - val_binary_accuracy: 0.9087 - val_loss: 0.2610\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.7969 - val_binary_accuracy: 0.9087 - val_loss: 0.2609\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9100 - loss: 0.2595 - val_auc: 0.7972 - val_binary_accuracy: 0.9085 - val_loss: 0.2611\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9095 - loss: 0.2592 - val_auc: 0.7974 - val_binary_accuracy: 0.9084 - val_loss: 0.2613\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7778 - binary_accuracy: 0.9078 - loss: 0.2679\n",
            "Fold 4 Metrics: Loss = 0.2613, Accuracy = 0.9084, AUC = 0.7974\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7020 - binary_accuracy: 0.9041 - loss: 0.3018 - val_auc: 0.7885 - val_binary_accuracy: 0.9056 - val_loss: 0.2620\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9056 - loss: 0.2711 - val_auc: 0.7952 - val_binary_accuracy: 0.9063 - val_loss: 0.2594\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9071 - loss: 0.2690 - val_auc: 0.7975 - val_binary_accuracy: 0.9075 - val_loss: 0.2583\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9078 - loss: 0.2681 - val_auc: 0.7964 - val_binary_accuracy: 0.9088 - val_loss: 0.2578\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9080 - loss: 0.2668 - val_auc: 0.7975 - val_binary_accuracy: 0.9097 - val_loss: 0.2574\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9080 - loss: 0.2657 - val_auc: 0.7985 - val_binary_accuracy: 0.9101 - val_loss: 0.2568\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8006 - val_binary_accuracy: 0.9091 - val_loss: 0.2561\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9075 - loss: 0.2642 - val_auc: 0.8026 - val_binary_accuracy: 0.9093 - val_loss: 0.2557\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9082 - loss: 0.2634 - val_auc: 0.8023 - val_binary_accuracy: 0.9085 - val_loss: 0.2554\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9088 - loss: 0.2629 - val_auc: 0.8029 - val_binary_accuracy: 0.9085 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8135 - binary_accuracy: 0.9076 - loss: 0.2521\n",
            "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9085, AUC = 0.8029\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2621\n",
            "Average Accuracy: 0.9086\n",
            "Average AUC: 0.7928\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 3, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7186 - binary_accuracy: 0.9060 - loss: 0.2886 - val_auc: 0.7727 - val_binary_accuracy: 0.9044 - val_loss: 0.2707\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9082 - loss: 0.2591 - val_auc: 0.7799 - val_binary_accuracy: 0.9047 - val_loss: 0.2673\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9102 - loss: 0.2556 - val_auc: 0.7833 - val_binary_accuracy: 0.9054 - val_loss: 0.2650\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7995 - binary_accuracy: 0.9120 - loss: 0.2533 - val_auc: 0.7855 - val_binary_accuracy: 0.9069 - val_loss: 0.2636\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8025 - binary_accuracy: 0.9124 - loss: 0.2516 - val_auc: 0.7865 - val_binary_accuracy: 0.9072 - val_loss: 0.2628\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9124 - loss: 0.2504 - val_auc: 0.7874 - val_binary_accuracy: 0.9078 - val_loss: 0.2625\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8055 - binary_accuracy: 0.9127 - loss: 0.2496 - val_auc: 0.7857 - val_binary_accuracy: 0.9075 - val_loss: 0.2630\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8060 - binary_accuracy: 0.9125 - loss: 0.2492 - val_auc: 0.7863 - val_binary_accuracy: 0.9078 - val_loss: 0.2631\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9126 - loss: 0.2493 - val_auc: 0.7871 - val_binary_accuracy: 0.9078 - val_loss: 0.2629\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9128 - loss: 0.2487 - val_auc: 0.7882 - val_binary_accuracy: 0.9082 - val_loss: 0.2622\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7870 - binary_accuracy: 0.9111 - loss: 0.2548\n",
            "Fold 1 Metrics: Loss = 0.2622, Accuracy = 0.9082, AUC = 0.7882\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6992 - binary_accuracy: 0.8989 - loss: 0.3037 - val_auc: 0.7879 - val_binary_accuracy: 0.9044 - val_loss: 0.2670\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9037 - loss: 0.2709 - val_auc: 0.7982 - val_binary_accuracy: 0.9057 - val_loss: 0.2619\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9041 - loss: 0.2673 - val_auc: 0.7975 - val_binary_accuracy: 0.9063 - val_loss: 0.2609\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9058 - loss: 0.2652 - val_auc: 0.7974 - val_binary_accuracy: 0.9059 - val_loss: 0.2613\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9051 - loss: 0.2639 - val_auc: 0.7987 - val_binary_accuracy: 0.9069 - val_loss: 0.2601\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9059 - loss: 0.2635 - val_auc: 0.8015 - val_binary_accuracy: 0.9071 - val_loss: 0.2588\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9074 - loss: 0.2622 - val_auc: 0.8029 - val_binary_accuracy: 0.9072 - val_loss: 0.2584\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9077 - loss: 0.2613 - val_auc: 0.8046 - val_binary_accuracy: 0.9072 - val_loss: 0.2578\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7993 - binary_accuracy: 0.9077 - loss: 0.2605 - val_auc: 0.8030 - val_binary_accuracy: 0.9069 - val_loss: 0.2586\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7991 - binary_accuracy: 0.9077 - loss: 0.2605 - val_auc: 0.8030 - val_binary_accuracy: 0.9076 - val_loss: 0.2573\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8101 - binary_accuracy: 0.9118 - loss: 0.2467\n",
            "Fold 2 Metrics: Loss = 0.2573, Accuracy = 0.9076, AUC = 0.8030\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6749 - binary_accuracy: 0.8913 - loss: 0.3076 - val_auc: 0.7857 - val_binary_accuracy: 0.9053 - val_loss: 0.2664\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9064 - loss: 0.2713 - val_auc: 0.7879 - val_binary_accuracy: 0.9060 - val_loss: 0.2645\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9080 - loss: 0.2680 - val_auc: 0.7892 - val_binary_accuracy: 0.9099 - val_loss: 0.2658\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7770 - binary_accuracy: 0.9080 - loss: 0.2651 - val_auc: 0.7945 - val_binary_accuracy: 0.9066 - val_loss: 0.2623\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9088 - loss: 0.2652 - val_auc: 0.7955 - val_binary_accuracy: 0.9069 - val_loss: 0.2615\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9088 - loss: 0.2644 - val_auc: 0.7971 - val_binary_accuracy: 0.9079 - val_loss: 0.2607\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9085 - loss: 0.2638 - val_auc: 0.7976 - val_binary_accuracy: 0.9091 - val_loss: 0.2596\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7810 - binary_accuracy: 0.9085 - loss: 0.2631 - val_auc: 0.7983 - val_binary_accuracy: 0.9103 - val_loss: 0.2587\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7817 - binary_accuracy: 0.9083 - loss: 0.2626 - val_auc: 0.7992 - val_binary_accuracy: 0.9106 - val_loss: 0.2583\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7833 - binary_accuracy: 0.9082 - loss: 0.2622 - val_auc: 0.7996 - val_binary_accuracy: 0.9110 - val_loss: 0.2576\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7900 - binary_accuracy: 0.9120 - loss: 0.2585\n",
            "Fold 3 Metrics: Loss = 0.2576, Accuracy = 0.9110, AUC = 0.7996\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6600 - binary_accuracy: 0.8742 - loss: 0.3284 - val_auc: 0.7844 - val_binary_accuracy: 0.9087 - val_loss: 0.2645\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9076 - loss: 0.2683 - val_auc: 0.7922 - val_binary_accuracy: 0.9084 - val_loss: 0.2601\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9092 - loss: 0.2638 - val_auc: 0.7939 - val_binary_accuracy: 0.9088 - val_loss: 0.2591\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9100 - loss: 0.2618 - val_auc: 0.7971 - val_binary_accuracy: 0.9087 - val_loss: 0.2583\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9105 - loss: 0.2604 - val_auc: 0.7999 - val_binary_accuracy: 0.9084 - val_loss: 0.2574\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9109 - loss: 0.2595 - val_auc: 0.8009 - val_binary_accuracy: 0.9085 - val_loss: 0.2572\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9112 - loss: 0.2591 - val_auc: 0.8001 - val_binary_accuracy: 0.9082 - val_loss: 0.2573\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9112 - loss: 0.2586 - val_auc: 0.8033 - val_binary_accuracy: 0.9082 - val_loss: 0.2569\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2583 - val_auc: 0.8029 - val_binary_accuracy: 0.9082 - val_loss: 0.2562\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9112 - loss: 0.2580 - val_auc: 0.8042 - val_binary_accuracy: 0.9091 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9085 - loss: 0.2616\n",
            "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9091, AUC = 0.8042\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6394 - binary_accuracy: 0.8589 - loss: 0.3551 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2648\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7641 - binary_accuracy: 0.9040 - loss: 0.2752 - val_auc: 0.7909 - val_binary_accuracy: 0.9044 - val_loss: 0.2607\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9045 - loss: 0.2725 - val_auc: 0.7961 - val_binary_accuracy: 0.9084 - val_loss: 0.2589\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9039 - loss: 0.2714 - val_auc: 0.8021 - val_binary_accuracy: 0.9098 - val_loss: 0.2562\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9056 - loss: 0.2692 - val_auc: 0.8040 - val_binary_accuracy: 0.9085 - val_loss: 0.2552\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9076 - loss: 0.2668 - val_auc: 0.8037 - val_binary_accuracy: 0.9088 - val_loss: 0.2547\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9079 - loss: 0.2659 - val_auc: 0.8036 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9087 - loss: 0.2648 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2551\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9087 - loss: 0.2639 - val_auc: 0.8045 - val_binary_accuracy: 0.9093 - val_loss: 0.2549\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7888 - binary_accuracy: 0.9088 - loss: 0.2632 - val_auc: 0.8044 - val_binary_accuracy: 0.9093 - val_loss: 0.2551\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8142 - binary_accuracy: 0.9077 - loss: 0.2534\n",
            "Fold 5 Metrics: Loss = 0.2551, Accuracy = 0.9093, AUC = 0.8044\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2577\n",
            "Average Accuracy: 0.9091\n",
            "Average AUC: 0.7999\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 3, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6982 - binary_accuracy: 0.8899 - loss: 0.3054 - val_auc: 0.7759 - val_binary_accuracy: 0.9044 - val_loss: 0.2685\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9073 - loss: 0.2610 - val_auc: 0.7826 - val_binary_accuracy: 0.9054 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7932 - binary_accuracy: 0.9083 - loss: 0.2567 - val_auc: 0.7850 - val_binary_accuracy: 0.9056 - val_loss: 0.2643\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9093 - loss: 0.2549 - val_auc: 0.7874 - val_binary_accuracy: 0.9075 - val_loss: 0.2633\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8008 - binary_accuracy: 0.9098 - loss: 0.2530 - val_auc: 0.7896 - val_binary_accuracy: 0.9093 - val_loss: 0.2622\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9109 - loss: 0.2515 - val_auc: 0.7911 - val_binary_accuracy: 0.9090 - val_loss: 0.2611\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8053 - binary_accuracy: 0.9120 - loss: 0.2505 - val_auc: 0.7922 - val_binary_accuracy: 0.9088 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9127 - loss: 0.2495 - val_auc: 0.7918 - val_binary_accuracy: 0.9087 - val_loss: 0.2602\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8071 - binary_accuracy: 0.9130 - loss: 0.2491 - val_auc: 0.7932 - val_binary_accuracy: 0.9084 - val_loss: 0.2602\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8090 - binary_accuracy: 0.9129 - loss: 0.2483 - val_auc: 0.7927 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7919 - binary_accuracy: 0.9126 - loss: 0.2516\n",
            "Fold 1 Metrics: Loss = 0.2595, Accuracy = 0.9087, AUC = 0.7927\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7276 - binary_accuracy: 0.9039 - loss: 0.2906 - val_auc: 0.8012 - val_binary_accuracy: 0.9068 - val_loss: 0.2673\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9055 - loss: 0.2699 - val_auc: 0.8019 - val_binary_accuracy: 0.9073 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9065 - loss: 0.2660 - val_auc: 0.8020 - val_binary_accuracy: 0.9071 - val_loss: 0.2635\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9066 - loss: 0.2647 - val_auc: 0.8039 - val_binary_accuracy: 0.9069 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9074 - loss: 0.2629 - val_auc: 0.8043 - val_binary_accuracy: 0.9082 - val_loss: 0.2611\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7935 - binary_accuracy: 0.9077 - loss: 0.2627 - val_auc: 0.8082 - val_binary_accuracy: 0.9071 - val_loss: 0.2602\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7953 - binary_accuracy: 0.9082 - loss: 0.2618 - val_auc: 0.8084 - val_binary_accuracy: 0.9068 - val_loss: 0.2603\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7952 - binary_accuracy: 0.9073 - loss: 0.2622 - val_auc: 0.8097 - val_binary_accuracy: 0.9053 - val_loss: 0.2602\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9077 - loss: 0.2618 - val_auc: 0.8109 - val_binary_accuracy: 0.9068 - val_loss: 0.2596\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7977 - binary_accuracy: 0.9070 - loss: 0.2611 - val_auc: 0.8111 - val_binary_accuracy: 0.9069 - val_loss: 0.2596\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8178 - binary_accuracy: 0.9106 - loss: 0.2501\n",
            "Fold 2 Metrics: Loss = 0.2596, Accuracy = 0.9069, AUC = 0.8111\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7209 - binary_accuracy: 0.9055 - loss: 0.2889 - val_auc: 0.7895 - val_binary_accuracy: 0.9068 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9072 - loss: 0.2686 - val_auc: 0.7918 - val_binary_accuracy: 0.9051 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9074 - loss: 0.2679 - val_auc: 0.7945 - val_binary_accuracy: 0.9066 - val_loss: 0.2654\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9076 - loss: 0.2671 - val_auc: 0.7964 - val_binary_accuracy: 0.9056 - val_loss: 0.2639\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9072 - loss: 0.2664 - val_auc: 0.7968 - val_binary_accuracy: 0.9071 - val_loss: 0.2637\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9086 - loss: 0.2653 - val_auc: 0.7985 - val_binary_accuracy: 0.9056 - val_loss: 0.2619\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9083 - loss: 0.2647 - val_auc: 0.7982 - val_binary_accuracy: 0.9066 - val_loss: 0.2624\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9087 - loss: 0.2643 - val_auc: 0.7989 - val_binary_accuracy: 0.9072 - val_loss: 0.2618\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9086 - loss: 0.2638 - val_auc: 0.8003 - val_binary_accuracy: 0.9084 - val_loss: 0.2605\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8008 - val_binary_accuracy: 0.9088 - val_loss: 0.2600\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7933 - binary_accuracy: 0.9100 - loss: 0.2607\n",
            "Fold 3 Metrics: Loss = 0.2600, Accuracy = 0.9088, AUC = 0.8008\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7056 - binary_accuracy: 0.8967 - loss: 0.2995 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2625\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9074 - loss: 0.2666 - val_auc: 0.7962 - val_binary_accuracy: 0.9075 - val_loss: 0.2614\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9079 - loss: 0.2637 - val_auc: 0.7978 - val_binary_accuracy: 0.9084 - val_loss: 0.2601\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9084 - loss: 0.2616 - val_auc: 0.7988 - val_binary_accuracy: 0.9087 - val_loss: 0.2592\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9090 - loss: 0.2605 - val_auc: 0.8013 - val_binary_accuracy: 0.9087 - val_loss: 0.2575\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9102 - loss: 0.2595 - val_auc: 0.8031 - val_binary_accuracy: 0.9093 - val_loss: 0.2571\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.8035 - val_binary_accuracy: 0.9097 - val_loss: 0.2568\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7921 - binary_accuracy: 0.9110 - loss: 0.2582 - val_auc: 0.8035 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7927 - binary_accuracy: 0.9106 - loss: 0.2583 - val_auc: 0.8044 - val_binary_accuracy: 0.9100 - val_loss: 0.2571\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7941 - binary_accuracy: 0.9112 - loss: 0.2577 - val_auc: 0.8062 - val_binary_accuracy: 0.9094 - val_loss: 0.2561\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7875 - binary_accuracy: 0.9083 - loss: 0.2636\n",
            "Fold 4 Metrics: Loss = 0.2561, Accuracy = 0.9094, AUC = 0.8062\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7007 - binary_accuracy: 0.9041 - loss: 0.2985 - val_auc: 0.7899 - val_binary_accuracy: 0.9066 - val_loss: 0.2644\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7617 - binary_accuracy: 0.9056 - loss: 0.2744 - val_auc: 0.7980 - val_binary_accuracy: 0.9072 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7715 - binary_accuracy: 0.9069 - loss: 0.2705 - val_auc: 0.8010 - val_binary_accuracy: 0.9084 - val_loss: 0.2629\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9073 - loss: 0.2680 - val_auc: 0.8044 - val_binary_accuracy: 0.9085 - val_loss: 0.2612\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9076 - loss: 0.2666 - val_auc: 0.8042 - val_binary_accuracy: 0.9090 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9070 - loss: 0.2655 - val_auc: 0.8077 - val_binary_accuracy: 0.9094 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7859 - binary_accuracy: 0.9084 - loss: 0.2638 - val_auc: 0.8081 - val_binary_accuracy: 0.9094 - val_loss: 0.2570\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9089 - loss: 0.2629 - val_auc: 0.8086 - val_binary_accuracy: 0.9090 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9091 - loss: 0.2623 - val_auc: 0.8089 - val_binary_accuracy: 0.9109 - val_loss: 0.2550\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7901 - binary_accuracy: 0.9094 - loss: 0.2618 - val_auc: 0.8090 - val_binary_accuracy: 0.9115 - val_loss: 0.2543\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8179 - binary_accuracy: 0.9097 - loss: 0.2522\n",
            "Fold 5 Metrics: Loss = 0.2543, Accuracy = 0.9115, AUC = 0.8090\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2579\n",
            "Average Accuracy: 0.9091\n",
            "Average AUC: 0.8040\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 3, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7155 - binary_accuracy: 0.9054 - loss: 0.2915 - val_auc: 0.7776 - val_binary_accuracy: 0.9045 - val_loss: 0.2668\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9086 - loss: 0.2600 - val_auc: 0.7844 - val_binary_accuracy: 0.9081 - val_loss: 0.2630\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7930 - binary_accuracy: 0.9106 - loss: 0.2559 - val_auc: 0.7884 - val_binary_accuracy: 0.9093 - val_loss: 0.2613\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7964 - binary_accuracy: 0.9111 - loss: 0.2545 - val_auc: 0.7904 - val_binary_accuracy: 0.9094 - val_loss: 0.2608\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7998 - binary_accuracy: 0.9118 - loss: 0.2529 - val_auc: 0.7904 - val_binary_accuracy: 0.9088 - val_loss: 0.2622\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8019 - binary_accuracy: 0.9111 - loss: 0.2521 - val_auc: 0.7908 - val_binary_accuracy: 0.9093 - val_loss: 0.2624\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8030 - binary_accuracy: 0.9120 - loss: 0.2511 - val_auc: 0.7907 - val_binary_accuracy: 0.9096 - val_loss: 0.2622\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8048 - binary_accuracy: 0.9122 - loss: 0.2503 - val_auc: 0.7912 - val_binary_accuracy: 0.9097 - val_loss: 0.2623\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9126 - loss: 0.2501 - val_auc: 0.7921 - val_binary_accuracy: 0.9093 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8058 - binary_accuracy: 0.9130 - loss: 0.2500 - val_auc: 0.7916 - val_binary_accuracy: 0.9090 - val_loss: 0.2615\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7895 - binary_accuracy: 0.9121 - loss: 0.2539\n",
            "Fold 1 Metrics: Loss = 0.2615, Accuracy = 0.9090, AUC = 0.7916\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - auc: 0.7058 - binary_accuracy: 0.9016 - loss: 0.3067 - val_auc: 0.8011 - val_binary_accuracy: 0.9045 - val_loss: 0.2670\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9034 - loss: 0.2702 - val_auc: 0.8061 - val_binary_accuracy: 0.9072 - val_loss: 0.2626\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9061 - loss: 0.2669 - val_auc: 0.8086 - val_binary_accuracy: 0.9082 - val_loss: 0.2598\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9063 - loss: 0.2648 - val_auc: 0.8084 - val_binary_accuracy: 0.9081 - val_loss: 0.2599\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9070 - loss: 0.2638 - val_auc: 0.8094 - val_binary_accuracy: 0.9075 - val_loss: 0.2613\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7908 - binary_accuracy: 0.9074 - loss: 0.2635 - val_auc: 0.8095 - val_binary_accuracy: 0.9071 - val_loss: 0.2621\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7924 - binary_accuracy: 0.9071 - loss: 0.2628 - val_auc: 0.8095 - val_binary_accuracy: 0.9071 - val_loss: 0.2615\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7937 - binary_accuracy: 0.9080 - loss: 0.2623 - val_auc: 0.8093 - val_binary_accuracy: 0.9069 - val_loss: 0.2620\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9079 - loss: 0.2618 - val_auc: 0.8097 - val_binary_accuracy: 0.9065 - val_loss: 0.2633\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9077 - loss: 0.2615 - val_auc: 0.8111 - val_binary_accuracy: 0.9066 - val_loss: 0.2624\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8168 - binary_accuracy: 0.9101 - loss: 0.2539\n",
            "Fold 2 Metrics: Loss = 0.2624, Accuracy = 0.9066, AUC = 0.8111\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7028 - binary_accuracy: 0.8871 - loss: 0.3199 - val_auc: 0.7849 - val_binary_accuracy: 0.9075 - val_loss: 0.2674\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7686 - binary_accuracy: 0.9070 - loss: 0.2691 - val_auc: 0.7910 - val_binary_accuracy: 0.9088 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7706 - binary_accuracy: 0.9075 - loss: 0.2676 - val_auc: 0.7931 - val_binary_accuracy: 0.9102 - val_loss: 0.2620\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9066 - loss: 0.2686 - val_auc: 0.7954 - val_binary_accuracy: 0.9100 - val_loss: 0.2611\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7711 - binary_accuracy: 0.9067 - loss: 0.2673 - val_auc: 0.7965 - val_binary_accuracy: 0.9094 - val_loss: 0.2618\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7725 - binary_accuracy: 0.9077 - loss: 0.2670 - val_auc: 0.7979 - val_binary_accuracy: 0.9107 - val_loss: 0.2617\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9079 - loss: 0.2662 - val_auc: 0.7992 - val_binary_accuracy: 0.9107 - val_loss: 0.2616\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9077 - loss: 0.2661 - val_auc: 0.7977 - val_binary_accuracy: 0.9106 - val_loss: 0.2624\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7750 - binary_accuracy: 0.9072 - loss: 0.2659 - val_auc: 0.8003 - val_binary_accuracy: 0.9103 - val_loss: 0.2615\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9084 - loss: 0.2648 - val_auc: 0.7996 - val_binary_accuracy: 0.9103 - val_loss: 0.2625\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7917 - binary_accuracy: 0.9101 - loss: 0.2635\n",
            "Fold 3 Metrics: Loss = 0.2625, Accuracy = 0.9103, AUC = 0.7996\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6977 - binary_accuracy: 0.9047 - loss: 0.3033 - val_auc: 0.7941 - val_binary_accuracy: 0.9062 - val_loss: 0.2647\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9066 - loss: 0.2681 - val_auc: 0.7963 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9071 - loss: 0.2652 - val_auc: 0.7989 - val_binary_accuracy: 0.9087 - val_loss: 0.2612\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9079 - loss: 0.2638 - val_auc: 0.8008 - val_binary_accuracy: 0.9047 - val_loss: 0.2661\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9075 - loss: 0.2637 - val_auc: 0.8018 - val_binary_accuracy: 0.9098 - val_loss: 0.2606\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7855 - binary_accuracy: 0.9094 - loss: 0.2620 - val_auc: 0.8039 - val_binary_accuracy: 0.9088 - val_loss: 0.2584\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9102 - loss: 0.2611 - val_auc: 0.8054 - val_binary_accuracy: 0.9094 - val_loss: 0.2575\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7876 - binary_accuracy: 0.9106 - loss: 0.2604 - val_auc: 0.8066 - val_binary_accuracy: 0.9098 - val_loss: 0.2569\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7880 - binary_accuracy: 0.9107 - loss: 0.2600 - val_auc: 0.8066 - val_binary_accuracy: 0.9098 - val_loss: 0.2569\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9106 - loss: 0.2593 - val_auc: 0.8087 - val_binary_accuracy: 0.9095 - val_loss: 0.2565\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7896 - binary_accuracy: 0.9087 - loss: 0.2656\n",
            "Fold 4 Metrics: Loss = 0.2565, Accuracy = 0.9095, AUC = 0.8087\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6900 - binary_accuracy: 0.9031 - loss: 0.3169 - val_auc: 0.7962 - val_binary_accuracy: 0.9093 - val_loss: 0.2583\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7672 - binary_accuracy: 0.9044 - loss: 0.2726 - val_auc: 0.8012 - val_binary_accuracy: 0.9093 - val_loss: 0.2577\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9064 - loss: 0.2681 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2581\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9072 - loss: 0.2658 - val_auc: 0.8042 - val_binary_accuracy: 0.9090 - val_loss: 0.2584\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7831 - binary_accuracy: 0.9078 - loss: 0.2646 - val_auc: 0.8042 - val_binary_accuracy: 0.9087 - val_loss: 0.2575\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9084 - loss: 0.2640 - val_auc: 0.8046 - val_binary_accuracy: 0.9095 - val_loss: 0.2588\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7851 - binary_accuracy: 0.9085 - loss: 0.2638 - val_auc: 0.8046 - val_binary_accuracy: 0.9100 - val_loss: 0.2587\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7858 - binary_accuracy: 0.9087 - loss: 0.2633 - val_auc: 0.8055 - val_binary_accuracy: 0.9088 - val_loss: 0.2589\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9083 - loss: 0.2629 - val_auc: 0.8066 - val_binary_accuracy: 0.9107 - val_loss: 0.2576\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9089 - loss: 0.2626 - val_auc: 0.8068 - val_binary_accuracy: 0.9091 - val_loss: 0.2573\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8149 - binary_accuracy: 0.9102 - loss: 0.2535\n",
            "Fold 5 Metrics: Loss = 0.2573, Accuracy = 0.9091, AUC = 0.8068\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2600\n",
            "Average Accuracy: 0.9089\n",
            "Average AUC: 0.8036\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 4, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6476 - binary_accuracy: 0.8983 - loss: 0.3192 - val_auc: 0.7569 - val_binary_accuracy: 0.9040 - val_loss: 0.2772\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9069 - loss: 0.2655 - val_auc: 0.7598 - val_binary_accuracy: 0.9040 - val_loss: 0.2751\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7794 - binary_accuracy: 0.9068 - loss: 0.2630 - val_auc: 0.7618 - val_binary_accuracy: 0.9040 - val_loss: 0.2753\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7808 - binary_accuracy: 0.9068 - loss: 0.2627 - val_auc: 0.7640 - val_binary_accuracy: 0.9038 - val_loss: 0.2747\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9068 - loss: 0.2619 - val_auc: 0.7646 - val_binary_accuracy: 0.9038 - val_loss: 0.2740\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9068 - loss: 0.2614 - val_auc: 0.7650 - val_binary_accuracy: 0.9038 - val_loss: 0.2738\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9069 - loss: 0.2610 - val_auc: 0.7653 - val_binary_accuracy: 0.9038 - val_loss: 0.2738\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9069 - loss: 0.2607 - val_auc: 0.7663 - val_binary_accuracy: 0.9038 - val_loss: 0.2735\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9069 - loss: 0.2603 - val_auc: 0.7658 - val_binary_accuracy: 0.9038 - val_loss: 0.2730\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2601 - val_auc: 0.7674 - val_binary_accuracy: 0.9038 - val_loss: 0.2727\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7665 - binary_accuracy: 0.9078 - loss: 0.2653\n",
            "Fold 1 Metrics: Loss = 0.2727, Accuracy = 0.9038, AUC = 0.7674\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5976 - binary_accuracy: 0.8574 - loss: 0.3663 - val_auc: 0.7235 - val_binary_accuracy: 0.9042 - val_loss: 0.2919\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7143 - binary_accuracy: 0.9029 - loss: 0.2893 - val_auc: 0.7334 - val_binary_accuracy: 0.9042 - val_loss: 0.2892\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7256 - binary_accuracy: 0.9029 - loss: 0.2847 - val_auc: 0.7427 - val_binary_accuracy: 0.9042 - val_loss: 0.2839\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7418 - binary_accuracy: 0.9029 - loss: 0.2799 - val_auc: 0.7575 - val_binary_accuracy: 0.9042 - val_loss: 0.2784\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7509 - binary_accuracy: 0.9029 - loss: 0.2768 - val_auc: 0.7835 - val_binary_accuracy: 0.9042 - val_loss: 0.2731\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7626 - binary_accuracy: 0.9029 - loss: 0.2743 - val_auc: 0.7865 - val_binary_accuracy: 0.9042 - val_loss: 0.2703\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9029 - loss: 0.2726 - val_auc: 0.7858 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9029 - loss: 0.2719 - val_auc: 0.7888 - val_binary_accuracy: 0.9042 - val_loss: 0.2709\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7757 - binary_accuracy: 0.9029 - loss: 0.2707 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2713\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9029 - loss: 0.2709 - val_auc: 0.7875 - val_binary_accuracy: 0.9042 - val_loss: 0.2717\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7795 - binary_accuracy: 0.9092 - loss: 0.2621\n",
            "Fold 2 Metrics: Loss = 0.2717, Accuracy = 0.9042, AUC = 0.7875\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6142 - binary_accuracy: 0.9045 - loss: 0.3365 - val_auc: 0.7581 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7563 - binary_accuracy: 0.9048 - loss: 0.2747 - val_auc: 0.7709 - val_binary_accuracy: 0.9042 - val_loss: 0.2748\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9051 - loss: 0.2687 - val_auc: 0.7749 - val_binary_accuracy: 0.9041 - val_loss: 0.2738\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7760 - binary_accuracy: 0.9051 - loss: 0.2666 - val_auc: 0.7773 - val_binary_accuracy: 0.9041 - val_loss: 0.2727\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7784 - binary_accuracy: 0.9051 - loss: 0.2658 - val_auc: 0.7809 - val_binary_accuracy: 0.9041 - val_loss: 0.2716\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7819 - val_binary_accuracy: 0.9042 - val_loss: 0.2698\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7821 - binary_accuracy: 0.9052 - loss: 0.2641 - val_auc: 0.7846 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9052 - loss: 0.2634 - val_auc: 0.7850 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9051 - loss: 0.2630 - val_auc: 0.7866 - val_binary_accuracy: 0.9042 - val_loss: 0.2672\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9051 - loss: 0.2627 - val_auc: 0.7878 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7824 - binary_accuracy: 0.9046 - loss: 0.2674\n",
            "Fold 3 Metrics: Loss = 0.2668, Accuracy = 0.9042, AUC = 0.7878\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.4936 - binary_accuracy: 0.8270 - loss: 0.4017 - val_auc: 0.4962 - val_binary_accuracy: 0.9044 - val_loss: 0.3157\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5056 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4973 - val_binary_accuracy: 0.9044 - val_loss: 0.3157\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5047 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4976 - val_binary_accuracy: 0.9044 - val_loss: 0.3158\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5095 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4977 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5098 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4978 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5085 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4982 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5084 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.4982 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5086 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5007 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5086 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5009 - val_binary_accuracy: 0.9044 - val_loss: 0.3159\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5093 - binary_accuracy: 0.9047 - loss: 0.3149 - val_auc: 0.5037 - val_binary_accuracy: 0.9044 - val_loss: 0.3158\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.5056 - binary_accuracy: 0.9049 - loss: 0.3146\n",
            "Fold 4 Metrics: Loss = 0.3158, Accuracy = 0.9044, AUC = 0.5037\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6141 - binary_accuracy: 0.8867 - loss: 0.3614 - val_auc: 0.7363 - val_binary_accuracy: 0.9044 - val_loss: 0.2835\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7209 - binary_accuracy: 0.9040 - loss: 0.2870 - val_auc: 0.7400 - val_binary_accuracy: 0.9044 - val_loss: 0.2800\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7253 - binary_accuracy: 0.9040 - loss: 0.2848 - val_auc: 0.7499 - val_binary_accuracy: 0.9045 - val_loss: 0.2768\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7319 - binary_accuracy: 0.9039 - loss: 0.2826 - val_auc: 0.7638 - val_binary_accuracy: 0.9045 - val_loss: 0.2738\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7450 - binary_accuracy: 0.9039 - loss: 0.2790 - val_auc: 0.7665 - val_binary_accuracy: 0.9044 - val_loss: 0.2721\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7503 - binary_accuracy: 0.9038 - loss: 0.2774 - val_auc: 0.7707 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7519 - binary_accuracy: 0.9039 - loss: 0.2781 - val_auc: 0.7705 - val_binary_accuracy: 0.9044 - val_loss: 0.2692\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7553 - binary_accuracy: 0.9039 - loss: 0.2771 - val_auc: 0.7736 - val_binary_accuracy: 0.9044 - val_loss: 0.2678\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7564 - binary_accuracy: 0.9039 - loss: 0.2753 - val_auc: 0.7763 - val_binary_accuracy: 0.9044 - val_loss: 0.2671\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7579 - binary_accuracy: 0.9039 - loss: 0.2752 - val_auc: 0.7754 - val_binary_accuracy: 0.9044 - val_loss: 0.2664\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7862 - binary_accuracy: 0.9013 - loss: 0.2665\n",
            "Fold 5 Metrics: Loss = 0.2664, Accuracy = 0.9044, AUC = 0.7754\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2787\n",
            "Average Accuracy: 0.9042\n",
            "Average AUC: 0.7244\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 4, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6469 - binary_accuracy: 0.9069 - loss: 0.3076 - val_auc: 0.7691 - val_binary_accuracy: 0.9044 - val_loss: 0.2735\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7783 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9068 - loss: 0.2585 - val_auc: 0.7828 - val_binary_accuracy: 0.9044 - val_loss: 0.2712\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7980 - binary_accuracy: 0.9070 - loss: 0.2564 - val_auc: 0.7849 - val_binary_accuracy: 0.9044 - val_loss: 0.2705\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8009 - binary_accuracy: 0.9072 - loss: 0.2549 - val_auc: 0.7883 - val_binary_accuracy: 0.9044 - val_loss: 0.2679\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9075 - loss: 0.2535 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2655\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9085 - loss: 0.2521 - val_auc: 0.7902 - val_binary_accuracy: 0.9044 - val_loss: 0.2642\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8063 - binary_accuracy: 0.9085 - loss: 0.2515 - val_auc: 0.7904 - val_binary_accuracy: 0.9051 - val_loss: 0.2641\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8073 - binary_accuracy: 0.9104 - loss: 0.2506 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2622\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8079 - binary_accuracy: 0.9105 - loss: 0.2500 - val_auc: 0.7925 - val_binary_accuracy: 0.9063 - val_loss: 0.2620\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7918 - binary_accuracy: 0.9094 - loss: 0.2548\n",
            "Fold 1 Metrics: Loss = 0.2620, Accuracy = 0.9063, AUC = 0.7925\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6112 - binary_accuracy: 0.8474 - loss: 0.3625 - val_auc: 0.7593 - val_binary_accuracy: 0.9042 - val_loss: 0.2813\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7562 - binary_accuracy: 0.9028 - loss: 0.2805 - val_auc: 0.7715 - val_binary_accuracy: 0.9041 - val_loss: 0.2794\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7634 - binary_accuracy: 0.9040 - loss: 0.2762 - val_auc: 0.7959 - val_binary_accuracy: 0.9053 - val_loss: 0.2630\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9047 - loss: 0.2688 - val_auc: 0.7993 - val_binary_accuracy: 0.9056 - val_loss: 0.2637\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9052 - loss: 0.2676 - val_auc: 0.7997 - val_binary_accuracy: 0.9053 - val_loss: 0.2632\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9052 - loss: 0.2667 - val_auc: 0.8000 - val_binary_accuracy: 0.9063 - val_loss: 0.2607\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7870 - binary_accuracy: 0.9066 - loss: 0.2654 - val_auc: 0.8003 - val_binary_accuracy: 0.9066 - val_loss: 0.2605\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7890 - binary_accuracy: 0.9064 - loss: 0.2647 - val_auc: 0.8012 - val_binary_accuracy: 0.9063 - val_loss: 0.2603\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9067 - loss: 0.2631 - val_auc: 0.8048 - val_binary_accuracy: 0.9066 - val_loss: 0.2595\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9071 - loss: 0.2634 - val_auc: 0.8021 - val_binary_accuracy: 0.9072 - val_loss: 0.2603\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8054 - binary_accuracy: 0.9113 - loss: 0.2502\n",
            "Fold 2 Metrics: Loss = 0.2603, Accuracy = 0.9072, AUC = 0.8021\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6254 - binary_accuracy: 0.8785 - loss: 0.3328 - val_auc: 0.7636 - val_binary_accuracy: 0.9042 - val_loss: 0.2742\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9057 - loss: 0.2729 - val_auc: 0.7714 - val_binary_accuracy: 0.9044 - val_loss: 0.2717\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9057 - loss: 0.2714 - val_auc: 0.7759 - val_binary_accuracy: 0.9047 - val_loss: 0.2708\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7677 - binary_accuracy: 0.9063 - loss: 0.2688 - val_auc: 0.7749 - val_binary_accuracy: 0.9059 - val_loss: 0.2697\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7704 - binary_accuracy: 0.9064 - loss: 0.2677 - val_auc: 0.7763 - val_binary_accuracy: 0.9084 - val_loss: 0.2684\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9073 - loss: 0.2669 - val_auc: 0.7775 - val_binary_accuracy: 0.9073 - val_loss: 0.2684\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7724 - binary_accuracy: 0.9065 - loss: 0.2664 - val_auc: 0.7790 - val_binary_accuracy: 0.9073 - val_loss: 0.2673\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9072 - loss: 0.2657 - val_auc: 0.7827 - val_binary_accuracy: 0.9076 - val_loss: 0.2661\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7759 - binary_accuracy: 0.9081 - loss: 0.2653 - val_auc: 0.7839 - val_binary_accuracy: 0.9072 - val_loss: 0.2658\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7774 - binary_accuracy: 0.9082 - loss: 0.2649 - val_auc: 0.7824 - val_binary_accuracy: 0.9075 - val_loss: 0.2657\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7762 - binary_accuracy: 0.9084 - loss: 0.2651\n",
            "Fold 3 Metrics: Loss = 0.2657, Accuracy = 0.9075, AUC = 0.7824\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6732 - binary_accuracy: 0.9052 - loss: 0.3074 - val_auc: 0.7863 - val_binary_accuracy: 0.9063 - val_loss: 0.2671\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9079 - loss: 0.2681 - val_auc: 0.7978 - val_binary_accuracy: 0.9075 - val_loss: 0.2623\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7795 - binary_accuracy: 0.9087 - loss: 0.2650 - val_auc: 0.8024 - val_binary_accuracy: 0.9078 - val_loss: 0.2608\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7835 - binary_accuracy: 0.9093 - loss: 0.2632 - val_auc: 0.8036 - val_binary_accuracy: 0.9081 - val_loss: 0.2594\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7871 - binary_accuracy: 0.9094 - loss: 0.2618 - val_auc: 0.8049 - val_binary_accuracy: 0.9082 - val_loss: 0.2586\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9097 - loss: 0.2611 - val_auc: 0.8057 - val_binary_accuracy: 0.9088 - val_loss: 0.2586\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7896 - binary_accuracy: 0.9097 - loss: 0.2607 - val_auc: 0.8049 - val_binary_accuracy: 0.9088 - val_loss: 0.2588\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9099 - loss: 0.2601 - val_auc: 0.8061 - val_binary_accuracy: 0.9090 - val_loss: 0.2587\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9097 - loss: 0.2598 - val_auc: 0.8074 - val_binary_accuracy: 0.9090 - val_loss: 0.2586\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7918 - binary_accuracy: 0.9097 - loss: 0.2596 - val_auc: 0.8076 - val_binary_accuracy: 0.9091 - val_loss: 0.2584\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7949 - binary_accuracy: 0.9090 - loss: 0.2623\n",
            "Fold 4 Metrics: Loss = 0.2584, Accuracy = 0.9091, AUC = 0.8076\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6298 - binary_accuracy: 0.9040 - loss: 0.3124 - val_auc: 0.7726 - val_binary_accuracy: 0.9044 - val_loss: 0.2703\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7584 - binary_accuracy: 0.9039 - loss: 0.2767 - val_auc: 0.7848 - val_binary_accuracy: 0.9044 - val_loss: 0.2639\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7684 - binary_accuracy: 0.9038 - loss: 0.2732 - val_auc: 0.7853 - val_binary_accuracy: 0.9044 - val_loss: 0.2633\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7718 - binary_accuracy: 0.9036 - loss: 0.2715 - val_auc: 0.7863 - val_binary_accuracy: 0.9044 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9042 - loss: 0.2696 - val_auc: 0.7892 - val_binary_accuracy: 0.9044 - val_loss: 0.2610\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9038 - loss: 0.2686 - val_auc: 0.7919 - val_binary_accuracy: 0.9093 - val_loss: 0.2602\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9053 - loss: 0.2677 - val_auc: 0.7962 - val_binary_accuracy: 0.9101 - val_loss: 0.2589\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9060 - loss: 0.2670 - val_auc: 0.7951 - val_binary_accuracy: 0.9106 - val_loss: 0.2581\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7838 - binary_accuracy: 0.9070 - loss: 0.2659 - val_auc: 0.7973 - val_binary_accuracy: 0.9112 - val_loss: 0.2576\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2656 - val_auc: 0.7970 - val_binary_accuracy: 0.9112 - val_loss: 0.2571\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8080 - binary_accuracy: 0.9111 - loss: 0.2538\n",
            "Fold 5 Metrics: Loss = 0.2571, Accuracy = 0.9112, AUC = 0.7970\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2607\n",
            "Average Accuracy: 0.9083\n",
            "Average AUC: 0.7963\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 4, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7309 - binary_accuracy: 0.9069 - loss: 0.2815 - val_auc: 0.7759 - val_binary_accuracy: 0.9048 - val_loss: 0.2681\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7875 - binary_accuracy: 0.9086 - loss: 0.2589 - val_auc: 0.7823 - val_binary_accuracy: 0.9056 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9091 - loss: 0.2556 - val_auc: 0.7835 - val_binary_accuracy: 0.9054 - val_loss: 0.2649\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7992 - binary_accuracy: 0.9088 - loss: 0.2539 - val_auc: 0.7848 - val_binary_accuracy: 0.9069 - val_loss: 0.2629\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8018 - binary_accuracy: 0.9099 - loss: 0.2526 - val_auc: 0.7862 - val_binary_accuracy: 0.9100 - val_loss: 0.2617\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8027 - binary_accuracy: 0.9102 - loss: 0.2520 - val_auc: 0.7867 - val_binary_accuracy: 0.9099 - val_loss: 0.2616\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8044 - binary_accuracy: 0.9113 - loss: 0.2511 - val_auc: 0.7886 - val_binary_accuracy: 0.9096 - val_loss: 0.2612\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8051 - binary_accuracy: 0.9114 - loss: 0.2505 - val_auc: 0.7881 - val_binary_accuracy: 0.9099 - val_loss: 0.2608\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8065 - binary_accuracy: 0.9117 - loss: 0.2498 - val_auc: 0.7888 - val_binary_accuracy: 0.9099 - val_loss: 0.2605\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8074 - binary_accuracy: 0.9120 - loss: 0.2491 - val_auc: 0.7889 - val_binary_accuracy: 0.9096 - val_loss: 0.2603\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7861 - binary_accuracy: 0.9128 - loss: 0.2534\n",
            "Fold 1 Metrics: Loss = 0.2603, Accuracy = 0.9096, AUC = 0.7889\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6884 - binary_accuracy: 0.8922 - loss: 0.3070 - val_auc: 0.7908 - val_binary_accuracy: 0.9042 - val_loss: 0.2749\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9029 - loss: 0.2733 - val_auc: 0.8033 - val_binary_accuracy: 0.9042 - val_loss: 0.2656\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7874 - binary_accuracy: 0.9038 - loss: 0.2673 - val_auc: 0.8096 - val_binary_accuracy: 0.9042 - val_loss: 0.2601\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7911 - binary_accuracy: 0.9056 - loss: 0.2648 - val_auc: 0.8118 - val_binary_accuracy: 0.9042 - val_loss: 0.2590\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9060 - loss: 0.2634 - val_auc: 0.8124 - val_binary_accuracy: 0.9042 - val_loss: 0.2589\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9056 - loss: 0.2627 - val_auc: 0.8121 - val_binary_accuracy: 0.9042 - val_loss: 0.2596\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7984 - binary_accuracy: 0.9050 - loss: 0.2618 - val_auc: 0.8112 - val_binary_accuracy: 0.9047 - val_loss: 0.2597\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7999 - binary_accuracy: 0.9061 - loss: 0.2609 - val_auc: 0.8109 - val_binary_accuracy: 0.9047 - val_loss: 0.2595\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9069 - loss: 0.2601 - val_auc: 0.8107 - val_binary_accuracy: 0.9051 - val_loss: 0.2585\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9079 - loss: 0.2598 - val_auc: 0.8099 - val_binary_accuracy: 0.9051 - val_loss: 0.2586\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8155 - binary_accuracy: 0.9100 - loss: 0.2487\n",
            "Fold 2 Metrics: Loss = 0.2586, Accuracy = 0.9051, AUC = 0.8099\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6706 - binary_accuracy: 0.8878 - loss: 0.3112 - val_auc: 0.7894 - val_binary_accuracy: 0.9065 - val_loss: 0.2684\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7642 - binary_accuracy: 0.9063 - loss: 0.2710 - val_auc: 0.7957 - val_binary_accuracy: 0.9084 - val_loss: 0.2655\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9074 - loss: 0.2681 - val_auc: 0.7979 - val_binary_accuracy: 0.9099 - val_loss: 0.2635\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7721 - binary_accuracy: 0.9089 - loss: 0.2666 - val_auc: 0.7986 - val_binary_accuracy: 0.9079 - val_loss: 0.2644\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9090 - loss: 0.2659 - val_auc: 0.7970 - val_binary_accuracy: 0.9066 - val_loss: 0.2641\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9084 - loss: 0.2657 - val_auc: 0.7996 - val_binary_accuracy: 0.9053 - val_loss: 0.2624\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9080 - loss: 0.2651 - val_auc: 0.7999 - val_binary_accuracy: 0.9053 - val_loss: 0.2614\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7777 - binary_accuracy: 0.9087 - loss: 0.2644 - val_auc: 0.8002 - val_binary_accuracy: 0.9054 - val_loss: 0.2611\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9086 - loss: 0.2639 - val_auc: 0.8011 - val_binary_accuracy: 0.9054 - val_loss: 0.2609\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7812 - binary_accuracy: 0.9086 - loss: 0.2632 - val_auc: 0.8008 - val_binary_accuracy: 0.9054 - val_loss: 0.2608\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7931 - binary_accuracy: 0.9058 - loss: 0.2620\n",
            "Fold 3 Metrics: Loss = 0.2608, Accuracy = 0.9054, AUC = 0.8008\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7012 - binary_accuracy: 0.9004 - loss: 0.2989 - val_auc: 0.7891 - val_binary_accuracy: 0.9072 - val_loss: 0.2649\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9075 - loss: 0.2686 - val_auc: 0.7877 - val_binary_accuracy: 0.9079 - val_loss: 0.2645\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7765 - binary_accuracy: 0.9086 - loss: 0.2659 - val_auc: 0.7927 - val_binary_accuracy: 0.9090 - val_loss: 0.2622\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7807 - binary_accuracy: 0.9096 - loss: 0.2634 - val_auc: 0.7951 - val_binary_accuracy: 0.9095 - val_loss: 0.2610\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9096 - loss: 0.2622 - val_auc: 0.7975 - val_binary_accuracy: 0.9097 - val_loss: 0.2594\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9099 - loss: 0.2613 - val_auc: 0.7966 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9102 - loss: 0.2607 - val_auc: 0.7971 - val_binary_accuracy: 0.9082 - val_loss: 0.2596\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9101 - loss: 0.2600 - val_auc: 0.7978 - val_binary_accuracy: 0.9082 - val_loss: 0.2595\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9103 - loss: 0.2594 - val_auc: 0.7976 - val_binary_accuracy: 0.9081 - val_loss: 0.2598\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9109 - loss: 0.2592 - val_auc: 0.7963 - val_binary_accuracy: 0.9085 - val_loss: 0.2599\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7777 - binary_accuracy: 0.9082 - loss: 0.2666\n",
            "Fold 4 Metrics: Loss = 0.2599, Accuracy = 0.9085, AUC = 0.7963\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6674 - binary_accuracy: 0.9039 - loss: 0.3090 - val_auc: 0.7882 - val_binary_accuracy: 0.9036 - val_loss: 0.2714\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9042 - loss: 0.2758 - val_auc: 0.7931 - val_binary_accuracy: 0.9038 - val_loss: 0.2647\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9045 - loss: 0.2723 - val_auc: 0.7967 - val_binary_accuracy: 0.9047 - val_loss: 0.2590\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7763 - binary_accuracy: 0.9059 - loss: 0.2694 - val_auc: 0.7981 - val_binary_accuracy: 0.9060 - val_loss: 0.2573\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9066 - loss: 0.2671 - val_auc: 0.8001 - val_binary_accuracy: 0.9078 - val_loss: 0.2562\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7832 - binary_accuracy: 0.9074 - loss: 0.2658 - val_auc: 0.8005 - val_binary_accuracy: 0.9073 - val_loss: 0.2559\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9081 - loss: 0.2645 - val_auc: 0.8017 - val_binary_accuracy: 0.9088 - val_loss: 0.2557\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9088 - loss: 0.2637 - val_auc: 0.8021 - val_binary_accuracy: 0.9095 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9094 - loss: 0.2630 - val_auc: 0.8023 - val_binary_accuracy: 0.9088 - val_loss: 0.2553\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7895 - binary_accuracy: 0.9093 - loss: 0.2624 - val_auc: 0.8027 - val_binary_accuracy: 0.9093 - val_loss: 0.2553\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8151 - binary_accuracy: 0.9075 - loss: 0.2533\n",
            "Fold 5 Metrics: Loss = 0.2553, Accuracy = 0.9093, AUC = 0.8027\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2590\n",
            "Average Accuracy: 0.9076\n",
            "Average AUC: 0.7998\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 4, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7170 - binary_accuracy: 0.9062 - loss: 0.2874 - val_auc: 0.7769 - val_binary_accuracy: 0.9045 - val_loss: 0.2674\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7823 - binary_accuracy: 0.9063 - loss: 0.2616 - val_auc: 0.7833 - val_binary_accuracy: 0.9062 - val_loss: 0.2640\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9076 - loss: 0.2578 - val_auc: 0.7875 - val_binary_accuracy: 0.9076 - val_loss: 0.2623\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7948 - binary_accuracy: 0.9091 - loss: 0.2555 - val_auc: 0.7903 - val_binary_accuracy: 0.9079 - val_loss: 0.2618\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7989 - binary_accuracy: 0.9098 - loss: 0.2537 - val_auc: 0.7909 - val_binary_accuracy: 0.9079 - val_loss: 0.2608\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8015 - binary_accuracy: 0.9104 - loss: 0.2525 - val_auc: 0.7931 - val_binary_accuracy: 0.9076 - val_loss: 0.2604\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8039 - binary_accuracy: 0.9111 - loss: 0.2514 - val_auc: 0.7918 - val_binary_accuracy: 0.9088 - val_loss: 0.2602\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8054 - binary_accuracy: 0.9123 - loss: 0.2508 - val_auc: 0.7924 - val_binary_accuracy: 0.9082 - val_loss: 0.2606\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8072 - binary_accuracy: 0.9120 - loss: 0.2495 - val_auc: 0.7917 - val_binary_accuracy: 0.9084 - val_loss: 0.2609\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8076 - binary_accuracy: 0.9126 - loss: 0.2489 - val_auc: 0.7926 - val_binary_accuracy: 0.9073 - val_loss: 0.2619\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7877 - binary_accuracy: 0.9115 - loss: 0.2551\n",
            "Fold 1 Metrics: Loss = 0.2619, Accuracy = 0.9073, AUC = 0.7926\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7122 - binary_accuracy: 0.8908 - loss: 0.3019 - val_auc: 0.7951 - val_binary_accuracy: 0.9042 - val_loss: 0.2736\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7786 - binary_accuracy: 0.9029 - loss: 0.2708 - val_auc: 0.8036 - val_binary_accuracy: 0.9059 - val_loss: 0.2662\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9052 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9085 - val_loss: 0.2620\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9065 - loss: 0.2649 - val_auc: 0.8022 - val_binary_accuracy: 0.9060 - val_loss: 0.2644\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9062 - loss: 0.2635 - val_auc: 0.8047 - val_binary_accuracy: 0.9073 - val_loss: 0.2643\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7940 - binary_accuracy: 0.9079 - loss: 0.2625 - val_auc: 0.8024 - val_binary_accuracy: 0.9072 - val_loss: 0.2644\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9084 - loss: 0.2621 - val_auc: 0.8017 - val_binary_accuracy: 0.9062 - val_loss: 0.2645\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9082 - loss: 0.2619 - val_auc: 0.8079 - val_binary_accuracy: 0.9060 - val_loss: 0.2634\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7963 - binary_accuracy: 0.9081 - loss: 0.2612 - val_auc: 0.8081 - val_binary_accuracy: 0.9057 - val_loss: 0.2628\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7974 - binary_accuracy: 0.9081 - loss: 0.2608 - val_auc: 0.8064 - val_binary_accuracy: 0.9053 - val_loss: 0.2640\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8128 - binary_accuracy: 0.9099 - loss: 0.2548\n",
            "Fold 2 Metrics: Loss = 0.2640, Accuracy = 0.9053, AUC = 0.8064\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7225 - binary_accuracy: 0.8978 - loss: 0.2938 - val_auc: 0.7896 - val_binary_accuracy: 0.9048 - val_loss: 0.2683\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7693 - binary_accuracy: 0.9068 - loss: 0.2687 - val_auc: 0.7924 - val_binary_accuracy: 0.9054 - val_loss: 0.2647\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7688 - binary_accuracy: 0.9062 - loss: 0.2689 - val_auc: 0.7954 - val_binary_accuracy: 0.9073 - val_loss: 0.2624\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7702 - binary_accuracy: 0.9070 - loss: 0.2683 - val_auc: 0.7969 - val_binary_accuracy: 0.9054 - val_loss: 0.2632\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9073 - loss: 0.2669 - val_auc: 0.7973 - val_binary_accuracy: 0.9075 - val_loss: 0.2621\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9088 - loss: 0.2654 - val_auc: 0.7995 - val_binary_accuracy: 0.9059 - val_loss: 0.2623\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9088 - loss: 0.2655 - val_auc: 0.7997 - val_binary_accuracy: 0.9059 - val_loss: 0.2628\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7744 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8017 - val_binary_accuracy: 0.9054 - val_loss: 0.2628\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7749 - binary_accuracy: 0.9090 - loss: 0.2648 - val_auc: 0.8025 - val_binary_accuracy: 0.9047 - val_loss: 0.2630\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7754 - binary_accuracy: 0.9084 - loss: 0.2647 - val_auc: 0.8046 - val_binary_accuracy: 0.9056 - val_loss: 0.2620\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7969 - binary_accuracy: 0.9058 - loss: 0.2628\n",
            "Fold 3 Metrics: Loss = 0.2620, Accuracy = 0.9056, AUC = 0.8046\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7177 - binary_accuracy: 0.9056 - loss: 0.2889 - val_auc: 0.7918 - val_binary_accuracy: 0.9056 - val_loss: 0.2641\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9074 - loss: 0.2679 - val_auc: 0.7957 - val_binary_accuracy: 0.9059 - val_loss: 0.2622\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7791 - binary_accuracy: 0.9083 - loss: 0.2656 - val_auc: 0.7999 - val_binary_accuracy: 0.9067 - val_loss: 0.2603\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9071 - loss: 0.2633 - val_auc: 0.8017 - val_binary_accuracy: 0.9075 - val_loss: 0.2592\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9084 - loss: 0.2619 - val_auc: 0.8021 - val_binary_accuracy: 0.9094 - val_loss: 0.2588\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9090 - loss: 0.2612 - val_auc: 0.8021 - val_binary_accuracy: 0.9098 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7878 - binary_accuracy: 0.9091 - loss: 0.2607 - val_auc: 0.8014 - val_binary_accuracy: 0.9093 - val_loss: 0.2591\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9098 - loss: 0.2604 - val_auc: 0.8013 - val_binary_accuracy: 0.9095 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9098 - loss: 0.2598 - val_auc: 0.8017 - val_binary_accuracy: 0.9090 - val_loss: 0.2594\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7903 - binary_accuracy: 0.9099 - loss: 0.2593 - val_auc: 0.8041 - val_binary_accuracy: 0.9084 - val_loss: 0.2591\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7847 - binary_accuracy: 0.9082 - loss: 0.2677\n",
            "Fold 4 Metrics: Loss = 0.2591, Accuracy = 0.9084, AUC = 0.8041\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.7079 - binary_accuracy: 0.8894 - loss: 0.3020 - val_auc: 0.7946 - val_binary_accuracy: 0.9076 - val_loss: 0.2590\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7661 - binary_accuracy: 0.9049 - loss: 0.2734 - val_auc: 0.8002 - val_binary_accuracy: 0.9079 - val_loss: 0.2577\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7745 - binary_accuracy: 0.9064 - loss: 0.2691 - val_auc: 0.8024 - val_binary_accuracy: 0.9091 - val_loss: 0.2584\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9070 - loss: 0.2669 - val_auc: 0.8034 - val_binary_accuracy: 0.9084 - val_loss: 0.2595\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7816 - binary_accuracy: 0.9073 - loss: 0.2655 - val_auc: 0.8040 - val_binary_accuracy: 0.9109 - val_loss: 0.2570\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9074 - loss: 0.2642 - val_auc: 0.8039 - val_binary_accuracy: 0.9093 - val_loss: 0.2561\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7860 - binary_accuracy: 0.9084 - loss: 0.2635 - val_auc: 0.8043 - val_binary_accuracy: 0.9095 - val_loss: 0.2557\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7869 - binary_accuracy: 0.9086 - loss: 0.2628 - val_auc: 0.8045 - val_binary_accuracy: 0.9097 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9084 - loss: 0.2623 - val_auc: 0.8047 - val_binary_accuracy: 0.9091 - val_loss: 0.2549\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9084 - loss: 0.2618 - val_auc: 0.8069 - val_binary_accuracy: 0.9095 - val_loss: 0.2548\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9101 - loss: 0.2511\n",
            "Fold 5 Metrics: Loss = 0.2548, Accuracy = 0.9095, AUC = 0.8069\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2603\n",
            "Average Accuracy: 0.9072\n",
            "Average AUC: 0.8029\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 4, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6985 - binary_accuracy: 0.8899 - loss: 0.3071 - val_auc: 0.7799 - val_binary_accuracy: 0.9081 - val_loss: 0.2732\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7783 - binary_accuracy: 0.9073 - loss: 0.2623 - val_auc: 0.7851 - val_binary_accuracy: 0.9048 - val_loss: 0.2637\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9086 - loss: 0.2582 - val_auc: 0.7885 - val_binary_accuracy: 0.9119 - val_loss: 0.2609\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9098 - loss: 0.2551 - val_auc: 0.7872 - val_binary_accuracy: 0.9103 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7973 - binary_accuracy: 0.9114 - loss: 0.2539 - val_auc: 0.7890 - val_binary_accuracy: 0.9081 - val_loss: 0.2647\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7996 - binary_accuracy: 0.9111 - loss: 0.2529 - val_auc: 0.7882 - val_binary_accuracy: 0.9099 - val_loss: 0.2660\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8007 - binary_accuracy: 0.9120 - loss: 0.2523 - val_auc: 0.7898 - val_binary_accuracy: 0.9097 - val_loss: 0.2645\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8033 - binary_accuracy: 0.9124 - loss: 0.2512 - val_auc: 0.7897 - val_binary_accuracy: 0.9088 - val_loss: 0.2643\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8046 - binary_accuracy: 0.9127 - loss: 0.2508 - val_auc: 0.7917 - val_binary_accuracy: 0.9088 - val_loss: 0.2646\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8028 - binary_accuracy: 0.9111 - loss: 0.2524 - val_auc: 0.7914 - val_binary_accuracy: 0.9091 - val_loss: 0.2643\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7888 - binary_accuracy: 0.9119 - loss: 0.2559\n",
            "Fold 1 Metrics: Loss = 0.2643, Accuracy = 0.9091, AUC = 0.7914\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6840 - binary_accuracy: 0.8860 - loss: 0.3194 - val_auc: 0.8017 - val_binary_accuracy: 0.9060 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9037 - loss: 0.2699 - val_auc: 0.7980 - val_binary_accuracy: 0.9082 - val_loss: 0.2638\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9052 - loss: 0.2691 - val_auc: 0.7978 - val_binary_accuracy: 0.9085 - val_loss: 0.2651\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9069 - loss: 0.2680 - val_auc: 0.8022 - val_binary_accuracy: 0.9091 - val_loss: 0.2636\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9070 - loss: 0.2654 - val_auc: 0.8038 - val_binary_accuracy: 0.9090 - val_loss: 0.2672\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7891 - binary_accuracy: 0.9073 - loss: 0.2652 - val_auc: 0.8056 - val_binary_accuracy: 0.9090 - val_loss: 0.2673\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9080 - loss: 0.2652 - val_auc: 0.8075 - val_binary_accuracy: 0.9094 - val_loss: 0.2707\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9082 - loss: 0.2635 - val_auc: 0.8056 - val_binary_accuracy: 0.9088 - val_loss: 0.2662\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9075 - loss: 0.2638 - val_auc: 0.8079 - val_binary_accuracy: 0.9094 - val_loss: 0.2690\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7881 - binary_accuracy: 0.9090 - loss: 0.2643 - val_auc: 0.8094 - val_binary_accuracy: 0.9076 - val_loss: 0.2668\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8156 - binary_accuracy: 0.9113 - loss: 0.2576\n",
            "Fold 2 Metrics: Loss = 0.2668, Accuracy = 0.9076, AUC = 0.8094\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6674 - binary_accuracy: 0.8867 - loss: 0.3288 - val_auc: 0.7851 - val_binary_accuracy: 0.9050 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7624 - binary_accuracy: 0.9048 - loss: 0.2717 - val_auc: 0.7902 - val_binary_accuracy: 0.9078 - val_loss: 0.2668\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9075 - loss: 0.2677 - val_auc: 0.7931 - val_binary_accuracy: 0.9096 - val_loss: 0.2634\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7669 - binary_accuracy: 0.9065 - loss: 0.2688 - val_auc: 0.7939 - val_binary_accuracy: 0.9112 - val_loss: 0.2629\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9069 - loss: 0.2684 - val_auc: 0.7966 - val_binary_accuracy: 0.9109 - val_loss: 0.2616\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9063 - loss: 0.2695 - val_auc: 0.7955 - val_binary_accuracy: 0.9096 - val_loss: 0.2618\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7635 - binary_accuracy: 0.9069 - loss: 0.2699 - val_auc: 0.7983 - val_binary_accuracy: 0.9109 - val_loss: 0.2608\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9067 - loss: 0.2675 - val_auc: 0.7994 - val_binary_accuracy: 0.9073 - val_loss: 0.2658\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9078 - loss: 0.2660 - val_auc: 0.7987 - val_binary_accuracy: 0.9112 - val_loss: 0.2624\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9082 - loss: 0.2661 - val_auc: 0.8020 - val_binary_accuracy: 0.9054 - val_loss: 0.2645\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7948 - binary_accuracy: 0.9059 - loss: 0.2651\n",
            "Fold 3 Metrics: Loss = 0.2645, Accuracy = 0.9054, AUC = 0.8020\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6779 - binary_accuracy: 0.8991 - loss: 0.3164 - val_auc: 0.7880 - val_binary_accuracy: 0.9038 - val_loss: 0.2694\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9054 - loss: 0.2715 - val_auc: 0.7949 - val_binary_accuracy: 0.9025 - val_loss: 0.2700\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9072 - loss: 0.2675 - val_auc: 0.7984 - val_binary_accuracy: 0.9041 - val_loss: 0.2680\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7758 - binary_accuracy: 0.9076 - loss: 0.2666 - val_auc: 0.7982 - val_binary_accuracy: 0.9035 - val_loss: 0.2690\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9083 - loss: 0.2660 - val_auc: 0.8014 - val_binary_accuracy: 0.9017 - val_loss: 0.2681\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9082 - loss: 0.2641 - val_auc: 0.8040 - val_binary_accuracy: 0.9087 - val_loss: 0.2621\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9089 - loss: 0.2624 - val_auc: 0.8042 - val_binary_accuracy: 0.9084 - val_loss: 0.2615\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7834 - binary_accuracy: 0.9093 - loss: 0.2619 - val_auc: 0.8039 - val_binary_accuracy: 0.9095 - val_loss: 0.2602\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9095 - loss: 0.2614 - val_auc: 0.8040 - val_binary_accuracy: 0.9078 - val_loss: 0.2628\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2611 - val_auc: 0.8068 - val_binary_accuracy: 0.9082 - val_loss: 0.2565\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7854 - binary_accuracy: 0.9079 - loss: 0.2659\n",
            "Fold 4 Metrics: Loss = 0.2565, Accuracy = 0.9082, AUC = 0.8068\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.6716 - binary_accuracy: 0.8855 - loss: 0.3284 - val_auc: 0.7931 - val_binary_accuracy: 0.9020 - val_loss: 0.2629\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7566 - binary_accuracy: 0.9030 - loss: 0.2780 - val_auc: 0.8001 - val_binary_accuracy: 0.9087 - val_loss: 0.2571\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9055 - loss: 0.2716 - val_auc: 0.8025 - val_binary_accuracy: 0.9085 - val_loss: 0.2571\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9064 - loss: 0.2688 - val_auc: 0.8052 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9067 - loss: 0.2671 - val_auc: 0.8062 - val_binary_accuracy: 0.9090 - val_loss: 0.2580\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9074 - loss: 0.2661 - val_auc: 0.8079 - val_binary_accuracy: 0.9093 - val_loss: 0.2589\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9074 - loss: 0.2657 - val_auc: 0.8075 - val_binary_accuracy: 0.9087 - val_loss: 0.2595\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7830 - binary_accuracy: 0.9083 - loss: 0.2649 - val_auc: 0.8077 - val_binary_accuracy: 0.9101 - val_loss: 0.2562\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9088 - loss: 0.2634 - val_auc: 0.8059 - val_binary_accuracy: 0.9104 - val_loss: 0.2555\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7861 - binary_accuracy: 0.9097 - loss: 0.2629 - val_auc: 0.8078 - val_binary_accuracy: 0.9104 - val_loss: 0.2560\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8158 - binary_accuracy: 0.9086 - loss: 0.2534\n",
            "Fold 5 Metrics: Loss = 0.2560, Accuracy = 0.9104, AUC = 0.8078\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2616\n",
            "Average Accuracy: 0.9082\n",
            "Average AUC: 0.8035\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 5, 16)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6146 - binary_accuracy: 0.9011 - loss: 0.3375 - val_auc: 0.7421 - val_binary_accuracy: 0.9038 - val_loss: 0.2842\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7610 - binary_accuracy: 0.9069 - loss: 0.2687 - val_auc: 0.7503 - val_binary_accuracy: 0.9041 - val_loss: 0.2796\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7678 - binary_accuracy: 0.9069 - loss: 0.2657 - val_auc: 0.7475 - val_binary_accuracy: 0.9040 - val_loss: 0.2767\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9069 - loss: 0.2636 - val_auc: 0.7646 - val_binary_accuracy: 0.9040 - val_loss: 0.2741\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9069 - loss: 0.2626 - val_auc: 0.7649 - val_binary_accuracy: 0.9040 - val_loss: 0.2732\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7782 - binary_accuracy: 0.9069 - loss: 0.2622 - val_auc: 0.7666 - val_binary_accuracy: 0.9040 - val_loss: 0.2727\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7775 - binary_accuracy: 0.9069 - loss: 0.2620 - val_auc: 0.7651 - val_binary_accuracy: 0.9040 - val_loss: 0.2725\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7789 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7659 - val_binary_accuracy: 0.9040 - val_loss: 0.2723\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9069 - loss: 0.2616 - val_auc: 0.7654 - val_binary_accuracy: 0.9040 - val_loss: 0.2721\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9069 - loss: 0.2614 - val_auc: 0.7652 - val_binary_accuracy: 0.9040 - val_loss: 0.2719\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7591 - binary_accuracy: 0.9079 - loss: 0.2648\n",
            "Fold 1 Metrics: Loss = 0.2719, Accuracy = 0.9040, AUC = 0.7652\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - auc: 0.5868 - binary_accuracy: 0.8233 - loss: 0.3924 - val_auc: 0.6861 - val_binary_accuracy: 0.9042 - val_loss: 0.2951\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.6966 - binary_accuracy: 0.9029 - loss: 0.2874 - val_auc: 0.7223 - val_binary_accuracy: 0.9042 - val_loss: 0.2889\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7317 - binary_accuracy: 0.9029 - loss: 0.2829 - val_auc: 0.7781 - val_binary_accuracy: 0.9042 - val_loss: 0.2733\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7569 - binary_accuracy: 0.9029 - loss: 0.2762 - val_auc: 0.7869 - val_binary_accuracy: 0.9042 - val_loss: 0.2711\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7629 - binary_accuracy: 0.9029 - loss: 0.2747 - val_auc: 0.7901 - val_binary_accuracy: 0.9042 - val_loss: 0.2689\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7690 - binary_accuracy: 0.9029 - loss: 0.2733 - val_auc: 0.7924 - val_binary_accuracy: 0.9042 - val_loss: 0.2672\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7695 - binary_accuracy: 0.9029 - loss: 0.2725 - val_auc: 0.7894 - val_binary_accuracy: 0.9042 - val_loss: 0.2695\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7673 - binary_accuracy: 0.9032 - loss: 0.2728 - val_auc: 0.7895 - val_binary_accuracy: 0.9042 - val_loss: 0.2674\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7700 - binary_accuracy: 0.9029 - loss: 0.2718 - val_auc: 0.7921 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9038 - loss: 0.2710 - val_auc: 0.7937 - val_binary_accuracy: 0.9042 - val_loss: 0.2659\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7886 - binary_accuracy: 0.9092 - loss: 0.2573\n",
            "Fold 2 Metrics: Loss = 0.2659, Accuracy = 0.9042, AUC = 0.7937\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5018 - binary_accuracy: 0.8569 - loss: 0.3752 - val_auc: 0.4997 - val_binary_accuracy: 0.9042 - val_loss: 0.3157\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.5982 - binary_accuracy: 0.9051 - loss: 0.3065 - val_auc: 0.7714 - val_binary_accuracy: 0.9042 - val_loss: 0.2797\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7594 - binary_accuracy: 0.9051 - loss: 0.2745 - val_auc: 0.7792 - val_binary_accuracy: 0.9042 - val_loss: 0.2722\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7676 - binary_accuracy: 0.9051 - loss: 0.2699 - val_auc: 0.7779 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7703 - binary_accuracy: 0.9051 - loss: 0.2687 - val_auc: 0.7757 - val_binary_accuracy: 0.9042 - val_loss: 0.2718\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7796 - val_binary_accuracy: 0.9042 - val_loss: 0.2719\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7747 - binary_accuracy: 0.9051 - loss: 0.2672 - val_auc: 0.7815 - val_binary_accuracy: 0.9042 - val_loss: 0.2706\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7746 - binary_accuracy: 0.9051 - loss: 0.2669 - val_auc: 0.7784 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9051 - loss: 0.2649 - val_auc: 0.7802 - val_binary_accuracy: 0.9042 - val_loss: 0.2696\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7792 - binary_accuracy: 0.9051 - loss: 0.2643 - val_auc: 0.7816 - val_binary_accuracy: 0.9042 - val_loss: 0.2693\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7779 - binary_accuracy: 0.9046 - loss: 0.2690\n",
            "Fold 3 Metrics: Loss = 0.2693, Accuracy = 0.9042, AUC = 0.7816\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.5972 - binary_accuracy: 0.8563 - loss: 0.3674 - val_auc: 0.7605 - val_binary_accuracy: 0.9048 - val_loss: 0.2780\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7537 - binary_accuracy: 0.9066 - loss: 0.2746 - val_auc: 0.7719 - val_binary_accuracy: 0.9069 - val_loss: 0.2699\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7675 - binary_accuracy: 0.9076 - loss: 0.2687 - val_auc: 0.7793 - val_binary_accuracy: 0.9079 - val_loss: 0.2671\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7740 - binary_accuracy: 0.9080 - loss: 0.2668 - val_auc: 0.7884 - val_binary_accuracy: 0.9081 - val_loss: 0.2649\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9077 - loss: 0.2653 - val_auc: 0.7904 - val_binary_accuracy: 0.9081 - val_loss: 0.2648\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7813 - binary_accuracy: 0.9080 - loss: 0.2642 - val_auc: 0.7916 - val_binary_accuracy: 0.9076 - val_loss: 0.2650\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7828 - binary_accuracy: 0.9088 - loss: 0.2633 - val_auc: 0.7922 - val_binary_accuracy: 0.9082 - val_loss: 0.2649\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7841 - binary_accuracy: 0.9091 - loss: 0.2627 - val_auc: 0.7924 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7853 - binary_accuracy: 0.9093 - loss: 0.2622 - val_auc: 0.7927 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7864 - binary_accuracy: 0.9094 - loss: 0.2619 - val_auc: 0.7923 - val_binary_accuracy: 0.9085 - val_loss: 0.2647\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7690 - binary_accuracy: 0.9086 - loss: 0.2704\n",
            "Fold 4 Metrics: Loss = 0.2647, Accuracy = 0.9085, AUC = 0.7923\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5539 - binary_accuracy: 0.9038 - loss: 0.3430 - val_auc: 0.7328 - val_binary_accuracy: 0.9044 - val_loss: 0.2860\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7154 - binary_accuracy: 0.9040 - loss: 0.2896 - val_auc: 0.7559 - val_binary_accuracy: 0.9044 - val_loss: 0.2763\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7375 - binary_accuracy: 0.9040 - loss: 0.2833 - val_auc: 0.7601 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7402 - binary_accuracy: 0.9040 - loss: 0.2814 - val_auc: 0.7622 - val_binary_accuracy: 0.9044 - val_loss: 0.2708\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7418 - binary_accuracy: 0.9040 - loss: 0.2806 - val_auc: 0.7629 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7433 - binary_accuracy: 0.9040 - loss: 0.2801 - val_auc: 0.7624 - val_binary_accuracy: 0.9044 - val_loss: 0.2695\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7432 - binary_accuracy: 0.9040 - loss: 0.2796 - val_auc: 0.7623 - val_binary_accuracy: 0.9044 - val_loss: 0.2690\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7446 - binary_accuracy: 0.9040 - loss: 0.2793 - val_auc: 0.7618 - val_binary_accuracy: 0.9044 - val_loss: 0.2687\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7443 - binary_accuracy: 0.9040 - loss: 0.2790 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2684\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7459 - binary_accuracy: 0.9040 - loss: 0.2787 - val_auc: 0.7615 - val_binary_accuracy: 0.9044 - val_loss: 0.2681\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7784 - binary_accuracy: 0.9013 - loss: 0.2666\n",
            "Fold 5 Metrics: Loss = 0.2681, Accuracy = 0.9044, AUC = 0.7615\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2680\n",
            "Average Accuracy: 0.9051\n",
            "Average AUC: 0.7788\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 5, 32)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7006 - binary_accuracy: 0.9069 - loss: 0.2901 - val_auc: 0.7626 - val_binary_accuracy: 0.9044 - val_loss: 0.2774\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9069 - loss: 0.2667 - val_auc: 0.7745 - val_binary_accuracy: 0.9044 - val_loss: 0.2732\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9069 - loss: 0.2631 - val_auc: 0.7772 - val_binary_accuracy: 0.9044 - val_loss: 0.2746\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9069 - loss: 0.2618 - val_auc: 0.7787 - val_binary_accuracy: 0.9044 - val_loss: 0.2752\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7894 - binary_accuracy: 0.9069 - loss: 0.2609 - val_auc: 0.7797 - val_binary_accuracy: 0.9044 - val_loss: 0.2744\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9069 - loss: 0.2604 - val_auc: 0.7801 - val_binary_accuracy: 0.9044 - val_loss: 0.2722\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9069 - loss: 0.2597 - val_auc: 0.7809 - val_binary_accuracy: 0.9044 - val_loss: 0.2713\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7931 - binary_accuracy: 0.9069 - loss: 0.2593 - val_auc: 0.7814 - val_binary_accuracy: 0.9044 - val_loss: 0.2710\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7945 - binary_accuracy: 0.9069 - loss: 0.2588 - val_auc: 0.7823 - val_binary_accuracy: 0.9044 - val_loss: 0.2702\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7961 - binary_accuracy: 0.9069 - loss: 0.2583 - val_auc: 0.7835 - val_binary_accuracy: 0.9044 - val_loss: 0.2700\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7794 - binary_accuracy: 0.9084 - loss: 0.2645\n",
            "Fold 1 Metrics: Loss = 0.2700, Accuracy = 0.9044, AUC = 0.7835\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6584 - binary_accuracy: 0.8835 - loss: 0.3277 - val_auc: 0.7882 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7731 - binary_accuracy: 0.9037 - loss: 0.2734 - val_auc: 0.7959 - val_binary_accuracy: 0.9044 - val_loss: 0.2669\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9029 - loss: 0.2712 - val_auc: 0.7965 - val_binary_accuracy: 0.9054 - val_loss: 0.2647\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7799 - binary_accuracy: 0.9029 - loss: 0.2694 - val_auc: 0.8010 - val_binary_accuracy: 0.9042 - val_loss: 0.2626\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9039 - loss: 0.2668 - val_auc: 0.8040 - val_binary_accuracy: 0.9044 - val_loss: 0.2604\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7849 - binary_accuracy: 0.9048 - loss: 0.2661 - val_auc: 0.8045 - val_binary_accuracy: 0.9056 - val_loss: 0.2601\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7887 - binary_accuracy: 0.9058 - loss: 0.2650 - val_auc: 0.8053 - val_binary_accuracy: 0.9054 - val_loss: 0.2596\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9056 - loss: 0.2646 - val_auc: 0.8052 - val_binary_accuracy: 0.9054 - val_loss: 0.2596\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7900 - binary_accuracy: 0.9064 - loss: 0.2643 - val_auc: 0.8047 - val_binary_accuracy: 0.9053 - val_loss: 0.2598\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7926 - binary_accuracy: 0.9056 - loss: 0.2631 - val_auc: 0.8056 - val_binary_accuracy: 0.9051 - val_loss: 0.2600\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8100 - binary_accuracy: 0.9096 - loss: 0.2494\n",
            "Fold 2 Metrics: Loss = 0.2600, Accuracy = 0.9051, AUC = 0.8056\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.5811 - binary_accuracy: 0.8507 - loss: 0.3665 - val_auc: 0.7571 - val_binary_accuracy: 0.9042 - val_loss: 0.2802\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7573 - binary_accuracy: 0.9051 - loss: 0.2753 - val_auc: 0.7719 - val_binary_accuracy: 0.9042 - val_loss: 0.2729\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7639 - binary_accuracy: 0.9051 - loss: 0.2722 - val_auc: 0.7703 - val_binary_accuracy: 0.9042 - val_loss: 0.2738\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7648 - binary_accuracy: 0.9051 - loss: 0.2710 - val_auc: 0.7728 - val_binary_accuracy: 0.9042 - val_loss: 0.2723\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9051 - loss: 0.2694 - val_auc: 0.7741 - val_binary_accuracy: 0.9042 - val_loss: 0.2708\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7716 - binary_accuracy: 0.9051 - loss: 0.2688 - val_auc: 0.7819 - val_binary_accuracy: 0.9042 - val_loss: 0.2694\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9051 - loss: 0.2689 - val_auc: 0.7851 - val_binary_accuracy: 0.9042 - val_loss: 0.2684\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7743 - binary_accuracy: 0.9051 - loss: 0.2677 - val_auc: 0.7862 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7764 - binary_accuracy: 0.9051 - loss: 0.2668 - val_auc: 0.7876 - val_binary_accuracy: 0.9042 - val_loss: 0.2671\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9051 - loss: 0.2663 - val_auc: 0.7826 - val_binary_accuracy: 0.9042 - val_loss: 0.2677\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7771 - binary_accuracy: 0.9046 - loss: 0.2683\n",
            "Fold 3 Metrics: Loss = 0.2677, Accuracy = 0.9042, AUC = 0.7826\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6636 - binary_accuracy: 0.8729 - loss: 0.3319 - val_auc: 0.7745 - val_binary_accuracy: 0.9056 - val_loss: 0.2709\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7707 - binary_accuracy: 0.9052 - loss: 0.2702 - val_auc: 0.7851 - val_binary_accuracy: 0.9073 - val_loss: 0.2644\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9067 - loss: 0.2659 - val_auc: 0.7946 - val_binary_accuracy: 0.9070 - val_loss: 0.2613\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7846 - binary_accuracy: 0.9071 - loss: 0.2639 - val_auc: 0.7966 - val_binary_accuracy: 0.9081 - val_loss: 0.2593\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9081 - loss: 0.2626 - val_auc: 0.7977 - val_binary_accuracy: 0.9091 - val_loss: 0.2587\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7877 - binary_accuracy: 0.9086 - loss: 0.2615 - val_auc: 0.7975 - val_binary_accuracy: 0.9090 - val_loss: 0.2581\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7882 - binary_accuracy: 0.9096 - loss: 0.2602 - val_auc: 0.7985 - val_binary_accuracy: 0.9091 - val_loss: 0.2582\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7886 - binary_accuracy: 0.9095 - loss: 0.2599 - val_auc: 0.7996 - val_binary_accuracy: 0.9079 - val_loss: 0.2582\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7907 - binary_accuracy: 0.9101 - loss: 0.2590 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2592\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7909 - binary_accuracy: 0.9102 - loss: 0.2589 - val_auc: 0.8006 - val_binary_accuracy: 0.9075 - val_loss: 0.2589\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7793 - binary_accuracy: 0.9075 - loss: 0.2657\n",
            "Fold 4 Metrics: Loss = 0.2589, Accuracy = 0.9075, AUC = 0.8006\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6761 - binary_accuracy: 0.8716 - loss: 0.3302 - val_auc: 0.7795 - val_binary_accuracy: 0.9044 - val_loss: 0.2657\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7591 - binary_accuracy: 0.9040 - loss: 0.2769 - val_auc: 0.7820 - val_binary_accuracy: 0.9044 - val_loss: 0.2641\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7626 - binary_accuracy: 0.9040 - loss: 0.2757 - val_auc: 0.7839 - val_binary_accuracy: 0.9044 - val_loss: 0.2637\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7655 - binary_accuracy: 0.9040 - loss: 0.2747 - val_auc: 0.7855 - val_binary_accuracy: 0.9044 - val_loss: 0.2634\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7674 - binary_accuracy: 0.9040 - loss: 0.2740 - val_auc: 0.7874 - val_binary_accuracy: 0.9044 - val_loss: 0.2628\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7694 - binary_accuracy: 0.9040 - loss: 0.2734 - val_auc: 0.7876 - val_binary_accuracy: 0.9044 - val_loss: 0.2624\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9040 - loss: 0.2730 - val_auc: 0.7910 - val_binary_accuracy: 0.9044 - val_loss: 0.2620\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7720 - binary_accuracy: 0.9040 - loss: 0.2724 - val_auc: 0.7899 - val_binary_accuracy: 0.9044 - val_loss: 0.2617\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7736 - binary_accuracy: 0.9040 - loss: 0.2718 - val_auc: 0.7873 - val_binary_accuracy: 0.9044 - val_loss: 0.2618\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7734 - binary_accuracy: 0.9040 - loss: 0.2716 - val_auc: 0.7889 - val_binary_accuracy: 0.9044 - val_loss: 0.2613\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8038 - binary_accuracy: 0.9013 - loss: 0.2577\n",
            "Fold 5 Metrics: Loss = 0.2613, Accuracy = 0.9044, AUC = 0.7889\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2636\n",
            "Average Accuracy: 0.9051\n",
            "Average AUC: 0.7923\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 5, 64)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7032 - binary_accuracy: 0.8961 - loss: 0.2951 - val_auc: 0.7677 - val_binary_accuracy: 0.9048 - val_loss: 0.2721\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9072 - loss: 0.2615 - val_auc: 0.7749 - val_binary_accuracy: 0.9060 - val_loss: 0.2691\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9086 - loss: 0.2590 - val_auc: 0.7809 - val_binary_accuracy: 0.9081 - val_loss: 0.2654\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7915 - binary_accuracy: 0.9092 - loss: 0.2572 - val_auc: 0.7846 - val_binary_accuracy: 0.9096 - val_loss: 0.2629\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9102 - loss: 0.2556 - val_auc: 0.7846 - val_binary_accuracy: 0.9090 - val_loss: 0.2627\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7972 - binary_accuracy: 0.9115 - loss: 0.2539 - val_auc: 0.7869 - val_binary_accuracy: 0.9087 - val_loss: 0.2622\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7994 - binary_accuracy: 0.9123 - loss: 0.2530 - val_auc: 0.7871 - val_binary_accuracy: 0.9057 - val_loss: 0.2636\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8029 - binary_accuracy: 0.9114 - loss: 0.2519 - val_auc: 0.7886 - val_binary_accuracy: 0.9068 - val_loss: 0.2628\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9111 - loss: 0.2516 - val_auc: 0.7897 - val_binary_accuracy: 0.9053 - val_loss: 0.2629\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8056 - binary_accuracy: 0.9111 - loss: 0.2506 - val_auc: 0.7914 - val_binary_accuracy: 0.9054 - val_loss: 0.2625\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7902 - binary_accuracy: 0.9097 - loss: 0.2552\n",
            "Fold 1 Metrics: Loss = 0.2625, Accuracy = 0.9054, AUC = 0.7914\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.6903 - binary_accuracy: 0.8854 - loss: 0.3112 - val_auc: 0.7976 - val_binary_accuracy: 0.9063 - val_loss: 0.2643\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7800 - binary_accuracy: 0.9040 - loss: 0.2693 - val_auc: 0.8024 - val_binary_accuracy: 0.9066 - val_loss: 0.2615\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7844 - binary_accuracy: 0.9061 - loss: 0.2676 - val_auc: 0.8006 - val_binary_accuracy: 0.9069 - val_loss: 0.2632\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9064 - loss: 0.2669 - val_auc: 0.8002 - val_binary_accuracy: 0.9071 - val_loss: 0.2654\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7885 - binary_accuracy: 0.9066 - loss: 0.2657 - val_auc: 0.8015 - val_binary_accuracy: 0.9072 - val_loss: 0.2643\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7897 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8034 - val_binary_accuracy: 0.9072 - val_loss: 0.2642\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7925 - binary_accuracy: 0.9074 - loss: 0.2638 - val_auc: 0.8030 - val_binary_accuracy: 0.9073 - val_loss: 0.2629\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7939 - binary_accuracy: 0.9070 - loss: 0.2635 - val_auc: 0.8028 - val_binary_accuracy: 0.9075 - val_loss: 0.2632\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7951 - binary_accuracy: 0.9086 - loss: 0.2625 - val_auc: 0.8054 - val_binary_accuracy: 0.9071 - val_loss: 0.2627\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7970 - binary_accuracy: 0.9079 - loss: 0.2617 - val_auc: 0.8055 - val_binary_accuracy: 0.9066 - val_loss: 0.2619\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9105 - loss: 0.2510\n",
            "Fold 2 Metrics: Loss = 0.2619, Accuracy = 0.9066, AUC = 0.8055\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7101 - binary_accuracy: 0.9050 - loss: 0.2927 - val_auc: 0.7822 - val_binary_accuracy: 0.9047 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7586 - binary_accuracy: 0.9048 - loss: 0.2738 - val_auc: 0.7888 - val_binary_accuracy: 0.9054 - val_loss: 0.2690\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7666 - binary_accuracy: 0.9057 - loss: 0.2702 - val_auc: 0.7911 - val_binary_accuracy: 0.9053 - val_loss: 0.2658\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7713 - binary_accuracy: 0.9062 - loss: 0.2679 - val_auc: 0.7912 - val_binary_accuracy: 0.9050 - val_loss: 0.2677\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7699 - binary_accuracy: 0.9076 - loss: 0.2678 - val_auc: 0.7939 - val_binary_accuracy: 0.9051 - val_loss: 0.2667\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7719 - binary_accuracy: 0.9077 - loss: 0.2673 - val_auc: 0.7965 - val_binary_accuracy: 0.9056 - val_loss: 0.2669\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7729 - binary_accuracy: 0.9078 - loss: 0.2671 - val_auc: 0.7985 - val_binary_accuracy: 0.9050 - val_loss: 0.2650\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7982 - val_binary_accuracy: 0.9053 - val_loss: 0.2640\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7748 - binary_accuracy: 0.9081 - loss: 0.2659 - val_auc: 0.7990 - val_binary_accuracy: 0.9060 - val_loss: 0.2628\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7768 - binary_accuracy: 0.9085 - loss: 0.2652 - val_auc: 0.7984 - val_binary_accuracy: 0.9068 - val_loss: 0.2609\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7910 - binary_accuracy: 0.9071 - loss: 0.2620\n",
            "Fold 3 Metrics: Loss = 0.2609, Accuracy = 0.9068, AUC = 0.7984\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6462 - binary_accuracy: 0.8846 - loss: 0.3234 - val_auc: 0.7892 - val_binary_accuracy: 0.9051 - val_loss: 0.2630\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7712 - binary_accuracy: 0.9048 - loss: 0.2695 - val_auc: 0.7938 - val_binary_accuracy: 0.9063 - val_loss: 0.2610\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7761 - binary_accuracy: 0.9071 - loss: 0.2671 - val_auc: 0.7968 - val_binary_accuracy: 0.9066 - val_loss: 0.2605\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7797 - binary_accuracy: 0.9065 - loss: 0.2655 - val_auc: 0.7995 - val_binary_accuracy: 0.9081 - val_loss: 0.2593\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7827 - binary_accuracy: 0.9082 - loss: 0.2636 - val_auc: 0.7995 - val_binary_accuracy: 0.9072 - val_loss: 0.2600\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9082 - loss: 0.2631 - val_auc: 0.8012 - val_binary_accuracy: 0.9075 - val_loss: 0.2587\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9093 - loss: 0.2618 - val_auc: 0.8026 - val_binary_accuracy: 0.9081 - val_loss: 0.2576\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7873 - binary_accuracy: 0.9094 - loss: 0.2609 - val_auc: 0.8039 - val_binary_accuracy: 0.9078 - val_loss: 0.2571\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7883 - binary_accuracy: 0.9095 - loss: 0.2605 - val_auc: 0.8058 - val_binary_accuracy: 0.9091 - val_loss: 0.2566\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7898 - binary_accuracy: 0.9097 - loss: 0.2601 - val_auc: 0.8040 - val_binary_accuracy: 0.9087 - val_loss: 0.2566\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7852 - binary_accuracy: 0.9090 - loss: 0.2631\n",
            "Fold 4 Metrics: Loss = 0.2566, Accuracy = 0.9087, AUC = 0.8040\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6929 - binary_accuracy: 0.9040 - loss: 0.2997 - val_auc: 0.7949 - val_binary_accuracy: 0.9063 - val_loss: 0.2659\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7696 - binary_accuracy: 0.9044 - loss: 0.2725 - val_auc: 0.7987 - val_binary_accuracy: 0.9079 - val_loss: 0.2643\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7733 - binary_accuracy: 0.9040 - loss: 0.2709 - val_auc: 0.8001 - val_binary_accuracy: 0.9070 - val_loss: 0.2618\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7796 - binary_accuracy: 0.9055 - loss: 0.2680 - val_auc: 0.8014 - val_binary_accuracy: 0.9087 - val_loss: 0.2601\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7811 - binary_accuracy: 0.9066 - loss: 0.2669 - val_auc: 0.8017 - val_binary_accuracy: 0.9091 - val_loss: 0.2588\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7837 - binary_accuracy: 0.9079 - loss: 0.2657 - val_auc: 0.8008 - val_binary_accuracy: 0.9098 - val_loss: 0.2579\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9080 - loss: 0.2648 - val_auc: 0.8002 - val_binary_accuracy: 0.9100 - val_loss: 0.2567\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7879 - binary_accuracy: 0.9092 - loss: 0.2636 - val_auc: 0.8027 - val_binary_accuracy: 0.9100 - val_loss: 0.2556\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7902 - binary_accuracy: 0.9101 - loss: 0.2626 - val_auc: 0.8026 - val_binary_accuracy: 0.9098 - val_loss: 0.2551\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7899 - binary_accuracy: 0.9101 - loss: 0.2623 - val_auc: 0.8028 - val_binary_accuracy: 0.9098 - val_loss: 0.2546\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8165 - binary_accuracy: 0.9080 - loss: 0.2513\n",
            "Fold 5 Metrics: Loss = 0.2546, Accuracy = 0.9098, AUC = 0.8028\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2593\n",
            "Average Accuracy: 0.9075\n",
            "Average AUC: 0.8004\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 5, 128)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6891 - binary_accuracy: 0.8898 - loss: 0.2983 - val_auc: 0.7726 - val_binary_accuracy: 0.9072 - val_loss: 0.2803\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9075 - loss: 0.2651 - val_auc: 0.7823 - val_binary_accuracy: 0.9087 - val_loss: 0.2650\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7863 - binary_accuracy: 0.9087 - loss: 0.2590 - val_auc: 0.7844 - val_binary_accuracy: 0.9091 - val_loss: 0.2642\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7912 - binary_accuracy: 0.9106 - loss: 0.2564 - val_auc: 0.7864 - val_binary_accuracy: 0.9096 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7966 - binary_accuracy: 0.9111 - loss: 0.2539 - val_auc: 0.7872 - val_binary_accuracy: 0.9090 - val_loss: 0.2619\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8001 - binary_accuracy: 0.9119 - loss: 0.2524 - val_auc: 0.7862 - val_binary_accuracy: 0.9094 - val_loss: 0.2626\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8013 - binary_accuracy: 0.9129 - loss: 0.2518 - val_auc: 0.7882 - val_binary_accuracy: 0.9045 - val_loss: 0.2642\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8043 - binary_accuracy: 0.9125 - loss: 0.2509 - val_auc: 0.7905 - val_binary_accuracy: 0.9073 - val_loss: 0.2626\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8038 - binary_accuracy: 0.9136 - loss: 0.2506 - val_auc: 0.7917 - val_binary_accuracy: 0.9044 - val_loss: 0.2647\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.8059 - binary_accuracy: 0.9107 - loss: 0.2519 - val_auc: 0.7902 - val_binary_accuracy: 0.9075 - val_loss: 0.2624\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7858 - binary_accuracy: 0.9106 - loss: 0.2559\n",
            "Fold 1 Metrics: Loss = 0.2624, Accuracy = 0.9075, AUC = 0.7902\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7181 - binary_accuracy: 0.9023 - loss: 0.2955 - val_auc: 0.7961 - val_binary_accuracy: 0.9053 - val_loss: 0.2736\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7762 - binary_accuracy: 0.9028 - loss: 0.2721 - val_auc: 0.8051 - val_binary_accuracy: 0.9068 - val_loss: 0.2648\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7826 - binary_accuracy: 0.9057 - loss: 0.2683 - val_auc: 0.8043 - val_binary_accuracy: 0.9084 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7867 - binary_accuracy: 0.9067 - loss: 0.2666 - val_auc: 0.8036 - val_binary_accuracy: 0.9079 - val_loss: 0.2644\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7892 - binary_accuracy: 0.9073 - loss: 0.2655 - val_auc: 0.8086 - val_binary_accuracy: 0.9081 - val_loss: 0.2640\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7920 - binary_accuracy: 0.9073 - loss: 0.2638 - val_auc: 0.8096 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7949 - binary_accuracy: 0.9073 - loss: 0.2626 - val_auc: 0.8102 - val_binary_accuracy: 0.9088 - val_loss: 0.2659\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9079 - loss: 0.2626 - val_auc: 0.8104 - val_binary_accuracy: 0.9088 - val_loss: 0.2678\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7936 - binary_accuracy: 0.9085 - loss: 0.2625 - val_auc: 0.8103 - val_binary_accuracy: 0.9081 - val_loss: 0.2677\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7962 - binary_accuracy: 0.9080 - loss: 0.2617 - val_auc: 0.8116 - val_binary_accuracy: 0.9082 - val_loss: 0.2636\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8177 - binary_accuracy: 0.9127 - loss: 0.2547\n",
            "Fold 2 Metrics: Loss = 0.2636, Accuracy = 0.9082, AUC = 0.8116\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.7121 - binary_accuracy: 0.8868 - loss: 0.2975 - val_auc: 0.7902 - val_binary_accuracy: 0.9047 - val_loss: 0.2664\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7666 - binary_accuracy: 0.9064 - loss: 0.2697 - val_auc: 0.7958 - val_binary_accuracy: 0.9066 - val_loss: 0.2655\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7705 - binary_accuracy: 0.9070 - loss: 0.2679 - val_auc: 0.7986 - val_binary_accuracy: 0.9063 - val_loss: 0.2666\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9073 - loss: 0.2676 - val_auc: 0.7986 - val_binary_accuracy: 0.9081 - val_loss: 0.2621\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7681 - binary_accuracy: 0.9070 - loss: 0.2690 - val_auc: 0.8012 - val_binary_accuracy: 0.9103 - val_loss: 0.2637\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7728 - binary_accuracy: 0.9081 - loss: 0.2668 - val_auc: 0.8016 - val_binary_accuracy: 0.9093 - val_loss: 0.2650\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7737 - binary_accuracy: 0.9078 - loss: 0.2664 - val_auc: 0.8017 - val_binary_accuracy: 0.9096 - val_loss: 0.2656\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7755 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.8025 - val_binary_accuracy: 0.9071 - val_loss: 0.2665\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9085 - loss: 0.2641 - val_auc: 0.8029 - val_binary_accuracy: 0.9057 - val_loss: 0.2660\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9086 - loss: 0.2643 - val_auc: 0.8027 - val_binary_accuracy: 0.9079 - val_loss: 0.2643\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7951 - binary_accuracy: 0.9082 - loss: 0.2656\n",
            "Fold 3 Metrics: Loss = 0.2643, Accuracy = 0.9079, AUC = 0.8027\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7232 - binary_accuracy: 0.8964 - loss: 0.2925 - val_auc: 0.7937 - val_binary_accuracy: 0.9064 - val_loss: 0.2670\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7722 - binary_accuracy: 0.9063 - loss: 0.2690 - val_auc: 0.7957 - val_binary_accuracy: 0.9056 - val_loss: 0.2658\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7790 - binary_accuracy: 0.9078 - loss: 0.2654 - val_auc: 0.7972 - val_binary_accuracy: 0.9050 - val_loss: 0.2676\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7814 - binary_accuracy: 0.9081 - loss: 0.2639 - val_auc: 0.7979 - val_binary_accuracy: 0.9075 - val_loss: 0.2663\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7839 - binary_accuracy: 0.9088 - loss: 0.2627 - val_auc: 0.7977 - val_binary_accuracy: 0.9085 - val_loss: 0.2648\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7842 - binary_accuracy: 0.9093 - loss: 0.2621 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2655\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7848 - binary_accuracy: 0.9095 - loss: 0.2618 - val_auc: 0.7987 - val_binary_accuracy: 0.9082 - val_loss: 0.2629\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7836 - binary_accuracy: 0.9099 - loss: 0.2612 - val_auc: 0.8001 - val_binary_accuracy: 0.9100 - val_loss: 0.2613\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7868 - binary_accuracy: 0.9095 - loss: 0.2607 - val_auc: 0.7986 - val_binary_accuracy: 0.9088 - val_loss: 0.2627\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7893 - binary_accuracy: 0.9094 - loss: 0.2601 - val_auc: 0.8002 - val_binary_accuracy: 0.9095 - val_loss: 0.2606\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7807 - binary_accuracy: 0.9091 - loss: 0.2699\n",
            "Fold 4 Metrics: Loss = 0.2606, Accuracy = 0.9095, AUC = 0.8002\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - auc: 0.7040 - binary_accuracy: 0.9036 - loss: 0.2973 - val_auc: 0.7878 - val_binary_accuracy: 0.9067 - val_loss: 0.2627\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7590 - binary_accuracy: 0.9041 - loss: 0.2760 - val_auc: 0.7976 - val_binary_accuracy: 0.9075 - val_loss: 0.2586\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7714 - binary_accuracy: 0.9063 - loss: 0.2704 - val_auc: 0.8002 - val_binary_accuracy: 0.9095 - val_loss: 0.2600\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7773 - binary_accuracy: 0.9072 - loss: 0.2676 - val_auc: 0.8030 - val_binary_accuracy: 0.9101 - val_loss: 0.2597\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7803 - binary_accuracy: 0.9077 - loss: 0.2663 - val_auc: 0.8040 - val_binary_accuracy: 0.9088 - val_loss: 0.2598\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7820 - binary_accuracy: 0.9077 - loss: 0.2652 - val_auc: 0.8047 - val_binary_accuracy: 0.9103 - val_loss: 0.2597\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7843 - binary_accuracy: 0.9083 - loss: 0.2642 - val_auc: 0.8050 - val_binary_accuracy: 0.9104 - val_loss: 0.2570\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7865 - binary_accuracy: 0.9092 - loss: 0.2633 - val_auc: 0.8059 - val_binary_accuracy: 0.9107 - val_loss: 0.2574\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9081 - loss: 0.2634 - val_auc: 0.8061 - val_binary_accuracy: 0.9107 - val_loss: 0.2583\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7856 - binary_accuracy: 0.9080 - loss: 0.2637 - val_auc: 0.8035 - val_binary_accuracy: 0.9094 - val_loss: 0.2575\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8148 - binary_accuracy: 0.9094 - loss: 0.2534\n",
            "Fold 5 Metrics: Loss = 0.2575, Accuracy = 0.9094, AUC = 0.8035\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2617\n",
            "Average Accuracy: 0.9085\n",
            "Average AUC: 0.8017\n",
            "----------------------------------------\n",
            "Performing training for: ('tanh', 5, 256)\n",
            "----------------------------------------\n",
            "\n",
            "--- Starting Fold 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6891 - binary_accuracy: 0.8859 - loss: 0.3075 - val_auc: 0.7797 - val_binary_accuracy: 0.9102 - val_loss: 0.2736\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9080 - loss: 0.2624 - val_auc: 0.7868 - val_binary_accuracy: 0.9044 - val_loss: 0.2689\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7840 - binary_accuracy: 0.9064 - loss: 0.2611 - val_auc: 0.7890 - val_binary_accuracy: 0.9103 - val_loss: 0.2617\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7905 - binary_accuracy: 0.9092 - loss: 0.2579 - val_auc: 0.7894 - val_binary_accuracy: 0.9119 - val_loss: 0.2606\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7942 - binary_accuracy: 0.9115 - loss: 0.2552 - val_auc: 0.7902 - val_binary_accuracy: 0.9103 - val_loss: 0.2633\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7959 - binary_accuracy: 0.9114 - loss: 0.2541 - val_auc: 0.7910 - val_binary_accuracy: 0.9094 - val_loss: 0.2605\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7928 - binary_accuracy: 0.9092 - loss: 0.2569 - val_auc: 0.7927 - val_binary_accuracy: 0.9118 - val_loss: 0.2637\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7916 - binary_accuracy: 0.9124 - loss: 0.2555 - val_auc: 0.7904 - val_binary_accuracy: 0.9066 - val_loss: 0.2643\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7965 - binary_accuracy: 0.9109 - loss: 0.2542 - val_auc: 0.7875 - val_binary_accuracy: 0.9088 - val_loss: 0.2627\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7950 - binary_accuracy: 0.9115 - loss: 0.2561 - val_auc: 0.7898 - val_binary_accuracy: 0.9082 - val_loss: 0.2631\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7844 - binary_accuracy: 0.9113 - loss: 0.2558\n",
            "Fold 1 Metrics: Loss = 0.2631, Accuracy = 0.9082, AUC = 0.7898\n",
            "\n",
            "--- Starting Fold 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6904 - binary_accuracy: 0.8845 - loss: 0.3209 - val_auc: 0.8003 - val_binary_accuracy: 0.9060 - val_loss: 0.2667\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7751 - binary_accuracy: 0.9040 - loss: 0.2722 - val_auc: 0.8018 - val_binary_accuracy: 0.9081 - val_loss: 0.2638\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7809 - binary_accuracy: 0.9057 - loss: 0.2689 - val_auc: 0.8025 - val_binary_accuracy: 0.9081 - val_loss: 0.2638\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7829 - binary_accuracy: 0.9071 - loss: 0.2676 - val_auc: 0.8006 - val_binary_accuracy: 0.9078 - val_loss: 0.2662\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7818 - binary_accuracy: 0.9071 - loss: 0.2675 - val_auc: 0.8026 - val_binary_accuracy: 0.9094 - val_loss: 0.2649\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9057 - loss: 0.2692 - val_auc: 0.8060 - val_binary_accuracy: 0.9066 - val_loss: 0.2660\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7845 - binary_accuracy: 0.9050 - loss: 0.2675 - val_auc: 0.7934 - val_binary_accuracy: 0.9088 - val_loss: 0.2690\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7866 - binary_accuracy: 0.9057 - loss: 0.2667 - val_auc: 0.8040 - val_binary_accuracy: 0.9096 - val_loss: 0.2650\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7857 - binary_accuracy: 0.9070 - loss: 0.2656 - val_auc: 0.7989 - val_binary_accuracy: 0.9091 - val_loss: 0.2674\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7889 - binary_accuracy: 0.9078 - loss: 0.2650 - val_auc: 0.8125 - val_binary_accuracy: 0.9094 - val_loss: 0.2620\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.8172 - binary_accuracy: 0.9135 - loss: 0.2530\n",
            "Fold 2 Metrics: Loss = 0.2620, Accuracy = 0.9094, AUC = 0.8125\n",
            "\n",
            "--- Starting Fold 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6702 - binary_accuracy: 0.8862 - loss: 0.3217 - val_auc: 0.7878 - val_binary_accuracy: 0.9042 - val_loss: 0.2668\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7607 - binary_accuracy: 0.9043 - loss: 0.2728 - val_auc: 0.7924 - val_binary_accuracy: 0.9042 - val_loss: 0.2661\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7658 - binary_accuracy: 0.9055 - loss: 0.2699 - val_auc: 0.7955 - val_binary_accuracy: 0.9078 - val_loss: 0.2668\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7644 - binary_accuracy: 0.9063 - loss: 0.2700 - val_auc: 0.7952 - val_binary_accuracy: 0.9042 - val_loss: 0.2639\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7621 - binary_accuracy: 0.9053 - loss: 0.2719 - val_auc: 0.7937 - val_binary_accuracy: 0.9042 - val_loss: 0.2637\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7605 - binary_accuracy: 0.9053 - loss: 0.2716 - val_auc: 0.7965 - val_binary_accuracy: 0.9093 - val_loss: 0.2663\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7671 - binary_accuracy: 0.9075 - loss: 0.2690 - val_auc: 0.7963 - val_binary_accuracy: 0.9042 - val_loss: 0.2675\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7640 - binary_accuracy: 0.9072 - loss: 0.2703 - val_auc: 0.7961 - val_binary_accuracy: 0.9090 - val_loss: 0.2607\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7630 - binary_accuracy: 0.9089 - loss: 0.2683 - val_auc: 0.7968 - val_binary_accuracy: 0.9066 - val_loss: 0.2639\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7657 - binary_accuracy: 0.9077 - loss: 0.2685 - val_auc: 0.7962 - val_binary_accuracy: 0.9104 - val_loss: 0.2635\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7872 - binary_accuracy: 0.9115 - loss: 0.2634\n",
            "Fold 3 Metrics: Loss = 0.2635, Accuracy = 0.9104, AUC = 0.7962\n",
            "\n",
            "--- Starting Fold 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6836 - binary_accuracy: 0.9007 - loss: 0.3080 - val_auc: 0.7859 - val_binary_accuracy: 0.9056 - val_loss: 0.2716\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7603 - binary_accuracy: 0.9044 - loss: 0.2734 - val_auc: 0.7899 - val_binary_accuracy: 0.9032 - val_loss: 0.2683\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7665 - binary_accuracy: 0.9053 - loss: 0.2704 - val_auc: 0.7958 - val_binary_accuracy: 0.9087 - val_loss: 0.2708\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7697 - binary_accuracy: 0.9059 - loss: 0.2687 - val_auc: 0.7993 - val_binary_accuracy: 0.8992 - val_loss: 0.2815\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7662 - binary_accuracy: 0.9067 - loss: 0.2706 - val_auc: 0.7954 - val_binary_accuracy: 0.9085 - val_loss: 0.2641\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7781 - binary_accuracy: 0.9078 - loss: 0.2652 - val_auc: 0.7958 - val_binary_accuracy: 0.9072 - val_loss: 0.2635\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7741 - binary_accuracy: 0.9092 - loss: 0.2649 - val_auc: 0.7956 - val_binary_accuracy: 0.9085 - val_loss: 0.2606\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7787 - binary_accuracy: 0.9088 - loss: 0.2632 - val_auc: 0.7937 - val_binary_accuracy: 0.9051 - val_loss: 0.2675\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7780 - binary_accuracy: 0.9092 - loss: 0.2638 - val_auc: 0.7939 - val_binary_accuracy: 0.9042 - val_loss: 0.2667\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7701 - binary_accuracy: 0.9088 - loss: 0.2671 - val_auc: 0.7916 - val_binary_accuracy: 0.9084 - val_loss: 0.2619\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7694 - binary_accuracy: 0.9085 - loss: 0.2711\n",
            "Fold 4 Metrics: Loss = 0.2619, Accuracy = 0.9084, AUC = 0.7916\n",
            "\n",
            "--- Starting Fold 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - auc: 0.6762 - binary_accuracy: 0.8851 - loss: 0.3195 - val_auc: 0.7930 - val_binary_accuracy: 0.9084 - val_loss: 0.2611\n",
            "Epoch 2/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7539 - binary_accuracy: 0.9025 - loss: 0.2790 - val_auc: 0.7988 - val_binary_accuracy: 0.9075 - val_loss: 0.2572\n",
            "Epoch 3/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7687 - binary_accuracy: 0.9053 - loss: 0.2720 - val_auc: 0.8037 - val_binary_accuracy: 0.9087 - val_loss: 0.2554\n",
            "Epoch 4/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7730 - binary_accuracy: 0.9058 - loss: 0.2698 - val_auc: 0.8034 - val_binary_accuracy: 0.9097 - val_loss: 0.2588\n",
            "Epoch 5/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7753 - binary_accuracy: 0.9063 - loss: 0.2684 - val_auc: 0.8045 - val_binary_accuracy: 0.9104 - val_loss: 0.2573\n",
            "Epoch 6/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7788 - binary_accuracy: 0.9067 - loss: 0.2668 - val_auc: 0.8047 - val_binary_accuracy: 0.9098 - val_loss: 0.2571\n",
            "Epoch 7/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7806 - binary_accuracy: 0.9097 - loss: 0.2655 - val_auc: 0.8072 - val_binary_accuracy: 0.9044 - val_loss: 0.2556\n",
            "Epoch 8/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7805 - binary_accuracy: 0.9072 - loss: 0.2654 - val_auc: 0.8057 - val_binary_accuracy: 0.9101 - val_loss: 0.2554\n",
            "Epoch 9/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7708 - binary_accuracy: 0.9071 - loss: 0.2701 - val_auc: 0.8062 - val_binary_accuracy: 0.9104 - val_loss: 0.2559\n",
            "Epoch 10/10\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7798 - binary_accuracy: 0.9090 - loss: 0.2655 - val_auc: 0.8044 - val_binary_accuracy: 0.9098 - val_loss: 0.2548\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.8136 - binary_accuracy: 0.9076 - loss: 0.2527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 3/3 [1:22:51<00:00, 1657.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 Metrics: Loss = 0.2548, Accuracy = 0.9098, AUC = 0.8044\n",
            "\n",
            "--- K-Fold Cross-Validation Complete ---\n",
            "Average Loss: 0.2610\n",
            "Average Accuracy: 0.9093\n",
            "Average AUC: 0.7989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# setting a seed\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# defining options\n",
        "hidden_layer_configs = [1,2,3,4,5]\n",
        "activation_config = ['relu', 'sigmoid', 'tanh']\n",
        "node_configs = [16, 32, 64, 128, 256]\n",
        "\n",
        "comparison_list = []\n",
        "comparison_df_new = pd.DataFrame()\n",
        "\n",
        "# training models\n",
        "with tf.device('/GPU:0'):\n",
        "    for activation in tqdm.tqdm(activation_config):\n",
        "        for hl in hidden_layer_configs:\n",
        "            for nodes in node_configs:\n",
        "                print(\"-\"*40)\n",
        "                print(f\"Performing training for: {activation, hl, nodes}\")\n",
        "                print(\"-\"*40)\n",
        "                # train model\n",
        "                fold_loss, fold_accuracies, fold_aucs, _ = k_fold_cross_validation(hl=hl, nodes=nodes, activation=activation, epochs = 10)\n",
        "                # store output\n",
        "                comparison_list.append((activation, hl, nodes, fold_loss, fold_accuracies, fold_aucs))\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_list)\n",
        "comparison_df.to_csv(\"/content/drive/MyDrive/Data Analytics/Assignments/Group Project/model_comparison_five_fold_strat.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "anByv4R4hb0V",
      "metadata": {
        "id": "anByv4R4hb0V"
      },
      "outputs": [],
      "source": [
        "comparison_df = pd.read_csv(PROCESSED_DIR / \"model_comparison_five_fold_strat_mac.csv\")\n",
        "comparison_df.columns = [\"act\", \"hl\", \"nodes\", \"loss\", \"acc\", \"auc\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "VmycvIWdhuWE",
      "metadata": {
        "id": "VmycvIWdhuWE"
      },
      "outputs": [],
      "source": [
        "comparison_df[\"avg_loss\"] = comparison_df[\"loss\"].apply(lambda x: np.mean(ast.literal_eval(x)))\n",
        "comparison_df[\"avg_acc\"] = comparison_df[\"acc\"].apply(lambda x: np.mean(ast.literal_eval(x)))\n",
        "comparison_df[\"avg_auc\"] = comparison_df[\"auc\"].apply(lambda x: np.mean(ast.literal_eval(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "jVC4AixTiKlo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "jVC4AixTiKlo",
        "outputId": "7e9539e1-d29e-408d-ec9e-2aca2190ec4a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act</th>\n",
              "      <th>hl</th>\n",
              "      <th>nodes</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>auc</th>\n",
              "      <th>avg_loss</th>\n",
              "      <th>avg_acc</th>\n",
              "      <th>avg_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>relu</td>\n",
              "      <td>1</td>\n",
              "      <td>128</td>\n",
              "      <td>[0.25773873925209045, 0.255301296710968, 0.275...</td>\n",
              "      <td>[0.9100029468536377, 0.9095603227615356, 0.896...</td>\n",
              "      <td>[0.7998226881027222, 0.8120778203010559, 0.808...</td>\n",
              "      <td>0.263293</td>\n",
              "      <td>0.904981</td>\n",
              "      <td>0.808436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relu</td>\n",
              "      <td>1</td>\n",
              "      <td>256</td>\n",
              "      <td>[0.278920441865921, 0.26857805252075195, 0.274...</td>\n",
              "      <td>[0.9089701771736145, 0.9046916365623474, 0.899...</td>\n",
              "      <td>[0.7992884516716003, 0.8113686442375183, 0.805...</td>\n",
              "      <td>0.277949</td>\n",
              "      <td>0.903624</td>\n",
              "      <td>0.807325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>sigmoid</td>\n",
              "      <td>1</td>\n",
              "      <td>256</td>\n",
              "      <td>[0.25873565673828125, 0.254452109336853, 0.255...</td>\n",
              "      <td>[0.9089701771736145, 0.9086751341819763, 0.910...</td>\n",
              "      <td>[0.7959154844284058, 0.8137859106063843, 0.806...</td>\n",
              "      <td>0.254814</td>\n",
              "      <td>0.909703</td>\n",
              "      <td>0.807126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>sigmoid</td>\n",
              "      <td>2</td>\n",
              "      <td>256</td>\n",
              "      <td>[0.2586652338504791, 0.25329306721687317, 0.25...</td>\n",
              "      <td>[0.9082325100898743, 0.9100029468536377, 0.911...</td>\n",
              "      <td>[0.7965725660324097, 0.8122545480728149, 0.806...</td>\n",
              "      <td>0.254432</td>\n",
              "      <td>0.910145</td>\n",
              "      <td>0.807085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>relu</td>\n",
              "      <td>5</td>\n",
              "      <td>256</td>\n",
              "      <td>[0.26417630910873413, 0.2618508040904999, 0.25...</td>\n",
              "      <td>[0.907494843006134, 0.9094128012657166, 0.9092...</td>\n",
              "      <td>[0.7966581583023071, 0.8115841150283813, 0.805...</td>\n",
              "      <td>0.260090</td>\n",
              "      <td>0.909526</td>\n",
              "      <td>0.807062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        act  hl  nodes                                               loss  \\\n",
              "3      relu   1    128  [0.25773873925209045, 0.255301296710968, 0.275...   \n",
              "4      relu   1    256  [0.278920441865921, 0.26857805252075195, 0.274...   \n",
              "29  sigmoid   1    256  [0.25873565673828125, 0.254452109336853, 0.255...   \n",
              "34  sigmoid   2    256  [0.2586652338504791, 0.25329306721687317, 0.25...   \n",
              "24     relu   5    256  [0.26417630910873413, 0.2618508040904999, 0.25...   \n",
              "\n",
              "                                                  acc  \\\n",
              "3   [0.9100029468536377, 0.9095603227615356, 0.896...   \n",
              "4   [0.9089701771736145, 0.9046916365623474, 0.899...   \n",
              "29  [0.9089701771736145, 0.9086751341819763, 0.910...   \n",
              "34  [0.9082325100898743, 0.9100029468536377, 0.911...   \n",
              "24  [0.907494843006134, 0.9094128012657166, 0.9092...   \n",
              "\n",
              "                                                  auc  avg_loss   avg_acc  \\\n",
              "3   [0.7998226881027222, 0.8120778203010559, 0.808...  0.263293  0.904981   \n",
              "4   [0.7992884516716003, 0.8113686442375183, 0.805...  0.277949  0.903624   \n",
              "29  [0.7959154844284058, 0.8137859106063843, 0.806...  0.254814  0.909703   \n",
              "34  [0.7965725660324097, 0.8122545480728149, 0.806...  0.254432  0.910145   \n",
              "24  [0.7966581583023071, 0.8115841150283813, 0.805...  0.260090  0.909526   \n",
              "\n",
              "     avg_auc  \n",
              "3   0.808436  \n",
              "4   0.807325  \n",
              "29  0.807126  \n",
              "34  0.807085  \n",
              "24  0.807062  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df.sort_values(by = [\"avg_auc\", \"avg_acc\"], ascending = [False, False]).head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8djlZJci05oD",
      "metadata": {
        "id": "8djlZJci05oD"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "099hWGV8z_NF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "099hWGV8z_NF",
        "outputId": "89052de1-b832-445f-a1c2-e0f3e3ec970c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ],
      "source": [
        "# setting a seed\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# confusion matrix\n",
        "best_model, _, _ = train_and_evaluate_model(hl = 1, nodes = 128, activation = \"relu\", epochs = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C8eXy1kl1JHA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8eXy1kl1JHA",
        "outputId": "cb0f356a-f9ed-471c-e88e-a162fb616b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m354/354\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        }
      ],
      "source": [
        "pred_probs = best_model.predict(test_x)\n",
        "y_pred = (pred_probs > 0.5).astype(int)   # convert probabilities to 0/1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KJlC_Hkyc6z7",
      "metadata": {
        "id": "KJlC_Hkyc6z7"
      },
      "source": [
        "### **Confusion matrix**\n",
        "\n",
        "*I am not sure, if that is the right way to evaluate it*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YsY-yaAP1ZY4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsY-yaAP1ZY4",
        "outputId": "f4ba9312-ce18-4d9b-dbb2-2ab90d6717df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[10170    46]\n",
            " [  978   103]]\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(test_y, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qDmVlbUk55H8",
      "metadata": {
        "id": "qDmVlbUk55H8"
      },
      "source": [
        "# Evaluating Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PU1dLc8tOpDv",
      "metadata": {
        "id": "PU1dLc8tOpDv"
      },
      "outputs": [],
      "source": [
        "evaluation = pd.DataFrame(pred_probs, test_y).reset_index()\n",
        "evaluation.columns = [\"outcome\", \"pred_prob\"]\n",
        "\n",
        "model_probs = np.linspace(0.025, 0.975, num = 20)\n",
        "true_probs = []\n",
        "\n",
        "for prob in model_probs:\n",
        "    true_probs.append(evaluation[(evaluation[\"pred_prob\"] >= prob -0.025) & (evaluation[\"pred_prob\"] <= prob + 0.025)][\"outcome\"].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AbkHeuuDVlB9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "AbkHeuuDVlB9",
        "outputId": "4d3c66e3-9a38-40c6-b035-37d6bd0bef1e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_probs = np.linspace(0,1.01, num = 10)\n",
        "\n",
        "plt.plot(model_probs, true_probs, color = \"red\", marker='.', label = \"Model line\")\n",
        "plt.plot(plot_probs, plot_probs, alpha = 0.5, color = \"blue\", label = \"Ideal line\")\n",
        "plt.xlim(0,1)\n",
        "plt.ylim(0,1)\n",
        "#plt.axvspan(0.9, 1, alpha=0.1, label = \"No shots with prob > 0.9\", color = \"red\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Model Probability\")\n",
        "plt.ylabel(\"True Probability\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OAKQKJOWcV4E",
      "metadata": {
        "id": "OAKQKJOWcV4E"
      },
      "source": [
        "## Isometric regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "if5vt00o6GhD",
      "metadata": {
        "id": "if5vt00o6GhD"
      },
      "outputs": [],
      "source": [
        "football_df = pd.read_csv(PROCESSED_DIR / \"football_processed.csv\")\n",
        "\n",
        "f_X = football_df.drop(\"shot_outcome_encoded\", axis = 1)\n",
        "f_y = football_df[\"shot_outcome_encoded\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "iGAzQ_k86GhD",
      "metadata": {
        "id": "iGAzQ_k86GhD"
      },
      "outputs": [],
      "source": [
        "# setting a seed\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# splitting the data\n",
        "f_train_x, f_test_x , f_train_y, f_test_y = train_test_split(\n",
        "    f_X, f_y,\n",
        "    test_size = 0.25,\n",
        "    random_state= 123,\n",
        "    stratify = y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "WeezwtfN5_n-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeezwtfN5_n-",
        "outputId": "b4a65c86-61a3-4deb-a4ed-afa7277240dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking that both are the same\n",
        "sum(f_test_y == test_y.numpy()) == len(test_y.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2lURL85k6aQj",
      "metadata": {
        "id": "2lURL85k6aQj"
      },
      "outputs": [],
      "source": [
        "# comparing statsbomb and our expected goal probabilities\n",
        "test = pd.concat([f_test_x[\"shot_statsbomb_xg\"].reset_index(), pd.DataFrame(pred_probs).reset_index()], axis = 1, ignore_index=True).drop([0,2], axis = 1)\n",
        "test.columns = [\"shot_statsbomb_xg\", \"pred_prob\"]\n",
        "test[\"diff\"] = test[\"shot_statsbomb_xg\"] - test[\"pred_prob\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "db75bfe1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'index', 'match_id', 'period', 'timestamp', 'second', 'minute',\n",
              "       'team', 'team_id', 'player', 'player_id', 'position', 'play_pattern',\n",
              "       'type', 'under_pressure', 'shot_deflected', 'shot_open_goal',\n",
              "       'shot_type', 'shot_statsbomb_xg', 'shot_freeze_frame', 'location',\n",
              "       'shot_outcome', 'shot_body_part', 'shot_first_time', 'shot_technique',\n",
              "       'shot_one_on_one', 'player_x', 'player_y', 'distance_from_goal_center',\n",
              "       'distance_from_goal_left_post', 'distance_from_goal_right_post',\n",
              "       'body_part_head', 'body_part_other', 'body_part_foot',\n",
              "       'shot_technique_backheel', 'shot_technique_diving_header',\n",
              "       'shot_technique_half_volley', 'shot_technique_lob',\n",
              "       'shot_technique_normal', 'shot_technique_overhead_kick',\n",
              "       'shot_technique_volley', 'play_pattern_from_corner',\n",
              "       'play_pattern_from_counter', 'play_pattern_from_free_kick',\n",
              "       'play_pattern_from_goal_kick', 'play_pattern_from_keeper',\n",
              "       'play_pattern_from_kick_off', 'play_pattern_from_throw_in',\n",
              "       'play_pattern_other', 'play_pattern_regular_play',\n",
              "       'shot_type_free_kick', 'shot_type_open_play', 'goalkeeper_location',\n",
              "       'goalkeeper_x', 'goalkeeper_y', 'gk_distance_from_goal_center',\n",
              "       'gk_distance_from_goal_left_post', 'gk_distance_from_goal_right_post',\n",
              "       'shot_angle', 'distance_player_gk'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f_test_x.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ccc6a7f4",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/_d/ljvnpndd76v52vr16dysc7lr0000gn/T/ipykernel_23545/1636921489.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[\"shot_outcome\"] = test[\"shot_outcome\"] == \"Goal\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>shot_statsbomb_xg</th>\n",
              "      <th>shot_outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6387</th>\n",
              "      <td>0.068243</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23862</th>\n",
              "      <td>0.030649</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11122</th>\n",
              "      <td>0.023535</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8146</th>\n",
              "      <td>0.078287</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43626</th>\n",
              "      <td>0.558380</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34586</th>\n",
              "      <td>0.010840</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9309</th>\n",
              "      <td>0.094702</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16901</th>\n",
              "      <td>0.019081</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29558</th>\n",
              "      <td>0.047929</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5793</th>\n",
              "      <td>0.025670</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11297 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       shot_statsbomb_xg  shot_outcome\n",
              "6387            0.068243          True\n",
              "23862           0.030649         False\n",
              "11122           0.023535         False\n",
              "8146            0.078287         False\n",
              "43626           0.558380          True\n",
              "...                  ...           ...\n",
              "34586           0.010840         False\n",
              "9309            0.094702         False\n",
              "16901           0.019081         False\n",
              "29558           0.047929         False\n",
              "5793            0.025670         False\n",
              "\n",
              "[11297 rows x 2 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = f_test_x[[\"shot_statsbomb_xg\", \"shot_outcome\"]]\n",
        "test[\"shot_outcome\"] = test[\"shot_outcome\"] == \"Goal\"\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ie9x1trc7NDN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "Ie9x1trc7NDN",
        "outputId": "6146cfcd-35a3-4fe1-8f1a-8da2c58a0b23"
      },
      "outputs": [],
      "source": [
        "f_i_r = sk_i.IsotonicRegression().fit(test[\"shot_statsbomb_xg\"], evaluation[\"outcome\"])\n",
        "i_r = sk_i.IsotonicRegression().fit(evaluation[\"pred_prob\"], evaluation[\"outcome\"])\n",
        "\n",
        "model_probs = np.linspace(0, 1, num=100)\n",
        "\n",
        "# calibrated_probs = i_r.predict(model_probs)\n",
        "f_calibrated_probs = f_i_r.predict(model_probs)\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot([0, 1], [0, 1])\n",
        "\n",
        "plt.plot(model_probs, f_calibrated_probs, color='black', alpha = 0.3, label = \"Statsb. perf.\")\n",
        "# plt.plot(model_probs, calibrated_probs, color='red', label = \"Model perf.\")\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel('Model probability')\n",
        "plt.ylabel('Calibrated probability')\n",
        "\n",
        "sns.despine()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fXcppND6-BxP",
      "metadata": {
        "id": "fXcppND6-BxP"
      },
      "source": [
        "## AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eqGunzpG7hI2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "eqGunzpG7hI2",
        "outputId": "4aeaffbb-ffbb-42e0-dbbc-bce1c3acc31c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC: 0.7993\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculate AUC\n",
        "auc = roc_auc_score(test_y, pred_probs)\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(test_y, pred_probs)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ct1Lf38D-HWy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "ct1Lf38D-HWy",
        "outputId": "1e6ef67a-5065-474f-fbf7-3f09d154c564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC: 0.8106\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculate AUC\n",
        "auc = roc_auc_score(test_y, test[\"shot_statsbomb_xg\"])\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(test_y, test[\"shot_statsbomb_xg\"])\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(fpr, tpr, color='black', label=f'SB ROC Curve (AUC = {auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
